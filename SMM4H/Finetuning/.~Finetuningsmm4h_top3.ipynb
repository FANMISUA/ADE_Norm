{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12800,
     "status": "ok",
     "timestamp": 1722754418563,
     "user": {
      "displayName": "F D",
      "userId": "09431385063825136827"
     },
     "user_tz": 300
    },
    "id": "u4Ymm56BAtwR",
    "outputId": "0f42ffa7-f478-4264-9807-5b1bf5b38aaf"
   },
   "outputs": [],
   "source": [
    "#install packages\n",
    "!pip install transformers\n",
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#Read smm4h data from git:\n",
    "#https://raw.githubusercontent.com/FANMISUA/ADE_Norm/main/Data/smm4h_soc.tsv\n",
    "# URL of the CSV file\n",
    "# csv_url = \"https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\"\n",
    "csv_url = \"https://raw.githubusercontent.com/FANMISUA/ADE_Norm/main/Data/smm4h_soc.tsv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"ade\", \"soc_code\"]\n",
    "smm4h_all = pd.read_csv(csv_url,names=column_names, sep = '\\t', header=None)\n",
    "\n",
    "smm4h_all = smm4h_all[smm4h_all['soc_code'] != 0]\n",
    "smm4h_all['soc_code'] = pd.to_numeric(smm4h_all['soc_code'], errors='coerce').astype('Int64')\n",
    "\n",
    "print(smm4h_all.head)\n",
    "# Display the first few rows of the DataFrame\n",
    "print(smm4h_all.shape)\n",
    "\n",
    "\n",
    "# Remove duplicate rows based on the 'ade' column\n",
    "# smm4h_unique = smm4h_all\n",
    "smm4h_unique = smm4h_all.drop_duplicates(subset='ade')\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(smm4h_unique.shape)\n",
    "# Count occurrences of each 'soc_code'\n",
    "soc_code_counts = smm4h_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "print(\"SOC count in CADEC: \",soc_code_counts)\n",
    "\n",
    "#get top 3 of the SMM4H list\n",
    "#['10037175','10018065','10029205','10017947''10028395','10022891']\n",
    "# top6SMM4H = [10018065,10037175,10029205,10022891,10028395,10017947]\n",
    "top3SMM4H = [10037175, 10018065,10029205]\n",
    "# top3SMM4H = ['10018065', '10037175', '10029205']\n",
    "\n",
    "top3label_dict = {\n",
    "    'Label': [0, 1, 2],\n",
    "    'soc_code': [10037175,10018065,10029205]\n",
    "}\n",
    "top3label_dict = {\n",
    "    10037175: 0,\n",
    "    10018065: 1,\n",
    "    10029205: 2\n",
    "}\n",
    "\n",
    "\n",
    "# Filter DataFrame\n",
    "filtered_data3 = smm4h_unique[smm4h_unique['soc_code'].isin(top3SMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "top3inSMM4H = filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "print(\"CADEC top3 in SMM4H:\",top3inSMM4H)\n",
    "data = top3inSMM4H\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(top3inSMM4H)\n",
    "\n",
    "#mapping dictionary for soc to label\n",
    "# soc_code_to_label = dict(zip(top3label_dict['soc_code'], top3label_dict['Label']))\n",
    "df['label'] = df['soc_code'].map(top3label_dict)\n",
    "\n",
    "# Replace `soc_code` values with corresponding labels\n",
    "# df['label'] = df['soc_code'].replace(soc_code_to_label)\n",
    "# print(top3label_dict)\n",
    "print(df)\n",
    "\n",
    "\n",
    "def custom_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    min_class_count = min(counts)\n",
    "\n",
    "    # Find classes with only one or two instances\n",
    "    single_or_double_instance_classes = classes[np.logical_or(counts == 1, counts == 2)]\n",
    "\n",
    "    # Remove instances of single-instance or two-instance classes\n",
    "    X_filtered = X[~np.isin(y, single_or_double_instance_classes)]\n",
    "    y_filtered = y[~np.isin(y, single_or_double_instance_classes)]\n",
    "\n",
    "    if len(y_filtered) < 2:\n",
    "        raise ValueError(\"No classes have more than two instances after filtering.\")\n",
    "\n",
    "    # Perform stratified split on the filtered dataset\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_filtered, y_filtered, test_size=test_size, random_state=random_state, stratify=y_filtered)\n",
    "\n",
    "    # Randomly assign instances of single-instance classes to training or testing sets\n",
    "    for class_label in single_or_double_instance_classes:\n",
    "        class_indices = np.where(y == class_label)[0]\n",
    "        np.random.shuffle(class_indices)\n",
    "\n",
    "        if len(class_indices) <= 2:\n",
    "            # Only one instance, randomly assign to training or testing set\n",
    "            if np.random.rand() < test_size:\n",
    "                X_val = np.concatenate((X_val, X[class_indices]))\n",
    "                y_val = np.concatenate((y_val, y[class_indices]))\n",
    "            else:\n",
    "                X_train = np.concatenate((X_train, X[class_indices]))\n",
    "                y_train = np.concatenate((y_train, y[class_indices]))\n",
    "\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "\n",
    "#evaluation\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "\n",
    "def accuracy_per_class(predictions, true_vals):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "\n",
    "    accuracy_dict = {}\n",
    "    count_dict = {}\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = pred_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        accuracy_dict[label] = np.sum(y_preds == y_true) / len(y_true) if len(y_true) > 0 else 0\n",
    "        count_dict[label] = len(y_true)\n",
    "\n",
    "    return accuracy_dict, count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vRUOcg2DXcZ",
    "outputId": "58270a1e-29e5-4d9a-dd5a-86a94807c9e3"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score as f1_score_func\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='smm4h_top3_finetuning.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class TQDMLoggingWrapper(tqdm):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.logger = logger\n",
    "\n",
    "    def display(self, msg=None, pos=None):\n",
    "        if msg is not None:\n",
    "            self.logger.info(msg)\n",
    "        super().display(msg, pos)\n",
    "\n",
    "    def update(self, n=1):\n",
    "        super().update(n)\n",
    "        desc = self.format_dict.get('desc', 'No description')\n",
    "        postfix = self.format_dict.get('postfix', '')\n",
    "        self.logger.info(f'{desc} - {postfix}')\n",
    "\n",
    "    def set_description(self, desc=None, refresh=True):\n",
    "        super().set_description(desc, refresh)\n",
    "        if desc:\n",
    "            self.logger.info(f'Set description: {desc}')\n",
    "\n",
    "\n",
    "# Define the random seeds and other parameters\n",
    "seed_values = list(range(2, 4, 2))\n",
    "# batch_size = 8\n",
    "# epochs = 10\n",
    "# Define parameter grid\n",
    "learning_rates = [1e-6, 1e-5, 1e-4, 1e-3]\n",
    "batch_sizes = [8, 16, 32, 64]\n",
    "epochs_list = [10, 20, 30, 40]\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "# Placeholder for accuracies\n",
    "all_accuracies = {label: [] for label in range(len(top3label_dict))}\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "# Main loop over seed values\n",
    "for seed_val in seed_values:\n",
    "  # Set seeds\n",
    "  random.seed(seed_val)\n",
    "  np.random.seed(seed_val)\n",
    "  torch.manual_seed(seed_val)\n",
    "  torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "  # Data preparation\n",
    "  X_train, X_val, y_train, y_val = custom_train_test_split(df.index.values, df.label.values, test_size=0.2, random_state=seed_val)\n",
    "  df['data_type'] = ['not_set'] * df.shape[0]\n",
    "  df.loc[X_train, 'data_type'] = 'train'\n",
    "  df.loc[X_val, 'data_type'] = 'val'\n",
    "  # logger.info(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "\n",
    "  # Training loop for grid search\n",
    "  for lr in learning_rates:\n",
    "      for batch_size in batch_sizes:\n",
    "          for epochs in epochs_list:\n",
    "            logger.info(f\"Seed: {seed_val}, Learning Rate: {lr}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "            encoded_data_train = tokenizer.batch_encode_plus(\n",
    "                df[df.data_type == 'train'].ade.values,\n",
    "                add_special_tokens=True,\n",
    "                return_attention_mask=True,\n",
    "                pad_to_max_length=True,\n",
    "                max_length=256,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            encoded_data_val = tokenizer.batch_encode_plus(\n",
    "                df[df.data_type == 'val'].ade.values,\n",
    "                add_special_tokens=True,\n",
    "                return_attention_mask=True,\n",
    "                pad_to_max_length=True,\n",
    "                max_length=256,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            input_ids_train = encoded_data_train['input_ids']\n",
    "            attention_masks_train = encoded_data_train['attention_mask']\n",
    "            labels_train = torch.tensor(df[df.data_type == 'train'].label.values)\n",
    "\n",
    "            input_ids_val = encoded_data_val['input_ids']\n",
    "            attention_masks_val = encoded_data_val['attention_mask']\n",
    "            labels_val = torch.tensor(df[df.data_type == 'val'].label.values)\n",
    "\n",
    "            dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "            dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "            model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(top3label_dict), output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "            dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "            dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)\n",
    "\n",
    "            optimizer = AdamW(model.parameters(), lr=lr, eps=1e-8)\n",
    "            scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train) * epochs)\n",
    "\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model.to(device)\n",
    "            logger.info(f\"Device used: {device}\")\n",
    "\n",
    "            # Training loop\n",
    "            for epoch in TQDMLoggingWrapper(range(1, epochs+1), desc='Epoch Progress'):\n",
    "                model.train()\n",
    "                loss_train_total = 0\n",
    "\n",
    "                progress_bar = TQDMLoggingWrapper(dataloader_train, desc=f'Epoch {epoch}', leave=False, disable=False)\n",
    "                for batch in progress_bar:\n",
    "                    model.zero_grad()\n",
    "                    batch = tuple(b.to(device) for b in batch)\n",
    "                    inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "                    outputs = model(**inputs)\n",
    "                    loss = outputs[0]\n",
    "                    loss_train_total += loss.item()\n",
    "                    loss.backward()\n",
    "\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "\n",
    "                    progress_bar.set_postfix({'training_loss': f'{loss.item()/len(batch):.3f}'})\n",
    "\n",
    "                # torch.save(model.state_dict(), f'./ADENorm_top3_epoch_{epoch}.model')\n",
    "\n",
    "                # logger.info(f'\\nEpoch {epoch}')\n",
    "                loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "                # logger.info(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "                val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "                val_f1 = f1_score_func(true_vals, np.argmax(predictions, axis=1), average='weighted')\n",
    "                # logger.info(f'Validation loss: {val_loss}')\n",
    "                # logger.info(f'F1 Score (Weighted): {val_f1}')\n",
    "\n",
    "            _, predictions, true_vals = evaluate(dataloader_validation)\n",
    "            accuracy_dict, count_dict = accuracy_per_class(predictions, true_vals)\n",
    "\n",
    "            for label, accuracy in accuracy_dict.items():\n",
    "                all_accuracies[label].append(accuracy)\n",
    "\n",
    "\n",
    "            # Calculate the average accuracy for each label\n",
    "            avg_accuracy = {label: np.mean(accs) for label, accs in all_accuracies.items()}\n",
    "\n",
    "            # Calculate the overall average accuracy across all labels\n",
    "            overall_avg_accuracy = np.mean(list(avg_accuracy.values()))\n",
    "\n",
    "            logger.info(f'Seed {seed_val} - Accuracy: {overall_avg_accuracy} - Count: {count_dict} - lr: {lr} -batchsize:{batch_size} -epochs:{epochs}')\n",
    "            #store results\n",
    "            results.append((lr, batch_size, epochs, overall_avg_accuracy))\n",
    "\n",
    "\n",
    "# Extract each parameter and accuracy for plotting\n",
    "learning_rates = [result[0] for result in results]\n",
    "batch_sizes = [result[1] for result in results]\n",
    "epochs = [result[2] for result in results]\n",
    "accuracies = [result[3] for result in results]\n",
    "\n",
    "# Find the best result based on accuracy\n",
    "best_result = max(results, key=lambda x: x[3])\n",
    "print(f\"Best result: LR={best_result[0]}, Batch={best_result[1]}, Epoch={best_result[2]}, Accuracy={best_result[3]:.4f}\")\n",
    "\n",
    "with open('smm4htop3_finetuning_results.txt', 'w') as file:\n",
    "    for result in results:\n",
    "        file.write(f'Learning Rate: {result[0]}, Batch Size: {result[1]}, Epochs: {result[2]}, Accuracy: {result[3]}\\n')\n",
    "     # Write the best result at the end\n",
    "    file.write('\\nBest result:\\n')\n",
    "    file.write(f'Learning Rate: {best_result[0]}, Batch Size: {best_result[1]}, Epochs: {best_result[2]}, Accuracy: {best_result[3]:.4f}\\n')\n",
    "    \n",
    "# Convert data to a DataFrame for easier manipulation\n",
    "data = pd.DataFrame({\n",
    "    'Learning Rate': learning_rates,\n",
    "    'Batch Size': batch_sizes,\n",
    "    'Epochs': epochs,\n",
    "    'Accuracy': accuracies\n",
    "})\n",
    "\n",
    "# Convert 'Learning Rate', 'Batch Size', and 'Epochs' to categorical types\n",
    "data['Learning Rate'] = pd.Categorical(data['Learning Rate'])\n",
    "data['Batch Size'] = pd.Categorical(data['Batch Size'])\n",
    "data['Epochs'] = pd.Categorical(data['Epochs'])\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Map categorical data to numeric values for plotting\n",
    "learning_rate_codes = data['Learning Rate'].cat.codes\n",
    "batch_size_codes = data['Batch Size'].cat.codes\n",
    "epoch_codes = data['Epochs'].cat.codes\n",
    "\n",
    "# Plot the data points\n",
    "sc = ax.scatter(learning_rate_codes, batch_size_codes, epoch_codes, c=accuracies, cmap='viridis', s=100, edgecolors='k')\n",
    "\n",
    "# Add color bar\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label('Overall Average Accuracy')\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('Learning Rate')\n",
    "ax.set_ylabel('Batch Size')\n",
    "ax.set_zlabel('Epochs')\n",
    "\n",
    "# Set tick labels to categories\n",
    "ax.set_xticks(np.arange(len(data['Learning Rate'].cat.categories)))\n",
    "ax.set_xticklabels(data['Learning Rate'].cat.categories)\n",
    "ax.set_yticks(np.arange(len(data['Batch Size'].cat.categories)))\n",
    "ax.set_yticklabels(data['Batch Size'].cat.categories)\n",
    "ax.set_zticks(np.arange(len(data['Epochs'].cat.categories)))\n",
    "ax.set_zticklabels(data['Epochs'].cat.categories)\n",
    "\n",
    "# Title\n",
    "ax.set_title('Hyperparameter Tuning Results for smm4h top3')\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig(\"hyperparameter_tuning_3d_plot.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOMq7buPEWSRlRCyRvoA9j+",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
