{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc8ff0-ad56-45c2-ad12-b4452e5c5f33",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "smm4h all data: (1107, 2)\n",
      "SOC count in CADEC:  soc_code\n",
      "10037175    287\n",
      "10018065    235\n",
      "10029205    212\n",
      "10017947     63\n",
      "10028395     58\n",
      "10022891     54\n",
      "10027433     48\n",
      "10040785     28\n",
      "10038738     22\n",
      "10022117     16\n",
      "10015919     16\n",
      "10038604     10\n",
      "10047065     10\n",
      "10021428      8\n",
      "10041244      7\n",
      "10007541      7\n",
      "10038359      6\n",
      "10021881      5\n",
      "10013993      4\n",
      "10019805      2\n",
      "10042613      2\n",
      "10029104      2\n",
      "10077536      1\n",
      "10010331      1\n",
      "0             1\n",
      "10014698      1\n",
      "Name: count, dtype: Int64\n",
      "CADEC top3 in SMM4H:                             ade  soc_code\n",
      "3                            AD  10037175\n",
      "4                         focus  10029205\n",
      "5                          died  10018065\n",
      "8                        dreams  10037175\n",
      "10                   withdrawal  10018065\n",
      "...                         ...       ...\n",
      "1695       talk a mile a minute  10037175\n",
      "1698     can't go back to sleep  10037175\n",
      "1703                 chest hurt  10018065\n",
      "1704   got ten minutes of sleep  10037175\n",
      "1708  never have another orgasm  10037175\n",
      "\n",
      "[734 rows x 2 columns]\n",
      "                            ade  soc_code  label\n",
      "3                            AD  10037175      0\n",
      "4                         focus  10029205      2\n",
      "5                          died  10018065      1\n",
      "8                        dreams  10037175      0\n",
      "10                   withdrawal  10018065      1\n",
      "...                         ...       ...    ...\n",
      "1695       talk a mile a minute  10037175      0\n",
      "1698     can't go back to sleep  10037175      0\n",
      "1703                 chest hurt  10018065      1\n",
      "1704   got ten minutes of sleep  10037175      0\n",
      "1708  never have another orgasm  10037175      0\n",
      "\n",
      "[734 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2888: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch Progress:   0%|                                                                          | 0/100 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|                                                                                  | 0/37 [00:00<?, ?it/s]\u001b[AC:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Epoch 1:   0%|                                                             | 0/37 [00:01<?, ?it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   3%|█▍                                                   | 1/37 [00:01<00:40,  1.13s/it, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   3%|█▍                                                   | 1/37 [00:01<00:40,  1.13s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:   5%|██▊                                                  | 2/37 [00:01<00:26,  1.31it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 1:   5%|██▊                                                  | 2/37 [00:02<00:26,  1.31it/s, training_loss=0.369]\u001b[A\n",
      "Epoch 1:   8%|████▎                                                | 3/37 [00:02<00:22,  1.54it/s, training_loss=0.369]\u001b[A\n",
      "Epoch 1:   8%|████▎                                                | 3/37 [00:02<00:22,  1.54it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  11%|█████▋                                               | 4/37 [00:02<00:19,  1.66it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  11%|█████▋                                               | 4/37 [00:03<00:19,  1.66it/s, training_loss=0.362]\u001b[A\n",
      "Epoch 1:  14%|███████▏                                             | 5/37 [00:03<00:18,  1.73it/s, training_loss=0.362]\u001b[A\n",
      "Epoch 1:  14%|███████▏                                             | 5/37 [00:03<00:18,  1.73it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  16%|████████▌                                            | 6/37 [00:03<00:16,  1.83it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  16%|████████▌                                            | 6/37 [00:04<00:16,  1.83it/s, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  19%|██████████                                           | 7/37 [00:04<00:16,  1.87it/s, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  19%|██████████                                           | 7/37 [00:04<00:16,  1.87it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  22%|███████████▍                                         | 8/37 [00:04<00:14,  1.93it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  22%|███████████▍                                         | 8/37 [00:05<00:14,  1.93it/s, training_loss=0.373]\u001b[A\n",
      "Epoch 1:  24%|████████████▉                                        | 9/37 [00:05<00:14,  1.96it/s, training_loss=0.373]\u001b[A\n",
      "Epoch 1:  24%|████████████▉                                        | 9/37 [00:05<00:14,  1.96it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  27%|██████████████                                      | 10/37 [00:05<00:13,  1.97it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  27%|██████████████                                      | 10/37 [00:06<00:13,  1.97it/s, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  30%|███████████████▍                                    | 11/37 [00:06<00:13,  1.96it/s, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  30%|███████████████▍                                    | 11/37 [00:06<00:13,  1.96it/s, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  32%|████████████████▊                                   | 12/37 [00:06<00:12,  1.99it/s, training_loss=0.361]\u001b[A\n",
      "Epoch 1:  32%|████████████████▊                                   | 12/37 [00:07<00:12,  1.99it/s, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  35%|██████████████████▎                                 | 13/37 [00:07<00:12,  1.98it/s, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  35%|██████████████████▎                                 | 13/37 [00:07<00:12,  1.98it/s, training_loss=0.392]\u001b[A\n",
      "Epoch 1:  38%|███████████████████▋                                | 14/37 [00:07<00:11,  1.98it/s, training_loss=0.392]\u001b[A\n",
      "Epoch 1:  38%|███████████████████▋                                | 14/37 [00:08<00:11,  1.98it/s, training_loss=0.377]\u001b[A\n",
      "Epoch 1:  41%|█████████████████████                               | 15/37 [00:08<00:11,  1.98it/s, training_loss=0.377]\u001b[A\n",
      "Epoch 1:  41%|█████████████████████                               | 15/37 [00:08<00:11,  1.98it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  43%|██████████████████████▍                             | 16/37 [00:08<00:10,  2.01it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  43%|██████████████████████▍                             | 16/37 [00:09<00:10,  2.01it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  46%|███████████████████████▉                            | 17/37 [00:09<00:10,  1.99it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  46%|███████████████████████▉                            | 17/37 [00:09<00:10,  1.99it/s, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  49%|█████████████████████████▎                          | 18/37 [00:09<00:09,  1.95it/s, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  49%|█████████████████████████▎                          | 18/37 [00:10<00:09,  1.95it/s, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  51%|██████████████████████████▋                         | 19/37 [00:10<00:09,  1.94it/s, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  51%|██████████████████████████▋                         | 19/37 [00:10<00:09,  1.94it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  54%|████████████████████████████                        | 20/37 [00:10<00:08,  1.94it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  54%|████████████████████████████                        | 20/37 [00:11<00:08,  1.94it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  57%|█████████████████████████████▌                      | 21/37 [00:11<00:08,  1.94it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  57%|█████████████████████████████▌                      | 21/37 [00:11<00:08,  1.94it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  59%|██████████████████████████████▉                     | 22/37 [00:11<00:07,  1.94it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  59%|██████████████████████████████▉                     | 22/37 [00:12<00:07,  1.94it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  62%|████████████████████████████████▎                   | 23/37 [00:12<00:07,  1.95it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  62%|████████████████████████████████▎                   | 23/37 [00:12<00:07,  1.95it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  65%|█████████████████████████████████▋                  | 24/37 [00:12<00:06,  1.97it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  65%|█████████████████████████████████▋                  | 24/37 [00:13<00:06,  1.97it/s, training_loss=0.362]\u001b[A\n",
      "Epoch 1:  68%|███████████████████████████████████▏                | 25/37 [00:13<00:06,  1.98it/s, training_loss=0.362]\u001b[A\n",
      "Epoch 1:  68%|███████████████████████████████████▏                | 25/37 [00:13<00:06,  1.98it/s, training_loss=0.405]\u001b[A\n",
      "Epoch 1:  70%|████████████████████████████████████▌               | 26/37 [00:13<00:05,  1.96it/s, training_loss=0.405]\u001b[A\n",
      "Epoch 1:  70%|████████████████████████████████████▌               | 26/37 [00:14<00:05,  1.96it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  73%|█████████████████████████████████████▉              | 27/37 [00:14<00:05,  1.99it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  73%|█████████████████████████████████████▉              | 27/37 [00:14<00:05,  1.99it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  76%|███████████████████████████████████████▎            | 28/37 [00:14<00:04,  1.99it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  76%|███████████████████████████████████████▎            | 28/37 [00:15<00:04,  1.99it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  78%|████████████████████████████████████████▊           | 29/37 [00:15<00:04,  2.00it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  78%|████████████████████████████████████████▊           | 29/37 [00:15<00:04,  2.00it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  81%|██████████████████████████████████████████▏         | 30/37 [00:15<00:03,  1.98it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  81%|██████████████████████████████████████████▏         | 30/37 [00:16<00:03,  1.98it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  84%|███████████████████████████████████████████▌        | 31/37 [00:16<00:02,  2.01it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  84%|███████████████████████████████████████████▌        | 31/37 [00:16<00:02,  2.01it/s, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  86%|████████████████████████████████████████████▉       | 32/37 [00:16<00:02,  2.00it/s, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  86%|████████████████████████████████████████████▉       | 32/37 [00:17<00:02,  2.00it/s, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  89%|██████████████████████████████████████████████▍     | 33/37 [00:17<00:02,  2.00it/s, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  89%|██████████████████████████████████████████████▍     | 33/37 [00:17<00:02,  2.00it/s, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  92%|███████████████████████████████████████████████▊    | 34/37 [00:17<00:01,  2.00it/s, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  92%|███████████████████████████████████████████████▊    | 34/37 [00:18<00:01,  2.00it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:18<00:01,  2.00it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:18<00:01,  2.00it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:18<00:00,  1.96it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:19<00:00,  1.96it/s, training_loss=0.380]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████████████████████| 37/37 [00:19<00:00,  2.12it/s, training_loss=0.380]\u001b[A\n",
      "Epoch Progress:   1%|▋                                                                 | 1/100 [00:20<34:08, 20.69s/it]\u001b[A\n",
      "Epoch 2:   0%|                                                                                  | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|                                                             | 0/37 [00:00<?, ?it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 2:   3%|█▍                                                   | 1/37 [00:00<00:18,  1.96it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 2:   3%|█▍                                                   | 1/37 [00:01<00:18,  1.96it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 2:   5%|██▊                                                  | 2/37 [00:01<00:18,  1.94it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 2:   5%|██▊                                                  | 2/37 [00:01<00:18,  1.94it/s, training_loss=0.358]\u001b[A\n",
      "Epoch 2:   8%|████▎                                                | 3/37 [00:01<00:17,  1.97it/s, training_loss=0.358]\u001b[A\n",
      "Epoch 2:   8%|████▎                                                | 3/37 [00:02<00:17,  1.97it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 2:  11%|█████▋                                               | 4/37 [00:02<00:16,  1.98it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 2:  11%|█████▋                                               | 4/37 [00:02<00:16,  1.98it/s, training_loss=0.376]\u001b[A\n",
      "Epoch 2:  14%|███████▏                                             | 5/37 [00:02<00:16,  1.97it/s, training_loss=0.376]\u001b[A\n",
      "Epoch 2:  14%|███████▏                                             | 5/37 [00:03<00:16,  1.97it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 2:  16%|████████▌                                            | 6/37 [00:03<00:15,  1.97it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 2:  16%|████████▌                                            | 6/37 [00:03<00:15,  1.97it/s, training_loss=0.353]\u001b[A\n",
      "Epoch 2:  19%|██████████                                           | 7/37 [00:03<00:15,  1.96it/s, training_loss=0.353]\u001b[A\n",
      "Epoch 2:  19%|██████████                                           | 7/37 [00:04<00:15,  1.96it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 2:  22%|███████████▍                                         | 8/37 [00:04<00:14,  1.97it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 2:  22%|███████████▍                                         | 8/37 [00:04<00:14,  1.97it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 2:  24%|████████████▉                                        | 9/37 [00:04<00:14,  1.98it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 2:  24%|████████████▉                                        | 9/37 [00:05<00:14,  1.98it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 2:  27%|██████████████                                      | 10/37 [00:05<00:13,  1.98it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 2:  27%|██████████████                                      | 10/37 [00:05<00:13,  1.98it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 2:  30%|███████████████▍                                    | 11/37 [00:05<00:13,  1.99it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 2:  30%|███████████████▍                                    | 11/37 [00:06<00:13,  1.99it/s, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  32%|████████████████▊                                   | 12/37 [00:06<00:12,  1.96it/s, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  32%|████████████████▊                                   | 12/37 [00:06<00:12,  1.96it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 2:  35%|██████████████████▎                                 | 13/37 [00:06<00:12,  1.97it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 2:  35%|██████████████████▎                                 | 13/37 [00:07<00:12,  1.97it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 2:  38%|███████████████████▋                                | 14/37 [00:07<00:11,  1.97it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 2:  38%|███████████████████▋                                | 14/37 [00:07<00:11,  1.97it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 2:  41%|█████████████████████                               | 15/37 [00:07<00:11,  1.98it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 2:  41%|█████████████████████                               | 15/37 [00:08<00:11,  1.98it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 2:  43%|██████████████████████▍                             | 16/37 [00:08<00:10,  2.02it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 2:  43%|██████████████████████▍                             | 16/37 [00:08<00:10,  2.02it/s, training_loss=0.333]\u001b[A\n",
      "Epoch 2:  46%|███████████████████████▉                            | 17/37 [00:08<00:09,  2.00it/s, training_loss=0.333]\u001b[A\n",
      "Epoch 2:  46%|███████████████████████▉                            | 17/37 [00:09<00:09,  2.00it/s, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  49%|█████████████████████████▎                          | 18/37 [00:09<00:09,  2.02it/s, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  49%|█████████████████████████▎                          | 18/37 [00:09<00:09,  2.02it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 2:  51%|██████████████████████████▋                         | 19/37 [00:09<00:08,  2.01it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 2:  51%|██████████████████████████▋                         | 19/37 [00:10<00:08,  2.01it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  54%|████████████████████████████                        | 20/37 [00:10<00:08,  2.05it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  54%|████████████████████████████                        | 20/37 [00:10<00:08,  2.05it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 2:  57%|█████████████████████████████▌                      | 21/37 [00:10<00:07,  2.02it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 2:  57%|█████████████████████████████▌                      | 21/37 [00:11<00:07,  2.02it/s, training_loss=0.349]\u001b[A\n",
      "Epoch 2:  59%|██████████████████████████████▉                     | 22/37 [00:11<00:07,  2.01it/s, training_loss=0.349]\u001b[A\n",
      "Epoch 2:  59%|██████████████████████████████▉                     | 22/37 [00:11<00:07,  2.01it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 2:  62%|████████████████████████████████▎                   | 23/37 [00:11<00:06,  2.01it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 2:  62%|████████████████████████████████▎                   | 23/37 [00:12<00:06,  2.01it/s, training_loss=0.312]\u001b[A\n",
      "Epoch 2:  65%|█████████████████████████████████▋                  | 24/37 [00:12<00:06,  2.02it/s, training_loss=0.312]\u001b[A\n",
      "Epoch 2:  65%|█████████████████████████████████▋                  | 24/37 [00:12<00:06,  2.02it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 2:  68%|███████████████████████████████████▏                | 25/37 [00:12<00:06,  2.00it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 2:  68%|███████████████████████████████████▏                | 25/37 [00:13<00:06,  2.00it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 2:  70%|████████████████████████████████████▌               | 26/37 [00:13<00:05,  2.02it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 2:  70%|████████████████████████████████████▌               | 26/37 [00:13<00:05,  2.02it/s, training_loss=0.294]\u001b[A\n",
      "Epoch 2:  73%|█████████████████████████████████████▉              | 27/37 [00:13<00:05,  1.99it/s, training_loss=0.294]\u001b[A\n",
      "Epoch 2:  73%|█████████████████████████████████████▉              | 27/37 [00:14<00:05,  1.99it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 2:  76%|███████████████████████████████████████▎            | 28/37 [00:14<00:04,  1.97it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 2:  76%|███████████████████████████████████████▎            | 28/37 [00:14<00:04,  1.97it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 2:  78%|████████████████████████████████████████▊           | 29/37 [00:14<00:04,  2.00it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 2:  78%|████████████████████████████████████████▊           | 29/37 [00:15<00:04,  2.00it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 2:  81%|██████████████████████████████████████████▏         | 30/37 [00:15<00:03,  2.00it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 2:  81%|██████████████████████████████████████████▏         | 30/37 [00:15<00:03,  2.00it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 2:  84%|███████████████████████████████████████████▌        | 31/37 [00:15<00:02,  2.02it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 2:  84%|███████████████████████████████████████████▌        | 31/37 [00:16<00:02,  2.02it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 2:  86%|████████████████████████████████████████████▉       | 32/37 [00:16<00:02,  2.03it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 2:  86%|████████████████████████████████████████████▉       | 32/37 [00:16<00:02,  2.03it/s, training_loss=0.358]\u001b[A\n",
      "Epoch 2:  89%|██████████████████████████████████████████████▍     | 33/37 [00:16<00:01,  2.02it/s, training_loss=0.358]\u001b[A\n",
      "Epoch 2:  89%|██████████████████████████████████████████████▍     | 33/37 [00:17<00:01,  2.02it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 2:  92%|███████████████████████████████████████████████▊    | 34/37 [00:17<00:01,  2.03it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 2:  92%|███████████████████████████████████████████████▊    | 34/37 [00:17<00:01,  2.03it/s, training_loss=0.323]\u001b[A\n",
      "Epoch 2:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:17<00:00,  2.03it/s, training_loss=0.323]\u001b[A\n",
      "Epoch 2:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:18<00:00,  2.03it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 2:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:18<00:00,  2.00it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 2:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:18<00:00,  2.00it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████████████████████| 37/37 [00:18<00:00,  2.20it/s, training_loss=0.339]\u001b[A\n",
      "Epoch Progress:   2%|█▎                                                                | 2/100 [00:40<32:57, 20.18s/it]\u001b[A\n",
      "Epoch 3:   0%|                                                                                  | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|                                                             | 0/37 [00:00<?, ?it/s, training_loss=0.312]\u001b[A\n",
      "Epoch 3:   3%|█▍                                                   | 1/37 [00:00<00:18,  1.98it/s, training_loss=0.312]\u001b[A\n",
      "Epoch 3:   3%|█▍                                                   | 1/37 [00:01<00:18,  1.98it/s, training_loss=0.317]\u001b[A\n",
      "Epoch 3:   5%|██▊                                                  | 2/37 [00:01<00:17,  1.99it/s, training_loss=0.317]\u001b[A\n",
      "Epoch 3:   5%|██▊                                                  | 2/37 [00:01<00:17,  1.99it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 3:   8%|████▎                                                | 3/37 [00:01<00:17,  1.99it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 3:   8%|████▎                                                | 3/37 [00:02<00:17,  1.99it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 3:  11%|█████▋                                               | 4/37 [00:02<00:16,  2.00it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 3:  11%|█████▋                                               | 4/37 [00:02<00:16,  2.00it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 3:  14%|███████▏                                             | 5/37 [00:02<00:16,  2.00it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 3:  14%|███████▏                                             | 5/37 [00:02<00:16,  2.00it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 3:  16%|████████▌                                            | 6/37 [00:02<00:15,  2.02it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 3:  16%|████████▌                                            | 6/37 [00:03<00:15,  2.02it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 3:  19%|██████████                                           | 7/37 [00:03<00:14,  2.08it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 3:  19%|██████████                                           | 7/37 [00:03<00:14,  2.08it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 3:  22%|███████████▍                                         | 8/37 [00:03<00:14,  2.06it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 3:  22%|███████████▍                                         | 8/37 [00:04<00:14,  2.06it/s, training_loss=0.331]\u001b[A\n",
      "Epoch 3:  24%|████████████▉                                        | 9/37 [00:04<00:13,  2.08it/s, training_loss=0.331]\u001b[A\n",
      "Epoch 3:  24%|████████████▉                                        | 9/37 [00:04<00:13,  2.08it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 3:  27%|██████████████                                      | 10/37 [00:04<00:13,  2.04it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 3:  27%|██████████████                                      | 10/37 [00:05<00:13,  2.04it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 3:  30%|███████████████▍                                    | 11/37 [00:05<00:12,  2.02it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 3:  30%|███████████████▍                                    | 11/37 [00:05<00:12,  2.02it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 3:  32%|████████████████▊                                   | 12/37 [00:05<00:12,  2.00it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 3:  32%|████████████████▊                                   | 12/37 [00:06<00:12,  2.00it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 3:  35%|██████████████████▎                                 | 13/37 [00:06<00:12,  1.95it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 3:  35%|██████████████████▎                                 | 13/37 [00:07<00:12,  1.95it/s, training_loss=0.303]\u001b[A\n",
      "Epoch 3:  38%|███████████████████▋                                | 14/37 [00:07<00:11,  1.93it/s, training_loss=0.303]\u001b[A\n",
      "Epoch 3:  38%|███████████████████▋                                | 14/37 [00:07<00:11,  1.93it/s, training_loss=0.375]\u001b[A\n",
      "Epoch 3:  41%|█████████████████████                               | 15/37 [00:07<00:11,  1.95it/s, training_loss=0.375]\u001b[A\n",
      "Epoch 3:  41%|█████████████████████                               | 15/37 [00:08<00:11,  1.95it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 3:  43%|██████████████████████▍                             | 16/37 [00:08<00:10,  1.98it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 3:  43%|██████████████████████▍                             | 16/37 [00:08<00:10,  1.98it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 3:  46%|███████████████████████▉                            | 17/37 [00:08<00:10,  1.98it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 3:  46%|███████████████████████▉                            | 17/37 [00:08<00:10,  1.98it/s, training_loss=0.305]\u001b[A\n",
      "Epoch 3:  49%|█████████████████████████▎                          | 18/37 [00:09<00:09,  2.00it/s, training_loss=0.305]\u001b[A\n",
      "Epoch 3:  49%|█████████████████████████▎                          | 18/37 [00:09<00:09,  2.00it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 3:  51%|██████████████████████████▋                         | 19/37 [00:09<00:08,  2.01it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 3:  51%|██████████████████████████▋                         | 19/37 [00:09<00:08,  2.01it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 3:  54%|████████████████████████████                        | 20/37 [00:09<00:08,  2.00it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 3:  54%|████████████████████████████                        | 20/37 [00:10<00:08,  2.00it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 3:  57%|█████████████████████████████▌                      | 21/37 [00:10<00:07,  2.03it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 3:  57%|█████████████████████████████▌                      | 21/37 [00:11<00:07,  2.03it/s, training_loss=0.305]\u001b[A\n",
      "Epoch 3:  59%|██████████████████████████████▉                     | 22/37 [00:11<00:07,  1.98it/s, training_loss=0.305]\u001b[A\n",
      "Epoch 3:  59%|██████████████████████████████▉                     | 22/37 [00:11<00:07,  1.98it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 3:  62%|████████████████████████████████▎                   | 23/37 [00:11<00:07,  1.99it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 3:  62%|████████████████████████████████▎                   | 23/37 [00:12<00:07,  1.99it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 3:  65%|█████████████████████████████████▋                  | 24/37 [00:12<00:06,  1.95it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 3:  65%|█████████████████████████████████▋                  | 24/37 [00:12<00:06,  1.95it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 3:  68%|███████████████████████████████████▏                | 25/37 [00:12<00:06,  1.93it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 3:  68%|███████████████████████████████████▏                | 25/37 [00:13<00:06,  1.93it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 3:  70%|████████████████████████████████████▌               | 26/37 [00:13<00:05,  1.95it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 3:  70%|████████████████████████████████████▌               | 26/37 [00:13<00:05,  1.95it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 3:  73%|█████████████████████████████████████▉              | 27/37 [00:13<00:05,  1.95it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 3:  73%|█████████████████████████████████████▉              | 27/37 [00:14<00:05,  1.95it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 3:  76%|███████████████████████████████████████▎            | 28/37 [00:14<00:04,  1.93it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 3:  76%|███████████████████████████████████████▎            | 28/37 [00:14<00:04,  1.93it/s, training_loss=0.316]\u001b[A\n",
      "Epoch 3:  78%|████████████████████████████████████████▊           | 29/37 [00:14<00:04,  1.94it/s, training_loss=0.316]\u001b[A\n",
      "Epoch 3:  78%|████████████████████████████████████████▊           | 29/37 [00:15<00:04,  1.94it/s, training_loss=0.304]\u001b[A\n",
      "Epoch 3:  81%|██████████████████████████████████████████▏         | 30/37 [00:15<00:03,  1.97it/s, training_loss=0.304]\u001b[A\n",
      "Epoch 3:  81%|██████████████████████████████████████████▏         | 30/37 [00:15<00:03,  1.97it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 3:  84%|███████████████████████████████████████████▌        | 31/37 [00:15<00:03,  1.99it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 3:  84%|███████████████████████████████████████████▌        | 31/37 [00:16<00:03,  1.99it/s, training_loss=0.305]\u001b[A\n",
      "Epoch 3:  86%|████████████████████████████████████████████▉       | 32/37 [00:16<00:02,  1.97it/s, training_loss=0.305]\u001b[A\n",
      "Epoch 3:  86%|████████████████████████████████████████████▉       | 32/37 [00:16<00:02,  1.97it/s, training_loss=0.310]\u001b[A\n",
      "Epoch 3:  89%|██████████████████████████████████████████████▍     | 33/37 [00:16<00:02,  1.98it/s, training_loss=0.310]\u001b[A\n",
      "Epoch 3:  89%|██████████████████████████████████████████████▍     | 33/37 [00:17<00:02,  1.98it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 3:  92%|███████████████████████████████████████████████▊    | 34/37 [00:17<00:01,  1.98it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 3:  92%|███████████████████████████████████████████████▊    | 34/37 [00:17<00:01,  1.98it/s, training_loss=0.316]\u001b[A\n",
      "Epoch 3:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:17<00:01,  1.95it/s, training_loss=0.316]\u001b[A\n",
      "Epoch 3:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:18<00:01,  1.95it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 3:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:18<00:00,  1.96it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 3:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:18<00:00,  1.96it/s, training_loss=0.272]\u001b[A\n",
      "Epoch 3: 100%|████████████████████████████████████████████████████| 37/37 [00:18<00:00,  2.11it/s, training_loss=0.272]\u001b[A\n",
      "Epoch Progress:   3%|█▉                                                                | 3/100 [01:00<32:29, 20.10s/it]\u001b[A\n",
      "Epoch 4:   0%|                                                                                  | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:   0%|                                                             | 0/37 [00:00<?, ?it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 4:   3%|█▍                                                   | 1/37 [00:00<00:17,  2.07it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 4:   3%|█▍                                                   | 1/37 [00:00<00:17,  2.07it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 4:   5%|██▊                                                  | 2/37 [00:00<00:16,  2.07it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 4:   5%|██▊                                                  | 2/37 [00:01<00:16,  2.07it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 4:   8%|████▎                                                | 3/37 [00:01<00:16,  2.04it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 4:   8%|████▎                                                | 3/37 [00:01<00:16,  2.04it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 4:  11%|█████▋                                               | 4/37 [00:01<00:16,  2.02it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 4:  11%|█████▋                                               | 4/37 [00:02<00:16,  2.02it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 4:  14%|███████▏                                             | 5/37 [00:02<00:15,  2.04it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 4:  14%|███████▏                                             | 5/37 [00:02<00:15,  2.04it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 4:  16%|████████▌                                            | 6/37 [00:02<00:15,  2.02it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 4:  16%|████████▌                                            | 6/37 [00:03<00:15,  2.02it/s, training_loss=0.312]\u001b[A\n",
      "Epoch 4:  19%|██████████                                           | 7/37 [00:03<00:14,  2.01it/s, training_loss=0.312]\u001b[A\n",
      "Epoch 4:  19%|██████████                                           | 7/37 [00:03<00:14,  2.01it/s, training_loss=0.284]\u001b[A\n",
      "Epoch 4:  22%|███████████▍                                         | 8/37 [00:03<00:14,  2.03it/s, training_loss=0.284]\u001b[A\n",
      "Epoch 4:  22%|███████████▍                                         | 8/37 [00:04<00:14,  2.03it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 4:  24%|████████████▉                                        | 9/37 [00:04<00:13,  2.02it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 4:  24%|████████████▉                                        | 9/37 [00:04<00:13,  2.02it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 4:  27%|██████████████                                      | 10/37 [00:04<00:13,  2.01it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 4:  27%|██████████████                                      | 10/37 [00:05<00:13,  2.01it/s, training_loss=0.259]\u001b[A\n",
      "Epoch 4:  30%|███████████████▍                                    | 11/37 [00:05<00:12,  2.01it/s, training_loss=0.259]\u001b[A\n",
      "Epoch 4:  30%|███████████████▍                                    | 11/37 [00:05<00:12,  2.01it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 4:  32%|████████████████▊                                   | 12/37 [00:05<00:12,  2.05it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 4:  32%|████████████████▊                                   | 12/37 [00:06<00:12,  2.05it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 4:  35%|██████████████████▎                                 | 13/37 [00:06<00:11,  2.03it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 4:  35%|██████████████████▎                                 | 13/37 [00:06<00:11,  2.03it/s, training_loss=0.330]\u001b[A\n",
      "Epoch 4:  38%|███████████████████▋                                | 14/37 [00:06<00:11,  2.02it/s, training_loss=0.330]\u001b[A\n",
      "Epoch 4:  38%|███████████████████▋                                | 14/37 [00:07<00:11,  2.02it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 4:  41%|█████████████████████                               | 15/37 [00:07<00:10,  2.01it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 4:  41%|█████████████████████                               | 15/37 [00:07<00:10,  2.01it/s, training_loss=0.307]\u001b[A\n",
      "Epoch 4:  43%|██████████████████████▍                             | 16/37 [00:07<00:10,  2.02it/s, training_loss=0.307]\u001b[A\n",
      "Epoch 4:  43%|██████████████████████▍                             | 16/37 [00:08<00:10,  2.02it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 4:  46%|███████████████████████▉                            | 17/37 [00:08<00:09,  2.02it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 4:  46%|███████████████████████▉                            | 17/37 [00:08<00:09,  2.02it/s, training_loss=0.257]\u001b[A\n",
      "Epoch 4:  49%|█████████████████████████▎                          | 18/37 [00:08<00:09,  2.04it/s, training_loss=0.257]\u001b[A\n",
      "Epoch 4:  49%|█████████████████████████▎                          | 18/37 [00:09<00:09,  2.04it/s, training_loss=0.284]\u001b[A\n",
      "Epoch 4:  51%|██████████████████████████▋                         | 19/37 [00:09<00:08,  2.05it/s, training_loss=0.284]\u001b[A\n",
      "Epoch 4:  51%|██████████████████████████▋                         | 19/37 [00:09<00:08,  2.05it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 4:  54%|████████████████████████████                        | 20/37 [00:09<00:08,  2.03it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 4:  54%|████████████████████████████                        | 20/37 [00:10<00:08,  2.03it/s, training_loss=0.286]\u001b[A\n",
      "Epoch 4:  57%|█████████████████████████████▌                      | 21/37 [00:10<00:07,  2.02it/s, training_loss=0.286]\u001b[A\n",
      "Epoch 4:  57%|█████████████████████████████▌                      | 21/37 [00:10<00:07,  2.02it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 4:  59%|██████████████████████████████▉                     | 22/37 [00:10<00:07,  2.01it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 4:  59%|██████████████████████████████▉                     | 22/37 [00:11<00:07,  2.01it/s, training_loss=0.269]\u001b[A\n",
      "Epoch 4:  62%|████████████████████████████████▎                   | 23/37 [00:11<00:06,  2.01it/s, training_loss=0.269]\u001b[A\n",
      "Epoch 4:  62%|████████████████████████████████▎                   | 23/37 [00:11<00:06,  2.01it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 4:  65%|█████████████████████████████████▋                  | 24/37 [00:11<00:06,  2.00it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 4:  65%|█████████████████████████████████▋                  | 24/37 [00:12<00:06,  2.00it/s, training_loss=0.289]\u001b[A\n",
      "Epoch 4:  68%|███████████████████████████████████▏                | 25/37 [00:12<00:05,  2.00it/s, training_loss=0.289]\u001b[A\n",
      "Epoch 4:  68%|███████████████████████████████████▏                | 25/37 [00:12<00:05,  2.00it/s, training_loss=0.281]\u001b[A\n",
      "Epoch 4:  70%|████████████████████████████████████▌               | 26/37 [00:12<00:05,  2.00it/s, training_loss=0.281]\u001b[A\n",
      "Epoch 4:  70%|████████████████████████████████████▌               | 26/37 [00:13<00:05,  2.00it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 4:  73%|█████████████████████████████████████▉              | 27/37 [00:13<00:04,  2.02it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 4:  73%|█████████████████████████████████████▉              | 27/37 [00:13<00:04,  2.02it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 4:  76%|███████████████████████████████████████▎            | 28/37 [00:13<00:04,  2.01it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 4:  76%|███████████████████████████████████████▎            | 28/37 [00:14<00:04,  2.01it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 4:  78%|████████████████████████████████████████▊           | 29/37 [00:14<00:03,  2.01it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 4:  78%|████████████████████████████████████████▊           | 29/37 [00:14<00:03,  2.01it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 4:  81%|██████████████████████████████████████████▏         | 30/37 [00:14<00:03,  1.99it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 4:  81%|██████████████████████████████████████████▏         | 30/37 [00:15<00:03,  1.99it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 4:  84%|███████████████████████████████████████████▌        | 31/37 [00:15<00:03,  1.96it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 4:  84%|███████████████████████████████████████████▌        | 31/37 [00:15<00:03,  1.96it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 4:  86%|████████████████████████████████████████████▉       | 32/37 [00:15<00:02,  1.98it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 4:  86%|████████████████████████████████████████████▉       | 32/37 [00:16<00:02,  1.98it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 4:  89%|██████████████████████████████████████████████▍     | 33/37 [00:16<00:02,  1.99it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 4:  89%|██████████████████████████████████████████████▍     | 33/37 [00:16<00:02,  1.99it/s, training_loss=0.283]\u001b[A\n",
      "Epoch 4:  92%|███████████████████████████████████████████████▊    | 34/37 [00:16<00:01,  1.97it/s, training_loss=0.283]\u001b[A\n",
      "Epoch 4:  92%|███████████████████████████████████████████████▊    | 34/37 [00:17<00:01,  1.97it/s, training_loss=0.321]\u001b[A\n",
      "Epoch 4:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:17<00:01,  1.96it/s, training_loss=0.321]\u001b[A\n",
      "Epoch 4:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:17<00:01,  1.96it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 4:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:17<00:00,  1.98it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 4:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:18<00:00,  1.98it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 4: 100%|████████████████████████████████████████████████████| 37/37 [00:18<00:00,  2.13it/s, training_loss=0.214]\u001b[A\n",
      "Epoch Progress:   4%|██▋                                                               | 4/100 [01:20<31:54, 19.94s/it]\u001b[A\n",
      "Epoch 5:   0%|                                                                                  | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:   0%|                                                             | 0/37 [00:00<?, ?it/s, training_loss=0.221]\u001b[A\n",
      "Epoch 5:   3%|█▍                                                   | 1/37 [00:00<00:17,  2.02it/s, training_loss=0.221]\u001b[A\n",
      "Epoch 5:   3%|█▍                                                   | 1/37 [00:01<00:17,  2.02it/s, training_loss=0.230]\u001b[A\n",
      "Epoch 5:   5%|██▊                                                  | 2/37 [00:01<00:17,  1.99it/s, training_loss=0.230]\u001b[A\n",
      "Epoch 5:   5%|██▊                                                  | 2/37 [00:01<00:17,  1.99it/s, training_loss=0.254]\u001b[A\n",
      "Epoch 5:   8%|████▎                                                | 3/37 [00:01<00:16,  2.06it/s, training_loss=0.254]\u001b[A\n",
      "Epoch 5:   8%|████▎                                                | 3/37 [00:02<00:16,  2.06it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 5:  11%|█████▋                                               | 4/37 [00:02<00:16,  1.97it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 5:  11%|█████▋                                               | 4/37 [00:02<00:16,  1.97it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 5:  14%|███████▏                                             | 5/37 [00:02<00:16,  2.00it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 5:  14%|███████▏                                             | 5/37 [00:03<00:16,  2.00it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 5:  16%|████████▌                                            | 6/37 [00:03<00:15,  1.98it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 5:  16%|████████▌                                            | 6/37 [00:03<00:15,  1.98it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 5:  19%|██████████                                           | 7/37 [00:03<00:15,  1.94it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 5:  19%|██████████                                           | 7/37 [00:04<00:15,  1.94it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 5:  22%|███████████▍                                         | 8/37 [00:04<00:14,  1.96it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 5:  22%|███████████▍                                         | 8/37 [00:04<00:14,  1.96it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 5:  24%|████████████▉                                        | 9/37 [00:04<00:14,  1.98it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 5:  24%|████████████▉                                        | 9/37 [00:05<00:14,  1.98it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 5:  27%|██████████████                                      | 10/37 [00:05<00:13,  1.99it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 5:  27%|██████████████                                      | 10/37 [00:05<00:13,  1.99it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 5:  30%|███████████████▍                                    | 11/37 [00:05<00:12,  2.02it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 5:  30%|███████████████▍                                    | 11/37 [00:05<00:12,  2.02it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 5:  32%|████████████████▊                                   | 12/37 [00:05<00:12,  2.04it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 5:  32%|████████████████▊                                   | 12/37 [00:06<00:12,  2.04it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 5:  35%|██████████████████▎                                 | 13/37 [00:06<00:11,  2.03it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 5:  35%|██████████████████▎                                 | 13/37 [00:06<00:11,  2.03it/s, training_loss=0.218]\u001b[A\n",
      "Epoch 5:  38%|███████████████████▋                                | 14/37 [00:06<00:11,  2.05it/s, training_loss=0.218]\u001b[A\n",
      "Epoch 5:  38%|███████████████████▋                                | 14/37 [00:07<00:11,  2.05it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 5:  41%|█████████████████████                               | 15/37 [00:07<00:10,  2.04it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 5:  41%|█████████████████████                               | 15/37 [00:07<00:10,  2.04it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 5:  43%|██████████████████████▍                             | 16/37 [00:07<00:10,  2.03it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 5:  43%|██████████████████████▍                             | 16/37 [00:08<00:10,  2.03it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 5:  46%|███████████████████████▉                            | 17/37 [00:08<00:09,  2.02it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 5:  46%|███████████████████████▉                            | 17/37 [00:08<00:09,  2.02it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 5:  49%|█████████████████████████▎                          | 18/37 [00:08<00:09,  2.00it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 5:  49%|█████████████████████████▎                          | 18/37 [00:09<00:09,  2.00it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 5:  51%|██████████████████████████▋                         | 19/37 [00:09<00:09,  2.00it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 5:  51%|██████████████████████████▋                         | 19/37 [00:09<00:09,  2.00it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 5:  54%|████████████████████████████                        | 20/37 [00:09<00:08,  2.01it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 5:  54%|████████████████████████████                        | 20/37 [00:10<00:08,  2.01it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 5:  57%|█████████████████████████████▌                      | 21/37 [00:10<00:07,  2.01it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 5:  57%|█████████████████████████████▌                      | 21/37 [00:10<00:07,  2.01it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 5:  59%|██████████████████████████████▉                     | 22/37 [00:10<00:07,  2.00it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 5:  59%|██████████████████████████████▉                     | 22/37 [00:11<00:07,  2.00it/s, training_loss=0.300]\u001b[A\n",
      "Epoch 5:  62%|████████████████████████████████▎                   | 23/37 [00:11<00:06,  2.03it/s, training_loss=0.300]\u001b[A\n",
      "Epoch 5:  62%|████████████████████████████████▎                   | 23/37 [00:11<00:06,  2.03it/s, training_loss=0.272]\u001b[A\n",
      "Epoch 5:  65%|█████████████████████████████████▋                  | 24/37 [00:11<00:06,  2.05it/s, training_loss=0.272]\u001b[A\n",
      "Epoch 5:  65%|█████████████████████████████████▋                  | 24/37 [00:12<00:06,  2.05it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 5:  68%|███████████████████████████████████▏                | 25/37 [00:12<00:05,  2.01it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 5:  68%|███████████████████████████████████▏                | 25/37 [00:12<00:05,  2.01it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 5:  70%|████████████████████████████████████▌               | 26/37 [00:12<00:05,  2.00it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 5:  70%|████████████████████████████████████▌               | 26/37 [00:13<00:05,  2.00it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 5:  73%|█████████████████████████████████████▉              | 27/37 [00:13<00:04,  2.04it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 5:  73%|█████████████████████████████████████▉              | 27/37 [00:13<00:04,  2.04it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 5:  76%|███████████████████████████████████████▎            | 28/37 [00:13<00:04,  2.01it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 5:  76%|███████████████████████████████████████▎            | 28/37 [00:14<00:04,  2.01it/s, training_loss=0.269]\u001b[A\n",
      "Epoch 5:  78%|████████████████████████████████████████▊           | 29/37 [00:14<00:03,  2.02it/s, training_loss=0.269]\u001b[A\n",
      "Epoch 5:  78%|████████████████████████████████████████▊           | 29/37 [00:14<00:03,  2.02it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 5:  81%|██████████████████████████████████████████▏         | 30/37 [00:14<00:03,  2.01it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 5:  81%|██████████████████████████████████████████▏         | 30/37 [00:15<00:03,  2.01it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 5:  84%|███████████████████████████████████████████▌        | 31/37 [00:15<00:02,  2.02it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 5:  84%|███████████████████████████████████████████▌        | 31/37 [00:15<00:02,  2.02it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 5:  86%|████████████████████████████████████████████▉       | 32/37 [00:15<00:02,  2.02it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 5:  86%|████████████████████████████████████████████▉       | 32/37 [00:16<00:02,  2.02it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 5:  89%|██████████████████████████████████████████████▍     | 33/37 [00:16<00:01,  2.02it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 5:  89%|██████████████████████████████████████████████▍     | 33/37 [00:16<00:01,  2.02it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 5:  92%|███████████████████████████████████████████████▊    | 34/37 [00:16<00:01,  2.03it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 5:  92%|███████████████████████████████████████████████▊    | 34/37 [00:17<00:01,  2.03it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 5:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:17<00:00,  2.02it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 5:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:17<00:00,  2.02it/s, training_loss=0.171]\u001b[A\n",
      "Epoch 5:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:17<00:00,  2.03it/s, training_loss=0.171]\u001b[A\n",
      "Epoch 5:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:18<00:00,  2.03it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 5: 100%|████████████████████████████████████████████████████| 37/37 [00:18<00:00,  2.15it/s, training_loss=0.233]\u001b[A\n",
      "Epoch Progress:   5%|███▎                                                              | 5/100 [01:39<31:26, 19.85s/it]\u001b[A\n",
      "Epoch 6:   0%|                                                                                  | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:   0%|                                                             | 0/37 [00:00<?, ?it/s, training_loss=0.253]\u001b[A\n",
      "Epoch 6:   3%|█▍                                                   | 1/37 [00:00<00:18,  1.98it/s, training_loss=0.253]\u001b[A\n",
      "Epoch 6:   3%|█▍                                                   | 1/37 [00:00<00:18,  1.98it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 6:   5%|██▊                                                  | 2/37 [00:00<00:17,  2.04it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 6:   5%|██▊                                                  | 2/37 [00:01<00:17,  2.04it/s, training_loss=0.226]\u001b[A\n",
      "Epoch 6:   8%|████▎                                                | 3/37 [00:01<00:16,  2.03it/s, training_loss=0.226]\u001b[A\n",
      "Epoch 6:   8%|████▎                                                | 3/37 [00:01<00:16,  2.03it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 6:  11%|█████▋                                               | 4/37 [00:01<00:16,  2.03it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 6:  11%|█████▋                                               | 4/37 [00:02<00:16,  2.03it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 6:  14%|███████▏                                             | 5/37 [00:02<00:15,  2.07it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 6:  14%|███████▏                                             | 5/37 [00:02<00:15,  2.07it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 6:  16%|████████▌                                            | 6/37 [00:02<00:15,  2.06it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 6:  16%|████████▌                                            | 6/37 [00:03<00:15,  2.06it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 6:  19%|██████████                                           | 7/37 [00:03<00:14,  2.04it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 6:  19%|██████████                                           | 7/37 [00:03<00:14,  2.04it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 6:  22%|███████████▍                                         | 8/37 [00:03<00:14,  2.03it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 6:  22%|███████████▍                                         | 8/37 [00:04<00:14,  2.03it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 6:  24%|████████████▉                                        | 9/37 [00:04<00:13,  2.02it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 6:  24%|████████████▉                                        | 9/37 [00:04<00:13,  2.02it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 6:  27%|██████████████                                      | 10/37 [00:04<00:13,  1.99it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 6:  27%|██████████████                                      | 10/37 [00:05<00:13,  1.99it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 6:  30%|███████████████▍                                    | 11/37 [00:05<00:12,  2.01it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 6:  30%|███████████████▍                                    | 11/37 [00:05<00:12,  2.01it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 6:  32%|████████████████▊                                   | 12/37 [00:05<00:12,  2.04it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 6:  32%|████████████████▊                                   | 12/37 [00:06<00:12,  2.04it/s, training_loss=0.284]\u001b[A\n",
      "Epoch 6:  35%|██████████████████▎                                 | 13/37 [00:06<00:11,  2.00it/s, training_loss=0.284]\u001b[A\n",
      "Epoch 6:  35%|██████████████████▎                                 | 13/37 [00:06<00:11,  2.00it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 6:  38%|███████████████████▋                                | 14/37 [00:06<00:11,  1.98it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 6:  38%|███████████████████▋                                | 14/37 [00:07<00:11,  1.98it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 6:  41%|█████████████████████                               | 15/37 [00:07<00:10,  2.02it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 6:  41%|█████████████████████                               | 15/37 [00:07<00:10,  2.02it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 6:  43%|██████████████████████▍                             | 16/37 [00:07<00:10,  1.98it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 6:  43%|██████████████████████▍                             | 16/37 [00:08<00:10,  1.98it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 6:  46%|███████████████████████▉                            | 17/37 [00:08<00:10,  1.97it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 6:  46%|███████████████████████▉                            | 17/37 [00:08<00:10,  1.97it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 6:  49%|█████████████████████████▎                          | 18/37 [00:08<00:09,  1.98it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 6:  49%|█████████████████████████▎                          | 18/37 [00:09<00:09,  1.98it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 6:  51%|██████████████████████████▋                         | 19/37 [00:09<00:09,  1.98it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 6:  51%|██████████████████████████▋                         | 19/37 [00:09<00:09,  1.98it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 6:  54%|████████████████████████████                        | 20/37 [00:09<00:08,  1.99it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 6:  54%|████████████████████████████                        | 20/37 [00:10<00:08,  1.99it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 6:  57%|█████████████████████████████▌                      | 21/37 [00:10<00:08,  1.97it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 6:  57%|█████████████████████████████▌                      | 21/37 [00:10<00:08,  1.97it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 6:  59%|██████████████████████████████▉                     | 22/37 [00:10<00:07,  1.98it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 6:  59%|██████████████████████████████▉                     | 22/37 [00:11<00:07,  1.98it/s, training_loss=0.221]\u001b[A\n",
      "Epoch 6:  62%|████████████████████████████████▎                   | 23/37 [00:11<00:07,  1.97it/s, training_loss=0.221]\u001b[A\n",
      "Epoch 6:  62%|████████████████████████████████▎                   | 23/37 [00:12<00:07,  1.97it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 6:  65%|█████████████████████████████████▋                  | 24/37 [00:12<00:06,  1.96it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 6:  65%|█████████████████████████████████▋                  | 24/37 [00:12<00:06,  1.96it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 6:  68%|███████████████████████████████████▏                | 25/37 [00:12<00:06,  1.97it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 6:  68%|███████████████████████████████████▏                | 25/37 [00:13<00:06,  1.97it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 6:  70%|████████████████████████████████████▌               | 26/37 [00:13<00:05,  1.96it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 6:  70%|████████████████████████████████████▌               | 26/37 [00:13<00:05,  1.96it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 6:  73%|█████████████████████████████████████▉              | 27/37 [00:13<00:05,  1.94it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 6:  73%|█████████████████████████████████████▉              | 27/37 [00:13<00:05,  1.94it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 6:  76%|███████████████████████████████████████▎            | 28/37 [00:13<00:04,  2.13it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 6:  76%|███████████████████████████████████████▎            | 28/37 [00:14<00:04,  2.13it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 6:  78%|████████████████████████████████████████▊           | 29/37 [00:14<00:03,  2.34it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 6:  78%|████████████████████████████████████████▊           | 29/37 [00:14<00:03,  2.34it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 6:  81%|██████████████████████████████████████████▏         | 30/37 [00:14<00:02,  2.46it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 6:  81%|██████████████████████████████████████████▏         | 30/37 [00:14<00:02,  2.46it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 6:  84%|███████████████████████████████████████████▌        | 31/37 [00:14<00:02,  2.64it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 6:  84%|███████████████████████████████████████████▌        | 31/37 [00:15<00:02,  2.64it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 6:  86%|████████████████████████████████████████████▉       | 32/37 [00:15<00:01,  2.71it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 6:  86%|████████████████████████████████████████████▉       | 32/37 [00:15<00:01,  2.71it/s, training_loss=0.218]\u001b[A\n",
      "Epoch 6:  89%|██████████████████████████████████████████████▍     | 33/37 [00:15<00:01,  2.80it/s, training_loss=0.218]\u001b[A\n",
      "Epoch 6:  89%|██████████████████████████████████████████████▍     | 33/37 [00:15<00:01,  2.80it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 6:  92%|███████████████████████████████████████████████▊    | 34/37 [00:15<00:01,  2.87it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 6:  92%|███████████████████████████████████████████████▊    | 34/37 [00:16<00:01,  2.87it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 6:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:16<00:00,  2.88it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 6:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:16<00:00,  2.88it/s, training_loss=0.159]\u001b[A\n",
      "Epoch 6:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:16<00:00,  2.89it/s, training_loss=0.159]\u001b[A\n",
      "Epoch 6:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:16<00:00,  2.89it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 6: 100%|████████████████████████████████████████████████████| 37/37 [00:16<00:00,  3.11it/s, training_loss=0.181]\u001b[A\n",
      "Epoch Progress:   6%|███▉                                                              | 6/100 [01:57<30:03, 19.19s/it]\u001b[A\n",
      "Epoch 7:   0%|                                                                                  | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:   0%|                                                             | 0/37 [00:00<?, ?it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 7:   3%|█▍                                                   | 1/37 [00:00<00:12,  2.91it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 7:   3%|█▍                                                   | 1/37 [00:00<00:12,  2.91it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 7:   5%|██▊                                                  | 2/37 [00:00<00:11,  2.99it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 7:   5%|██▊                                                  | 2/37 [00:01<00:11,  2.99it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 7:   8%|████▎                                                | 3/37 [00:01<00:11,  2.95it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 7:   8%|████▎                                                | 3/37 [00:01<00:11,  2.95it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 7:  11%|█████▋                                               | 4/37 [00:01<00:11,  2.94it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 7:  11%|█████▋                                               | 4/37 [00:01<00:11,  2.94it/s, training_loss=0.179]\u001b[A\n",
      "Epoch 7:  14%|███████▏                                             | 5/37 [00:01<00:10,  2.93it/s, training_loss=0.179]\u001b[A\n",
      "Epoch 7:  14%|███████▏                                             | 5/37 [00:02<00:10,  2.93it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 7:  16%|████████▌                                            | 6/37 [00:02<00:10,  2.97it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 7:  16%|████████▌                                            | 6/37 [00:02<00:10,  2.97it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 7:  19%|██████████                                           | 7/37 [00:02<00:10,  2.95it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 7:  19%|██████████                                           | 7/37 [00:02<00:10,  2.95it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 7:  22%|███████████▍                                         | 8/37 [00:02<00:09,  2.94it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 7:  22%|███████████▍                                         | 8/37 [00:03<00:09,  2.94it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 7:  24%|████████████▉                                        | 9/37 [00:03<00:09,  2.93it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 7:  24%|████████████▉                                        | 9/37 [00:03<00:09,  2.93it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 7:  27%|██████████████                                      | 10/37 [00:03<00:09,  2.92it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 7:  27%|██████████████                                      | 10/37 [00:03<00:09,  2.92it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 7:  30%|███████████████▍                                    | 11/37 [00:03<00:08,  2.92it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 7:  30%|███████████████▍                                    | 11/37 [00:04<00:08,  2.92it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 7:  32%|████████████████▊                                   | 12/37 [00:04<00:08,  2.96it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 7:  32%|████████████████▊                                   | 12/37 [00:04<00:08,  2.96it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 7:  35%|██████████████████▎                                 | 13/37 [00:04<00:08,  2.90it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 7:  35%|██████████████████▎                                 | 13/37 [00:04<00:08,  2.90it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 7:  38%|███████████████████▋                                | 14/37 [00:04<00:07,  2.99it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 7:  38%|███████████████████▋                                | 14/37 [00:05<00:07,  2.99it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 7:  41%|█████████████████████                               | 15/37 [00:05<00:07,  3.00it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 7:  41%|█████████████████████                               | 15/37 [00:05<00:07,  3.00it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 7:  43%|██████████████████████▍                             | 16/37 [00:05<00:06,  3.03it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 7:  43%|██████████████████████▍                             | 16/37 [00:05<00:06,  3.03it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 7:  46%|███████████████████████▉                            | 17/37 [00:05<00:06,  3.04it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 7:  46%|███████████████████████▉                            | 17/37 [00:06<00:06,  3.04it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 7:  49%|█████████████████████████▎                          | 18/37 [00:06<00:06,  3.04it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 7:  49%|█████████████████████████▎                          | 18/37 [00:06<00:06,  3.04it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 7:  51%|██████████████████████████▋                         | 19/37 [00:06<00:06,  3.00it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 7:  51%|██████████████████████████▋                         | 19/37 [00:06<00:06,  3.00it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 7:  54%|████████████████████████████                        | 20/37 [00:06<00:05,  3.01it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 7:  54%|████████████████████████████                        | 20/37 [00:07<00:05,  3.01it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 7:  57%|█████████████████████████████▌                      | 21/37 [00:07<00:05,  3.02it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 7:  57%|█████████████████████████████▌                      | 21/37 [00:07<00:05,  3.02it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 7:  59%|██████████████████████████████▉                     | 22/37 [00:07<00:04,  3.03it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 7:  59%|██████████████████████████████▉                     | 22/37 [00:07<00:04,  3.03it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 7:  62%|████████████████████████████████▎                   | 23/37 [00:07<00:04,  3.04it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 7:  62%|████████████████████████████████▎                   | 23/37 [00:08<00:04,  3.04it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 7:  65%|█████████████████████████████████▋                  | 24/37 [00:08<00:04,  3.04it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 7:  65%|█████████████████████████████████▋                  | 24/37 [00:08<00:04,  3.04it/s, training_loss=0.156]\u001b[A\n",
      "Epoch 7:  68%|███████████████████████████████████▏                | 25/37 [00:08<00:03,  3.04it/s, training_loss=0.156]\u001b[A\n",
      "Epoch 7:  68%|███████████████████████████████████▏                | 25/37 [00:08<00:03,  3.04it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 7:  70%|████████████████████████████████████▌               | 26/37 [00:08<00:03,  3.00it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 7:  70%|████████████████████████████████████▌               | 26/37 [00:09<00:03,  3.00it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 7:  73%|█████████████████████████████████████▉              | 27/37 [00:09<00:03,  3.02it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 7:  73%|█████████████████████████████████████▉              | 27/37 [00:09<00:03,  3.02it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 7:  76%|███████████████████████████████████████▎            | 28/37 [00:09<00:02,  3.03it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 7:  76%|███████████████████████████████████████▎            | 28/37 [00:09<00:02,  3.03it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 7:  78%|████████████████████████████████████████▊           | 29/37 [00:09<00:02,  3.03it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 7:  78%|████████████████████████████████████████▊           | 29/37 [00:10<00:02,  3.03it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 7:  81%|██████████████████████████████████████████▏         | 30/37 [00:10<00:02,  3.04it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 7:  81%|██████████████████████████████████████████▏         | 30/37 [00:10<00:02,  3.04it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 7:  84%|███████████████████████████████████████████▌        | 31/37 [00:10<00:01,  3.04it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 7:  84%|███████████████████████████████████████████▌        | 31/37 [00:10<00:01,  3.04it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 7:  86%|████████████████████████████████████████████▉       | 32/37 [00:10<00:01,  3.04it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 7:  86%|████████████████████████████████████████████▉       | 32/37 [00:11<00:01,  3.04it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 7:  89%|██████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  3.00it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 7:  89%|██████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  3.00it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 7:  92%|███████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.02it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 7:  92%|███████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.02it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 7:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.03it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 7:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:12<00:00,  3.03it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 7:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  3.03it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 7:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  3.03it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 7: 100%|████████████████████████████████████████████████████| 37/37 [00:12<00:00,  3.27it/s, training_loss=0.189]\u001b[A\n",
      "Epoch Progress:   7%|████▌                                                             | 7/100 [02:11<26:44, 17.25s/it]\u001b[A\n",
      "Epoch 8:   0%|                                                                                  | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:   0%|                                                             | 0/37 [00:00<?, ?it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 8:   3%|█▍                                                   | 1/37 [00:00<00:12,  2.78it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 8:   3%|█▍                                                   | 1/37 [00:00<00:12,  2.78it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 8:   5%|██▊                                                  | 2/37 [00:00<00:12,  2.86it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 8:   5%|██▊                                                  | 2/37 [00:01<00:12,  2.86it/s, training_loss=0.150]\u001b[A\n",
      "Epoch 8:   8%|████▎                                                | 3/37 [00:01<00:11,  3.00it/s, training_loss=0.150]\u001b[A\n",
      "Epoch 8:   8%|████▎                                                | 3/37 [00:01<00:11,  3.00it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 8:  11%|█████▋                                               | 4/37 [00:01<00:10,  3.02it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 8:  11%|█████▋                                               | 4/37 [00:01<00:10,  3.02it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 8:  14%|███████▏                                             | 5/37 [00:01<00:10,  3.03it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 8:  14%|███████▏                                             | 5/37 [00:01<00:10,  3.03it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 8:  16%|████████▌                                            | 6/37 [00:02<00:10,  2.99it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 8:  16%|████████▌                                            | 6/37 [00:02<00:10,  2.99it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 8:  19%|██████████                                           | 7/37 [00:02<00:09,  3.01it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 8:  19%|██████████                                           | 7/37 [00:02<00:09,  3.01it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 8:  22%|███████████▍                                         | 8/37 [00:02<00:09,  3.02it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 8:  22%|███████████▍                                         | 8/37 [00:02<00:09,  3.02it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 8:  24%|████████████▉                                        | 9/37 [00:02<00:09,  3.03it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 8:  24%|████████████▉                                        | 9/37 [00:03<00:09,  3.03it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 8:  27%|██████████████                                      | 10/37 [00:03<00:08,  3.04it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 8:  27%|██████████████                                      | 10/37 [00:03<00:08,  3.04it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 8:  30%|███████████████▍                                    | 11/37 [00:03<00:08,  3.04it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 8:  30%|███████████████▍                                    | 11/37 [00:03<00:08,  3.04it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 8:  32%|████████████████▊                                   | 12/37 [00:03<00:08,  3.00it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 8:  32%|████████████████▊                                   | 12/37 [00:04<00:08,  3.00it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 8:  35%|██████████████████▎                                 | 13/37 [00:04<00:07,  3.01it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 8:  35%|██████████████████▎                                 | 13/37 [00:04<00:07,  3.01it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 8:  38%|███████████████████▋                                | 14/37 [00:04<00:07,  3.02it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 8:  38%|███████████████████▋                                | 14/37 [00:04<00:07,  3.02it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 8:  41%|█████████████████████                               | 15/37 [00:04<00:07,  3.03it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 8:  41%|█████████████████████                               | 15/37 [00:05<00:07,  3.03it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 8:  43%|██████████████████████▍                             | 16/37 [00:05<00:06,  3.04it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 8:  43%|██████████████████████▍                             | 16/37 [00:05<00:06,  3.04it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 8:  46%|███████████████████████▉                            | 17/37 [00:05<00:06,  3.04it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 8:  46%|███████████████████████▉                            | 17/37 [00:05<00:06,  3.04it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 8:  49%|█████████████████████████▎                          | 18/37 [00:05<00:06,  3.00it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 8:  49%|█████████████████████████▎                          | 18/37 [00:06<00:06,  3.00it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 8:  51%|██████████████████████████▋                         | 19/37 [00:06<00:05,  3.01it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 8:  51%|██████████████████████████▋                         | 19/37 [00:06<00:05,  3.01it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 8:  54%|████████████████████████████                        | 20/37 [00:06<00:05,  3.02it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 8:  54%|████████████████████████████                        | 20/37 [00:06<00:05,  3.02it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 8:  57%|█████████████████████████████▌                      | 21/37 [00:06<00:05,  3.03it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 8:  57%|█████████████████████████████▌                      | 21/37 [00:07<00:05,  3.03it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 8:  59%|██████████████████████████████▉                     | 22/37 [00:07<00:05,  2.99it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 8:  59%|██████████████████████████████▉                     | 22/37 [00:07<00:05,  2.99it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 8:  62%|████████████████████████████████▎                   | 23/37 [00:07<00:04,  3.05it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 8:  62%|████████████████████████████████▎                   | 23/37 [00:07<00:04,  3.05it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 8:  65%|█████████████████████████████████▋                  | 24/37 [00:07<00:04,  3.05it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 8:  65%|█████████████████████████████████▋                  | 24/37 [00:08<00:04,  3.05it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 8:  68%|███████████████████████████████████▏                | 25/37 [00:08<00:03,  3.05it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 8:  68%|███████████████████████████████████▏                | 25/37 [00:08<00:03,  3.05it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 8:  70%|████████████████████████████████████▌               | 26/37 [00:08<00:03,  3.01it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 8:  70%|████████████████████████████████████▌               | 26/37 [00:08<00:03,  3.01it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 8:  73%|█████████████████████████████████████▉              | 27/37 [00:08<00:03,  3.02it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 8:  73%|█████████████████████████████████████▉              | 27/37 [00:09<00:03,  3.02it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 8:  76%|███████████████████████████████████████▎            | 28/37 [00:09<00:03,  2.99it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 8:  76%|███████████████████████████████████████▎            | 28/37 [00:09<00:03,  2.99it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 8:  78%|████████████████████████████████████████▊           | 29/37 [00:09<00:02,  3.00it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 8:  78%|████████████████████████████████████████▊           | 29/37 [00:09<00:02,  3.00it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 8:  81%|██████████████████████████████████████████▏         | 30/37 [00:09<00:02,  3.02it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 8:  81%|██████████████████████████████████████████▏         | 30/37 [00:10<00:02,  3.02it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 8:  84%|███████████████████████████████████████████▌        | 31/37 [00:10<00:01,  3.03it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 8:  84%|███████████████████████████████████████████▌        | 31/37 [00:10<00:01,  3.03it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 8:  86%|████████████████████████████████████████████▉       | 32/37 [00:10<00:01,  3.03it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 8:  86%|████████████████████████████████████████████▉       | 32/37 [00:10<00:01,  3.03it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 8:  89%|██████████████████████████████████████████████▍     | 33/37 [00:10<00:01,  2.99it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 8:  89%|██████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  2.99it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 8:  92%|███████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.05it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 8:  92%|███████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.05it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 8:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.05it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 8:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.05it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 8:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:11<00:00,  3.05it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 8:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  3.05it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 8: 100%|████████████████████████████████████████████████████| 37/37 [00:12<00:00,  3.29it/s, training_loss=0.168]\u001b[A\n",
      "Epoch Progress:   8%|█████▎                                                            | 8/100 [02:24<24:27, 15.95s/it]\u001b[A\n",
      "Epoch 9:   0%|                                                                                  | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:   0%|                                                             | 0/37 [00:00<?, ?it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 9:   3%|█▍                                                   | 1/37 [00:00<00:11,  3.05it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 9:   3%|█▍                                                   | 1/37 [00:00<00:11,  3.05it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 9:   5%|██▊                                                  | 2/37 [00:00<00:11,  3.05it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 9:   5%|██▊                                                  | 2/37 [00:00<00:11,  3.05it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 9:   8%|████▎                                                | 3/37 [00:00<00:11,  3.05it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 9:   8%|████▎                                                | 3/37 [00:01<00:11,  3.05it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 9:  11%|█████▋                                               | 4/37 [00:01<00:10,  3.05it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 9:  11%|█████▋                                               | 4/37 [00:01<00:10,  3.05it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 9:  14%|███████▏                                             | 5/37 [00:01<00:10,  3.05it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 9:  14%|███████▏                                             | 5/37 [00:01<00:10,  3.05it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 9:  16%|████████▌                                            | 6/37 [00:01<00:10,  3.05it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 9:  16%|████████▌                                            | 6/37 [00:02<00:10,  3.05it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 9:  19%|██████████                                           | 7/37 [00:02<00:09,  3.00it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 9:  19%|██████████                                           | 7/37 [00:02<00:09,  3.00it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 9:  22%|███████████▍                                         | 8/37 [00:02<00:09,  3.02it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 9:  22%|███████████▍                                         | 8/37 [00:02<00:09,  3.02it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 9:  24%|████████████▉                                        | 9/37 [00:02<00:09,  3.03it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 9:  24%|████████████▉                                        | 9/37 [00:03<00:09,  3.03it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 9:  27%|██████████████                                      | 10/37 [00:03<00:08,  3.03it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 9:  27%|██████████████                                      | 10/37 [00:03<00:08,  3.03it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 9:  30%|███████████████▍                                    | 11/37 [00:03<00:08,  3.08it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 9:  30%|███████████████▍                                    | 11/37 [00:03<00:08,  3.08it/s, training_loss=0.185]\u001b[A\n",
      "Epoch 9:  32%|████████████████▊                                   | 12/37 [00:03<00:08,  3.03it/s, training_loss=0.185]\u001b[A\n",
      "Epoch 9:  32%|████████████████▊                                   | 12/37 [00:04<00:08,  3.03it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 9:  35%|██████████████████▎                                 | 13/37 [00:04<00:07,  3.03it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 9:  35%|██████████████████▎                                 | 13/37 [00:04<00:07,  3.03it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 9:  38%|███████████████████▋                                | 14/37 [00:04<00:07,  3.04it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 9:  38%|███████████████████▋                                | 14/37 [00:04<00:07,  3.04it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 9:  41%|█████████████████████                               | 15/37 [00:04<00:07,  3.04it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 9:  41%|█████████████████████                               | 15/37 [00:05<00:07,  3.04it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 9:  43%|██████████████████████▍                             | 16/37 [00:05<00:06,  3.04it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 9:  43%|██████████████████████▍                             | 16/37 [00:05<00:06,  3.04it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 9:  46%|███████████████████████▉                            | 17/37 [00:05<00:06,  3.04it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 9:  46%|███████████████████████▉                            | 17/37 [00:05<00:06,  3.04it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 9:  49%|█████████████████████████▎                          | 18/37 [00:05<00:06,  3.05it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 9:  49%|█████████████████████████▎                          | 18/37 [00:06<00:06,  3.05it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 9:  51%|██████████████████████████▋                         | 19/37 [00:06<00:05,  3.05it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 9:  51%|██████████████████████████▋                         | 19/37 [00:06<00:05,  3.05it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 9:  54%|████████████████████████████                        | 20/37 [00:06<00:05,  3.05it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 9:  54%|████████████████████████████                        | 20/37 [00:06<00:05,  3.05it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 9:  57%|█████████████████████████████▌                      | 21/37 [00:06<00:05,  3.05it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 9:  57%|█████████████████████████████▌                      | 21/37 [00:07<00:05,  3.05it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 9:  59%|██████████████████████████████▉                     | 22/37 [00:07<00:04,  3.00it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 9:  59%|██████████████████████████████▉                     | 22/37 [00:07<00:04,  3.00it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 9:  62%|████████████████████████████████▎                   | 23/37 [00:07<00:04,  3.02it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 9:  62%|████████████████████████████████▎                   | 23/37 [00:07<00:04,  3.02it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 9:  65%|█████████████████████████████████▋                  | 24/37 [00:07<00:04,  3.03it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 9:  65%|█████████████████████████████████▋                  | 24/37 [00:08<00:04,  3.03it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 9:  68%|███████████████████████████████████▏                | 25/37 [00:08<00:03,  3.03it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 9:  68%|███████████████████████████████████▏                | 25/37 [00:08<00:03,  3.03it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 9:  70%|████████████████████████████████████▌               | 26/37 [00:08<00:03,  3.04it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 9:  70%|████████████████████████████████████▌               | 26/37 [00:08<00:03,  3.04it/s, training_loss=0.150]\u001b[A\n",
      "Epoch 9:  73%|█████████████████████████████████████▉              | 27/37 [00:08<00:03,  3.08it/s, training_loss=0.150]\u001b[A\n",
      "Epoch 9:  73%|█████████████████████████████████████▉              | 27/37 [00:09<00:03,  3.08it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 9:  76%|███████████████████████████████████████▎            | 28/37 [00:09<00:02,  3.08it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 9:  76%|███████████████████████████████████████▎            | 28/37 [00:09<00:02,  3.08it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 9:  78%|████████████████████████████████████████▊           | 29/37 [00:09<00:02,  3.07it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 9:  78%|████████████████████████████████████████▊           | 29/37 [00:09<00:02,  3.07it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 9:  81%|██████████████████████████████████████████▏         | 30/37 [00:09<00:02,  3.06it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 9:  81%|██████████████████████████████████████████▏         | 30/37 [00:10<00:02,  3.06it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 9:  84%|███████████████████████████████████████████▌        | 31/37 [00:10<00:01,  3.01it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 9:  84%|███████████████████████████████████████████▌        | 31/37 [00:10<00:01,  3.01it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 9:  86%|████████████████████████████████████████████▉       | 32/37 [00:10<00:01,  3.02it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 9:  86%|████████████████████████████████████████████▉       | 32/37 [00:10<00:01,  3.02it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 9:  89%|██████████████████████████████████████████████▍     | 33/37 [00:10<00:01,  3.03it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 9:  89%|██████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  3.03it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 9:  92%|███████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.04it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 9:  92%|███████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.04it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 9:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.04it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 9:  95%|█████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.04it/s, training_loss=0.171]\u001b[A\n",
      "Epoch 9:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:11<00:00,  3.04it/s, training_loss=0.171]\u001b[A\n",
      "Epoch 9:  97%|██████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  3.04it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 9: 100%|████████████████████████████████████████████████████| 37/37 [00:12<00:00,  3.23it/s, training_loss=0.161]\u001b[A\n",
      "Epoch Progress:   9%|█████▉                                                            | 9/100 [02:37<22:49, 15.05s/it]\u001b[A\n",
      "Epoch 10:   0%|                                                                                 | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:   0%|                                                            | 0/37 [00:00<?, ?it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 10:   3%|█▍                                                  | 1/37 [00:00<00:11,  3.05it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 10:   3%|█▍                                                  | 1/37 [00:00<00:11,  3.05it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 10:   5%|██▊                                                 | 2/37 [00:00<00:11,  2.97it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 10:   5%|██▊                                                 | 2/37 [00:00<00:11,  2.97it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 10:   8%|████▏                                               | 3/37 [00:00<00:11,  3.00it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 10:   8%|████▏                                               | 3/37 [00:01<00:11,  3.00it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 10:  11%|█████▌                                              | 4/37 [00:01<00:10,  3.08it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 10:  11%|█████▌                                              | 4/37 [00:01<00:10,  3.08it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 10:  14%|███████                                             | 5/37 [00:01<00:10,  3.02it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 10:  14%|███████                                             | 5/37 [00:01<00:10,  3.02it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 10:  16%|████████▍                                           | 6/37 [00:01<00:10,  3.03it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 10:  16%|████████▍                                           | 6/37 [00:02<00:10,  3.03it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 10:  19%|█████████▊                                          | 7/37 [00:02<00:09,  3.03it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 10:  19%|█████████▊                                          | 7/37 [00:02<00:09,  3.03it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 10:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.04it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 10:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.04it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 10:  24%|████████████▋                                       | 9/37 [00:02<00:09,  3.04it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 10:  24%|████████████▋                                       | 9/37 [00:03<00:09,  3.04it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 10:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.04it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 10:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.04it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 10:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  3.04it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 10:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  3.04it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 10:  32%|████████████████▌                                  | 12/37 [00:03<00:08,  3.05it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 10:  32%|████████████████▌                                  | 12/37 [00:04<00:08,  3.05it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 10:  35%|█████████████████▉                                 | 13/37 [00:04<00:07,  3.00it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 10:  35%|█████████████████▉                                 | 13/37 [00:04<00:07,  3.00it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 10:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  3.02it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 10:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  3.02it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 10:  41%|████████████████████▋                              | 15/37 [00:04<00:07,  3.03it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 10:  41%|████████████████████▋                              | 15/37 [00:05<00:07,  3.03it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 10:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.03it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 10:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.03it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 10:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  3.04it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 10:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  3.04it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 10:  49%|████████████████████████▊                          | 18/37 [00:05<00:06,  2.96it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 10:  49%|████████████████████████▊                          | 18/37 [00:06<00:06,  2.96it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 10:  51%|██████████████████████████▏                        | 19/37 [00:06<00:06,  2.98it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 10:  51%|██████████████████████████▏                        | 19/37 [00:06<00:06,  2.98it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 10:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  3.00it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 10:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  3.00it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 10:  57%|████████████████████████████▉                      | 21/37 [00:06<00:05,  3.02it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 10:  57%|████████████████████████████▉                      | 21/37 [00:07<00:05,  3.02it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 10:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:04,  3.03it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 10:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:04,  3.03it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 10:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  3.03it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 10:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  3.03it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 10:  65%|█████████████████████████████████                  | 24/37 [00:07<00:04,  3.04it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 10:  65%|█████████████████████████████████                  | 24/37 [00:08<00:04,  3.04it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 10:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:03,  3.08it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 10:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:03,  3.08it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 10:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  2.99it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 10:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  2.99it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 10:  73%|█████████████████████████████████████▏             | 27/37 [00:08<00:03,  3.05it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 10:  73%|█████████████████████████████████████▏             | 27/37 [00:09<00:03,  3.05it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 10:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:02,  3.05it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 10:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:02,  3.05it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 10:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  3.05it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 10:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  3.05it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 10:  81%|█████████████████████████████████████████▎         | 30/37 [00:09<00:02,  3.05it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 10:  81%|█████████████████████████████████████████▎         | 30/37 [00:10<00:02,  3.05it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 10:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:01,  3.05it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 10:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:01,  3.05it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 10:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  3.01it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 10:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  3.01it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 10:  89%|█████████████████████████████████████████████▍     | 33/37 [00:10<00:01,  3.02it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 10:  89%|█████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  3.02it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 10:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.03it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 10:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.03it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 10:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.03it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 10:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.03it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 10:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:11<00:00,  3.04it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 10:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  3.04it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 10: 100%|███████████████████████████████████████████████████| 37/37 [00:12<00:00,  3.27it/s, training_loss=0.115]\u001b[A\n",
      "Epoch Progress:  10%|██████▌                                                          | 10/100 [02:50<21:40, 14.45s/it]\u001b[A\n",
      "Epoch 11:   0%|                                                                                 | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:   0%|                                                            | 0/37 [00:00<?, ?it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 11:   3%|█▍                                                  | 1/37 [00:00<00:11,  3.05it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 11:   3%|█▍                                                  | 1/37 [00:00<00:11,  3.05it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 11:   5%|██▊                                                 | 2/37 [00:00<00:11,  3.05it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 11:   5%|██▊                                                 | 2/37 [00:00<00:11,  3.05it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 11:   8%|████▏                                               | 3/37 [00:00<00:11,  3.05it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 11:   8%|████▏                                               | 3/37 [00:01<00:11,  3.05it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 11:  11%|█████▌                                              | 4/37 [00:01<00:10,  3.05it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 11:  11%|█████▌                                              | 4/37 [00:01<00:10,  3.05it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 11:  14%|███████                                             | 5/37 [00:01<00:10,  3.05it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 11:  14%|███████                                             | 5/37 [00:01<00:10,  3.05it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 11:  16%|████████▍                                           | 6/37 [00:01<00:10,  3.05it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 11:  16%|████████▍                                           | 6/37 [00:02<00:10,  3.05it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 11:  19%|█████████▊                                          | 7/37 [00:02<00:09,  3.05it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 11:  19%|█████████▊                                          | 7/37 [00:02<00:09,  3.05it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 11:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.05it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 11:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.05it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 11:  24%|████████████▋                                       | 9/37 [00:02<00:09,  3.01it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 11:  24%|████████████▋                                       | 9/37 [00:03<00:09,  3.01it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 11:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.02it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 11:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.02it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 11:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  3.03it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 11:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  3.03it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 11:  32%|████████████████▌                                  | 12/37 [00:03<00:08,  3.04it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 11:  32%|████████████████▌                                  | 12/37 [00:04<00:08,  3.04it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 11:  35%|█████████████████▉                                 | 13/37 [00:04<00:07,  3.04it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 11:  35%|█████████████████▉                                 | 13/37 [00:04<00:07,  3.04it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 11:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  3.04it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 11:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  3.04it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 11:  41%|████████████████████▋                              | 15/37 [00:04<00:07,  3.04it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 11:  41%|████████████████████▋                              | 15/37 [00:05<00:07,  3.04it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 11:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.00it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 11:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.00it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 11:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  3.02it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 11:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  3.02it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 11:  49%|████████████████████████▊                          | 18/37 [00:05<00:06,  3.03it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 11:  49%|████████████████████████▊                          | 18/37 [00:06<00:06,  3.03it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 11:  51%|██████████████████████████▏                        | 19/37 [00:06<00:05,  3.03it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 11:  51%|██████████████████████████▏                        | 19/37 [00:06<00:05,  3.03it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 11:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  3.04it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 11:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  3.04it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 11:  57%|████████████████████████████▉                      | 21/37 [00:06<00:05,  3.04it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 11:  57%|████████████████████████████▉                      | 21/37 [00:07<00:05,  3.04it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 11:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:04,  3.04it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 11:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:04,  3.04it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 11:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  3.04it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 11:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  3.04it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 11:  65%|█████████████████████████████████                  | 24/37 [00:07<00:04,  3.05it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 11:  65%|█████████████████████████████████                  | 24/37 [00:08<00:04,  3.05it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 11:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:03,  3.05it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 11:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:03,  3.05it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 11:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  3.05it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 11:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  3.05it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 11:  73%|█████████████████████████████████████▏             | 27/37 [00:08<00:03,  3.09it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 11:  73%|█████████████████████████████████████▏             | 27/37 [00:09<00:03,  3.09it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 11:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:02,  3.08it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 11:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:02,  3.08it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 11:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  3.03it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 11:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  3.03it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 11:  81%|█████████████████████████████████████████▎         | 30/37 [00:09<00:02,  3.03it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 11:  81%|█████████████████████████████████████████▎         | 30/37 [00:10<00:02,  3.03it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 11:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:01,  3.04it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 11:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:01,  3.04it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 11:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  3.04it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 11:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  3.04it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 11:  89%|█████████████████████████████████████████████▍     | 33/37 [00:10<00:01,  3.04it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 11:  89%|█████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  3.04it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 11:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.04it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 11:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.04it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 11:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.05it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 11:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.05it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 11:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:11<00:00,  3.05it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 11:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  3.05it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 11: 100%|███████████████████████████████████████████████████| 37/37 [00:12<00:00,  3.28it/s, training_loss=0.060]\u001b[A\n",
      "Epoch Progress:  11%|███████▏                                                         | 11/100 [03:03<20:50, 14.05s/it]\u001b[A\n",
      "Epoch 12:   0%|                                                                                 | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:   0%|                                                            | 0/37 [00:00<?, ?it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 12:   3%|█▍                                                  | 1/37 [00:00<00:11,  3.05it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 12:   3%|█▍                                                  | 1/37 [00:00<00:11,  3.05it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 12:   5%|██▊                                                 | 2/37 [00:00<00:11,  3.05it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 12:   5%|██▊                                                 | 2/37 [00:00<00:11,  3.05it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 12:   8%|████▏                                               | 3/37 [00:00<00:11,  3.05it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 12:   8%|████▏                                               | 3/37 [00:01<00:11,  3.05it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 12:  11%|█████▌                                              | 4/37 [00:01<00:10,  3.05it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 12:  11%|█████▌                                              | 4/37 [00:01<00:10,  3.05it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 12:  14%|███████                                             | 5/37 [00:01<00:10,  3.05it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 12:  14%|███████                                             | 5/37 [00:01<00:10,  3.05it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 12:  16%|████████▍                                           | 6/37 [00:01<00:10,  3.05it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 12:  16%|████████▍                                           | 6/37 [00:02<00:10,  3.05it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 12:  19%|█████████▊                                          | 7/37 [00:02<00:09,  3.05it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 12:  19%|█████████▊                                          | 7/37 [00:02<00:09,  3.05it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 12:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.00it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 12:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.00it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 12:  24%|████████████▋                                       | 9/37 [00:02<00:09,  3.02it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 12:  24%|████████████▋                                       | 9/37 [00:03<00:09,  3.02it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 12:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.03it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 12:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.03it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 12:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  3.03it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 12:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  3.03it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 12:  32%|████████████████▌                                  | 12/37 [00:03<00:08,  3.04it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 12:  32%|████████████████▌                                  | 12/37 [00:04<00:08,  3.04it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 12:  35%|█████████████████▉                                 | 13/37 [00:04<00:07,  3.04it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 12:  35%|█████████████████▉                                 | 13/37 [00:04<00:07,  3.04it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 12:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  3.00it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 12:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  3.00it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 12:  41%|████████████████████▋                              | 15/37 [00:04<00:07,  3.01it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 12:  41%|████████████████████▋                              | 15/37 [00:05<00:07,  3.01it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 12:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.02it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 12:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.02it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 12:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  3.08it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 12:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  3.08it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 12:  49%|████████████████████████▊                          | 18/37 [00:05<00:06,  3.07it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 12:  49%|████████████████████████▊                          | 18/37 [00:06<00:06,  3.07it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 12:  51%|██████████████████████████▏                        | 19/37 [00:06<00:05,  3.02it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 12:  51%|██████████████████████████▏                        | 19/37 [00:06<00:05,  3.02it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 12:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  2.98it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 12:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  2.98it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 12:  57%|████████████████████████████▉                      | 21/37 [00:06<00:05,  3.00it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 12:  57%|████████████████████████████▉                      | 21/37 [00:07<00:05,  3.00it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 12:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:05,  2.97it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 12:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:05,  2.97it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 12:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  3.04it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 12:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  3.04it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 12:  65%|█████████████████████████████████                  | 24/37 [00:07<00:04,  3.00it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 12:  65%|█████████████████████████████████                  | 24/37 [00:08<00:04,  3.00it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 12:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:03,  3.06it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 12:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:03,  3.06it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 12:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  3.01it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 12:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  3.01it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 12:  73%|█████████████████████████████████████▏             | 27/37 [00:08<00:03,  3.02it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 12:  73%|█████████████████████████████████████▏             | 27/37 [00:09<00:03,  3.02it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 12:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:02,  3.03it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 12:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:02,  3.03it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 12:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  3.04it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 12:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  3.04it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 12:  81%|█████████████████████████████████████████▎         | 30/37 [00:09<00:02,  3.04it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 12:  81%|█████████████████████████████████████████▎         | 30/37 [00:10<00:02,  3.04it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 12:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:01,  3.00it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 12:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:01,  3.00it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 12:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  3.02it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 12:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  3.02it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 12:  89%|█████████████████████████████████████████████▍     | 33/37 [00:10<00:01,  3.03it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 12:  89%|█████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  3.03it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 12:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.03it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 12:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.03it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 12:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.04it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 12:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.04it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 12:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:11<00:00,  3.00it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 12:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  3.00it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 12: 100%|███████████████████████████████████████████████████| 37/37 [00:12<00:00,  3.24it/s, training_loss=0.017]\u001b[A\n",
      "Epoch Progress:  12%|███████▊                                                         | 12/100 [03:16<20:13, 13.78s/it]\u001b[A\n",
      "Epoch 13:   0%|                                                                                 | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:   0%|                                                            | 0/37 [00:00<?, ?it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 13:   3%|█▍                                                  | 1/37 [00:00<00:11,  3.05it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 13:   3%|█▍                                                  | 1/37 [00:00<00:11,  3.05it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 13:   5%|██▊                                                 | 2/37 [00:00<00:11,  3.05it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 13:   5%|██▊                                                 | 2/37 [00:00<00:11,  3.05it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 13:   8%|████▏                                               | 3/37 [00:00<00:11,  3.05it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 13:   8%|████▏                                               | 3/37 [00:01<00:11,  3.05it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 13:  11%|█████▌                                              | 4/37 [00:01<00:11,  2.99it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 13:  11%|█████▌                                              | 4/37 [00:01<00:11,  2.99it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 13:  14%|███████                                             | 5/37 [00:01<00:10,  3.06it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 13:  14%|███████                                             | 5/37 [00:01<00:10,  3.06it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 13:  16%|████████▍                                           | 6/37 [00:01<00:10,  3.01it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 13:  16%|████████▍                                           | 6/37 [00:02<00:10,  3.01it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 13:  19%|█████████▊                                          | 7/37 [00:02<00:09,  3.02it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 13:  19%|█████████▊                                          | 7/37 [00:02<00:09,  3.02it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 13:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.03it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 13:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.03it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 13:  24%|████████████▋                                       | 9/37 [00:02<00:09,  3.00it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 13:  24%|████████████▋                                       | 9/37 [00:03<00:09,  3.00it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 13:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.01it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 13:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.01it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 13:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  2.98it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 13:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  2.98it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 13:  32%|████████████████▌                                  | 12/37 [00:03<00:08,  3.04it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 13:  32%|████████████████▌                                  | 12/37 [00:04<00:08,  3.04it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 13:  35%|█████████████████▉                                 | 13/37 [00:04<00:07,  3.00it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 13:  35%|█████████████████▉                                 | 13/37 [00:04<00:07,  3.00it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 13:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  3.02it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 13:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  3.02it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 13:  41%|████████████████████▋                              | 15/37 [00:04<00:07,  3.03it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 13:  41%|████████████████████▋                              | 15/37 [00:05<00:07,  3.03it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 13:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.03it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 13:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.03it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 13:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  3.04it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 13:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  3.04it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 13:  49%|████████████████████████▊                          | 18/37 [00:05<00:06,  3.00it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 13:  49%|████████████████████████▊                          | 18/37 [00:06<00:06,  3.00it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 13:  51%|██████████████████████████▏                        | 19/37 [00:06<00:05,  3.01it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 13:  51%|██████████████████████████▏                        | 19/37 [00:06<00:05,  3.01it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 13:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  2.99it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 13:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  2.99it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 13:  57%|████████████████████████████▉                      | 21/37 [00:06<00:05,  3.04it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 13:  57%|████████████████████████████▉                      | 21/37 [00:07<00:05,  3.04it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 13:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:04,  3.04it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 13:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:04,  3.04it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 13:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  3.04it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 13:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  3.04it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 13:  65%|█████████████████████████████████                  | 24/37 [00:07<00:04,  3.00it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 13:  65%|█████████████████████████████████                  | 24/37 [00:08<00:04,  3.00it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 13:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:03,  3.02it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 13:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:03,  3.02it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 13:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  3.03it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 13:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  3.03it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 13:  73%|█████████████████████████████████████▏             | 27/37 [00:08<00:03,  3.03it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 13:  73%|█████████████████████████████████████▏             | 27/37 [00:09<00:03,  3.03it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 13:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:03,  2.99it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 13:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:03,  2.99it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 13:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  3.05it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 13:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  3.05it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 13:  81%|█████████████████████████████████████████▎         | 30/37 [00:09<00:02,  3.01it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 13:  81%|█████████████████████████████████████████▎         | 30/37 [00:10<00:02,  3.01it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 13:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:01,  3.02it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 13:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:01,  3.02it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 13:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  2.99it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 13:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  2.99it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 13:  89%|█████████████████████████████████████████████▍     | 33/37 [00:10<00:01,  3.05it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 13:  89%|█████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  3.05it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 13:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.05it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 13:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.05it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 13:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.05it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 13:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.05it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 13:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:11<00:00,  3.05it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 13:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  3.05it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 13: 100%|███████████████████████████████████████████████████| 37/37 [00:12<00:00,  3.23it/s, training_loss=0.017]\u001b[A\n",
      "Epoch Progress:  13%|████████▍                                                        | 13/100 [03:29<19:43, 13.60s/it]\u001b[A\n",
      "Epoch 14:   0%|                                                                                 | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:   0%|                                                            | 0/37 [00:00<?, ?it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 14:   3%|█▍                                                  | 1/37 [00:00<00:12,  2.91it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 14:   3%|█▍                                                  | 1/37 [00:00<00:12,  2.91it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 14:   5%|██▊                                                 | 2/37 [00:00<00:11,  3.07it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 14:   5%|██▊                                                 | 2/37 [00:00<00:11,  3.07it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 14:   8%|████▏                                               | 3/37 [00:00<00:11,  3.00it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 14:   8%|████▏                                               | 3/37 [00:01<00:11,  3.00it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 14:  11%|█████▌                                              | 4/37 [00:01<00:10,  3.02it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 14:  11%|█████▌                                              | 4/37 [00:01<00:10,  3.02it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 14:  14%|███████                                             | 5/37 [00:01<00:10,  3.03it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 14:  14%|███████                                             | 5/37 [00:01<00:10,  3.03it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 14:  16%|████████▍                                           | 6/37 [00:01<00:10,  2.99it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 14:  16%|████████▍                                           | 6/37 [00:02<00:10,  2.99it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 14:  19%|█████████▊                                          | 7/37 [00:02<00:10,  2.96it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 14:  19%|█████████▊                                          | 7/37 [00:02<00:10,  2.96it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 14:  22%|███████████▏                                        | 8/37 [00:02<00:09,  2.99it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 14:  22%|███████████▏                                        | 8/37 [00:02<00:09,  2.99it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 14:  24%|████████████▋                                       | 9/37 [00:02<00:09,  3.01it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 14:  24%|████████████▋                                       | 9/37 [00:03<00:09,  3.01it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 14:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.02it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 14:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.02it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 14:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  2.99it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 14:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  2.99it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 14:  32%|████████████████▌                                  | 12/37 [00:03<00:08,  3.05it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 14:  32%|████████████████▌                                  | 12/37 [00:04<00:08,  3.05it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 14:  35%|█████████████████▉                                 | 13/37 [00:04<00:07,  3.09it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 14:  35%|█████████████████▉                                 | 13/37 [00:04<00:07,  3.09it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 14:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  3.08it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 14:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  3.08it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 14:  41%|████████████████████▋                              | 15/37 [00:04<00:07,  3.03it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 14:  41%|████████████████████▋                              | 15/37 [00:05<00:07,  3.03it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 14:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.03it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 14:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.03it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 14:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  3.04it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 14:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  3.04it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 14:  49%|████████████████████████▊                          | 18/37 [00:05<00:06,  3.04it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 14:  49%|████████████████████████▊                          | 18/37 [00:06<00:06,  3.04it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 14:  51%|██████████████████████████▏                        | 19/37 [00:06<00:05,  3.04it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 14:  51%|██████████████████████████▏                        | 19/37 [00:06<00:05,  3.04it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 14:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  3.04it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 14:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  3.04it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 14:  57%|████████████████████████████▉                      | 21/37 [00:06<00:05,  3.05it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 14:  57%|████████████████████████████▉                      | 21/37 [00:07<00:05,  3.05it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 14:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:04,  3.05it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 14:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:04,  3.05it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 14:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  3.00it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 14:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  3.00it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 14:  65%|█████████████████████████████████                  | 24/37 [00:07<00:04,  3.02it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 14:  65%|█████████████████████████████████                  | 24/37 [00:08<00:04,  3.02it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 14:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:03,  3.03it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 14:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:03,  3.03it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 14:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  3.03it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 14:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  3.03it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 14:  73%|█████████████████████████████████████▏             | 27/37 [00:08<00:03,  3.04it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 14:  73%|█████████████████████████████████████▏             | 27/37 [00:09<00:03,  3.04it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 14:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:02,  3.04it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 14:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:02,  3.04it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 14:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  3.04it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 14:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  3.04it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 14:  81%|█████████████████████████████████████████▎         | 30/37 [00:09<00:02,  3.00it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 14:  81%|█████████████████████████████████████████▎         | 30/37 [00:10<00:02,  3.00it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 14:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:01,  3.02it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 14:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:01,  3.02it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 14:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  3.03it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 14:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  3.03it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 14:  89%|█████████████████████████████████████████████▍     | 33/37 [00:10<00:01,  3.03it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 14:  89%|█████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  3.03it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 14:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.04it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 14:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.04it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 14:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.04it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 14:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.04it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 14:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:11<00:00,  3.04it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 14:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  3.04it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 14: 100%|███████████████████████████████████████████████████| 37/37 [00:12<00:00,  3.23it/s, training_loss=0.027]\u001b[A\n",
      "Epoch Progress:  14%|█████████                                                        | 14/100 [03:43<19:18, 13.48s/it]\u001b[A\n",
      "Epoch 15:   0%|                                                                                 | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:   0%|                                                            | 0/37 [00:00<?, ?it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 15:   3%|█▍                                                  | 1/37 [00:00<00:11,  3.13it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 15:   3%|█▍                                                  | 1/37 [00:00<00:11,  3.13it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 15:   5%|██▊                                                 | 2/37 [00:00<00:11,  3.13it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 15:   5%|██▊                                                 | 2/37 [00:00<00:11,  3.13it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:   8%|████▏                                               | 3/37 [00:00<00:10,  3.16it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:   8%|████▏                                               | 3/37 [00:01<00:10,  3.16it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 15:  11%|█████▌                                              | 4/37 [00:01<00:10,  3.06it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 15:  11%|█████▌                                              | 4/37 [00:01<00:10,  3.06it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 15:  14%|███████                                             | 5/37 [00:01<00:10,  3.05it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 15:  14%|███████                                             | 5/37 [00:01<00:10,  3.05it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:  16%|████████▍                                           | 6/37 [00:01<00:10,  3.05it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:  16%|████████▍                                           | 6/37 [00:02<00:10,  3.05it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:  19%|█████████▊                                          | 7/37 [00:02<00:09,  3.05it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:  19%|█████████▊                                          | 7/37 [00:02<00:09,  3.05it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 15:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.05it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 15:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.05it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 15:  24%|████████████▋                                       | 9/37 [00:02<00:09,  3.05it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 15:  24%|████████████▋                                       | 9/37 [00:03<00:09,  3.05it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.00it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.00it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 15:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  3.02it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 15:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  3.02it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 15:  32%|████████████████▌                                  | 12/37 [00:03<00:08,  3.03it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 15:  32%|████████████████▌                                  | 12/37 [00:04<00:08,  3.03it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 15:  35%|█████████████████▉                                 | 13/37 [00:04<00:08,  2.99it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 15:  35%|█████████████████▉                                 | 13/37 [00:04<00:08,  2.99it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 15:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  3.01it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 15:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  3.01it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:  41%|████████████████████▋                              | 15/37 [00:04<00:07,  3.02it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:  41%|████████████████████▋                              | 15/37 [00:05<00:07,  3.02it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.03it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.03it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  2.99it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  2.99it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 15:  49%|████████████████████████▊                          | 18/37 [00:05<00:06,  2.97it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 15:  49%|████████████████████████▊                          | 18/37 [00:06<00:06,  2.97it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  51%|██████████████████████████▏                        | 19/37 [00:06<00:06,  2.99it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  51%|██████████████████████████▏                        | 19/37 [00:06<00:06,  2.99it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  3.01it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  3.01it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 15:  57%|████████████████████████████▉                      | 21/37 [00:06<00:05,  2.98it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 15:  57%|████████████████████████████▉                      | 21/37 [00:07<00:05,  2.98it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:05,  3.00it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:05,  3.00it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 15:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  2.97it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 15:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  2.97it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 15:  65%|█████████████████████████████████                  | 24/37 [00:07<00:04,  2.95it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 15:  65%|█████████████████████████████████                  | 24/37 [00:08<00:04,  2.95it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:04,  2.94it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:04,  2.94it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 15:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  2.93it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 15:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  2.93it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 15:  73%|█████████████████████████████████████▏             | 27/37 [00:08<00:03,  2.96it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 15:  73%|█████████████████████████████████████▏             | 27/37 [00:09<00:03,  2.96it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 15:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:03,  2.95it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 15:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:03,  2.95it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 15:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  2.98it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 15:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  2.98it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 15:  81%|█████████████████████████████████████████▎         | 30/37 [00:09<00:02,  3.00it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 15:  81%|█████████████████████████████████████████▎         | 30/37 [00:10<00:02,  3.00it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:02,  2.97it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:02,  2.97it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  2.91it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 15:  86%|████████████████████████████████████████████       | 32/37 [00:11<00:01,  2.91it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  89%|█████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  2.91it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15:  89%|█████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  2.91it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 15:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:01,  2.95it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 15:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:01,  2.95it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 15:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  2.94it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 15:  95%|████████████████████████████████████████████████▏  | 35/37 [00:12<00:00,  2.94it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 15:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  2.97it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 15:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  2.97it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 15: 100%|███████████████████████████████████████████████████| 37/37 [00:12<00:00,  3.17it/s, training_loss=0.004]\u001b[A\n",
      "Epoch Progress:  15%|█████████▊                                                       | 15/100 [03:56<19:01, 13.43s/it]\u001b[A\n",
      "Epoch 16:   0%|                                                                                 | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:   0%|                                                            | 0/37 [00:00<?, ?it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:   3%|█▍                                                  | 1/37 [00:00<00:12,  2.78it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:   3%|█▍                                                  | 1/37 [00:00<00:12,  2.78it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 16:   5%|██▊                                                 | 2/37 [00:00<00:12,  2.86it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 16:   5%|██▊                                                 | 2/37 [00:01<00:12,  2.86it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:   8%|████▏                                               | 3/37 [00:01<00:11,  2.94it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:   8%|████▏                                               | 3/37 [00:01<00:11,  2.94it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 16:  11%|█████▌                                              | 4/37 [00:01<00:11,  2.98it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 16:  11%|█████▌                                              | 4/37 [00:01<00:11,  2.98it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  14%|███████                                             | 5/37 [00:01<00:10,  3.01it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  14%|███████                                             | 5/37 [00:02<00:10,  3.01it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 16:  16%|████████▍                                           | 6/37 [00:02<00:10,  3.02it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 16:  16%|████████▍                                           | 6/37 [00:02<00:10,  3.02it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 16:  19%|█████████▊                                          | 7/37 [00:02<00:09,  3.03it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 16:  19%|█████████▊                                          | 7/37 [00:02<00:09,  3.03it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.04it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.04it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  24%|████████████▋                                       | 9/37 [00:02<00:09,  3.04it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  24%|████████████▋                                       | 9/37 [00:03<00:09,  3.04it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  27%|█████████████▊                                     | 10/37 [00:03<00:09,  3.00it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  27%|█████████████▊                                     | 10/37 [00:03<00:09,  3.00it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  2.92it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  30%|███████████████▏                                   | 11/37 [00:04<00:08,  2.92it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 16:  32%|████████████████▌                                  | 12/37 [00:04<00:08,  2.95it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 16:  32%|████████████████▌                                  | 12/37 [00:04<00:08,  2.95it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 16:  35%|█████████████████▉                                 | 13/37 [00:04<00:08,  2.98it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 16:  35%|█████████████████▉                                 | 13/37 [00:04<00:08,  2.98it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  2.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  38%|███████████████████▎                               | 14/37 [00:05<00:07,  2.99it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:  41%|████████████████████▋                              | 15/37 [00:05<00:07,  2.98it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:  41%|████████████████████▋                              | 15/37 [00:05<00:07,  2.98it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:  43%|██████████████████████                             | 16/37 [00:05<00:07,  2.94it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:  43%|██████████████████████                             | 16/37 [00:05<00:07,  2.94it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  3.00it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:  46%|███████████████████████▍                           | 17/37 [00:06<00:06,  3.00it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 16:  49%|████████████████████████▊                          | 18/37 [00:06<00:06,  3.00it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 16:  49%|████████████████████████▊                          | 18/37 [00:06<00:06,  3.00it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 16:  51%|██████████████████████████▏                        | 19/37 [00:06<00:06,  3.00it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 16:  51%|██████████████████████████▏                        | 19/37 [00:06<00:06,  3.00it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 16:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  3.01it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 16:  54%|███████████████████████████▌                       | 20/37 [00:07<00:05,  3.01it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 16:  57%|████████████████████████████▉                      | 21/37 [00:07<00:05,  2.99it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 16:  57%|████████████████████████████▉                      | 21/37 [00:07<00:05,  2.99it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:05,  2.99it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:05,  2.99it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  3.02it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 16:  62%|███████████████████████████████▋                   | 23/37 [00:08<00:04,  3.02it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 16:  65%|█████████████████████████████████                  | 24/37 [00:08<00:04,  2.99it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 16:  65%|█████████████████████████████████                  | 24/37 [00:08<00:04,  2.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:04,  2.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:04,  2.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 16:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  3.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 16:  70%|███████████████████████████████████▊               | 26/37 [00:09<00:03,  3.04it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  73%|█████████████████████████████████████▏             | 27/37 [00:09<00:03,  3.03it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  73%|█████████████████████████████████████▏             | 27/37 [00:09<00:03,  3.03it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:02,  3.02it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:02,  3.02it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  3.03it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  78%|███████████████████████████████████████▉           | 29/37 [00:10<00:02,  3.03it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  81%|█████████████████████████████████████████▎         | 30/37 [00:10<00:02,  3.00it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  81%|█████████████████████████████████████████▎         | 30/37 [00:10<00:02,  3.00it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 16:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:02,  2.97it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 16:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:02,  2.97it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 16:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  3.02it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 16:  86%|████████████████████████████████████████████       | 32/37 [00:11<00:01,  3.02it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  89%|█████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  2.96it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  89%|█████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  2.96it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.00it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.00it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 16:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  2.97it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 16:  95%|████████████████████████████████████████████████▏  | 35/37 [00:12<00:00,  2.97it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  2.90it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 16:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  2.90it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 16: 100%|███████████████████████████████████████████████████| 37/37 [00:12<00:00,  3.10it/s, training_loss=0.002]\u001b[A\n",
      "Epoch Progress:  16%|██████████▍                                                      | 16/100 [04:09<18:47, 13.42s/it]\u001b[A\n",
      "Epoch 17:   0%|                                                                                 | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:   0%|                                                            | 0/37 [00:00<?, ?it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:   3%|█▍                                                  | 1/37 [00:00<00:12,  2.84it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:   3%|█▍                                                  | 1/37 [00:00<00:12,  2.84it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:   5%|██▊                                                 | 2/37 [00:00<00:11,  3.00it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:   5%|██▊                                                 | 2/37 [00:01<00:11,  3.00it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 17:   8%|████▏                                               | 3/37 [00:01<00:11,  2.93it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 17:   8%|████▏                                               | 3/37 [00:01<00:11,  2.93it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  11%|█████▌                                              | 4/37 [00:01<00:10,  3.02it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  11%|█████▌                                              | 4/37 [00:01<00:10,  3.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  14%|███████                                             | 5/37 [00:01<00:10,  3.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  14%|███████                                             | 5/37 [00:02<00:10,  3.01it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 17:  16%|████████▍                                           | 6/37 [00:02<00:10,  3.00it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 17:  16%|████████▍                                           | 6/37 [00:02<00:10,  3.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  19%|█████████▊                                          | 7/37 [00:02<00:10,  2.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  19%|█████████▊                                          | 7/37 [00:02<00:10,  2.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  22%|███████████▏                                        | 8/37 [00:02<00:09,  2.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  22%|███████████▏                                        | 8/37 [00:03<00:09,  2.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  24%|████████████▋                                       | 9/37 [00:03<00:09,  3.00it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  24%|████████████▋                                       | 9/37 [00:03<00:09,  3.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  27%|█████████████▊                                     | 10/37 [00:03<00:08,  3.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  3.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  3.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  32%|████████████████▌                                  | 12/37 [00:03<00:08,  3.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  32%|████████████████▌                                  | 12/37 [00:04<00:08,  3.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  35%|█████████████████▉                                 | 13/37 [00:04<00:07,  3.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  35%|█████████████████▉                                 | 13/37 [00:04<00:07,  3.04it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  2.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  38%|███████████████████▎                               | 14/37 [00:05<00:07,  2.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  41%|████████████████████▋                              | 15/37 [00:05<00:07,  3.01it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  41%|████████████████████▋                              | 15/37 [00:05<00:07,  3.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  43%|██████████████████████                             | 16/37 [00:05<00:06,  3.00it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 17:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  3.02it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 17:  46%|███████████████████████▍                           | 17/37 [00:06<00:06,  3.02it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  49%|████████████████████████▊                          | 18/37 [00:06<00:06,  2.96it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  49%|████████████████████████▊                          | 18/37 [00:06<00:06,  2.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  51%|██████████████████████████▏                        | 19/37 [00:06<00:06,  2.98it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  51%|██████████████████████████▏                        | 19/37 [00:06<00:06,  2.98it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  2.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  2.99it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 17:  57%|████████████████████████████▉                      | 21/37 [00:06<00:05,  3.03it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 17:  57%|████████████████████████████▉                      | 21/37 [00:07<00:05,  3.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:04,  3.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:04,  3.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  3.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  62%|███████████████████████████████▋                   | 23/37 [00:08<00:04,  3.02it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 17:  65%|█████████████████████████████████                  | 24/37 [00:08<00:04,  2.97it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 17:  65%|█████████████████████████████████                  | 24/37 [00:08<00:04,  2.97it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:03,  3.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:03,  3.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  3.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  3.02it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 17:  73%|█████████████████████████████████████▏             | 27/37 [00:08<00:03,  3.01it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 17:  73%|█████████████████████████████████████▏             | 27/37 [00:09<00:03,  3.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:03,  2.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:03,  2.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  2.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  2.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  81%|█████████████████████████████████████████▎         | 30/37 [00:09<00:02,  3.05it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  81%|█████████████████████████████████████████▎         | 30/37 [00:10<00:02,  3.05it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:02,  2.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  84%|██████████████████████████████████████████▋        | 31/37 [00:10<00:02,  2.96it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  3.00it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17:  86%|████████████████████████████████████████████       | 32/37 [00:10<00:01,  3.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  89%|█████████████████████████████████████████████▍     | 33/37 [00:10<00:01,  3.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  89%|█████████████████████████████████████████████▍     | 33/37 [00:11<00:01,  3.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  92%|██████████████████████████████████████████████▊    | 34/37 [00:11<00:00,  3.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  95%|████████████████████████████████████████████████▏  | 35/37 [00:11<00:00,  3.04it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:11<00:00,  2.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 17:  97%|█████████████████████████████████████████████████▌ | 36/37 [00:12<00:00,  2.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 17: 100%|███████████████████████████████████████████████████| 37/37 [00:12<00:00,  3.17it/s, training_loss=0.003]\u001b[A\n",
      "Epoch Progress:  17%|███████████                                                      | 17/100 [04:23<18:30, 13.37s/it]\u001b[A\n",
      "Epoch 18:   0%|                                                                                 | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:   0%|                                                            | 0/37 [00:00<?, ?it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:   3%|█▍                                                  | 1/37 [00:00<00:13,  2.72it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:   3%|█▍                                                  | 1/37 [00:00<00:13,  2.72it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:   5%|██▊                                                 | 2/37 [00:00<00:12,  2.80it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:   5%|██▊                                                 | 2/37 [00:01<00:12,  2.80it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:   8%|████▏                                               | 3/37 [00:01<00:11,  2.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:   8%|████▏                                               | 3/37 [00:01<00:11,  2.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  11%|█████▌                                              | 4/37 [00:01<00:11,  2.94it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  11%|█████▌                                              | 4/37 [00:01<00:11,  2.94it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  14%|███████                                             | 5/37 [00:01<00:10,  2.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  14%|███████                                             | 5/37 [00:02<00:10,  2.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  16%|████████▍                                           | 6/37 [00:02<00:10,  2.97it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  16%|████████▍                                           | 6/37 [00:02<00:10,  2.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  19%|█████████▊                                          | 7/37 [00:02<00:10,  2.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  19%|█████████▊                                          | 7/37 [00:02<00:10,  2.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  22%|███████████▏                                        | 8/37 [00:02<00:09,  3.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  22%|███████████▏                                        | 8/37 [00:03<00:09,  3.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  24%|████████████▋                                       | 9/37 [00:03<00:09,  2.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  24%|████████████▋                                       | 9/37 [00:03<00:09,  2.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  27%|█████████████▊                                     | 10/37 [00:03<00:09,  2.92it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  27%|█████████████▊                                     | 10/37 [00:03<00:09,  2.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  30%|███████████████▏                                   | 11/37 [00:03<00:08,  2.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  30%|███████████████▏                                   | 11/37 [00:04<00:08,  2.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  32%|████████████████▌                                  | 12/37 [00:04<00:08,  2.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  32%|████████████████▌                                  | 12/37 [00:04<00:08,  2.94it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  35%|█████████████████▉                                 | 13/37 [00:04<00:08,  2.93it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  35%|█████████████████▉                                 | 13/37 [00:04<00:08,  2.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  38%|███████████████████▎                               | 14/37 [00:04<00:07,  2.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  38%|███████████████████▎                               | 14/37 [00:05<00:07,  2.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  41%|████████████████████▋                              | 15/37 [00:05<00:07,  2.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  41%|████████████████████▋                              | 15/37 [00:05<00:07,  2.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  43%|██████████████████████                             | 16/37 [00:05<00:07,  2.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  43%|██████████████████████                             | 16/37 [00:05<00:07,  2.97it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 18:  46%|███████████████████████▍                           | 17/37 [00:05<00:06,  2.96it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 18:  46%|███████████████████████▍                           | 17/37 [00:06<00:06,  2.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  49%|████████████████████████▊                          | 18/37 [00:06<00:06,  2.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  49%|████████████████████████▊                          | 18/37 [00:06<00:06,  2.95it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  51%|██████████████████████████▏                        | 19/37 [00:06<00:06,  2.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  51%|██████████████████████████▏                        | 19/37 [00:06<00:06,  2.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  54%|███████████████████████████▌                       | 20/37 [00:06<00:05,  2.97it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  54%|███████████████████████████▌                       | 20/37 [00:07<00:05,  2.97it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  57%|████████████████████████████▉                      | 21/37 [00:07<00:05,  2.94it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  57%|████████████████████████████▉                      | 21/37 [00:07<00:05,  2.94it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:05,  2.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  59%|██████████████████████████████▎                    | 22/37 [00:07<00:05,  2.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  62%|███████████████████████████████▋                   | 23/37 [00:07<00:04,  2.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  62%|███████████████████████████████▋                   | 23/37 [00:08<00:04,  2.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  65%|█████████████████████████████████                  | 24/37 [00:08<00:04,  3.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  65%|█████████████████████████████████                  | 24/37 [00:08<00:04,  3.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:04,  2.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  68%|██████████████████████████████████▍                | 25/37 [00:08<00:04,  2.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  70%|███████████████████████████████████▊               | 26/37 [00:08<00:03,  2.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  70%|███████████████████████████████████▊               | 26/37 [00:09<00:03,  2.97it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  73%|█████████████████████████████████████▏             | 27/37 [00:09<00:03,  2.98it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 18:  73%|█████████████████████████████████████▏             | 27/37 [00:09<00:03,  2.98it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 18:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:03,  2.95it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 18:  76%|██████████████████████████████████████▌            | 28/37 [00:09<00:03,  2.95it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 18:  78%|███████████████████████████████████████▉           | 29/37 [00:09<00:02,  2.93it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 18:  78%|███████████████████████████████████████▉           | 29/37 [00:10<00:02,  2.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 18:  81%|█████████████████████████████████████████▎         | 30/37 [00:10<00:02,  2.89it/s, training_loss=0.001]\u001b[A"
     ]
    }
   ],
   "source": [
    "#install packages\n",
    "!pip install transformers\n",
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "import logging\n",
    "import random\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "#data split function\n",
    "def custom_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    min_class_count = min(counts)\n",
    "\n",
    "    # Find classes with only one or two instances\n",
    "    single_or_double_instance_classes = classes[np.logical_or(counts == 1, counts == 2)]\n",
    "\n",
    "    # Remove instances of single-instance or two-instance classes\n",
    "    X_filtered = X[~np.isin(y, single_or_double_instance_classes)]\n",
    "    y_filtered = y[~np.isin(y, single_or_double_instance_classes)]\n",
    "\n",
    "    if len(y_filtered) < 2:\n",
    "        raise ValueError(\"No classes have more than two instances after filtering.\")\n",
    "\n",
    "    # Perform stratified split on the filtered dataset\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_filtered, y_filtered, test_size=test_size, random_state=random_state, stratify=y_filtered)\n",
    "\n",
    "    # Randomly assign instances of single-instance classes to training or testing sets\n",
    "    for class_label in single_or_double_instance_classes:\n",
    "        class_indices = np.where(y == class_label)[0]\n",
    "        np.random.shuffle(class_indices)\n",
    "\n",
    "        if len(class_indices) <= 2:\n",
    "            # Only one instance, randomly assign to training or testing set\n",
    "            if np.random.rand() < test_size:\n",
    "                X_val = np.concatenate((X_val, X[class_indices]))\n",
    "                y_val = np.concatenate((y_val, y[class_indices]))\n",
    "            else:\n",
    "                X_train = np.concatenate((X_train, X[class_indices]))\n",
    "                y_train = np.concatenate((y_train, y[class_indices]))\n",
    "\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "\n",
    "#evaluation\n",
    "def accuracy_per_class(predictions, true_vals):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "\n",
    "    accuracy_dict = {}\n",
    "    count_dict = {}\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = pred_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        accuracy_dict[label] = np.sum(y_preds == y_true) / len(y_true) if len(y_true) > 0 else 0\n",
    "        count_dict[label] = len(y_true)\n",
    "\n",
    "    return accuracy_dict, count_dict\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='smm4h_top3_finetuning_training_epochs_100_20times.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class TQDMLoggingWrapper(tqdm):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.logger = logger\n",
    "\n",
    "    def display(self, msg=None, pos=None):\n",
    "        if msg is not None:\n",
    "            self.logger.info(msg)\n",
    "        super().display(msg, pos)\n",
    "\n",
    "    def update(self, n=1):\n",
    "        super().update(n)\n",
    "        desc = self.format_dict.get('desc', 'No description')\n",
    "        postfix = self.format_dict.get('postfix', '')\n",
    "        self.logger.info(f'{desc} - {postfix}')\n",
    "\n",
    "    def set_description(self, desc=None, refresh=True):\n",
    "        super().set_description(desc, refresh)\n",
    "        if desc:\n",
    "            self.logger.info(f'Set description: {desc}')\n",
    "\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "#Read smm4h data from git:\n",
    "#https://raw.githubusercontent.com/FANMISUA/ADE_Norm/main/Data/smm4h_soc.tsv\n",
    "# URL of the CSV file\n",
    "smm4h_csv_url = \"https://raw.githubusercontent.com/FANMISUA/ADE_Norm/main/Data/smm4h_soc.tsv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "smm4h_column_names = [\"ade\", \"soc_code\"]\n",
    "smm4h_all = pd.read_csv(smm4h_csv_url,names=smm4h_column_names, sep = '\\t', header=None)\n",
    "\n",
    "smm4h_all = smm4h_all[smm4h_all['soc_code'] != 0]\n",
    "smm4h_all['soc_code'] = pd.to_numeric(smm4h_all['soc_code'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Display the first few rows of the DataFrame and the shape\n",
    "# print(smm4h_all.head)\n",
    "# print(smm4h_all.shape)\n",
    "\n",
    "\n",
    "# Remove duplicate rows based on the 'ade' column\n",
    "smm4h_unique = smm4h_all.drop_duplicates(subset='ade')\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"smm4h all data:\",smm4h_unique.shape)\n",
    "# Count occurrences of each 'soc_code'\n",
    "soc_code_counts = smm4h_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "print(\"SOC count in CADEC: \",soc_code_counts)\n",
    "\n",
    "#get top 3 of the SMM4H list\n",
    "#['10037175','10018065','10029205','10017947','10028395','10022891']\n",
    "top3SMM4H = [10037175, 10018065,10029205]\n",
    "# top6SMM4H = [10037175,10018065,10029205,1001794,10028395,10022891]\n",
    "\n",
    "top3label_dict = {\n",
    "    10037175: 0,\n",
    "    10018065: 1,\n",
    "    10029205: 2\n",
    "}\n",
    "\n",
    "\n",
    "# Filter DataFrame\n",
    "filtered_data3 = smm4h_unique[smm4h_unique['soc_code'].isin(top3SMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "top3inSMM4H = filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "print(\"CADEC top3 in SMM4H:\",top3inSMM4H)\n",
    "data = top3inSMM4H\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(top3inSMM4H)\n",
    "\n",
    "#mapping dictionary for soc to label\n",
    "# soc_code_to_label = dict(zip(top3label_dict['soc_code'], top3label_dict['Label']))\n",
    "df['label'] = df['soc_code'].map(top3label_dict)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Define the random seeds and other parameters\n",
    "seed_values = list(range(2, 12, 2))\n",
    "\n",
    "# fix batch_size 16, learning rate 1e-5; Finetuning epochs\n",
    "# learning_rates = [1e-6, 1e-5, 1e-4, 1e-3]\n",
    "# batch_sizes = [8, 16, 32, 64]\n",
    "# epochs_list = [10, 20, 30, 40]\n",
    "learning_rates = [1e-5]\n",
    "batch_sizes = [16]\n",
    "epochs_list = [100]\n",
    "# Results storage\n",
    "results = []\n",
    "# Store the training losses across all splits\n",
    "all_training_losses = []\n",
    "all_val_losses = []\n",
    "# Main loop over seed values\n",
    "for seed_val in seed_values:\n",
    "    # Set seeds\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "    \n",
    "    # Placeholder for accuracies\n",
    "    all_accuracies = {label: [] for label in range(len(top3label_dict))}\n",
    "    # Store the training losses for this split\n",
    "    training_losses = []\n",
    "    val_losses = []\n",
    "    val_f1s = []\n",
    "    \n",
    "    # Data preparation\n",
    "    X_train, X_val, y_train, y_val = custom_train_test_split(df.index.values, df.label.values, test_size=0.2, random_state=seed_val)\n",
    "    df['data_type'] = ['not_set'] * df.shape[0]\n",
    "    df.loc[X_train, 'data_type'] = 'train'\n",
    "    df.loc[X_val, 'data_type'] = 'val'\n",
    "    logger.info(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "    \n",
    "    # Training loop for grid search\n",
    "    for lr in learning_rates:\n",
    "      for batch_size in batch_sizes:\n",
    "          for epochs in epochs_list:\n",
    "            logger.info(f\"Seed: {seed_val}, Learning Rate: {lr}, Batch Size: {batch_size}, Epochs: {epochs}\")\n",
    "            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "            encoded_data_train = tokenizer.batch_encode_plus(\n",
    "                df[df.data_type == 'train'].ade.values,\n",
    "                add_special_tokens=True,\n",
    "                return_attention_mask=True,\n",
    "                pad_to_max_length=True,\n",
    "                max_length=256,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "    \n",
    "            encoded_data_val = tokenizer.batch_encode_plus(\n",
    "                df[df.data_type == 'val'].ade.values,\n",
    "                add_special_tokens=True,\n",
    "                return_attention_mask=True,\n",
    "                pad_to_max_length=True,\n",
    "                max_length=256,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "    \n",
    "            input_ids_train = encoded_data_train['input_ids']\n",
    "            attention_masks_train = encoded_data_train['attention_mask']\n",
    "            labels_train = torch.tensor(df[df.data_type == 'train'].label.values)\n",
    "    \n",
    "            input_ids_val = encoded_data_val['input_ids']\n",
    "            attention_masks_val = encoded_data_val['attention_mask']\n",
    "            labels_val = torch.tensor(df[df.data_type == 'val'].label.values)\n",
    "    \n",
    "            dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "            dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "    \n",
    "            model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(top3label_dict), output_attentions=False, output_hidden_states=False)\n",
    "    \n",
    "            dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "            dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)\n",
    "    \n",
    "            optimizer = AdamW(model.parameters(), lr=lr, eps=1e-8)\n",
    "            scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train) * epochs)\n",
    "    \n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model.to(device)\n",
    "            logger.info(f\"Device used: {device}\")\n",
    "    \n",
    "            # Training loop\n",
    "            for epoch in TQDMLoggingWrapper(range(1, epochs+1), desc='Epoch Progress'):\n",
    "                model.train()\n",
    "                loss_train_total = 0\n",
    "    \n",
    "                progress_bar = TQDMLoggingWrapper(dataloader_train, desc=f'Epoch {epoch}', leave=False, disable=False)\n",
    "                for batch in progress_bar:\n",
    "                    model.zero_grad()\n",
    "                    batch = tuple(b.to(device) for b in batch)\n",
    "                    inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "    \n",
    "                    outputs = model(**inputs)\n",
    "                    loss = outputs[0]\n",
    "                    loss_train_total += loss.item()\n",
    "                    loss.backward()\n",
    "    \n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "    \n",
    "                    progress_bar.set_postfix({'training_loss': f'{loss.item()/len(batch):.3f}'})\n",
    "    \n",
    "                # torch.save(model.state_dict(), f'./ADENorm_top3_epoch_{epoch}.model')\n",
    "    \n",
    "                logger.info(f'\\nEpoch {epoch}')\n",
    "                loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "                logger.info(f'Training loss: {loss_train_avg}')\n",
    "                training_losses.append(loss_train_avg)\n",
    "\n",
    "    \n",
    "                val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "                val_f1 = f1_score(true_vals, np.argmax(predictions, axis=1), average='weighted')\n",
    "                val_losses.append(val_loss)\n",
    "                val_f1s.append(val_f1)\n",
    "                logger.info(f'Validation loss: {val_loss}')\n",
    "                logger.info(f'F1 Score (Weighted): {val_f1}')\n",
    "\n",
    "            #store the training loss\n",
    "            all_training_losses.append(training_losses)\n",
    "            #store the val loss\n",
    "            all_val_losses.append(val_losses)\n",
    "            #store the prediction  \n",
    "            _, predictions, true_vals = evaluate(dataloader_validation)\n",
    "            accuracy_dict, count_dict = accuracy_per_class(predictions, true_vals)\n",
    "    \n",
    "            for label, accuracy in accuracy_dict.items():\n",
    "                all_accuracies[label].append(accuracy)\n",
    "    \n",
    "    \n",
    "            # Calculate the average accuracy for each label\n",
    "            avg_accuracy = {label: np.mean(accs) for label, accs in all_accuracies.items()}\n",
    "    \n",
    "            # Calculate the overall average accuracy across all labels\n",
    "            overall_avg_accuracy = np.mean(list(avg_accuracy.values()))\n",
    "    \n",
    "            logger.info(f'Seed {seed_val} - Accuracy: {overall_avg_accuracy} - Count: {count_dict} - lr: {lr} -batchsize:{batch_size} -epochs:{epochs}')\n",
    "            #store results\n",
    "            results.append((lr, batch_size, epochs, overall_avg_accuracy))\n",
    "\n",
    "\n",
    "# Extract each parameter and accuracy for plotting\n",
    "learning_rates = [result[0] for result in results]\n",
    "batch_sizes = [result[1] for result in results]\n",
    "epochs = [result[2] for result in results]\n",
    "accuracies = [result[3] for result in results]\n",
    "\n",
    "# # Find the best result based on accuracy\n",
    "# best_result = max(results, key=lambda x: x[3])\n",
    "# print(f\"Best result: LR={best_result[0]}, Batch={best_result[1]}, Epoch={best_result[2]}, Accuracy={best_result[3]:.4f}\")\n",
    "\n",
    "# with open('smm4htop3_finetuning_results.txt', 'w') as file:\n",
    "#     for result in results:\n",
    "#         file.write(f'Learning Rate: {result[0]}, Batch Size: {result[1]}, Epochs: {result[2]}, Accuracy: {result[3]}\\n')\n",
    "#      # Write the best result at the end\n",
    "#     file.write('\\nBest result:\\n')\n",
    "#     file.write(f'Learning Rate: {best_result[0]}, Batch Size: {best_result[1]}, Epochs: {best_result[2]}, Accuracy: {best_result[3]:.4f}\\n')\n",
    "    \n",
    "\n",
    "# Calculate the average training loss and standard deviation across all splits\n",
    "average_training_losses = np.mean(all_training_losses, axis=0)\n",
    "std_training_losses = np.std(all_training_losses, axis=0)\n",
    "\n",
    "#plot \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(range(1, len(average_training_losses) + 1), \n",
    "             average_training_losses, \n",
    "             yerr=std_training_losses, \n",
    "             fmt='-o', \n",
    "             capsize=5, \n",
    "             color='blue',       # Color for the line and markers\n",
    "             ecolor='red',       # Color for the error bars\n",
    "             elinewidth=2,       # Width of the error bars\n",
    "             alpha=0.7)          # Transparency of the error bars\n",
    "\n",
    "plt.title('Average Training Loss with Standard Deviation vs Epochs', fontsize=16)\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Average Training Loss', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('smm4h_top3_avg_training_loss_std_vs_epochs.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average validation loss and standard deviation across all splits\n",
    "average_val_losses = np.mean(all_val_losses, axis=0)\n",
    "std_val_losses = np.std(all_val_losses, axis=0)\n",
    "\n",
    "# Plot average validation loss with standard deviation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(range(1, len(average_val_losses) + 1), \n",
    "             average_val_losses, \n",
    "             yerr=std_val_losses, \n",
    "             fmt='-o', \n",
    "             capsize=5, \n",
    "             color='green',     # Color for the line and markers\n",
    "             ecolor='orange',   # Color for the error bars\n",
    "             elinewidth=2,      # Width of the error bars\n",
    "             alpha=0.7)         # Transparency of the error bars\n",
    "\n",
    "plt.title('Average Validation Loss with Standard Deviation vs Epochs', fontsize=16)\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Average Validation Loss', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('smm4h_top3_avg_val_loss_std_vs_epochs.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff92d29-1a3b-4daa-826d-161786e7bc82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
