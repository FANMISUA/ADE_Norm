{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb14a1f-1132-4f5c-8839-db79f5bbdb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "SOC count in CADEC:  soc_code\n",
      "10037175    287\n",
      "10018065    235\n",
      "10029205    212\n",
      "10017947     63\n",
      "10028395     58\n",
      "10022891     54\n",
      "10027433     48\n",
      "10040785     28\n",
      "10038738     22\n",
      "10022117     16\n",
      "10015919     16\n",
      "10038604     10\n",
      "10047065     10\n",
      "10021428      8\n",
      "10041244      7\n",
      "10007541      7\n",
      "10038359      6\n",
      "10021881      5\n",
      "10013993      4\n",
      "10019805      2\n",
      "10042613      2\n",
      "10029104      2\n",
      "10077536      1\n",
      "10010331      1\n",
      "0             1\n",
      "10014698      1\n",
      "Name: count, dtype: Int64\n",
      "SMM4H top 6                             ade  soc_code  label\n",
      "3                            AD  10037175      0\n",
      "4                         focus  10029205      2\n",
      "5                          died  10018065      1\n",
      "8                        dreams  10037175      0\n",
      "10                   withdrawal  10018065      1\n",
      "...                         ...       ...    ...\n",
      "1698     can't go back to sleep  10037175      0\n",
      "1703                 chest hurt  10018065      1\n",
      "1704   got ten minutes of sleep  10037175      0\n",
      "1708  never have another orgasm  10037175      0\n",
      "1710        gain so much weight  10022891      5\n",
      "\n",
      "[909 rows x 3 columns]\n",
      "CADEC top 6                             ade  soc_code  label\n",
      "299      bowel/uterine cramping  10017947      3\n",
      "300            Abdominal cramps  10017947      3\n",
      "301          abdominal cramping  10017947      3\n",
      "302   abdominal cramps and pain  10017947      3\n",
      "303            abdominal cramps  10017947      3\n",
      "...                         ...       ...    ...\n",
      "5326  short term memory lacking  10037175      0\n",
      "5328      couldn't eat or drink  10037175      0\n",
      "5329              Could not eat  10037175      0\n",
      "5331           can't eat normal  10037175      0\n",
      "5332   Disturbed sleep patterns  10037175      0\n",
      "\n",
      "[2685 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2888: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch Progress:   0%|                                                                          | 0/100 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|                                                                                 | 0/225 [00:00<?, ?it/s]\u001b[AC:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Epoch 1:   0%|                                                            | 0/225 [00:00<?, ?it/s, training_loss=0.599]\u001b[A\n",
      "Epoch 1:   0%|▏                                                   | 1/225 [00:00<03:08,  1.19it/s, training_loss=0.599]\u001b[A\n",
      "Epoch 1:   0%|▏                                                   | 1/225 [00:01<03:08,  1.19it/s, training_loss=0.586]\u001b[A\n",
      "Epoch 1:   1%|▍                                                   | 2/225 [00:01<02:02,  1.82it/s, training_loss=0.586]\u001b[A\n",
      "Epoch 1:   1%|▍                                                   | 2/225 [00:01<02:02,  1.82it/s, training_loss=0.619]\u001b[A\n",
      "Epoch 1:   1%|▋                                                   | 3/225 [00:01<01:40,  2.22it/s, training_loss=0.619]\u001b[A\n",
      "Epoch 1:   1%|▋                                                   | 3/225 [00:01<01:40,  2.22it/s, training_loss=0.588]\u001b[A\n",
      "Epoch 1:   2%|▉                                                   | 4/225 [00:01<01:30,  2.45it/s, training_loss=0.588]\u001b[A\n",
      "Epoch 1:   2%|▉                                                   | 4/225 [00:02<01:30,  2.45it/s, training_loss=0.607]\u001b[A\n",
      "Epoch 1:   2%|█▏                                                  | 5/225 [00:02<01:24,  2.60it/s, training_loss=0.607]\u001b[A\n",
      "Epoch 1:   2%|█▏                                                  | 5/225 [00:02<01:24,  2.60it/s, training_loss=0.620]\u001b[A\n",
      "Epoch 1:   3%|█▍                                                  | 6/225 [00:02<01:21,  2.68it/s, training_loss=0.620]\u001b[A\n",
      "Epoch 1:   3%|█▍                                                  | 6/225 [00:02<01:21,  2.68it/s, training_loss=0.558]\u001b[A\n",
      "Epoch 1:   3%|█▌                                                  | 7/225 [00:02<01:19,  2.76it/s, training_loss=0.558]\u001b[A\n",
      "Epoch 1:   3%|█▌                                                  | 7/225 [00:03<01:19,  2.76it/s, training_loss=0.609]\u001b[A\n",
      "Epoch 1:   4%|█▊                                                  | 8/225 [00:03<01:17,  2.80it/s, training_loss=0.609]\u001b[A\n",
      "Epoch 1:   4%|█▊                                                  | 8/225 [00:03<01:17,  2.80it/s, training_loss=0.534]\u001b[A\n",
      "Epoch 1:   4%|██                                                  | 9/225 [00:03<01:15,  2.87it/s, training_loss=0.534]\u001b[A\n",
      "Epoch 1:   4%|██                                                  | 9/225 [00:03<01:15,  2.87it/s, training_loss=0.572]\u001b[A\n",
      "Epoch 1:   4%|██▎                                                | 10/225 [00:03<01:14,  2.89it/s, training_loss=0.572]\u001b[A\n",
      "Epoch 1:   4%|██▎                                                | 10/225 [00:04<01:14,  2.89it/s, training_loss=0.579]\u001b[A\n",
      "Epoch 1:   5%|██▍                                                | 11/225 [00:04<01:13,  2.90it/s, training_loss=0.579]\u001b[A\n",
      "Epoch 1:   5%|██▍                                                | 11/225 [00:04<01:13,  2.90it/s, training_loss=0.573]\u001b[A\n",
      "Epoch 1:   5%|██▋                                                | 12/225 [00:04<01:13,  2.90it/s, training_loss=0.573]\u001b[A\n",
      "Epoch 1:   5%|██▋                                                | 12/225 [00:04<01:13,  2.90it/s, training_loss=0.518]\u001b[A\n",
      "Epoch 1:   6%|██▉                                                | 13/225 [00:04<01:12,  2.91it/s, training_loss=0.518]\u001b[A\n",
      "Epoch 1:   6%|██▉                                                | 13/225 [00:05<01:12,  2.91it/s, training_loss=0.538]\u001b[A\n",
      "Epoch 1:   6%|███▏                                               | 14/225 [00:05<01:12,  2.89it/s, training_loss=0.538]\u001b[A\n",
      "Epoch 1:   6%|███▏                                               | 14/225 [00:05<01:12,  2.89it/s, training_loss=0.475]\u001b[A\n",
      "Epoch 1:   7%|███▍                                               | 15/225 [00:05<01:11,  2.92it/s, training_loss=0.475]\u001b[A\n",
      "Epoch 1:   7%|███▍                                               | 15/225 [00:05<01:11,  2.92it/s, training_loss=0.556]\u001b[A\n",
      "Epoch 1:   7%|███▋                                               | 16/225 [00:05<01:11,  2.91it/s, training_loss=0.556]\u001b[A\n",
      "Epoch 1:   7%|███▋                                               | 16/225 [00:06<01:11,  2.91it/s, training_loss=0.544]\u001b[A\n",
      "Epoch 1:   8%|███▊                                               | 17/225 [00:06<01:11,  2.90it/s, training_loss=0.544]\u001b[A\n",
      "Epoch 1:   8%|███▊                                               | 17/225 [00:06<01:11,  2.90it/s, training_loss=0.519]\u001b[A\n",
      "Epoch 1:   8%|████                                               | 18/225 [00:06<01:11,  2.91it/s, training_loss=0.519]\u001b[A\n",
      "Epoch 1:   8%|████                                               | 18/225 [00:07<01:11,  2.91it/s, training_loss=0.509]\u001b[A\n",
      "Epoch 1:   8%|████▎                                              | 19/225 [00:07<01:10,  2.91it/s, training_loss=0.509]\u001b[A\n",
      "Epoch 1:   8%|████▎                                              | 19/225 [00:07<01:10,  2.91it/s, training_loss=0.537]\u001b[A\n",
      "Epoch 1:   9%|████▌                                              | 20/225 [00:07<01:10,  2.91it/s, training_loss=0.537]\u001b[A\n",
      "Epoch 1:   9%|████▌                                              | 20/225 [00:07<01:10,  2.91it/s, training_loss=0.589]\u001b[A\n",
      "Epoch 1:   9%|████▊                                              | 21/225 [00:07<01:11,  2.86it/s, training_loss=0.589]\u001b[A\n",
      "Epoch 1:   9%|████▊                                              | 21/225 [00:08<01:11,  2.86it/s, training_loss=0.567]\u001b[A\n",
      "Epoch 1:  10%|████▉                                              | 22/225 [00:08<01:10,  2.90it/s, training_loss=0.567]\u001b[A\n",
      "Epoch 1:  10%|████▉                                              | 22/225 [00:08<01:10,  2.90it/s, training_loss=0.587]\u001b[A\n",
      "Epoch 1:  10%|█████▏                                             | 23/225 [00:08<01:10,  2.88it/s, training_loss=0.587]\u001b[A\n",
      "Epoch 1:  10%|█████▏                                             | 23/225 [00:08<01:10,  2.88it/s, training_loss=0.536]\u001b[A\n",
      "Epoch 1:  11%|█████▍                                             | 24/225 [00:08<01:09,  2.89it/s, training_loss=0.536]\u001b[A\n",
      "Epoch 1:  11%|█████▍                                             | 24/225 [00:09<01:09,  2.89it/s, training_loss=0.611]\u001b[A\n",
      "Epoch 1:  11%|█████▋                                             | 25/225 [00:09<01:08,  2.92it/s, training_loss=0.611]\u001b[A\n",
      "Epoch 1:  11%|█████▋                                             | 25/225 [00:09<01:08,  2.92it/s, training_loss=0.594]\u001b[A\n",
      "Epoch 1:  12%|█████▉                                             | 26/225 [00:09<01:08,  2.89it/s, training_loss=0.594]\u001b[A\n",
      "Epoch 1:  12%|█████▉                                             | 26/225 [00:09<01:08,  2.89it/s, training_loss=0.568]\u001b[A\n",
      "Epoch 1:  12%|██████                                             | 27/225 [00:09<01:08,  2.90it/s, training_loss=0.568]\u001b[A\n",
      "Epoch 1:  12%|██████                                             | 27/225 [00:10<01:08,  2.90it/s, training_loss=0.568]\u001b[A\n",
      "Epoch 1:  12%|██████▎                                            | 28/225 [00:10<01:07,  2.93it/s, training_loss=0.568]\u001b[A\n",
      "Epoch 1:  12%|██████▎                                            | 28/225 [00:10<01:07,  2.93it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  13%|██████▌                                            | 29/225 [00:10<01:07,  2.91it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  13%|██████▌                                            | 29/225 [00:10<01:07,  2.91it/s, training_loss=0.518]\u001b[A\n",
      "Epoch 1:  13%|██████▊                                            | 30/225 [00:10<01:07,  2.90it/s, training_loss=0.518]\u001b[A\n",
      "Epoch 1:  13%|██████▊                                            | 30/225 [00:11<01:07,  2.90it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  14%|███████                                            | 31/225 [00:11<01:06,  2.93it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  14%|███████                                            | 31/225 [00:11<01:06,  2.93it/s, training_loss=0.609]\u001b[A\n",
      "Epoch 1:  14%|███████▎                                           | 32/225 [00:11<01:05,  2.93it/s, training_loss=0.609]\u001b[A\n",
      "Epoch 1:  14%|███████▎                                           | 32/225 [00:11<01:05,  2.93it/s, training_loss=0.578]\u001b[A\n",
      "Epoch 1:  15%|███████▍                                           | 33/225 [00:11<01:06,  2.90it/s, training_loss=0.578]\u001b[A\n",
      "Epoch 1:  15%|███████▍                                           | 33/225 [00:12<01:06,  2.90it/s, training_loss=0.538]\u001b[A\n",
      "Epoch 1:  15%|███████▋                                           | 34/225 [00:12<01:04,  2.95it/s, training_loss=0.538]\u001b[A\n",
      "Epoch 1:  15%|███████▋                                           | 34/225 [00:12<01:04,  2.95it/s, training_loss=0.501]\u001b[A\n",
      "Epoch 1:  16%|███████▉                                           | 35/225 [00:12<01:03,  2.98it/s, training_loss=0.501]\u001b[A\n",
      "Epoch 1:  16%|███████▉                                           | 35/225 [00:12<01:03,  2.98it/s, training_loss=0.499]\u001b[A\n",
      "Epoch 1:  16%|████████▏                                          | 36/225 [00:12<01:03,  2.96it/s, training_loss=0.499]\u001b[A\n",
      "Epoch 1:  16%|████████▏                                          | 36/225 [00:13<01:03,  2.96it/s, training_loss=0.528]\u001b[A\n",
      "Epoch 1:  16%|████████▍                                          | 37/225 [00:13<01:03,  2.97it/s, training_loss=0.528]\u001b[A\n",
      "Epoch 1:  16%|████████▍                                          | 37/225 [00:13<01:03,  2.97it/s, training_loss=0.578]\u001b[A\n",
      "Epoch 1:  17%|████████▌                                          | 38/225 [00:13<01:04,  2.91it/s, training_loss=0.578]\u001b[A\n",
      "Epoch 1:  17%|████████▌                                          | 38/225 [00:13<01:04,  2.91it/s, training_loss=0.535]\u001b[A\n",
      "Epoch 1:  17%|████████▊                                          | 39/225 [00:13<01:03,  2.93it/s, training_loss=0.535]\u001b[A\n",
      "Epoch 1:  17%|████████▊                                          | 39/225 [00:14<01:03,  2.93it/s, training_loss=0.590]\u001b[A\n",
      "Epoch 1:  18%|█████████                                          | 40/225 [00:14<01:02,  2.94it/s, training_loss=0.590]\u001b[A\n",
      "Epoch 1:  18%|█████████                                          | 40/225 [00:14<01:02,  2.94it/s, training_loss=0.592]\u001b[A\n",
      "Epoch 1:  18%|█████████▎                                         | 41/225 [00:14<01:03,  2.91it/s, training_loss=0.592]\u001b[A\n",
      "Epoch 1:  18%|█████████▎                                         | 41/225 [00:14<01:03,  2.91it/s, training_loss=0.598]\u001b[A\n",
      "Epoch 1:  19%|█████████▌                                         | 42/225 [00:14<01:02,  2.92it/s, training_loss=0.598]\u001b[A\n",
      "Epoch 1:  19%|█████████▌                                         | 42/225 [00:15<01:02,  2.92it/s, training_loss=0.549]\u001b[A\n",
      "Epoch 1:  19%|█████████▋                                         | 43/225 [00:15<01:02,  2.93it/s, training_loss=0.549]\u001b[A\n",
      "Epoch 1:  19%|█████████▋                                         | 43/225 [00:15<01:02,  2.93it/s, training_loss=0.477]\u001b[A\n",
      "Epoch 1:  20%|█████████▉                                         | 44/225 [00:15<01:02,  2.91it/s, training_loss=0.477]\u001b[A\n",
      "Epoch 1:  20%|█████████▉                                         | 44/225 [00:15<01:02,  2.91it/s, training_loss=0.504]\u001b[A\n",
      "Epoch 1:  20%|██████████▏                                        | 45/225 [00:15<01:01,  2.91it/s, training_loss=0.504]\u001b[A\n",
      "Epoch 1:  20%|██████████▏                                        | 45/225 [00:16<01:01,  2.91it/s, training_loss=0.555]\u001b[A\n",
      "Epoch 1:  20%|██████████▍                                        | 46/225 [00:16<01:01,  2.92it/s, training_loss=0.555]\u001b[A\n",
      "Epoch 1:  20%|██████████▍                                        | 46/225 [00:16<01:01,  2.92it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  21%|██████████▋                                        | 47/225 [00:16<01:00,  2.93it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  21%|██████████▋                                        | 47/225 [00:16<01:00,  2.93it/s, training_loss=0.573]\u001b[A\n",
      "Epoch 1:  21%|██████████▉                                        | 48/225 [00:16<01:01,  2.90it/s, training_loss=0.573]\u001b[A\n",
      "Epoch 1:  21%|██████████▉                                        | 48/225 [00:17<01:01,  2.90it/s, training_loss=0.472]\u001b[A\n",
      "Epoch 1:  22%|███████████                                        | 49/225 [00:17<01:00,  2.90it/s, training_loss=0.472]\u001b[A\n",
      "Epoch 1:  22%|███████████                                        | 49/225 [00:17<01:00,  2.90it/s, training_loss=0.471]\u001b[A\n",
      "Epoch 1:  22%|███████████▎                                       | 50/225 [00:17<01:00,  2.91it/s, training_loss=0.471]\u001b[A\n",
      "Epoch 1:  22%|███████████▎                                       | 50/225 [00:17<01:00,  2.91it/s, training_loss=0.561]\u001b[A\n",
      "Epoch 1:  23%|███████████▌                                       | 51/225 [00:17<00:59,  2.93it/s, training_loss=0.561]\u001b[A\n",
      "Epoch 1:  23%|███████████▌                                       | 51/225 [00:18<00:59,  2.93it/s, training_loss=0.544]\u001b[A\n",
      "Epoch 1:  23%|███████████▊                                       | 52/225 [00:18<00:59,  2.90it/s, training_loss=0.544]\u001b[A\n",
      "Epoch 1:  23%|███████████▊                                       | 52/225 [00:18<00:59,  2.90it/s, training_loss=0.502]\u001b[A\n",
      "Epoch 1:  24%|████████████                                       | 53/225 [00:18<00:58,  2.92it/s, training_loss=0.502]\u001b[A\n",
      "Epoch 1:  24%|████████████                                       | 53/225 [00:18<00:58,  2.92it/s, training_loss=0.536]\u001b[A\n",
      "Epoch 1:  24%|████████████▏                                      | 54/225 [00:18<00:58,  2.92it/s, training_loss=0.536]\u001b[A\n",
      "Epoch 1:  24%|████████████▏                                      | 54/225 [00:19<00:58,  2.92it/s, training_loss=0.511]\u001b[A\n",
      "Epoch 1:  24%|████████████▍                                      | 55/225 [00:19<00:58,  2.91it/s, training_loss=0.511]\u001b[A\n",
      "Epoch 1:  24%|████████████▍                                      | 55/225 [00:19<00:58,  2.91it/s, training_loss=0.515]\u001b[A\n",
      "Epoch 1:  25%|████████████▋                                      | 56/225 [00:19<00:57,  2.92it/s, training_loss=0.515]\u001b[A\n",
      "Epoch 1:  25%|████████████▋                                      | 56/225 [00:20<00:57,  2.92it/s, training_loss=0.497]\u001b[A\n",
      "Epoch 1:  25%|████████████▉                                      | 57/225 [00:20<00:57,  2.93it/s, training_loss=0.497]\u001b[A\n",
      "Epoch 1:  25%|████████████▉                                      | 57/225 [00:20<00:57,  2.93it/s, training_loss=0.540]\u001b[A\n",
      "Epoch 1:  26%|█████████████▏                                     | 58/225 [00:20<00:57,  2.90it/s, training_loss=0.540]\u001b[A\n",
      "Epoch 1:  26%|█████████████▏                                     | 58/225 [00:20<00:57,  2.90it/s, training_loss=0.521]\u001b[A\n",
      "Epoch 1:  26%|█████████████▎                                     | 59/225 [00:20<00:57,  2.91it/s, training_loss=0.521]\u001b[A\n",
      "Epoch 1:  26%|█████████████▎                                     | 59/225 [00:21<00:57,  2.91it/s, training_loss=0.449]\u001b[A\n",
      "Epoch 1:  27%|█████████████▌                                     | 60/225 [00:21<00:56,  2.90it/s, training_loss=0.449]\u001b[A\n",
      "Epoch 1:  27%|█████████████▌                                     | 60/225 [00:21<00:56,  2.90it/s, training_loss=0.425]\u001b[A\n",
      "Epoch 1:  27%|█████████████▊                                     | 61/225 [00:21<00:56,  2.91it/s, training_loss=0.425]\u001b[A\n",
      "Epoch 1:  27%|█████████████▊                                     | 61/225 [00:21<00:56,  2.91it/s, training_loss=0.470]\u001b[A\n",
      "Epoch 1:  28%|██████████████                                     | 62/225 [00:21<00:55,  2.93it/s, training_loss=0.470]\u001b[A\n",
      "Epoch 1:  28%|██████████████                                     | 62/225 [00:22<00:55,  2.93it/s, training_loss=0.485]\u001b[A\n",
      "Epoch 1:  28%|██████████████▎                                    | 63/225 [00:22<00:55,  2.90it/s, training_loss=0.485]\u001b[A\n",
      "Epoch 1:  28%|██████████████▎                                    | 63/225 [00:22<00:55,  2.90it/s, training_loss=0.588]\u001b[A\n",
      "Epoch 1:  28%|██████████████▌                                    | 64/225 [00:22<00:55,  2.90it/s, training_loss=0.588]\u001b[A\n",
      "Epoch 1:  28%|██████████████▌                                    | 64/225 [00:22<00:55,  2.90it/s, training_loss=0.503]\u001b[A\n",
      "Epoch 1:  29%|██████████████▋                                    | 65/225 [00:22<00:54,  2.93it/s, training_loss=0.503]\u001b[A\n",
      "Epoch 1:  29%|██████████████▋                                    | 65/225 [00:23<00:54,  2.93it/s, training_loss=0.486]\u001b[A\n",
      "Epoch 1:  29%|██████████████▉                                    | 66/225 [00:23<00:54,  2.92it/s, training_loss=0.486]\u001b[A\n",
      "Epoch 1:  29%|██████████████▉                                    | 66/225 [00:23<00:54,  2.92it/s, training_loss=0.529]\u001b[A\n",
      "Epoch 1:  30%|███████████████▏                                   | 67/225 [00:23<00:54,  2.90it/s, training_loss=0.529]\u001b[A\n",
      "Epoch 1:  30%|███████████████▏                                   | 67/225 [00:23<00:54,  2.90it/s, training_loss=0.477]\u001b[A\n",
      "Epoch 1:  30%|███████████████▍                                   | 68/225 [00:23<00:54,  2.90it/s, training_loss=0.477]\u001b[A\n",
      "Epoch 1:  30%|███████████████▍                                   | 68/225 [00:24<00:54,  2.90it/s, training_loss=0.518]\u001b[A\n",
      "Epoch 1:  31%|███████████████▋                                   | 69/225 [00:24<00:53,  2.90it/s, training_loss=0.518]\u001b[A\n",
      "Epoch 1:  31%|███████████████▋                                   | 69/225 [00:24<00:53,  2.90it/s, training_loss=0.552]\u001b[A\n",
      "Epoch 1:  31%|███████████████▊                                   | 70/225 [00:24<00:53,  2.92it/s, training_loss=0.552]\u001b[A\n",
      "Epoch 1:  31%|███████████████▊                                   | 70/225 [00:24<00:53,  2.92it/s, training_loss=0.458]\u001b[A\n",
      "Epoch 1:  32%|████████████████                                   | 71/225 [00:24<00:53,  2.90it/s, training_loss=0.458]\u001b[A\n",
      "Epoch 1:  32%|████████████████                                   | 71/225 [00:25<00:53,  2.90it/s, training_loss=0.469]\u001b[A\n",
      "Epoch 1:  32%|████████████████▎                                  | 72/225 [00:25<00:52,  2.90it/s, training_loss=0.469]\u001b[A\n",
      "Epoch 1:  32%|████████████████▎                                  | 72/225 [00:25<00:52,  2.90it/s, training_loss=0.420]\u001b[A\n",
      "Epoch 1:  32%|████████████████▌                                  | 73/225 [00:25<00:52,  2.91it/s, training_loss=0.420]\u001b[A\n",
      "Epoch 1:  32%|████████████████▌                                  | 73/225 [00:25<00:52,  2.91it/s, training_loss=0.489]\u001b[A\n",
      "Epoch 1:  33%|████████████████▊                                  | 74/225 [00:25<00:51,  2.91it/s, training_loss=0.489]\u001b[A\n",
      "Epoch 1:  33%|████████████████▊                                  | 74/225 [00:26<00:51,  2.91it/s, training_loss=0.446]\u001b[A\n",
      "Epoch 1:  33%|█████████████████                                  | 75/225 [00:26<00:51,  2.91it/s, training_loss=0.446]\u001b[A\n",
      "Epoch 1:  33%|█████████████████                                  | 75/225 [00:26<00:51,  2.91it/s, training_loss=0.531]\u001b[A\n",
      "Epoch 1:  34%|█████████████████▏                                 | 76/225 [00:26<00:51,  2.91it/s, training_loss=0.531]\u001b[A\n",
      "Epoch 1:  34%|█████████████████▏                                 | 76/225 [00:26<00:51,  2.91it/s, training_loss=0.475]\u001b[A\n",
      "Epoch 1:  34%|█████████████████▍                                 | 77/225 [00:26<00:51,  2.90it/s, training_loss=0.475]\u001b[A\n",
      "Epoch 1:  34%|█████████████████▍                                 | 77/225 [00:27<00:51,  2.90it/s, training_loss=0.471]\u001b[A\n",
      "Epoch 1:  35%|█████████████████▋                                 | 78/225 [00:27<00:50,  2.93it/s, training_loss=0.471]\u001b[A\n",
      "Epoch 1:  35%|█████████████████▋                                 | 78/225 [00:27<00:50,  2.93it/s, training_loss=0.424]\u001b[A\n",
      "Epoch 1:  35%|█████████████████▉                                 | 79/225 [00:27<00:50,  2.90it/s, training_loss=0.424]\u001b[A\n",
      "Epoch 1:  35%|█████████████████▉                                 | 79/225 [00:27<00:50,  2.90it/s, training_loss=0.461]\u001b[A\n",
      "Epoch 1:  36%|██████████████████▏                                | 80/225 [00:27<00:50,  2.89it/s, training_loss=0.461]\u001b[A\n",
      "Epoch 1:  36%|██████████████████▏                                | 80/225 [00:28<00:50,  2.89it/s, training_loss=0.436]\u001b[A\n",
      "Epoch 1:  36%|██████████████████▎                                | 81/225 [00:28<00:49,  2.90it/s, training_loss=0.436]\u001b[A\n",
      "Epoch 1:  36%|██████████████████▎                                | 81/225 [00:28<00:49,  2.90it/s, training_loss=0.466]\u001b[A\n",
      "Epoch 1:  36%|██████████████████▌                                | 82/225 [00:28<00:49,  2.91it/s, training_loss=0.466]\u001b[A\n",
      "Epoch 1:  36%|██████████████████▌                                | 82/225 [00:28<00:49,  2.91it/s, training_loss=0.504]\u001b[A\n",
      "Epoch 1:  37%|██████████████████▊                                | 83/225 [00:28<00:48,  2.92it/s, training_loss=0.504]\u001b[A\n",
      "Epoch 1:  37%|██████████████████▊                                | 83/225 [00:29<00:48,  2.92it/s, training_loss=0.511]\u001b[A\n",
      "Epoch 1:  37%|███████████████████                                | 84/225 [00:29<00:48,  2.89it/s, training_loss=0.511]\u001b[A\n",
      "Epoch 1:  37%|███████████████████                                | 84/225 [00:29<00:48,  2.89it/s, training_loss=0.433]\u001b[A\n",
      "Epoch 1:  38%|███████████████████▎                               | 85/225 [00:29<00:48,  2.90it/s, training_loss=0.433]\u001b[A\n",
      "Epoch 1:  38%|███████████████████▎                               | 85/225 [00:30<00:48,  2.90it/s, training_loss=0.430]\u001b[A\n",
      "Epoch 1:  38%|███████████████████▍                               | 86/225 [00:30<00:47,  2.91it/s, training_loss=0.430]\u001b[A\n",
      "Epoch 1:  38%|███████████████████▍                               | 86/225 [00:30<00:47,  2.91it/s, training_loss=0.526]\u001b[A\n",
      "Epoch 1:  39%|███████████████████▋                               | 87/225 [00:30<00:47,  2.90it/s, training_loss=0.526]\u001b[A\n",
      "Epoch 1:  39%|███████████████████▋                               | 87/225 [00:30<00:47,  2.90it/s, training_loss=0.486]\u001b[A\n",
      "Epoch 1:  39%|███████████████████▉                               | 88/225 [00:30<00:46,  2.92it/s, training_loss=0.486]\u001b[A\n",
      "Epoch 1:  39%|███████████████████▉                               | 88/225 [00:31<00:46,  2.92it/s, training_loss=0.582]\u001b[A\n",
      "Epoch 1:  40%|████████████████████▏                              | 89/225 [00:31<00:46,  2.92it/s, training_loss=0.582]\u001b[A\n",
      "Epoch 1:  40%|████████████████████▏                              | 89/225 [00:31<00:46,  2.92it/s, training_loss=0.495]\u001b[A\n",
      "Epoch 1:  40%|████████████████████▍                              | 90/225 [00:31<00:46,  2.89it/s, training_loss=0.495]\u001b[A\n",
      "Epoch 1:  40%|████████████████████▍                              | 90/225 [00:31<00:46,  2.89it/s, training_loss=0.438]\u001b[A\n",
      "Epoch 1:  40%|████████████████████▋                              | 91/225 [00:31<00:46,  2.90it/s, training_loss=0.438]\u001b[A\n",
      "Epoch 1:  40%|████████████████████▋                              | 91/225 [00:32<00:46,  2.90it/s, training_loss=0.459]\u001b[A\n",
      "Epoch 1:  41%|████████████████████▊                              | 92/225 [00:32<00:45,  2.92it/s, training_loss=0.459]\u001b[A\n",
      "Epoch 1:  41%|████████████████████▊                              | 92/225 [00:32<00:45,  2.92it/s, training_loss=0.517]\u001b[A\n",
      "Epoch 1:  41%|█████████████████████                              | 93/225 [00:32<00:45,  2.92it/s, training_loss=0.517]\u001b[A\n",
      "Epoch 1:  41%|█████████████████████                              | 93/225 [00:32<00:45,  2.92it/s, training_loss=0.467]\u001b[A\n",
      "Epoch 1:  42%|█████████████████████▎                             | 94/225 [00:32<00:45,  2.86it/s, training_loss=0.467]\u001b[A\n",
      "Epoch 1:  42%|█████████████████████▎                             | 94/225 [00:33<00:45,  2.86it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  42%|█████████████████████▌                             | 95/225 [00:33<00:44,  2.90it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  42%|█████████████████████▌                             | 95/225 [00:33<00:44,  2.90it/s, training_loss=0.439]\u001b[A\n",
      "Epoch 1:  43%|█████████████████████▊                             | 96/225 [00:33<00:44,  2.90it/s, training_loss=0.439]\u001b[A\n",
      "Epoch 1:  43%|█████████████████████▊                             | 96/225 [00:33<00:44,  2.90it/s, training_loss=0.456]\u001b[A\n",
      "Epoch 1:  43%|█████████████████████▉                             | 97/225 [00:33<00:44,  2.90it/s, training_loss=0.456]\u001b[A\n",
      "Epoch 1:  43%|█████████████████████▉                             | 97/225 [00:34<00:44,  2.90it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  44%|██████████████████████▏                            | 98/225 [00:34<00:43,  2.92it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  44%|██████████████████████▏                            | 98/225 [00:34<00:43,  2.92it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  44%|██████████████████████▍                            | 99/225 [00:34<00:43,  2.92it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  44%|██████████████████████▍                            | 99/225 [00:34<00:43,  2.92it/s, training_loss=0.560]\u001b[A\n",
      "Epoch 1:  44%|██████████████████████▏                           | 100/225 [00:34<00:43,  2.89it/s, training_loss=0.560]\u001b[A\n",
      "Epoch 1:  44%|██████████████████████▏                           | 100/225 [00:35<00:43,  2.89it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  45%|██████████████████████▍                           | 101/225 [00:35<00:42,  2.90it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  45%|██████████████████████▍                           | 101/225 [00:35<00:42,  2.90it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  45%|██████████████████████▋                           | 102/225 [00:35<00:42,  2.90it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  45%|██████████████████████▋                           | 102/225 [00:35<00:42,  2.90it/s, training_loss=0.578]\u001b[A\n",
      "Epoch 1:  46%|██████████████████████▉                           | 103/225 [00:35<00:41,  2.93it/s, training_loss=0.578]\u001b[A\n",
      "Epoch 1:  46%|██████████████████████▉                           | 103/225 [00:36<00:41,  2.93it/s, training_loss=0.510]\u001b[A\n",
      "Epoch 1:  46%|███████████████████████                           | 104/225 [00:36<00:41,  2.91it/s, training_loss=0.510]\u001b[A\n",
      "Epoch 1:  46%|███████████████████████                           | 104/225 [00:36<00:41,  2.91it/s, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  47%|███████████████████████▎                          | 105/225 [00:36<00:41,  2.92it/s, training_loss=0.306]\u001b[A\n",
      "Epoch 1:  47%|███████████████████████▎                          | 105/225 [00:36<00:41,  2.92it/s, training_loss=0.476]\u001b[A\n",
      "Epoch 1:  47%|███████████████████████▌                          | 106/225 [00:36<00:40,  2.91it/s, training_loss=0.476]\u001b[A\n",
      "Epoch 1:  47%|███████████████████████▌                          | 106/225 [00:37<00:40,  2.91it/s, training_loss=0.460]\u001b[A\n",
      "Epoch 1:  48%|███████████████████████▊                          | 107/225 [00:37<00:40,  2.88it/s, training_loss=0.460]\u001b[A\n",
      "Epoch 1:  48%|███████████████████████▊                          | 107/225 [00:37<00:40,  2.88it/s, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  48%|████████████████████████                          | 108/225 [00:37<00:40,  2.91it/s, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  48%|████████████████████████                          | 108/225 [00:37<00:40,  2.91it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  48%|████████████████████████▏                         | 109/225 [00:37<00:39,  2.91it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  48%|████████████████████████▏                         | 109/225 [00:38<00:39,  2.91it/s, training_loss=0.463]\u001b[A\n",
      "Epoch 1:  49%|████████████████████████▍                         | 110/225 [00:38<00:39,  2.89it/s, training_loss=0.463]\u001b[A\n",
      "Epoch 1:  49%|████████████████████████▍                         | 110/225 [00:38<00:39,  2.89it/s, training_loss=0.450]\u001b[A\n",
      "Epoch 1:  49%|████████████████████████▋                         | 111/225 [00:38<00:39,  2.89it/s, training_loss=0.450]\u001b[A\n",
      "Epoch 1:  49%|████████████████████████▋                         | 111/225 [00:38<00:39,  2.89it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  50%|████████████████████████▉                         | 112/225 [00:38<00:38,  2.90it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  50%|████████████████████████▉                         | 112/225 [00:39<00:38,  2.90it/s, training_loss=0.432]\u001b[A\n",
      "Epoch 1:  50%|█████████████████████████                         | 113/225 [00:39<00:38,  2.92it/s, training_loss=0.432]\u001b[A\n",
      "Epoch 1:  50%|█████████████████████████                         | 113/225 [00:39<00:38,  2.92it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  51%|█████████████████████████▎                        | 114/225 [00:39<00:38,  2.89it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  51%|█████████████████████████▎                        | 114/225 [00:39<00:38,  2.89it/s, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  51%|█████████████████████████▌                        | 115/225 [00:39<00:37,  2.91it/s, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  51%|█████████████████████████▌                        | 115/225 [00:40<00:37,  2.91it/s, training_loss=0.555]\u001b[A\n",
      "Epoch 1:  52%|█████████████████████████▊                        | 116/225 [00:40<00:37,  2.92it/s, training_loss=0.555]\u001b[A\n",
      "Epoch 1:  52%|█████████████████████████▊                        | 116/225 [00:40<00:37,  2.92it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  52%|██████████████████████████                        | 117/225 [00:40<00:37,  2.92it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  52%|██████████████████████████                        | 117/225 [00:41<00:37,  2.92it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  52%|██████████████████████████▏                       | 118/225 [00:41<00:36,  2.89it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  52%|██████████████████████████▏                       | 118/225 [00:41<00:36,  2.89it/s, training_loss=0.414]\u001b[A\n",
      "Epoch 1:  53%|██████████████████████████▍                       | 119/225 [00:41<00:36,  2.92it/s, training_loss=0.414]\u001b[A\n",
      "Epoch 1:  53%|██████████████████████████▍                       | 119/225 [00:41<00:36,  2.92it/s, training_loss=0.476]\u001b[A\n",
      "Epoch 1:  53%|██████████████████████████▋                       | 120/225 [00:41<00:36,  2.90it/s, training_loss=0.476]\u001b[A\n",
      "Epoch 1:  53%|██████████████████████████▋                       | 120/225 [00:42<00:36,  2.90it/s, training_loss=0.426]\u001b[A\n",
      "Epoch 1:  54%|██████████████████████████▉                       | 121/225 [00:42<00:35,  2.90it/s, training_loss=0.426]\u001b[A\n",
      "Epoch 1:  54%|██████████████████████████▉                       | 121/225 [00:42<00:35,  2.90it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  54%|███████████████████████████                       | 122/225 [00:42<00:35,  2.88it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  54%|███████████████████████████                       | 122/225 [00:42<00:35,  2.88it/s, training_loss=0.469]\u001b[A\n",
      "Epoch 1:  55%|███████████████████████████▎                      | 123/225 [00:42<00:35,  2.90it/s, training_loss=0.469]\u001b[A\n",
      "Epoch 1:  55%|███████████████████████████▎                      | 123/225 [00:43<00:35,  2.90it/s, training_loss=0.391]\u001b[A\n",
      "Epoch 1:  55%|███████████████████████████▌                      | 124/225 [00:43<00:34,  2.91it/s, training_loss=0.391]\u001b[A\n",
      "Epoch 1:  55%|███████████████████████████▌                      | 124/225 [00:43<00:34,  2.91it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  56%|███████████████████████████▊                      | 125/225 [00:43<00:34,  2.90it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  56%|███████████████████████████▊                      | 125/225 [00:43<00:34,  2.90it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████                      | 126/225 [00:43<00:34,  2.91it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████                      | 126/225 [00:44<00:34,  2.91it/s, training_loss=0.399]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████▏                     | 127/225 [00:44<00:33,  2.90it/s, training_loss=0.399]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████▏                     | 127/225 [00:44<00:33,  2.90it/s, training_loss=0.366]\u001b[A\n",
      "Epoch 1:  57%|████████████████████████████▍                     | 128/225 [00:44<00:33,  2.90it/s, training_loss=0.366]\u001b[A\n",
      "Epoch 1:  57%|████████████████████████████▍                     | 128/225 [00:44<00:33,  2.90it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  57%|████████████████████████████▋                     | 129/225 [00:44<00:33,  2.90it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  57%|████████████████████████████▋                     | 129/225 [00:45<00:33,  2.90it/s, training_loss=0.523]\u001b[A\n",
      "Epoch 1:  58%|████████████████████████████▉                     | 130/225 [00:45<00:32,  2.93it/s, training_loss=0.523]\u001b[A\n",
      "Epoch 1:  58%|████████████████████████████▉                     | 130/225 [00:45<00:32,  2.93it/s, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  58%|█████████████████████████████                     | 131/225 [00:45<00:32,  2.92it/s, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  58%|█████████████████████████████                     | 131/225 [00:45<00:32,  2.92it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  59%|█████████████████████████████▎                    | 132/225 [00:45<00:31,  2.91it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  59%|█████████████████████████████▎                    | 132/225 [00:46<00:31,  2.91it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  59%|█████████████████████████████▌                    | 133/225 [00:46<00:31,  2.90it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  59%|█████████████████████████████▌                    | 133/225 [00:46<00:31,  2.90it/s, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  60%|█████████████████████████████▊                    | 134/225 [00:46<00:31,  2.89it/s, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  60%|█████████████████████████████▊                    | 134/225 [00:46<00:31,  2.89it/s, training_loss=0.440]\u001b[A\n",
      "Epoch 1:  60%|██████████████████████████████                    | 135/225 [00:46<00:31,  2.89it/s, training_loss=0.440]\u001b[A\n",
      "Epoch 1:  60%|██████████████████████████████                    | 135/225 [00:47<00:31,  2.89it/s, training_loss=0.444]\u001b[A\n",
      "Epoch 1:  60%|██████████████████████████████▏                   | 136/225 [00:47<00:30,  2.92it/s, training_loss=0.444]\u001b[A\n",
      "Epoch 1:  60%|██████████████████████████████▏                   | 136/225 [00:47<00:30,  2.92it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  61%|██████████████████████████████▍                   | 137/225 [00:47<00:30,  2.89it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 1:  61%|██████████████████████████████▍                   | 137/225 [00:47<00:30,  2.89it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  61%|██████████████████████████████▋                   | 138/225 [00:47<00:30,  2.89it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  61%|██████████████████████████████▋                   | 138/225 [00:48<00:30,  2.89it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  62%|██████████████████████████████▉                   | 139/225 [00:48<00:29,  2.92it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  62%|██████████████████████████████▉                   | 139/225 [00:48<00:29,  2.92it/s, training_loss=0.400]\u001b[A\n",
      "Epoch 1:  62%|███████████████████████████████                   | 140/225 [00:48<00:29,  2.92it/s, training_loss=0.400]\u001b[A\n",
      "Epoch 1:  62%|███████████████████████████████                   | 140/225 [00:48<00:29,  2.92it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  63%|███████████████████████████████▎                  | 141/225 [00:48<00:29,  2.88it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  63%|███████████████████████████████▎                  | 141/225 [00:49<00:29,  2.88it/s, training_loss=0.517]\u001b[A\n",
      "Epoch 1:  63%|███████████████████████████████▌                  | 142/225 [00:49<00:28,  2.89it/s, training_loss=0.517]\u001b[A\n",
      "Epoch 1:  63%|███████████████████████████████▌                  | 142/225 [00:49<00:28,  2.89it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  64%|███████████████████████████████▊                  | 143/225 [00:49<00:28,  2.90it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  64%|███████████████████████████████▊                  | 143/225 [00:49<00:28,  2.90it/s, training_loss=0.393]\u001b[A\n",
      "Epoch 1:  64%|████████████████████████████████                  | 144/225 [00:49<00:27,  2.90it/s, training_loss=0.393]\u001b[A\n",
      "Epoch 1:  64%|████████████████████████████████                  | 144/225 [00:50<00:27,  2.90it/s, training_loss=0.534]\u001b[A\n",
      "Epoch 1:  64%|████████████████████████████████▏                 | 145/225 [00:50<00:27,  2.90it/s, training_loss=0.534]\u001b[A\n",
      "Epoch 1:  64%|████████████████████████████████▏                 | 145/225 [00:50<00:27,  2.90it/s, training_loss=0.484]\u001b[A\n",
      "Epoch 1:  65%|████████████████████████████████▍                 | 146/225 [00:50<00:27,  2.90it/s, training_loss=0.484]\u001b[A\n",
      "Epoch 1:  65%|████████████████████████████████▍                 | 146/225 [00:51<00:27,  2.90it/s, training_loss=0.447]\u001b[A\n",
      "Epoch 1:  65%|████████████████████████████████▋                 | 147/225 [00:51<00:26,  2.91it/s, training_loss=0.447]\u001b[A\n",
      "Epoch 1:  65%|████████████████████████████████▋                 | 147/225 [00:51<00:26,  2.91it/s, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  66%|████████████████████████████████▉                 | 148/225 [00:51<00:26,  2.89it/s, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  66%|████████████████████████████████▉                 | 148/225 [00:51<00:26,  2.89it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  66%|█████████████████████████████████                 | 149/225 [00:51<00:26,  2.82it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  66%|█████████████████████████████████                 | 149/225 [00:52<00:26,  2.82it/s, training_loss=0.441]\u001b[A\n",
      "Epoch 1:  67%|█████████████████████████████████▎                | 150/225 [00:52<00:25,  2.89it/s, training_loss=0.441]\u001b[A\n",
      "Epoch 1:  67%|█████████████████████████████████▎                | 150/225 [00:52<00:25,  2.89it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  67%|█████████████████████████████████▌                | 151/225 [00:52<00:25,  2.91it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  67%|█████████████████████████████████▌                | 151/225 [00:52<00:25,  2.91it/s, training_loss=0.468]\u001b[A\n",
      "Epoch 1:  68%|█████████████████████████████████▊                | 152/225 [00:52<00:25,  2.91it/s, training_loss=0.468]\u001b[A\n",
      "Epoch 1:  68%|█████████████████████████████████▊                | 152/225 [00:53<00:25,  2.91it/s, training_loss=0.403]\u001b[A\n",
      "Epoch 1:  68%|██████████████████████████████████                | 153/225 [00:53<00:24,  2.91it/s, training_loss=0.403]\u001b[A\n",
      "Epoch 1:  68%|██████████████████████████████████                | 153/225 [00:53<00:24,  2.91it/s, training_loss=0.401]\u001b[A\n",
      "Epoch 1:  68%|██████████████████████████████████▏               | 154/225 [00:53<00:24,  2.92it/s, training_loss=0.401]\u001b[A\n",
      "Epoch 1:  68%|██████████████████████████████████▏               | 154/225 [00:53<00:24,  2.92it/s, training_loss=0.478]\u001b[A\n",
      "Epoch 1:  69%|██████████████████████████████████▍               | 155/225 [00:53<00:24,  2.90it/s, training_loss=0.478]\u001b[A\n",
      "Epoch 1:  69%|██████████████████████████████████▍               | 155/225 [00:54<00:24,  2.90it/s, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  69%|██████████████████████████████████▋               | 156/225 [00:54<00:23,  2.90it/s, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  69%|██████████████████████████████████▋               | 156/225 [00:54<00:23,  2.90it/s, training_loss=0.407]\u001b[A\n",
      "Epoch 1:  70%|██████████████████████████████████▉               | 157/225 [00:54<00:23,  2.93it/s, training_loss=0.407]\u001b[A\n",
      "Epoch 1:  70%|██████████████████████████████████▉               | 157/225 [00:54<00:23,  2.93it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  70%|███████████████████████████████████               | 158/225 [00:54<00:23,  2.90it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  70%|███████████████████████████████████               | 158/225 [00:55<00:23,  2.90it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 1:  71%|███████████████████████████████████▎              | 159/225 [00:55<00:22,  2.89it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 1:  71%|███████████████████████████████████▎              | 159/225 [00:55<00:22,  2.89it/s, training_loss=0.425]\u001b[A\n",
      "Epoch 1:  71%|███████████████████████████████████▌              | 160/225 [00:55<00:22,  2.90it/s, training_loss=0.425]\u001b[A\n",
      "Epoch 1:  71%|███████████████████████████████████▌              | 160/225 [00:55<00:22,  2.90it/s, training_loss=0.459]\u001b[A\n",
      "Epoch 1:  72%|███████████████████████████████████▊              | 161/225 [00:55<00:21,  2.93it/s, training_loss=0.459]\u001b[A\n",
      "Epoch 1:  72%|███████████████████████████████████▊              | 161/225 [00:56<00:21,  2.93it/s, training_loss=0.413]\u001b[A\n",
      "Epoch 1:  72%|████████████████████████████████████              | 162/225 [00:56<00:21,  2.90it/s, training_loss=0.413]\u001b[A\n",
      "Epoch 1:  72%|████████████████████████████████████              | 162/225 [00:56<00:21,  2.90it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  72%|████████████████████████████████████▏             | 163/225 [00:56<00:21,  2.92it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  72%|████████████████████████████████████▏             | 163/225 [00:56<00:21,  2.92it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  73%|████████████████████████████████████▍             | 164/225 [00:56<00:21,  2.89it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  73%|████████████████████████████████████▍             | 164/225 [00:57<00:21,  2.89it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  73%|████████████████████████████████████▋             | 165/225 [00:57<00:20,  2.90it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  73%|████████████████████████████████████▋             | 165/225 [00:57<00:20,  2.90it/s, training_loss=0.406]\u001b[A\n",
      "Epoch 1:  74%|████████████████████████████████████▉             | 166/225 [00:57<00:20,  2.88it/s, training_loss=0.406]\u001b[A\n",
      "Epoch 1:  74%|████████████████████████████████████▉             | 166/225 [00:57<00:20,  2.88it/s, training_loss=0.399]\u001b[A\n",
      "Epoch 1:  74%|█████████████████████████████████████             | 167/225 [00:57<00:19,  2.92it/s, training_loss=0.399]\u001b[A\n",
      "Epoch 1:  74%|█████████████████████████████████████             | 167/225 [00:58<00:19,  2.92it/s, training_loss=0.410]\u001b[A\n",
      "Epoch 1:  75%|█████████████████████████████████████▎            | 168/225 [00:58<00:19,  2.89it/s, training_loss=0.410]\u001b[A\n",
      "Epoch 1:  75%|█████████████████████████████████████▎            | 168/225 [00:58<00:19,  2.89it/s, training_loss=0.402]\u001b[A\n",
      "Epoch 1:  75%|█████████████████████████████████████▌            | 169/225 [00:58<00:19,  2.90it/s, training_loss=0.402]\u001b[A\n",
      "Epoch 1:  75%|█████████████████████████████████████▌            | 169/225 [00:58<00:19,  2.90it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  76%|█████████████████████████████████████▊            | 170/225 [00:58<00:18,  2.90it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  76%|█████████████████████████████████████▊            | 170/225 [00:59<00:18,  2.90it/s, training_loss=0.435]\u001b[A\n",
      "Epoch 1:  76%|██████████████████████████████████████            | 171/225 [00:59<00:18,  2.89it/s, training_loss=0.435]\u001b[A\n",
      "Epoch 1:  76%|██████████████████████████████████████            | 171/225 [00:59<00:18,  2.89it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  76%|██████████████████████████████████████▏           | 172/225 [00:59<00:18,  2.90it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  76%|██████████████████████████████████████▏           | 172/225 [00:59<00:18,  2.90it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  77%|██████████████████████████████████████▍           | 173/225 [00:59<00:17,  2.91it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  77%|██████████████████████████████████████▍           | 173/225 [01:00<00:17,  2.91it/s, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  77%|██████████████████████████████████████▋           | 174/225 [01:00<00:17,  2.93it/s, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  77%|██████████████████████████████████████▋           | 174/225 [01:00<00:17,  2.93it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  78%|██████████████████████████████████████▉           | 175/225 [01:00<00:17,  2.90it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  78%|██████████████████████████████████████▉           | 175/225 [01:01<00:17,  2.90it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  78%|███████████████████████████████████████           | 176/225 [01:01<00:16,  2.90it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  78%|███████████████████████████████████████           | 176/225 [01:01<00:16,  2.90it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  79%|███████████████████████████████████████▎          | 177/225 [01:01<00:16,  2.93it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  79%|███████████████████████████████████████▎          | 177/225 [01:01<00:16,  2.93it/s, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  79%|███████████████████████████████████████▌          | 178/225 [01:01<00:16,  2.90it/s, training_loss=0.317]\u001b[A\n",
      "Epoch 1:  79%|███████████████████████████████████████▌          | 178/225 [01:02<00:16,  2.90it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  80%|███████████████████████████████████████▊          | 179/225 [01:02<00:15,  2.90it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  80%|███████████████████████████████████████▊          | 179/225 [01:02<00:15,  2.90it/s, training_loss=0.446]\u001b[A\n",
      "Epoch 1:  80%|████████████████████████████████████████          | 180/225 [01:02<00:15,  2.90it/s, training_loss=0.446]\u001b[A\n",
      "Epoch 1:  80%|████████████████████████████████████████          | 180/225 [01:02<00:15,  2.90it/s, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  80%|████████████████████████████████████████▏         | 181/225 [01:02<00:15,  2.91it/s, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  80%|████████████████████████████████████████▏         | 181/225 [01:03<00:15,  2.91it/s, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  81%|████████████████████████████████████████▍         | 182/225 [01:03<00:14,  2.91it/s, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  81%|████████████████████████████████████████▍         | 182/225 [01:03<00:14,  2.91it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  81%|████████████████████████████████████████▋         | 183/225 [01:03<00:14,  2.90it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  81%|████████████████████████████████████████▋         | 183/225 [01:03<00:14,  2.90it/s, training_loss=0.346]\u001b[A\n",
      "Epoch 1:  82%|████████████████████████████████████████▉         | 184/225 [01:03<00:14,  2.90it/s, training_loss=0.346]\u001b[A\n",
      "Epoch 1:  82%|████████████████████████████████████████▉         | 184/225 [01:04<00:14,  2.90it/s, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  82%|█████████████████████████████████████████         | 185/225 [01:04<00:13,  2.89it/s, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  82%|█████████████████████████████████████████         | 185/225 [01:04<00:13,  2.89it/s, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  83%|█████████████████████████████████████████▎        | 186/225 [01:04<00:13,  2.90it/s, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  83%|█████████████████████████████████████████▎        | 186/225 [01:04<00:13,  2.90it/s, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  83%|█████████████████████████████████████████▌        | 187/225 [01:04<00:12,  2.92it/s, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  83%|█████████████████████████████████████████▌        | 187/225 [01:05<00:12,  2.92it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  84%|█████████████████████████████████████████▊        | 188/225 [01:05<00:12,  2.90it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  84%|█████████████████████████████████████████▊        | 188/225 [01:05<00:12,  2.90it/s, training_loss=0.426]\u001b[A\n",
      "Epoch 1:  84%|██████████████████████████████████████████        | 189/225 [01:05<00:12,  2.91it/s, training_loss=0.426]\u001b[A\n",
      "Epoch 1:  84%|██████████████████████████████████████████        | 189/225 [01:05<00:12,  2.91it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  84%|██████████████████████████████████████████▏       | 190/225 [01:05<00:12,  2.90it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  84%|██████████████████████████████████████████▏       | 190/225 [01:06<00:12,  2.90it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  85%|██████████████████████████████████████████▍       | 191/225 [01:06<00:11,  2.92it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  85%|██████████████████████████████████████████▍       | 191/225 [01:06<00:11,  2.92it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  85%|██████████████████████████████████████████▋       | 192/225 [01:06<00:11,  2.91it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  85%|██████████████████████████████████████████▋       | 192/225 [01:06<00:11,  2.91it/s, training_loss=0.390]\u001b[A\n",
      "Epoch 1:  86%|██████████████████████████████████████████▉       | 193/225 [01:06<00:11,  2.87it/s, training_loss=0.390]\u001b[A\n",
      "Epoch 1:  86%|██████████████████████████████████████████▉       | 193/225 [01:07<00:11,  2.87it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  86%|███████████████████████████████████████████       | 194/225 [01:07<00:10,  2.91it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  86%|███████████████████████████████████████████       | 194/225 [01:07<00:10,  2.91it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████████████████████▎      | 195/225 [01:07<00:10,  2.92it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████████████████████▎      | 195/225 [01:07<00:10,  2.92it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████████████████████▌      | 196/225 [01:07<00:10,  2.85it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████████████████████▌      | 196/225 [01:08<00:10,  2.85it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  88%|███████████████████████████████████████████▊      | 197/225 [01:08<00:09,  2.92it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  88%|███████████████████████████████████████████▊      | 197/225 [01:08<00:09,  2.92it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████████████████████      | 198/225 [01:08<00:09,  2.93it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████████████████████      | 198/225 [01:08<00:09,  2.93it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████████████████████▏     | 199/225 [01:08<00:08,  2.92it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████████████████████▏     | 199/225 [01:09<00:08,  2.92it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████████████████████▍     | 200/225 [01:09<00:08,  2.89it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████████████████████▍     | 200/225 [01:09<00:08,  2.89it/s, training_loss=0.417]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████████████████████▋     | 201/225 [01:09<00:08,  2.91it/s, training_loss=0.417]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████████████████████▋     | 201/225 [01:09<00:08,  2.91it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  90%|████████████████████████████████████████████▉     | 202/225 [01:09<00:07,  2.94it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  90%|████████████████████████████████████████████▉     | 202/225 [01:10<00:07,  2.94it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  90%|█████████████████████████████████████████████     | 203/225 [01:10<00:07,  2.97it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  90%|█████████████████████████████████████████████     | 203/225 [01:10<00:07,  2.97it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████▎    | 204/225 [01:10<00:07,  2.97it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████▎    | 204/225 [01:10<00:07,  2.97it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████▌    | 205/225 [01:10<00:06,  2.93it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████▌    | 205/225 [01:11<00:06,  2.93it/s, training_loss=0.368]\u001b[A\n",
      "Epoch 1:  92%|█████████████████████████████████████████████▊    | 206/225 [01:11<00:06,  2.92it/s, training_loss=0.368]\u001b[A\n",
      "Epoch 1:  92%|█████████████████████████████████████████████▊    | 206/225 [01:11<00:06,  2.92it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  92%|██████████████████████████████████████████████    | 207/225 [01:11<00:06,  2.94it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  92%|██████████████████████████████████████████████    | 207/225 [01:11<00:06,  2.94it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  92%|██████████████████████████████████████████████▏   | 208/225 [01:11<00:05,  2.91it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  92%|██████████████████████████████████████████████▏   | 208/225 [01:12<00:05,  2.91it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  93%|██████████████████████████████████████████████▍   | 209/225 [01:12<00:05,  2.91it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  93%|██████████████████████████████████████████████▍   | 209/225 [01:12<00:05,  2.91it/s, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  93%|██████████████████████████████████████████████▋   | 210/225 [01:12<00:05,  2.93it/s, training_loss=0.333]\u001b[A\n",
      "Epoch 1:  93%|██████████████████████████████████████████████▋   | 210/225 [01:13<00:05,  2.93it/s, training_loss=0.390]\u001b[A\n",
      "Epoch 1:  94%|██████████████████████████████████████████████▉   | 211/225 [01:13<00:04,  2.91it/s, training_loss=0.390]\u001b[A\n",
      "Epoch 1:  94%|██████████████████████████████████████████████▉   | 211/225 [01:13<00:04,  2.91it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  94%|███████████████████████████████████████████████   | 212/225 [01:13<00:04,  2.90it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  94%|███████████████████████████████████████████████   | 212/225 [01:13<00:04,  2.90it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  95%|███████████████████████████████████████████████▎  | 213/225 [01:13<00:04,  2.91it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  95%|███████████████████████████████████████████████▎  | 213/225 [01:14<00:04,  2.91it/s, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  95%|███████████████████████████████████████████████▌  | 214/225 [01:14<00:03,  2.92it/s, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  95%|███████████████████████████████████████████████▌  | 214/225 [01:14<00:03,  2.92it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  96%|███████████████████████████████████████████████▊  | 215/225 [01:14<00:03,  2.90it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  96%|███████████████████████████████████████████████▊  | 215/225 [01:14<00:03,  2.90it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████  | 216/225 [01:14<00:03,  2.90it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████  | 216/225 [01:15<00:03,  2.90it/s, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████▏ | 217/225 [01:15<00:02,  2.92it/s, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████▏ | 217/225 [01:15<00:02,  2.92it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  97%|████████████████████████████████████████████████▍ | 218/225 [01:15<00:02,  2.92it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  97%|████████████████████████████████████████████████▍ | 218/225 [01:15<00:02,  2.92it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  97%|████████████████████████████████████████████████▋ | 219/225 [01:15<00:02,  2.89it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  97%|████████████████████████████████████████████████▋ | 219/225 [01:16<00:02,  2.89it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  98%|████████████████████████████████████████████████▉ | 220/225 [01:16<00:01,  2.92it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  98%|████████████████████████████████████████████████▉ | 220/225 [01:16<00:01,  2.92it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████████████████████████████████ | 221/225 [01:16<00:01,  2.91it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████████████████████████████████ | 221/225 [01:16<00:01,  2.91it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████████████████████████████████▎| 222/225 [01:16<00:01,  2.91it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████████████████████████████████▎| 222/225 [01:17<00:01,  2.91it/s, training_loss=0.441]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████████████████████████████████▌| 223/225 [01:17<00:00,  2.89it/s, training_loss=0.441]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████████████████████████████████▌| 223/225 [01:17<00:00,  2.89it/s, training_loss=0.366]\u001b[A\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████▊| 224/225 [01:17<00:00,  2.92it/s, training_loss=0.366]\u001b[A\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████▊| 224/225 [01:17<00:00,  2.92it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 1: 100%|██████████████████████████████████████████████████| 225/225 [01:17<00:00,  3.22it/s, training_loss=0.233]\u001b[A\n",
      "Epoch Progress:   1%|▋                                                               | 1/100 [01:17<2:08:15, 77.73s/it]\u001b[A\n",
      "Epoch 2:   0%|                                                                                 | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|                                                            | 0/225 [00:00<?, ?it/s, training_loss=0.283]\u001b[A\n",
      "Epoch 2:   0%|▏                                                   | 1/225 [00:00<01:15,  2.97it/s, training_loss=0.283]\u001b[A\n",
      "Epoch 2:   0%|▏                                                   | 1/225 [00:00<01:15,  2.97it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 2:   1%|▍                                                   | 2/225 [00:00<01:15,  2.94it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 2:   1%|▍                                                   | 2/225 [00:01<01:15,  2.94it/s, training_loss=0.478]\u001b[A\n",
      "Epoch 2:   1%|▋                                                   | 3/225 [00:01<01:16,  2.90it/s, training_loss=0.478]\u001b[A\n",
      "Epoch 2:   1%|▋                                                   | 3/225 [00:01<01:16,  2.90it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 2:   2%|▉                                                   | 4/225 [00:01<01:17,  2.86it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 2:   2%|▉                                                   | 4/225 [00:01<01:17,  2.86it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 2:   2%|█▏                                                  | 5/225 [00:01<01:15,  2.90it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 2:   2%|█▏                                                  | 5/225 [00:02<01:15,  2.90it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 2:   3%|█▍                                                  | 6/225 [00:02<01:15,  2.88it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 2:   3%|█▍                                                  | 6/225 [00:02<01:15,  2.88it/s, training_loss=0.301]\u001b[A\n",
      "Epoch 2:   3%|█▌                                                  | 7/225 [00:02<01:15,  2.89it/s, training_loss=0.301]\u001b[A\n",
      "Epoch 2:   3%|█▌                                                  | 7/225 [00:02<01:15,  2.89it/s, training_loss=0.323]\u001b[A\n",
      "Epoch 2:   4%|█▊                                                  | 8/225 [00:02<01:15,  2.88it/s, training_loss=0.323]\u001b[A\n",
      "Epoch 2:   4%|█▊                                                  | 8/225 [00:03<01:15,  2.88it/s, training_loss=0.346]\u001b[A\n",
      "Epoch 2:   4%|██                                                  | 9/225 [00:03<01:14,  2.89it/s, training_loss=0.346]\u001b[A\n",
      "Epoch 2:   4%|██                                                  | 9/225 [00:03<01:14,  2.89it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 2:   4%|██▎                                                | 10/225 [00:03<01:14,  2.89it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 2:   4%|██▎                                                | 10/225 [00:03<01:14,  2.89it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 2:   5%|██▍                                                | 11/225 [00:03<01:13,  2.92it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 2:   5%|██▍                                                | 11/225 [00:04<01:13,  2.92it/s, training_loss=0.415]\u001b[A\n",
      "Epoch 2:   5%|██▋                                                | 12/225 [00:04<01:13,  2.90it/s, training_loss=0.415]\u001b[A\n",
      "Epoch 2:   5%|██▋                                                | 12/225 [00:04<01:13,  2.90it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 2:   6%|██▉                                                | 13/225 [00:04<01:13,  2.90it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 2:   6%|██▉                                                | 13/225 [00:04<01:13,  2.90it/s, training_loss=0.330]\u001b[A\n",
      "Epoch 2:   6%|███▏                                               | 14/225 [00:04<01:12,  2.90it/s, training_loss=0.330]\u001b[A\n",
      "Epoch 2:   6%|███▏                                               | 14/225 [00:05<01:12,  2.90it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 2:   7%|███▍                                               | 15/225 [00:05<01:12,  2.91it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 2:   7%|███▍                                               | 15/225 [00:05<01:12,  2.91it/s, training_loss=0.248]\u001b[A\n",
      "Epoch 2:   7%|███▋                                               | 16/225 [00:05<01:12,  2.89it/s, training_loss=0.248]\u001b[A\n",
      "Epoch 2:   7%|███▋                                               | 16/225 [00:05<01:12,  2.89it/s, training_loss=0.279]\u001b[A\n",
      "Epoch 2:   8%|███▊                                               | 17/225 [00:05<01:11,  2.91it/s, training_loss=0.279]\u001b[A\n",
      "Epoch 2:   8%|███▊                                               | 17/225 [00:06<01:11,  2.91it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 2:   8%|████                                               | 18/225 [00:06<01:10,  2.92it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 2:   8%|████                                               | 18/225 [00:06<01:10,  2.92it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 2:   8%|████▎                                              | 19/225 [00:06<01:10,  2.93it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 2:   8%|████▎                                              | 19/225 [00:06<01:10,  2.93it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 2:   9%|████▌                                              | 20/225 [00:06<01:09,  2.93it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 2:   9%|████▌                                              | 20/225 [00:07<01:09,  2.93it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 2:   9%|████▊                                              | 21/225 [00:07<01:10,  2.91it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 2:   9%|████▊                                              | 21/225 [00:07<01:10,  2.91it/s, training_loss=0.236]\u001b[A\n",
      "Epoch 2:  10%|████▉                                              | 22/225 [00:07<01:08,  2.95it/s, training_loss=0.236]\u001b[A\n",
      "Epoch 2:  10%|████▉                                              | 22/225 [00:07<01:08,  2.95it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 2:  10%|█████▏                                             | 23/225 [00:07<01:09,  2.92it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 2:  10%|█████▏                                             | 23/225 [00:08<01:09,  2.92it/s, training_loss=0.316]\u001b[A\n",
      "Epoch 2:  11%|█████▍                                             | 24/225 [00:08<01:08,  2.92it/s, training_loss=0.316]\u001b[A\n",
      "Epoch 2:  11%|█████▍                                             | 24/225 [00:08<01:08,  2.92it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 2:  11%|█████▋                                             | 25/225 [00:08<01:08,  2.91it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 2:  11%|█████▋                                             | 25/225 [00:08<01:08,  2.91it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 2:  12%|█████▉                                             | 26/225 [00:08<01:08,  2.91it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 2:  12%|█████▉                                             | 26/225 [00:09<01:08,  2.91it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 2:  12%|██████                                             | 27/225 [00:09<01:08,  2.90it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 2:  12%|██████                                             | 27/225 [00:09<01:08,  2.90it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  12%|██████▎                                            | 28/225 [00:09<01:08,  2.88it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  12%|██████▎                                            | 28/225 [00:09<01:08,  2.88it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 2:  13%|██████▌                                            | 29/225 [00:09<01:07,  2.91it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 2:  13%|██████▌                                            | 29/225 [00:10<01:07,  2.91it/s, training_loss=0.224]\u001b[A\n",
      "Epoch 2:  13%|██████▊                                            | 30/225 [00:10<01:07,  2.91it/s, training_loss=0.224]\u001b[A\n",
      "Epoch 2:  13%|██████▊                                            | 30/225 [00:10<01:07,  2.91it/s, training_loss=0.281]\u001b[A\n",
      "Epoch 2:  14%|███████                                            | 31/225 [00:10<01:07,  2.89it/s, training_loss=0.281]\u001b[A\n",
      "Epoch 2:  14%|███████                                            | 31/225 [00:11<01:07,  2.89it/s, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  14%|███████▎                                           | 32/225 [00:11<01:06,  2.90it/s, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  14%|███████▎                                           | 32/225 [00:11<01:06,  2.90it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 2:  15%|███████▍                                           | 33/225 [00:11<01:05,  2.92it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 2:  15%|███████▍                                           | 33/225 [00:11<01:05,  2.92it/s, training_loss=0.380]\u001b[A\n",
      "Epoch 2:  15%|███████▋                                           | 34/225 [00:11<01:05,  2.92it/s, training_loss=0.380]\u001b[A\n",
      "Epoch 2:  15%|███████▋                                           | 34/225 [00:12<01:05,  2.92it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 2:  16%|███████▉                                           | 35/225 [00:12<01:05,  2.89it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 2:  16%|███████▉                                           | 35/225 [00:12<01:05,  2.89it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 2:  16%|████████▏                                          | 36/225 [00:12<01:05,  2.89it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 2:  16%|████████▏                                          | 36/225 [00:12<01:05,  2.89it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 2:  16%|████████▍                                          | 37/225 [00:12<01:04,  2.90it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 2:  16%|████████▍                                          | 37/225 [00:13<01:04,  2.90it/s, training_loss=0.275]\u001b[A\n",
      "Epoch 2:  17%|████████▌                                          | 38/225 [00:13<01:04,  2.91it/s, training_loss=0.275]\u001b[A\n",
      "Epoch 2:  17%|████████▌                                          | 38/225 [00:13<01:04,  2.91it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 2:  17%|████████▊                                          | 39/225 [00:13<01:03,  2.93it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 2:  17%|████████▊                                          | 39/225 [00:13<01:03,  2.93it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 2:  18%|█████████                                          | 40/225 [00:13<01:03,  2.93it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 2:  18%|█████████                                          | 40/225 [00:14<01:03,  2.93it/s, training_loss=0.375]\u001b[A\n",
      "Epoch 2:  18%|█████████▎                                         | 41/225 [00:14<01:02,  2.92it/s, training_loss=0.375]\u001b[A\n",
      "Epoch 2:  18%|█████████▎                                         | 41/225 [00:14<01:02,  2.92it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 2:  19%|█████████▌                                         | 42/225 [00:14<01:02,  2.91it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 2:  19%|█████████▌                                         | 42/225 [00:14<01:02,  2.91it/s, training_loss=0.267]\u001b[A\n",
      "Epoch 2:  19%|█████████▋                                         | 43/225 [00:14<01:02,  2.92it/s, training_loss=0.267]\u001b[A\n",
      "Epoch 2:  19%|█████████▋                                         | 43/225 [00:15<01:02,  2.92it/s, training_loss=0.272]\u001b[A\n",
      "Epoch 2:  20%|█████████▉                                         | 44/225 [00:15<01:01,  2.93it/s, training_loss=0.272]\u001b[A\n",
      "Epoch 2:  20%|█████████▉                                         | 44/225 [00:15<01:01,  2.93it/s, training_loss=0.235]\u001b[A\n",
      "Epoch 2:  20%|██████████▏                                        | 45/225 [00:15<01:01,  2.95it/s, training_loss=0.235]\u001b[A\n",
      "Epoch 2:  20%|██████████▏                                        | 45/225 [00:15<01:01,  2.95it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 2:  20%|██████████▍                                        | 46/225 [00:15<01:01,  2.91it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 2:  20%|██████████▍                                        | 46/225 [00:16<01:01,  2.91it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 2:  21%|██████████▋                                        | 47/225 [00:16<01:00,  2.93it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 2:  21%|██████████▋                                        | 47/225 [00:16<01:00,  2.93it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 2:  21%|██████████▉                                        | 48/225 [00:16<00:59,  2.96it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 2:  21%|██████████▉                                        | 48/225 [00:16<00:59,  2.96it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 2:  22%|███████████                                        | 49/225 [00:16<00:59,  2.94it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 2:  22%|███████████                                        | 49/225 [00:17<00:59,  2.94it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 2:  22%|███████████▎                                       | 50/225 [00:17<01:00,  2.91it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 2:  22%|███████████▎                                       | 50/225 [00:17<01:00,  2.91it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 2:  23%|███████████▌                                       | 51/225 [00:17<01:00,  2.89it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 2:  23%|███████████▌                                       | 51/225 [00:17<01:00,  2.89it/s, training_loss=0.343]\u001b[A\n",
      "Epoch 2:  23%|███████████▊                                       | 52/225 [00:17<01:00,  2.88it/s, training_loss=0.343]\u001b[A\n",
      "Epoch 2:  23%|███████████▊                                       | 52/225 [00:18<01:00,  2.88it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  24%|████████████                                       | 53/225 [00:18<00:59,  2.90it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  24%|████████████                                       | 53/225 [00:18<00:59,  2.90it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 2:  24%|████████████▏                                      | 54/225 [00:18<00:59,  2.89it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 2:  24%|████████████▏                                      | 54/225 [00:18<00:59,  2.89it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 2:  24%|████████████▍                                      | 55/225 [00:18<00:58,  2.89it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 2:  24%|████████████▍                                      | 55/225 [00:19<00:58,  2.89it/s, training_loss=0.333]\u001b[A\n",
      "Epoch 2:  25%|████████████▋                                      | 56/225 [00:19<00:58,  2.87it/s, training_loss=0.333]\u001b[A\n",
      "Epoch 2:  25%|████████████▋                                      | 56/225 [00:19<00:58,  2.87it/s, training_loss=0.343]\u001b[A\n",
      "Epoch 2:  25%|████████████▉                                      | 57/225 [00:19<00:58,  2.86it/s, training_loss=0.343]\u001b[A\n",
      "Epoch 2:  25%|████████████▉                                      | 57/225 [00:19<00:58,  2.86it/s, training_loss=0.293]\u001b[A\n",
      "Epoch 2:  26%|█████████████▏                                     | 58/225 [00:19<00:57,  2.88it/s, training_loss=0.293]\u001b[A\n",
      "Epoch 2:  26%|█████████████▏                                     | 58/225 [00:20<00:57,  2.88it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 2:  26%|█████████████▎                                     | 59/225 [00:20<00:57,  2.89it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 2:  26%|█████████████▎                                     | 59/225 [00:20<00:57,  2.89it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 2:  27%|█████████████▌                                     | 60/225 [00:20<00:56,  2.93it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 2:  27%|█████████████▌                                     | 60/225 [00:20<00:56,  2.93it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 2:  27%|█████████████▊                                     | 61/225 [00:20<00:56,  2.91it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 2:  27%|█████████████▊                                     | 61/225 [00:21<00:56,  2.91it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  28%|██████████████                                     | 62/225 [00:21<00:55,  2.92it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  28%|██████████████                                     | 62/225 [00:21<00:55,  2.92it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 2:  28%|██████████████▎                                    | 63/225 [00:21<00:55,  2.91it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 2:  28%|██████████████▎                                    | 63/225 [00:22<00:55,  2.91it/s, training_loss=0.294]\u001b[A\n",
      "Epoch 2:  28%|██████████████▌                                    | 64/225 [00:22<00:55,  2.91it/s, training_loss=0.294]\u001b[A\n",
      "Epoch 2:  28%|██████████████▌                                    | 64/225 [00:22<00:55,  2.91it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 2:  29%|██████████████▋                                    | 65/225 [00:22<00:54,  2.92it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 2:  29%|██████████████▋                                    | 65/225 [00:22<00:54,  2.92it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  29%|██████████████▉                                    | 66/225 [00:22<00:54,  2.92it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  29%|██████████████▉                                    | 66/225 [00:23<00:54,  2.92it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 2:  30%|███████████████▏                                   | 67/225 [00:23<00:54,  2.88it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 2:  30%|███████████████▏                                   | 67/225 [00:23<00:54,  2.88it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 2:  30%|███████████████▍                                   | 68/225 [00:23<00:54,  2.90it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 2:  30%|███████████████▍                                   | 68/225 [00:23<00:54,  2.90it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  31%|███████████████▋                                   | 69/225 [00:23<00:54,  2.88it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  31%|███████████████▋                                   | 69/225 [00:24<00:54,  2.88it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 2:  31%|███████████████▊                                   | 70/225 [00:24<00:53,  2.92it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 2:  31%|███████████████▊                                   | 70/225 [00:24<00:53,  2.92it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  32%|████████████████                                   | 71/225 [00:24<00:52,  2.91it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  32%|████████████████                                   | 71/225 [00:24<00:52,  2.91it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 2:  32%|████████████████▎                                  | 72/225 [00:24<00:52,  2.93it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 2:  32%|████████████████▎                                  | 72/225 [00:25<00:52,  2.93it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 2:  32%|████████████████▌                                  | 73/225 [00:25<00:51,  2.95it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 2:  32%|████████████████▌                                  | 73/225 [00:25<00:51,  2.95it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  33%|████████████████▊                                  | 74/225 [00:25<00:51,  2.92it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  33%|████████████████▊                                  | 74/225 [00:25<00:51,  2.92it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 2:  33%|█████████████████                                  | 75/225 [00:25<00:51,  2.89it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 2:  33%|█████████████████                                  | 75/225 [00:26<00:51,  2.89it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 2:  34%|█████████████████▏                                 | 76/225 [00:26<00:50,  2.93it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 2:  34%|█████████████████▏                                 | 76/225 [00:26<00:50,  2.93it/s, training_loss=0.270]\u001b[A\n",
      "Epoch 2:  34%|█████████████████▍                                 | 77/225 [00:26<00:50,  2.94it/s, training_loss=0.270]\u001b[A\n",
      "Epoch 2:  34%|█████████████████▍                                 | 77/225 [00:26<00:50,  2.94it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 2:  35%|█████████████████▋                                 | 78/225 [00:26<00:50,  2.91it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 2:  35%|█████████████████▋                                 | 78/225 [00:27<00:50,  2.91it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 2:  35%|█████████████████▉                                 | 79/225 [00:27<00:50,  2.91it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 2:  35%|█████████████████▉                                 | 79/225 [00:27<00:50,  2.91it/s, training_loss=0.398]\u001b[A\n",
      "Epoch 2:  36%|██████████████████▏                                | 80/225 [00:27<00:49,  2.93it/s, training_loss=0.398]\u001b[A\n",
      "Epoch 2:  36%|██████████████████▏                                | 80/225 [00:27<00:49,  2.93it/s, training_loss=0.301]\u001b[A\n",
      "Epoch 2:  36%|██████████████████▎                                | 81/225 [00:27<00:48,  2.95it/s, training_loss=0.301]\u001b[A\n",
      "Epoch 2:  36%|██████████████████▎                                | 81/225 [00:28<00:48,  2.95it/s, training_loss=0.236]\u001b[A\n",
      "Epoch 2:  36%|██████████████████▌                                | 82/225 [00:28<00:48,  2.94it/s, training_loss=0.236]\u001b[A\n",
      "Epoch 2:  36%|██████████████████▌                                | 82/225 [00:28<00:48,  2.94it/s, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  37%|██████████████████▊                                | 83/225 [00:28<00:48,  2.95it/s, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  37%|██████████████████▊                                | 83/225 [00:28<00:48,  2.95it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 2:  37%|███████████████████                                | 84/225 [00:28<00:47,  2.97it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 2:  37%|███████████████████                                | 84/225 [00:29<00:47,  2.97it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 2:  38%|███████████████████▎                               | 85/225 [00:29<00:47,  2.94it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 2:  38%|███████████████████▎                               | 85/225 [00:29<00:47,  2.94it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 2:  38%|███████████████████▍                               | 86/225 [00:29<00:47,  2.94it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 2:  38%|███████████████████▍                               | 86/225 [00:29<00:47,  2.94it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  39%|███████████████████▋                               | 87/225 [00:29<00:47,  2.93it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  39%|███████████████████▋                               | 87/225 [00:30<00:47,  2.93it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 2:  39%|███████████████████▉                               | 88/225 [00:30<00:46,  2.93it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 2:  39%|███████████████████▉                               | 88/225 [00:30<00:46,  2.93it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 2:  40%|████████████████████▏                              | 89/225 [00:30<00:46,  2.90it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 2:  40%|████████████████████▏                              | 89/225 [00:30<00:46,  2.90it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 2:  40%|████████████████████▍                              | 90/225 [00:30<00:46,  2.88it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 2:  40%|████████████████████▍                              | 90/225 [00:31<00:46,  2.88it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 2:  40%|████████████████████▋                              | 91/225 [00:31<00:46,  2.86it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 2:  40%|████████████████████▋                              | 91/225 [00:31<00:46,  2.86it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 2:  41%|████████████████████▊                              | 92/225 [00:31<00:46,  2.88it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 2:  41%|████████████████████▊                              | 92/225 [00:31<00:46,  2.88it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 2:  41%|█████████████████████                              | 93/225 [00:31<00:45,  2.91it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 2:  41%|█████████████████████                              | 93/225 [00:32<00:45,  2.91it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 2:  42%|█████████████████████▎                             | 94/225 [00:32<00:45,  2.91it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 2:  42%|█████████████████████▎                             | 94/225 [00:32<00:45,  2.91it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 2:  42%|█████████████████████▌                             | 95/225 [00:32<00:44,  2.90it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 2:  42%|█████████████████████▌                             | 95/225 [00:32<00:44,  2.90it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 2:  43%|█████████████████████▊                             | 96/225 [00:32<00:44,  2.88it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 2:  43%|█████████████████████▊                             | 96/225 [00:33<00:44,  2.88it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 2:  43%|█████████████████████▉                             | 97/225 [00:33<00:43,  2.92it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 2:  43%|█████████████████████▉                             | 97/225 [00:33<00:43,  2.92it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 2:  44%|██████████████████████▏                            | 98/225 [00:33<00:43,  2.92it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 2:  44%|██████████████████████▏                            | 98/225 [00:34<00:43,  2.92it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 2:  44%|██████████████████████▍                            | 99/225 [00:34<00:43,  2.90it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 2:  44%|██████████████████████▍                            | 99/225 [00:34<00:43,  2.90it/s, training_loss=0.317]\u001b[A\n",
      "Epoch 2:  44%|██████████████████████▏                           | 100/225 [00:34<00:43,  2.90it/s, training_loss=0.317]\u001b[A\n",
      "Epoch 2:  44%|██████████████████████▏                           | 100/225 [00:34<00:43,  2.90it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  45%|██████████████████████▍                           | 101/225 [00:34<00:42,  2.91it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  45%|██████████████████████▍                           | 101/225 [00:35<00:42,  2.91it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 2:  45%|██████████████████████▋                           | 102/225 [00:35<00:42,  2.89it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 2:  45%|██████████████████████▋                           | 102/225 [00:35<00:42,  2.89it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  46%|██████████████████████▉                           | 103/225 [00:35<00:41,  2.91it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  46%|██████████████████████▉                           | 103/225 [00:35<00:41,  2.91it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 2:  46%|███████████████████████                           | 104/225 [00:35<00:41,  2.91it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 2:  46%|███████████████████████                           | 104/225 [00:36<00:41,  2.91it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 2:  47%|███████████████████████▎                          | 105/225 [00:36<00:41,  2.91it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 2:  47%|███████████████████████▎                          | 105/225 [00:36<00:41,  2.91it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 2:  47%|███████████████████████▌                          | 106/225 [00:36<00:40,  2.91it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 2:  47%|███████████████████████▌                          | 106/225 [00:36<00:40,  2.91it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 2:  48%|███████████████████████▊                          | 107/225 [00:36<00:40,  2.91it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 2:  48%|███████████████████████▊                          | 107/225 [00:37<00:40,  2.91it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 2:  48%|████████████████████████                          | 108/225 [00:37<00:40,  2.88it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 2:  48%|████████████████████████                          | 108/225 [00:37<00:40,  2.88it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 2:  48%|████████████████████████▏                         | 109/225 [00:37<00:40,  2.86it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 2:  48%|████████████████████████▏                         | 109/225 [00:37<00:40,  2.86it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  49%|████████████████████████▍                         | 110/225 [00:37<00:39,  2.89it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  49%|████████████████████████▍                         | 110/225 [00:38<00:39,  2.89it/s, training_loss=0.257]\u001b[A\n",
      "Epoch 2:  49%|████████████████████████▋                         | 111/225 [00:38<00:39,  2.88it/s, training_loss=0.257]\u001b[A\n",
      "Epoch 2:  49%|████████████████████████▋                         | 111/225 [00:38<00:39,  2.88it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 2:  50%|████████████████████████▉                         | 112/225 [00:38<00:39,  2.89it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 2:  50%|████████████████████████▉                         | 112/225 [00:38<00:39,  2.89it/s, training_loss=0.267]\u001b[A\n",
      "Epoch 2:  50%|█████████████████████████                         | 113/225 [00:38<00:39,  2.87it/s, training_loss=0.267]\u001b[A\n",
      "Epoch 2:  50%|█████████████████████████                         | 113/225 [00:39<00:39,  2.87it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 2:  51%|█████████████████████████▎                        | 114/225 [00:39<00:38,  2.88it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 2:  51%|█████████████████████████▎                        | 114/225 [00:39<00:38,  2.88it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 2:  51%|█████████████████████████▌                        | 115/225 [00:39<00:37,  2.91it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 2:  51%|█████████████████████████▌                        | 115/225 [00:39<00:37,  2.91it/s, training_loss=0.333]\u001b[A\n",
      "Epoch 2:  52%|█████████████████████████▊                        | 116/225 [00:39<00:37,  2.89it/s, training_loss=0.333]\u001b[A\n",
      "Epoch 2:  52%|█████████████████████████▊                        | 116/225 [00:40<00:37,  2.89it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  52%|██████████████████████████                        | 117/225 [00:40<00:37,  2.90it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  52%|██████████████████████████                        | 117/225 [00:40<00:37,  2.90it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 2:  52%|██████████████████████████▏                       | 118/225 [00:40<00:36,  2.90it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 2:  52%|██████████████████████████▏                       | 118/225 [00:40<00:36,  2.90it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  53%|██████████████████████████▍                       | 119/225 [00:40<00:36,  2.91it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  53%|██████████████████████████▍                       | 119/225 [00:41<00:36,  2.91it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 2:  53%|██████████████████████████▋                       | 120/225 [00:41<00:35,  2.95it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 2:  53%|██████████████████████████▋                       | 120/225 [00:41<00:35,  2.95it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 2:  54%|██████████████████████████▉                       | 121/225 [00:41<00:35,  2.92it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 2:  54%|██████████████████████████▉                       | 121/225 [00:41<00:35,  2.92it/s, training_loss=0.253]\u001b[A\n",
      "Epoch 2:  54%|███████████████████████████                       | 122/225 [00:41<00:35,  2.92it/s, training_loss=0.253]\u001b[A\n",
      "Epoch 2:  54%|███████████████████████████                       | 122/225 [00:42<00:35,  2.92it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  55%|███████████████████████████▎                      | 123/225 [00:42<00:35,  2.89it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  55%|███████████████████████████▎                      | 123/225 [00:42<00:35,  2.89it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 2:  55%|███████████████████████████▌                      | 124/225 [00:42<00:34,  2.90it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 2:  55%|███████████████████████████▌                      | 124/225 [00:42<00:34,  2.90it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  56%|███████████████████████████▊                      | 125/225 [00:42<00:34,  2.89it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  56%|███████████████████████████▊                      | 125/225 [00:43<00:34,  2.89it/s, training_loss=0.275]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████                      | 126/225 [00:43<00:34,  2.86it/s, training_loss=0.275]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████                      | 126/225 [00:43<00:34,  2.86it/s, training_loss=0.375]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████▏                     | 127/225 [00:43<00:34,  2.88it/s, training_loss=0.375]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████▏                     | 127/225 [00:44<00:34,  2.88it/s, training_loss=0.272]\u001b[A\n",
      "Epoch 2:  57%|████████████████████████████▍                     | 128/225 [00:44<00:33,  2.88it/s, training_loss=0.272]\u001b[A\n",
      "Epoch 2:  57%|████████████████████████████▍                     | 128/225 [00:44<00:33,  2.88it/s, training_loss=0.257]\u001b[A\n",
      "Epoch 2:  57%|████████████████████████████▋                     | 129/225 [00:44<00:33,  2.89it/s, training_loss=0.257]\u001b[A\n",
      "Epoch 2:  57%|████████████████████████████▋                     | 129/225 [00:44<00:33,  2.89it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  58%|████████████████████████████▉                     | 130/225 [00:44<00:32,  2.91it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  58%|████████████████████████████▉                     | 130/225 [00:45<00:32,  2.91it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  58%|█████████████████████████████                     | 131/225 [00:45<00:32,  2.85it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  58%|█████████████████████████████                     | 131/225 [00:45<00:32,  2.85it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  59%|█████████████████████████████▎                    | 132/225 [00:45<00:32,  2.87it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  59%|█████████████████████████████▎                    | 132/225 [00:45<00:32,  2.87it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 2:  59%|█████████████████████████████▌                    | 133/225 [00:45<00:31,  2.95it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 2:  59%|█████████████████████████████▌                    | 133/225 [00:46<00:31,  2.95it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  60%|█████████████████████████████▊                    | 134/225 [00:46<00:31,  2.92it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  60%|█████████████████████████████▊                    | 134/225 [00:46<00:31,  2.92it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 2:  60%|██████████████████████████████                    | 135/225 [00:46<00:30,  2.91it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 2:  60%|██████████████████████████████                    | 135/225 [00:46<00:30,  2.91it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 2:  60%|██████████████████████████████▏                   | 136/225 [00:46<00:30,  2.91it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 2:  60%|██████████████████████████████▏                   | 136/225 [00:47<00:30,  2.91it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  61%|██████████████████████████████▍                   | 137/225 [00:47<00:30,  2.92it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  61%|██████████████████████████████▍                   | 137/225 [00:47<00:30,  2.92it/s, training_loss=0.310]\u001b[A\n",
      "Epoch 2:  61%|██████████████████████████████▋                   | 138/225 [00:47<00:30,  2.89it/s, training_loss=0.310]\u001b[A\n",
      "Epoch 2:  61%|██████████████████████████████▋                   | 138/225 [00:47<00:30,  2.89it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 2:  62%|██████████████████████████████▉                   | 139/225 [00:47<00:29,  2.90it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 2:  62%|██████████████████████████████▉                   | 139/225 [00:48<00:29,  2.90it/s, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  62%|███████████████████████████████                   | 140/225 [00:48<00:29,  2.93it/s, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  62%|███████████████████████████████                   | 140/225 [00:48<00:29,  2.93it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 2:  63%|███████████████████████████████▎                  | 141/225 [00:48<00:28,  2.92it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 2:  63%|███████████████████████████████▎                  | 141/225 [00:48<00:28,  2.92it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 2:  63%|███████████████████████████████▌                  | 142/225 [00:48<00:28,  2.87it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 2:  63%|███████████████████████████████▌                  | 142/225 [00:49<00:28,  2.87it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 2:  64%|███████████████████████████████▊                  | 143/225 [00:49<00:28,  2.90it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 2:  64%|███████████████████████████████▊                  | 143/225 [00:49<00:28,  2.90it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  64%|████████████████████████████████                  | 144/225 [00:49<00:27,  2.91it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  64%|████████████████████████████████                  | 144/225 [00:49<00:27,  2.91it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  64%|████████████████████████████████▏                 | 145/225 [00:49<00:27,  2.95it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  64%|████████████████████████████████▏                 | 145/225 [00:50<00:27,  2.95it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 2:  65%|████████████████████████████████▍                 | 146/225 [00:50<00:26,  2.95it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 2:  65%|████████████████████████████████▍                 | 146/225 [00:50<00:26,  2.95it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 2:  65%|████████████████████████████████▋                 | 147/225 [00:50<00:26,  2.97it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 2:  65%|████████████████████████████████▋                 | 147/225 [00:50<00:26,  2.97it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  66%|████████████████████████████████▉                 | 148/225 [00:50<00:26,  2.94it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  66%|████████████████████████████████▉                 | 148/225 [00:51<00:26,  2.94it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 2:  66%|█████████████████████████████████                 | 149/225 [00:51<00:25,  2.95it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 2:  66%|█████████████████████████████████                 | 149/225 [00:51<00:25,  2.95it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 2:  67%|█████████████████████████████████▎                | 150/225 [00:51<00:25,  2.92it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 2:  67%|█████████████████████████████████▎                | 150/225 [00:51<00:25,  2.92it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  67%|█████████████████████████████████▌                | 151/225 [00:51<00:25,  2.92it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  67%|█████████████████████████████████▌                | 151/225 [00:52<00:25,  2.92it/s, training_loss=0.226]\u001b[A\n",
      "Epoch 2:  68%|█████████████████████████████████▊                | 152/225 [00:52<00:24,  2.93it/s, training_loss=0.226]\u001b[A\n",
      "Epoch 2:  68%|█████████████████████████████████▊                | 152/225 [00:52<00:24,  2.93it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 2:  68%|██████████████████████████████████                | 153/225 [00:52<00:24,  2.91it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 2:  68%|██████████████████████████████████                | 153/225 [00:52<00:24,  2.91it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  68%|██████████████████████████████████▏               | 154/225 [00:52<00:24,  2.91it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  68%|██████████████████████████████████▏               | 154/225 [00:53<00:24,  2.91it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  69%|██████████████████████████████████▍               | 155/225 [00:53<00:23,  2.92it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  69%|██████████████████████████████████▍               | 155/225 [00:53<00:23,  2.92it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 2:  69%|██████████████████████████████████▋               | 156/225 [00:53<00:23,  2.92it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 2:  69%|██████████████████████████████████▋               | 156/225 [00:53<00:23,  2.92it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 2:  70%|██████████████████████████████████▉               | 157/225 [00:53<00:23,  2.91it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 2:  70%|██████████████████████████████████▉               | 157/225 [00:54<00:23,  2.91it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 2:  70%|███████████████████████████████████               | 158/225 [00:54<00:23,  2.91it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 2:  70%|███████████████████████████████████               | 158/225 [00:54<00:23,  2.91it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 2:  71%|███████████████████████████████████▎              | 159/225 [00:54<00:22,  2.93it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 2:  71%|███████████████████████████████████▎              | 159/225 [00:55<00:22,  2.93it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 2:  71%|███████████████████████████████████▌              | 160/225 [00:55<00:22,  2.90it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 2:  71%|███████████████████████████████████▌              | 160/225 [00:55<00:22,  2.90it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 2:  72%|███████████████████████████████████▊              | 161/225 [00:55<00:22,  2.90it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 2:  72%|███████████████████████████████████▊              | 161/225 [00:55<00:22,  2.90it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 2:  72%|████████████████████████████████████              | 162/225 [00:55<00:21,  2.91it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 2:  72%|████████████████████████████████████              | 162/225 [00:56<00:21,  2.91it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 2:  72%|████████████████████████████████████▏             | 163/225 [00:56<00:21,  2.93it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 2:  72%|████████████████████████████████████▏             | 163/225 [00:56<00:21,  2.93it/s, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  73%|████████████████████████████████████▍             | 164/225 [00:56<00:21,  2.90it/s, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  73%|████████████████████████████████████▍             | 164/225 [00:56<00:21,  2.90it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 2:  73%|████████████████████████████████████▋             | 165/225 [00:56<00:20,  2.90it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 2:  73%|████████████████████████████████████▋             | 165/225 [00:57<00:20,  2.90it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 2:  74%|████████████████████████████████████▉             | 166/225 [00:57<00:20,  2.93it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 2:  74%|████████████████████████████████████▉             | 166/225 [00:57<00:20,  2.93it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 2:  74%|█████████████████████████████████████             | 167/225 [00:57<00:19,  2.90it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 2:  74%|█████████████████████████████████████             | 167/225 [00:57<00:19,  2.90it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 2:  75%|█████████████████████████████████████▎            | 168/225 [00:57<00:19,  2.86it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 2:  75%|█████████████████████████████████████▎            | 168/225 [00:58<00:19,  2.86it/s, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  75%|█████████████████████████████████████▌            | 169/225 [00:58<00:19,  2.90it/s, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  75%|█████████████████████████████████████▌            | 169/225 [00:58<00:19,  2.90it/s, training_loss=0.230]\u001b[A\n",
      "Epoch 2:  76%|█████████████████████████████████████▊            | 170/225 [00:58<00:18,  2.92it/s, training_loss=0.230]\u001b[A\n",
      "Epoch 2:  76%|█████████████████████████████████████▊            | 170/225 [00:58<00:18,  2.92it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 2:  76%|██████████████████████████████████████            | 171/225 [00:58<00:18,  2.92it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 2:  76%|██████████████████████████████████████            | 171/225 [00:59<00:18,  2.92it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 2:  76%|██████████████████████████████████████▏           | 172/225 [00:59<00:18,  2.92it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 2:  76%|██████████████████████████████████████▏           | 172/225 [00:59<00:18,  2.92it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 2:  77%|██████████████████████████████████████▍           | 173/225 [00:59<00:17,  2.94it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 2:  77%|██████████████████████████████████████▍           | 173/225 [00:59<00:17,  2.94it/s, training_loss=0.275]\u001b[A\n",
      "Epoch 2:  77%|██████████████████████████████████████▋           | 174/225 [00:59<00:17,  2.91it/s, training_loss=0.275]\u001b[A\n",
      "Epoch 2:  77%|██████████████████████████████████████▋           | 174/225 [01:00<00:17,  2.91it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  78%|██████████████████████████████████████▉           | 175/225 [01:00<00:17,  2.91it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  78%|██████████████████████████████████████▉           | 175/225 [01:00<00:17,  2.91it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 2:  78%|███████████████████████████████████████           | 176/225 [01:00<00:16,  2.93it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 2:  78%|███████████████████████████████████████           | 176/225 [01:00<00:16,  2.93it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  79%|███████████████████████████████████████▎          | 177/225 [01:00<00:16,  2.90it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  79%|███████████████████████████████████████▎          | 177/225 [01:01<00:16,  2.90it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  79%|███████████████████████████████████████▌          | 178/225 [01:01<00:16,  2.89it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  79%|███████████████████████████████████████▌          | 178/225 [01:01<00:16,  2.89it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  80%|███████████████████████████████████████▊          | 179/225 [01:01<00:15,  2.90it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  80%|███████████████████████████████████████▊          | 179/225 [01:01<00:15,  2.90it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 2:  80%|████████████████████████████████████████          | 180/225 [01:01<00:15,  2.92it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 2:  80%|████████████████████████████████████████          | 180/225 [01:02<00:15,  2.92it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 2:  80%|████████████████████████████████████████▏         | 181/225 [01:02<00:15,  2.90it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 2:  80%|████████████████████████████████████████▏         | 181/225 [01:02<00:15,  2.90it/s, training_loss=0.303]\u001b[A\n",
      "Epoch 2:  81%|████████████████████████████████████████▍         | 182/225 [01:02<00:14,  2.90it/s, training_loss=0.303]\u001b[A\n",
      "Epoch 2:  81%|████████████████████████████████████████▍         | 182/225 [01:02<00:14,  2.90it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  81%|████████████████████████████████████████▋         | 183/225 [01:02<00:14,  2.92it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  81%|████████████████████████████████████████▋         | 183/225 [01:03<00:14,  2.92it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 2:  82%|████████████████████████████████████████▉         | 184/225 [01:03<00:14,  2.93it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 2:  82%|████████████████████████████████████████▉         | 184/225 [01:03<00:14,  2.93it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 2:  82%|█████████████████████████████████████████         | 185/225 [01:03<00:13,  2.89it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 2:  82%|█████████████████████████████████████████         | 185/225 [01:03<00:13,  2.89it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 2:  83%|█████████████████████████████████████████▎        | 186/225 [01:03<00:13,  2.90it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 2:  83%|█████████████████████████████████████████▎        | 186/225 [01:04<00:13,  2.90it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 2:  83%|█████████████████████████████████████████▌        | 187/225 [01:04<00:13,  2.90it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 2:  83%|█████████████████████████████████████████▌        | 187/225 [01:04<00:13,  2.90it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 2:  84%|█████████████████████████████████████████▊        | 188/225 [01:04<00:12,  2.92it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 2:  84%|█████████████████████████████████████████▊        | 188/225 [01:04<00:12,  2.92it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 2:  84%|██████████████████████████████████████████        | 189/225 [01:04<00:12,  2.89it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 2:  84%|██████████████████████████████████████████        | 189/225 [01:05<00:12,  2.89it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 2:  84%|██████████████████████████████████████████▏       | 190/225 [01:05<00:12,  2.90it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 2:  84%|██████████████████████████████████████████▏       | 190/225 [01:05<00:12,  2.90it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  85%|██████████████████████████████████████████▍       | 191/225 [01:05<00:11,  2.90it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  85%|██████████████████████████████████████████▍       | 191/225 [01:06<00:11,  2.90it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 2:  85%|██████████████████████████████████████████▋       | 192/225 [01:06<00:11,  2.93it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 2:  85%|██████████████████████████████████████████▋       | 192/225 [01:06<00:11,  2.93it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  86%|██████████████████████████████████████████▉       | 193/225 [01:06<00:11,  2.89it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  86%|██████████████████████████████████████████▉       | 193/225 [01:06<00:11,  2.89it/s, training_loss=0.256]\u001b[A\n",
      "Epoch 2:  86%|███████████████████████████████████████████       | 194/225 [01:06<00:10,  2.90it/s, training_loss=0.256]\u001b[A\n",
      "Epoch 2:  86%|███████████████████████████████████████████       | 194/225 [01:07<00:10,  2.90it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████████████████████▎      | 195/225 [01:07<00:10,  2.92it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████████████████████▎      | 195/225 [01:07<00:10,  2.92it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████████████████████▌      | 196/225 [01:07<00:10,  2.90it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████████████████████▌      | 196/225 [01:07<00:10,  2.90it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  88%|███████████████████████████████████████████▊      | 197/225 [01:07<00:09,  2.90it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  88%|███████████████████████████████████████████▊      | 197/225 [01:08<00:09,  2.90it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████████████████████      | 198/225 [01:08<00:09,  2.92it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████████████████████      | 198/225 [01:08<00:09,  2.92it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████████████████████▏     | 199/225 [01:08<00:08,  2.89it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████████████████████▏     | 199/225 [01:08<00:08,  2.89it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████████████████████▍     | 200/225 [01:08<00:08,  2.90it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████████████████████▍     | 200/225 [01:09<00:08,  2.90it/s, training_loss=0.156]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████████████████████▋     | 201/225 [01:09<00:08,  2.92it/s, training_loss=0.156]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████████████████████▋     | 201/225 [01:09<00:08,  2.92it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 2:  90%|████████████████████████████████████████████▉     | 202/225 [01:09<00:07,  2.90it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 2:  90%|████████████████████████████████████████████▉     | 202/225 [01:09<00:07,  2.90it/s, training_loss=0.156]\u001b[A\n",
      "Epoch 2:  90%|█████████████████████████████████████████████     | 203/225 [01:09<00:07,  2.90it/s, training_loss=0.156]\u001b[A\n",
      "Epoch 2:  90%|█████████████████████████████████████████████     | 203/225 [01:10<00:07,  2.90it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████▎    | 204/225 [01:10<00:07,  2.90it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████▎    | 204/225 [01:10<00:07,  2.90it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████▌    | 205/225 [01:10<00:06,  2.92it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████▌    | 205/225 [01:10<00:06,  2.92it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 2:  92%|█████████████████████████████████████████████▊    | 206/225 [01:10<00:06,  2.89it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 2:  92%|█████████████████████████████████████████████▊    | 206/225 [01:11<00:06,  2.89it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  92%|██████████████████████████████████████████████    | 207/225 [01:11<00:06,  2.91it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  92%|██████████████████████████████████████████████    | 207/225 [01:11<00:06,  2.91it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  92%|██████████████████████████████████████████████▏   | 208/225 [01:11<00:05,  2.93it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  92%|██████████████████████████████████████████████▏   | 208/225 [01:11<00:05,  2.93it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 2:  93%|██████████████████████████████████████████████▍   | 209/225 [01:11<00:05,  2.93it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 2:  93%|██████████████████████████████████████████████▍   | 209/225 [01:12<00:05,  2.93it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 2:  93%|██████████████████████████████████████████████▋   | 210/225 [01:12<00:05,  2.90it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 2:  93%|██████████████████████████████████████████████▋   | 210/225 [01:12<00:05,  2.90it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 2:  94%|██████████████████████████████████████████████▉   | 211/225 [01:12<00:04,  2.91it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 2:  94%|██████████████████████████████████████████████▉   | 211/225 [01:12<00:04,  2.91it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 2:  94%|███████████████████████████████████████████████   | 212/225 [01:12<00:04,  2.93it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 2:  94%|███████████████████████████████████████████████   | 212/225 [01:13<00:04,  2.93it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 2:  95%|███████████████████████████████████████████████▎  | 213/225 [01:13<00:04,  2.89it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 2:  95%|███████████████████████████████████████████████▎  | 213/225 [01:13<00:04,  2.89it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  95%|███████████████████████████████████████████████▌  | 214/225 [01:13<00:03,  2.92it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  95%|███████████████████████████████████████████████▌  | 214/225 [01:13<00:03,  2.92it/s, training_loss=0.179]\u001b[A\n",
      "Epoch 2:  96%|███████████████████████████████████████████████▊  | 215/225 [01:13<00:03,  2.92it/s, training_loss=0.179]\u001b[A\n",
      "Epoch 2:  96%|███████████████████████████████████████████████▊  | 215/225 [01:14<00:03,  2.92it/s, training_loss=0.275]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████  | 216/225 [01:14<00:03,  2.90it/s, training_loss=0.275]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████  | 216/225 [01:14<00:03,  2.90it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████▏ | 217/225 [01:14<00:02,  2.90it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████▏ | 217/225 [01:14<00:02,  2.90it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 2:  97%|████████████████████████████████████████████████▍ | 218/225 [01:14<00:02,  2.91it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 2:  97%|████████████████████████████████████████████████▍ | 218/225 [01:15<00:02,  2.91it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 2:  97%|████████████████████████████████████████████████▋ | 219/225 [01:15<00:02,  2.93it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 2:  97%|████████████████████████████████████████████████▋ | 219/225 [01:15<00:02,  2.93it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:  98%|████████████████████████████████████████████████▉ | 220/225 [01:15<00:01,  2.87it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:  98%|████████████████████████████████████████████████▉ | 220/225 [01:15<00:01,  2.87it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 2:  98%|█████████████████████████████████████████████████ | 221/225 [01:15<00:01,  2.90it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 2:  98%|█████████████████████████████████████████████████ | 221/225 [01:16<00:01,  2.90it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 2:  99%|█████████████████████████████████████████████████▎| 222/225 [01:16<00:01,  2.93it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 2:  99%|█████████████████████████████████████████████████▎| 222/225 [01:16<00:01,  2.93it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  99%|█████████████████████████████████████████████████▌| 223/225 [01:16<00:00,  2.90it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  99%|█████████████████████████████████████████████████▌| 223/225 [01:17<00:00,  2.90it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 2: 100%|█████████████████████████████████████████████████▊| 224/225 [01:17<00:00,  2.90it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 2: 100%|█████████████████████████████████████████████████▊| 224/225 [01:17<00:00,  2.90it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 2: 100%|██████████████████████████████████████████████████| 225/225 [01:17<00:00,  3.14it/s, training_loss=0.223]\u001b[A\n",
      "Epoch Progress:   2%|█▎                                                              | 2/100 [02:35<2:06:32, 77.47s/it]\u001b[A\n",
      "Epoch 3:   0%|                                                                                 | 0/225 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|                                                            | 0/225 [00:00<?, ?it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 3:   0%|▏                                                   | 1/225 [00:00<01:17,  2.90it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 3:   0%|▏                                                   | 1/225 [00:00<01:17,  2.90it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 3:   1%|▍                                                   | 2/225 [00:00<01:15,  2.96it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 3:   1%|▍                                                   | 2/225 [00:01<01:15,  2.96it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 3:   1%|▋                                                   | 3/225 [00:01<01:15,  2.94it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 3:   1%|▋                                                   | 3/225 [00:01<01:15,  2.94it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 3:   2%|▉                                                   | 4/225 [00:01<01:15,  2.93it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 3:   2%|▉                                                   | 4/225 [00:01<01:15,  2.93it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 3:   2%|█▏                                                  | 5/225 [00:01<01:14,  2.95it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 3:   2%|█▏                                                  | 5/225 [00:02<01:14,  2.95it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 3:   3%|█▍                                                  | 6/225 [00:02<01:15,  2.91it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 3:   3%|█▍                                                  | 6/225 [00:02<01:15,  2.91it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 3:   3%|█▌                                                  | 7/225 [00:02<01:15,  2.89it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 3:   3%|█▌                                                  | 7/225 [00:02<01:15,  2.89it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 3:   4%|█▊                                                  | 8/225 [00:02<01:15,  2.89it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 3:   4%|█▊                                                  | 8/225 [00:03<01:15,  2.89it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 3:   4%|██                                                  | 9/225 [00:03<01:14,  2.90it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 3:   4%|██                                                  | 9/225 [00:03<01:14,  2.90it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 3:   4%|██▎                                                | 10/225 [00:03<01:13,  2.92it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 3:   4%|██▎                                                | 10/225 [00:03<01:13,  2.92it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 3:   5%|██▍                                                | 11/225 [00:03<01:13,  2.90it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 3:   5%|██▍                                                | 11/225 [00:04<01:13,  2.90it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 3:   5%|██▋                                                | 12/225 [00:04<01:13,  2.90it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 3:   5%|██▋                                                | 12/225 [00:04<01:13,  2.90it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 3:   6%|██▉                                                | 13/225 [00:04<01:12,  2.92it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 3:   6%|██▉                                                | 13/225 [00:04<01:12,  2.92it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 3:   6%|███▏                                               | 14/225 [00:04<01:12,  2.93it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 3:   6%|███▏                                               | 14/225 [00:05<01:12,  2.93it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 3:   7%|███▍                                               | 15/225 [00:05<01:11,  2.92it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 3:   7%|███▍                                               | 15/225 [00:05<01:11,  2.92it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 3:   7%|███▋                                               | 16/225 [00:05<01:11,  2.91it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 3:   7%|███▋                                               | 16/225 [00:05<01:11,  2.91it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 3:   8%|███▊                                               | 17/225 [00:05<01:10,  2.94it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 3:   8%|███▊                                               | 17/225 [00:06<01:10,  2.94it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 3:   8%|████                                               | 18/225 [00:06<01:10,  2.93it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 3:   8%|████                                               | 18/225 [00:06<01:10,  2.93it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 3:   8%|████▎                                              | 19/225 [00:06<01:11,  2.89it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 3:   8%|████▎                                              | 19/225 [00:06<01:11,  2.89it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 3:   9%|████▌                                              | 20/225 [00:06<01:11,  2.89it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 3:   9%|████▌                                              | 20/225 [00:07<01:11,  2.89it/s, training_loss=0.293]\u001b[A\n",
      "Epoch 3:   9%|████▊                                              | 21/225 [00:07<01:10,  2.90it/s, training_loss=0.293]\u001b[A\n",
      "Epoch 3:   9%|████▊                                              | 21/225 [00:07<01:10,  2.90it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  10%|████▉                                              | 22/225 [00:07<01:09,  2.90it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  10%|████▉                                              | 22/225 [00:07<01:09,  2.90it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  10%|█████▏                                             | 23/225 [00:07<01:09,  2.90it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  10%|█████▏                                             | 23/225 [00:08<01:09,  2.90it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 3:  11%|█████▍                                             | 24/225 [00:08<01:08,  2.92it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 3:  11%|█████▍                                             | 24/225 [00:08<01:08,  2.92it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 3:  11%|█████▋                                             | 25/225 [00:08<01:08,  2.92it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 3:  11%|█████▋                                             | 25/225 [00:08<01:08,  2.92it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 3:  12%|█████▉                                             | 26/225 [00:08<01:08,  2.91it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 3:  12%|█████▉                                             | 26/225 [00:09<01:08,  2.91it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 3:  12%|██████                                             | 27/225 [00:09<01:07,  2.91it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 3:  12%|██████                                             | 27/225 [00:09<01:07,  2.91it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  12%|██████▎                                            | 28/225 [00:09<01:07,  2.94it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  12%|██████▎                                            | 28/225 [00:09<01:07,  2.94it/s, training_loss=0.323]\u001b[A\n",
      "Epoch 3:  13%|██████▌                                            | 29/225 [00:09<01:06,  2.93it/s, training_loss=0.323]\u001b[A\n",
      "Epoch 3:  13%|██████▌                                            | 29/225 [00:10<01:06,  2.93it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 3:  13%|██████▊                                            | 30/225 [00:10<01:06,  2.92it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 3:  13%|██████▊                                            | 30/225 [00:10<01:06,  2.92it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 3:  14%|███████                                            | 31/225 [00:10<01:06,  2.92it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 3:  14%|███████                                            | 31/225 [00:10<01:06,  2.92it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 3:  14%|███████▎                                           | 32/225 [00:10<01:06,  2.89it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 3:  14%|███████▎                                           | 32/225 [00:11<01:06,  2.89it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 3:  15%|███████▍                                           | 33/225 [00:11<01:05,  2.92it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 3:  15%|███████▍                                           | 33/225 [00:11<01:05,  2.92it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  15%|███████▋                                           | 34/225 [00:11<01:05,  2.93it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  15%|███████▋                                           | 34/225 [00:11<01:05,  2.93it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  16%|███████▉                                           | 35/225 [00:11<01:04,  2.94it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  16%|███████▉                                           | 35/225 [00:12<01:04,  2.94it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 3:  16%|████████▏                                          | 36/225 [00:12<01:04,  2.94it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 3:  16%|████████▏                                          | 36/225 [00:12<01:04,  2.94it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 3:  16%|████████▍                                          | 37/225 [00:12<01:04,  2.93it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 3:  16%|████████▍                                          | 37/225 [00:13<01:04,  2.93it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 3:  17%|████████▌                                          | 38/225 [00:13<01:03,  2.92it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 3:  17%|████████▌                                          | 38/225 [00:13<01:03,  2.92it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 3:  17%|████████▊                                          | 39/225 [00:13<01:03,  2.92it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 3:  17%|████████▊                                          | 39/225 [00:13<01:03,  2.92it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  18%|█████████                                          | 40/225 [00:13<01:02,  2.94it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  18%|█████████                                          | 40/225 [00:14<01:02,  2.94it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 3:  18%|█████████▎                                         | 41/225 [00:14<01:02,  2.95it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 3:  18%|█████████▎                                         | 41/225 [00:14<01:02,  2.95it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 3:  19%|█████████▌                                         | 42/225 [00:14<01:03,  2.90it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 3:  19%|█████████▌                                         | 42/225 [00:14<01:03,  2.90it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 3:  19%|█████████▋                                         | 43/225 [00:14<01:03,  2.89it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 3:  19%|█████████▋                                         | 43/225 [00:15<01:03,  2.89it/s, training_loss=0.224]\u001b[A\n",
      "Epoch 3:  20%|█████████▉                                         | 44/225 [00:15<01:02,  2.89it/s, training_loss=0.224]\u001b[A\n",
      "Epoch 3:  20%|█████████▉                                         | 44/225 [00:15<01:02,  2.89it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  20%|██████████▏                                        | 45/225 [00:15<01:01,  2.92it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  20%|██████████▏                                        | 45/225 [00:15<01:01,  2.92it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  20%|██████████▍                                        | 46/225 [00:15<01:01,  2.92it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  20%|██████████▍                                        | 46/225 [00:16<01:01,  2.92it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 3:  21%|██████████▋                                        | 47/225 [00:16<01:00,  2.92it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 3:  21%|██████████▋                                        | 47/225 [00:16<01:00,  2.92it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 3:  21%|██████████▉                                        | 48/225 [00:16<01:00,  2.92it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 3:  21%|██████████▉                                        | 48/225 [00:16<01:00,  2.92it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 3:  22%|███████████                                        | 49/225 [00:16<01:00,  2.93it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 3:  22%|███████████                                        | 49/225 [00:17<01:00,  2.93it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 3:  22%|███████████▎                                       | 50/225 [00:17<00:59,  2.93it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 3:  22%|███████████▎                                       | 50/225 [00:17<00:59,  2.93it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 3:  23%|███████████▌                                       | 51/225 [00:17<00:59,  2.91it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 3:  23%|███████████▌                                       | 51/225 [00:17<00:59,  2.91it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 3:  23%|███████████▊                                       | 52/225 [00:17<01:00,  2.88it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 3:  23%|███████████▊                                       | 52/225 [00:18<01:00,  2.88it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 3:  24%|████████████                                       | 53/225 [00:18<00:59,  2.89it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 3:  24%|████████████                                       | 53/225 [00:18<00:59,  2.89it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 3:  24%|████████████▏                                      | 54/225 [00:18<00:58,  2.92it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 3:  24%|████████████▏                                      | 54/225 [00:18<00:58,  2.92it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 3:  24%|████████████▍                                      | 55/225 [00:18<00:57,  2.94it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 3:  24%|████████████▍                                      | 55/225 [00:19<00:57,  2.94it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 3:  25%|████████████▋                                      | 56/225 [00:19<00:57,  2.93it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 3:  25%|████████████▋                                      | 56/225 [00:19<00:57,  2.93it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 3:  25%|████████████▉                                      | 57/225 [00:19<00:58,  2.90it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 3:  25%|████████████▉                                      | 57/225 [00:19<00:58,  2.90it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 3:  26%|█████████████▏                                     | 58/225 [00:19<00:57,  2.91it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 3:  26%|█████████████▏                                     | 58/225 [00:20<00:57,  2.91it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  26%|█████████████▎                                     | 59/225 [00:20<00:57,  2.91it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  26%|█████████████▎                                     | 59/225 [00:20<00:57,  2.91it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  27%|█████████████▌                                     | 60/225 [00:20<00:56,  2.95it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  27%|█████████████▌                                     | 60/225 [00:20<00:56,  2.95it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 3:  27%|█████████████▊                                     | 61/225 [00:20<00:56,  2.91it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 3:  27%|█████████████▊                                     | 61/225 [00:21<00:56,  2.91it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  28%|██████████████                                     | 62/225 [00:21<00:55,  2.91it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  28%|██████████████                                     | 62/225 [00:21<00:55,  2.91it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 3:  28%|██████████████▎                                    | 63/225 [00:21<00:55,  2.91it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 3:  28%|██████████████▎                                    | 63/225 [00:21<00:55,  2.91it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 3:  28%|██████████████▌                                    | 64/225 [00:21<00:54,  2.93it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 3:  28%|██████████████▌                                    | 64/225 [00:22<00:54,  2.93it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 3:  29%|██████████████▋                                    | 65/225 [00:22<00:54,  2.93it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 3:  29%|██████████████▋                                    | 65/225 [00:22<00:54,  2.93it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 3:  29%|██████████████▉                                    | 66/225 [00:22<00:54,  2.90it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 3:  29%|██████████████▉                                    | 66/225 [00:22<00:54,  2.90it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 3:  30%|███████████████▏                                   | 67/225 [00:22<00:54,  2.91it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 3:  30%|███████████████▏                                   | 67/225 [00:23<00:54,  2.91it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 3:  30%|███████████████▍                                   | 68/225 [00:23<00:53,  2.91it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 3:  30%|███████████████▍                                   | 68/225 [00:23<00:53,  2.91it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  31%|███████████████▋                                   | 69/225 [00:23<00:54,  2.88it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  31%|███████████████▋                                   | 69/225 [00:23<00:54,  2.88it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 3:  31%|███████████████▊                                   | 70/225 [00:23<00:53,  2.92it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 3:  31%|███████████████▊                                   | 70/225 [00:24<00:53,  2.92it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  32%|████████████████                                   | 71/225 [00:24<00:53,  2.90it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  32%|████████████████                                   | 71/225 [00:24<00:53,  2.90it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 3:  32%|████████████████▎                                  | 72/225 [00:24<00:53,  2.88it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 3:  32%|████████████████▎                                  | 72/225 [00:25<00:53,  2.88it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 3:  32%|████████████████▌                                  | 73/225 [00:25<00:52,  2.89it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 3:  32%|████████████████▌                                  | 73/225 [00:25<00:52,  2.89it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 3:  33%|████████████████▊                                  | 74/225 [00:25<00:51,  2.91it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 3:  33%|████████████████▊                                  | 74/225 [00:25<00:51,  2.91it/s, training_loss=0.304]\u001b[A\n",
      "Epoch 3:  33%|█████████████████                                  | 75/225 [00:25<00:51,  2.89it/s, training_loss=0.304]\u001b[A\n",
      "Epoch 3:  33%|█████████████████                                  | 75/225 [00:26<00:51,  2.89it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 3:  34%|█████████████████▏                                 | 76/225 [00:26<00:51,  2.91it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 3:  34%|█████████████████▏                                 | 76/225 [00:26<00:51,  2.91it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 3:  34%|█████████████████▍                                 | 77/225 [00:26<00:51,  2.90it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 3:  34%|█████████████████▍                                 | 77/225 [00:26<00:51,  2.90it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 3:  35%|█████████████████▋                                 | 78/225 [00:26<00:51,  2.88it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 3:  35%|█████████████████▋                                 | 78/225 [00:27<00:51,  2.88it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  35%|█████████████████▉                                 | 79/225 [00:27<00:50,  2.90it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  35%|█████████████████▉                                 | 79/225 [00:27<00:50,  2.90it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 3:  36%|██████████████████▏                                | 80/225 [00:27<00:50,  2.87it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 3:  36%|██████████████████▏                                | 80/225 [00:27<00:50,  2.87it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 3:  36%|██████████████████▎                                | 81/225 [00:27<00:50,  2.87it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 3:  36%|██████████████████▎                                | 81/225 [00:28<00:50,  2.87it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 3:  36%|██████████████████▌                                | 82/225 [00:28<00:50,  2.84it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 3:  36%|██████████████████▌                                | 82/225 [00:28<00:50,  2.84it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  37%|██████████████████▊                                | 83/225 [00:28<00:49,  2.84it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  37%|██████████████████▊                                | 83/225 [00:28<00:49,  2.84it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  37%|███████████████████                                | 84/225 [00:28<00:48,  2.88it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  37%|███████████████████                                | 84/225 [00:29<00:48,  2.88it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  38%|███████████████████▎                               | 85/225 [00:29<00:48,  2.88it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  38%|███████████████████▎                               | 85/225 [00:29<00:48,  2.88it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 3:  38%|███████████████████▍                               | 86/225 [00:29<00:48,  2.89it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 3:  38%|███████████████████▍                               | 86/225 [00:29<00:48,  2.89it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  39%|███████████████████▋                               | 87/225 [00:29<00:47,  2.90it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  39%|███████████████████▋                               | 87/225 [00:30<00:47,  2.90it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 3:  39%|███████████████████▉                               | 88/225 [00:30<00:46,  2.94it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 3:  39%|███████████████████▉                               | 88/225 [00:30<00:46,  2.94it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 3:  40%|████████████████████▏                              | 89/225 [00:30<00:45,  2.96it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 3:  40%|████████████████████▏                              | 89/225 [00:30<00:45,  2.96it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 3:  40%|████████████████████▍                              | 90/225 [00:30<00:45,  2.95it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 3:  40%|████████████████████▍                              | 90/225 [00:31<00:45,  2.95it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  40%|████████████████████▋                              | 91/225 [00:31<00:45,  2.96it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  40%|████████████████████▋                              | 91/225 [00:31<00:45,  2.96it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 3:  41%|████████████████████▊                              | 92/225 [00:31<00:45,  2.93it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 3:  41%|████████████████████▊                              | 92/225 [00:31<00:45,  2.93it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  41%|█████████████████████                              | 93/225 [00:31<00:45,  2.92it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  41%|█████████████████████                              | 93/225 [00:32<00:45,  2.92it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  42%|█████████████████████▎                             | 94/225 [00:32<00:44,  2.91it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  42%|█████████████████████▎                             | 94/225 [00:32<00:44,  2.91it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 3:  42%|█████████████████████▌                             | 95/225 [00:32<00:44,  2.93it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 3:  42%|█████████████████████▌                             | 95/225 [00:32<00:44,  2.93it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 3:  43%|█████████████████████▊                             | 96/225 [00:32<00:44,  2.90it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 3:  43%|█████████████████████▊                             | 96/225 [00:33<00:44,  2.90it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 3:  43%|█████████████████████▉                             | 97/225 [00:33<00:44,  2.90it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 3:  43%|█████████████████████▉                             | 97/225 [00:33<00:44,  2.90it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 3:  44%|██████████████████████▏                            | 98/225 [00:33<00:43,  2.92it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 3:  44%|██████████████████████▏                            | 98/225 [00:33<00:43,  2.92it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 3:  44%|██████████████████████▍                            | 99/225 [00:33<00:43,  2.91it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 3:  44%|██████████████████████▍                            | 99/225 [00:34<00:43,  2.91it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 3:  44%|██████████████████████▏                           | 100/225 [00:34<00:43,  2.90it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 3:  44%|██████████████████████▏                           | 100/225 [00:34<00:43,  2.90it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 3:  45%|██████████████████████▍                           | 101/225 [00:34<00:42,  2.93it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 3:  45%|██████████████████████▍                           | 101/225 [00:35<00:42,  2.93it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 3:  45%|██████████████████████▋                           | 102/225 [00:35<00:41,  2.93it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 3:  45%|██████████████████████▋                           | 102/225 [00:35<00:41,  2.93it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 3:  46%|██████████████████████▉                           | 103/225 [00:35<00:41,  2.91it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 3:  46%|██████████████████████▉                           | 103/225 [00:35<00:41,  2.91it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 3:  46%|███████████████████████                           | 104/225 [00:35<00:41,  2.92it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 3:  46%|███████████████████████                           | 104/225 [00:36<00:41,  2.92it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 3:  47%|███████████████████████▎                          | 105/225 [00:36<00:41,  2.89it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 3:  47%|███████████████████████▎                          | 105/225 [00:36<00:41,  2.89it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 3:  47%|███████████████████████▌                          | 106/225 [00:36<00:40,  2.94it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 3:  47%|███████████████████████▌                          | 106/225 [00:36<00:40,  2.94it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  48%|███████████████████████▊                          | 107/225 [00:36<00:40,  2.90it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  48%|███████████████████████▊                          | 107/225 [00:37<00:40,  2.90it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  48%|████████████████████████                          | 108/225 [00:37<00:40,  2.91it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  48%|████████████████████████                          | 108/225 [00:37<00:40,  2.91it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 3:  48%|████████████████████████▏                         | 109/225 [00:37<00:39,  2.92it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 3:  48%|████████████████████████▏                         | 109/225 [00:37<00:39,  2.92it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  49%|████████████████████████▍                         | 110/225 [00:37<00:39,  2.92it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  49%|████████████████████████▍                         | 110/225 [00:38<00:39,  2.92it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  49%|████████████████████████▋                         | 111/225 [00:38<00:39,  2.92it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  49%|████████████████████████▋                         | 111/225 [00:38<00:39,  2.92it/s, training_loss=0.323]\u001b[A\n",
      "Epoch 3:  50%|████████████████████████▉                         | 112/225 [00:38<00:38,  2.92it/s, training_loss=0.323]\u001b[A\n",
      "Epoch 3:  50%|████████████████████████▉                         | 112/225 [00:38<00:38,  2.92it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 3:  50%|█████████████████████████                         | 113/225 [00:38<00:38,  2.89it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 3:  50%|█████████████████████████                         | 113/225 [00:39<00:38,  2.89it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  51%|█████████████████████████▎                        | 114/225 [00:39<00:38,  2.90it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  51%|█████████████████████████▎                        | 114/225 [00:39<00:38,  2.90it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 3:  51%|█████████████████████████▌                        | 115/225 [00:39<00:37,  2.93it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 3:  51%|█████████████████████████▌                        | 115/225 [00:39<00:37,  2.93it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 3:  52%|█████████████████████████▊                        | 116/225 [00:39<00:37,  2.90it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 3:  52%|█████████████████████████▊                        | 116/225 [00:40<00:37,  2.90it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  52%|██████████████████████████                        | 117/225 [00:40<00:37,  2.90it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  52%|██████████████████████████                        | 117/225 [00:40<00:37,  2.90it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 3:  52%|██████████████████████████▏                       | 118/225 [00:40<00:36,  2.92it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 3:  52%|██████████████████████████▏                       | 118/225 [00:40<00:36,  2.92it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 3:  53%|██████████████████████████▍                       | 119/225 [00:40<00:36,  2.92it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 3:  53%|██████████████████████████▍                       | 119/225 [00:41<00:36,  2.92it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 3:  53%|██████████████████████████▋                       | 120/225 [00:41<00:36,  2.87it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 3:  53%|██████████████████████████▋                       | 120/225 [00:41<00:36,  2.87it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 3:  54%|██████████████████████████▉                       | 121/225 [00:41<00:35,  2.92it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 3:  54%|██████████████████████████▉                       | 121/225 [00:41<00:35,  2.92it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:  54%|███████████████████████████                       | 122/225 [00:41<00:35,  2.93it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:  54%|███████████████████████████                       | 122/225 [00:42<00:35,  2.93it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  55%|███████████████████████████▎                      | 123/225 [00:42<00:34,  2.93it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  55%|███████████████████████████▎                      | 123/225 [00:42<00:34,  2.93it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  55%|███████████████████████████▌                      | 124/225 [00:42<00:34,  2.92it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  55%|███████████████████████████▌                      | 124/225 [00:42<00:34,  2.92it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 3:  56%|███████████████████████████▊                      | 125/225 [00:42<00:34,  2.92it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 3:  56%|███████████████████████████▊                      | 125/225 [00:43<00:34,  2.92it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████                      | 126/225 [00:43<00:34,  2.90it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████                      | 126/225 [00:43<00:34,  2.90it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████▏                     | 127/225 [00:43<00:33,  2.90it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████▏                     | 127/225 [00:43<00:33,  2.90it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 3:  57%|████████████████████████████▍                     | 128/225 [00:43<00:33,  2.91it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 3:  57%|████████████████████████████▍                     | 128/225 [00:44<00:33,  2.91it/s, training_loss=0.259]\u001b[A\n",
      "Epoch 3:  57%|████████████████████████████▋                     | 129/225 [00:44<00:32,  2.93it/s, training_loss=0.259]\u001b[A\n",
      "Epoch 3:  57%|████████████████████████████▋                     | 129/225 [00:44<00:32,  2.93it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 3:  58%|████████████████████████████▉                     | 130/225 [00:44<00:32,  2.90it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 3:  58%|████████████████████████████▉                     | 130/225 [00:44<00:32,  2.90it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 3:  58%|█████████████████████████████                     | 131/225 [00:44<00:32,  2.90it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 3:  58%|█████████████████████████████                     | 131/225 [00:45<00:32,  2.90it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  59%|█████████████████████████████▎                    | 132/225 [00:45<00:31,  2.93it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  59%|█████████████████████████████▎                    | 132/225 [00:45<00:31,  2.93it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 3:  59%|█████████████████████████████▌                    | 133/225 [00:45<00:31,  2.90it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 3:  59%|█████████████████████████████▌                    | 133/225 [00:46<00:31,  2.90it/s, training_loss=0.213]\u001b[A\n",
      "Epoch 3:  60%|█████████████████████████████▊                    | 134/225 [00:46<00:31,  2.90it/s, training_loss=0.213]\u001b[A\n",
      "Epoch 3:  60%|█████████████████████████████▊                    | 134/225 [00:46<00:31,  2.90it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 3:  60%|██████████████████████████████                    | 135/225 [00:46<00:30,  2.93it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 3:  60%|██████████████████████████████                    | 135/225 [00:46<00:30,  2.93it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  60%|██████████████████████████████▏                   | 136/225 [00:46<00:30,  2.93it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  60%|██████████████████████████████▏                   | 136/225 [00:47<00:30,  2.93it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 3:  61%|██████████████████████████████▍                   | 137/225 [00:47<00:30,  2.90it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 3:  61%|██████████████████████████████▍                   | 137/225 [00:47<00:30,  2.90it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  61%|██████████████████████████████▋                   | 138/225 [00:47<00:29,  2.91it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  61%|██████████████████████████████▋                   | 138/225 [00:47<00:29,  2.91it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  62%|██████████████████████████████▉                   | 139/225 [00:47<00:29,  2.93it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  62%|██████████████████████████████▉                   | 139/225 [00:48<00:29,  2.93it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 3:  62%|███████████████████████████████                   | 140/225 [00:48<00:29,  2.90it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 3:  62%|███████████████████████████████                   | 140/225 [00:48<00:29,  2.90it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 3:  63%|███████████████████████████████▎                  | 141/225 [00:48<00:28,  2.90it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 3:  63%|███████████████████████████████▎                  | 141/225 [00:48<00:28,  2.90it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 3:  63%|███████████████████████████████▌                  | 142/225 [00:48<00:28,  2.90it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 3:  63%|███████████████████████████████▌                  | 142/225 [00:49<00:28,  2.90it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 3:  64%|███████████████████████████████▊                  | 143/225 [00:49<00:28,  2.92it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 3:  64%|███████████████████████████████▊                  | 143/225 [00:49<00:28,  2.92it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 3:  64%|████████████████████████████████                  | 144/225 [00:49<00:27,  2.90it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 3:  64%|████████████████████████████████                  | 144/225 [00:49<00:27,  2.90it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 3:  64%|████████████████████████████████▏                 | 145/225 [00:49<00:27,  2.90it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 3:  64%|████████████████████████████████▏                 | 145/225 [00:50<00:27,  2.90it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 3:  65%|████████████████████████████████▍                 | 146/225 [00:50<00:27,  2.91it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 3:  65%|████████████████████████████████▍                 | 146/225 [00:50<00:27,  2.91it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 3:  65%|████████████████████████████████▋                 | 147/225 [00:50<00:26,  2.92it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 3:  65%|████████████████████████████████▋                 | 147/225 [00:50<00:26,  2.92it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 3:  66%|████████████████████████████████▉                 | 148/225 [00:50<00:26,  2.89it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 3:  66%|████████████████████████████████▉                 | 148/225 [00:51<00:26,  2.89it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 3:  66%|█████████████████████████████████                 | 149/225 [00:51<00:26,  2.92it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 3:  66%|█████████████████████████████████                 | 149/225 [00:51<00:26,  2.92it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  67%|█████████████████████████████████▎                | 150/225 [00:51<00:25,  2.91it/s, training_loss=0.037]\u001b[A"
     ]
    }
   ],
   "source": [
    "#install packages\n",
    "!pip install transformers\n",
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import logging\n",
    "import random\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def custom_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    if test_size == 0:\n",
    "        return X, [], y, []\n",
    "    # Find classes with only one or two instances\n",
    "    small_classes = classes[counts < 5]\n",
    "\n",
    "    # Separate out the instances of small classes\n",
    "    large_class_mask = ~np.isin(y, small_classes)\n",
    "    X_large = X[large_class_mask]\n",
    "    y_large = y[large_class_mask]\n",
    "    X_small = X[~large_class_mask]\n",
    "    y_small = y[~large_class_mask]\n",
    "\n",
    "    # Perform stratified split on the larger classes dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_large, y_large, test_size=test_size, random_state=random_state, stratify=y_large\n",
    "    )\n",
    "\n",
    "    # Randomly assign instances of small classes to training or testing sets\n",
    "    for i in range(len(X_small)):\n",
    "        if np.random.rand() < test_size:\n",
    "            X_test = np.vstack([X_test, X_small[i]])\n",
    "            y_test = np.hstack([y_test, y_small[i]])\n",
    "        else:\n",
    "            X_train = np.vstack([X_train, X_small[i]])\n",
    "            y_train = np.hstack([y_train, y_small[i]])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#evaluation\n",
    "def accuracy_per_class(predictions, true_vals):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "\n",
    "    accuracy_dict = {}\n",
    "    count_dict = {}\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = pred_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        accuracy_dict[label] = np.sum(y_preds == y_true) / len(y_true) if len(y_true) > 0 else 0\n",
    "        count_dict[label] = len(y_true)\n",
    "\n",
    "    return accuracy_dict, count_dict\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='combine_top6_finetuning_training_epochs_100.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class TQDMLoggingWrapper(tqdm):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.logger = logger\n",
    "\n",
    "    def display(self, msg=None, pos=None):\n",
    "        if msg is not None:\n",
    "            self.logger.info(msg)\n",
    "        super().display(msg, pos)\n",
    "\n",
    "    def update(self, n=1):\n",
    "        super().update(n)\n",
    "        desc = self.format_dict.get('desc', 'No description')\n",
    "        postfix = self.format_dict.get('postfix', '')\n",
    "        self.logger.info(f'{desc} - {postfix}')\n",
    "\n",
    "    def set_description(self, desc=None, refresh=True):\n",
    "        super().set_description(desc, refresh)\n",
    "        if desc:\n",
    "            self.logger.info(f'Set description: {desc}')\n",
    "\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "#Read data from git:\n",
    "#https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\n",
    "# URL of the CSV file\n",
    "cadec_csv_url = \"https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\"\n",
    "# read data from smm4h\n",
    "smm4h_csv_url = \"https://raw.githubusercontent.com/FANMISUA/ADE_Norm/main/Data/smm4h_soc.tsv\"\n",
    "\n",
    "top6SMM4H = [10037175, 10018065,10029205, 10017947, 10028395, 10022891]\n",
    "top6label_dict = {\n",
    "    10037175: 0,\n",
    "    10018065: 1,\n",
    "    10029205: 2,\n",
    "    10017947: 3,\n",
    "    10028395: 4,\n",
    "    10022891: 5\n",
    "}\n",
    "\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"ade\", \"soc_code\"]\n",
    "smm4h_all = pd.read_csv(smm4h_csv_url,names=column_names, sep = '\\t', header=None)\n",
    "\n",
    "smm4h_all = smm4h_all[smm4h_all['soc_code'] != 0]\n",
    "smm4h_all['soc_code'] = pd.to_numeric(smm4h_all['soc_code'], errors='coerce').astype('Int64')\n",
    "smm4h_unique = smm4h_all.drop_duplicates(subset='ade')\n",
    "\n",
    "# print(\"smm4h data:\",smm4h_all.shape)\n",
    "smm4h_soc_code_counts = smm4h_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "print(\"SOC count in CADEC: \",smm4h_soc_code_counts)\n",
    "# Filter DataFrame\n",
    "smm4h_filtered_data3 = smm4h_unique[smm4h_unique['soc_code'].isin(top6SMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "top6inSMM4H = smm4h_filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"TT\", \"llt_code\", \"ade\", \"soc_code\"]\n",
    "cadec_all = pd.read_csv(cadec_csv_url,names=column_names, header=None)\n",
    "\n",
    "# Remove duplicate rows based on the 'ade' column\n",
    "cadec_unique = cadec_all.drop_duplicates(subset='ade')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "# print(\"clean cadec data:\",cadec_unique.shape)\n",
    "# Count occurrences of each 'soc_code'\n",
    "cadec_soc_code_counts = cadec_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "# print(\"SOC count in CADEC: \",cadec_soc_code_counts)\n",
    "\n",
    "\n",
    "# Filter DataFrame\n",
    "cadec_filtered_data3 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "CADECtop6inSMM4H = cadec_filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "\n",
    "# For SMM4H data\n",
    "df1 = top6inSMM4H.copy()\n",
    "df1.loc[:, 'label'] = df1['soc_code'].map(top6label_dict)\n",
    "\n",
    "# For CADEC data\n",
    "df2 = CADECtop6inSMM4H.copy()\n",
    "df2.loc[:, 'label'] = df2['soc_code'].map(top6label_dict)\n",
    "\n",
    "print(\"SMM4H top 6\",df1)\n",
    "print(\"CADEC top 6\",df2)\n",
    "\n",
    "#combine top6 data\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "# Define the random seeds and other parameters\n",
    "seed_values = list(range(2, 4, 2))\n",
    "\n",
    "# fix batch_size 16, learning rate 1e-5; Finetuning epochs\n",
    "learning_rates = [1e-5]\n",
    "batch_sizes = [16]\n",
    "epochs_list = [100]\n",
    "# Results storage\n",
    "results = []\n",
    "# Store the training losses across all splits\n",
    "all_training_losses = []\n",
    "# Main loop over seed values\n",
    "# Training loop\n",
    "for seed_val in seed_values:\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "    \n",
    "    training_losses = []\n",
    "    \n",
    "\n",
    "\n",
    "    # Training loop for grid search\n",
    "    for lr in learning_rates:\n",
    "      for batch_size in batch_sizes:\n",
    "          for epochs in epochs_list:\n",
    "              # Data preparation\n",
    "                tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "                encoded_data_train = tokenizer.batch_encode_plus(\n",
    "                    df.ade.values,\n",
    "                    add_special_tokens=True,\n",
    "                    return_attention_mask=True,\n",
    "                    pad_to_max_length=True,\n",
    "                    max_length=256,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                input_ids_train = encoded_data_train['input_ids']\n",
    "                attention_masks_train = encoded_data_train['attention_mask']\n",
    "                labels_train = torch.tensor(df.label.values)\n",
    "                \n",
    "                dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "                dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "                \n",
    "                model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(top6label_dict), output_attentions=False, output_hidden_states=False)\n",
    "                optimizer = AdamW(model.parameters(), lr=lr, eps=1e-8)\n",
    "                scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train) * epochs)\n",
    "                \n",
    "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                model.to(device)\n",
    "                \n",
    "                # Training loop\n",
    "                for epoch in TQDMLoggingWrapper(range(1, epochs+1), desc='Epoch Progress'):\n",
    "                    model.train()\n",
    "                    loss_train_total = 0\n",
    "                \n",
    "                    progress_bar = TQDMLoggingWrapper(dataloader_train, desc=f'Epoch {epoch}', leave=False, disable=False)\n",
    "                    for batch in progress_bar:\n",
    "                        model.zero_grad()\n",
    "                        batch = tuple(b.to(device) for b in batch)\n",
    "                        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "                \n",
    "                        outputs = model(**inputs)\n",
    "                        loss = outputs[0]\n",
    "                        loss_train_total += loss.item()\n",
    "                        loss.backward()\n",
    "                \n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "                \n",
    "                        progress_bar.set_postfix({'training_loss': f'{loss.item()/len(batch):.3f}'})\n",
    "                \n",
    "                    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "                    training_losses.append(loss_train_avg)\n",
    "                \n",
    "                    logger.info(f'Epoch {epoch}: Training loss = {loss_train_avg:.4f}')\n",
    "                \n",
    "                all_training_losses.append(training_losses)\n",
    "\n",
    "# Calculate the average training loss and standard deviation across all splits\n",
    "average_training_losses = np.mean(all_training_losses, axis=0)\n",
    "std_training_losses = np.std(all_training_losses, axis=0)\n",
    "\n",
    "# Save the training losses to a file\n",
    "with open('combine_top6_training_losses.txt', 'w') as f:\n",
    "    for epoch, loss in enumerate(average_training_losses, 1):\n",
    "        f.write(f'Epoch {epoch}: {loss:.4f}\\n')\n",
    "\n",
    "# Plotting training loss\n",
    "epochs_range = range(1, epochs + 1)\n",
    "mean_losses = np.mean(all_training_losses, axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs_range, mean_losses, '-o', color='b', alpha=0.7)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss vs. Epochs')\n",
    "plt.grid(True)\n",
    "plt.savefig('combine_top6_trainingloss_vs_epochs.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
