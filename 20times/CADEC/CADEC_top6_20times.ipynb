{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a8a85b-3d0d-4b4b-900b-f56171359b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "SOC count in CADEC:  soc_code\n",
      "10037175    287\n",
      "10018065    235\n",
      "10029205    212\n",
      "10017947     63\n",
      "10028395     58\n",
      "10022891     54\n",
      "10027433     48\n",
      "10040785     28\n",
      "10038738     22\n",
      "10022117     16\n",
      "10015919     16\n",
      "10038604     10\n",
      "10047065     10\n",
      "10021428      8\n",
      "10041244      7\n",
      "10007541      7\n",
      "10038359      6\n",
      "10021881      5\n",
      "10013993      4\n",
      "10019805      2\n",
      "10042613      2\n",
      "10029104      2\n",
      "10077536      1\n",
      "10010331      1\n",
      "0             1\n",
      "10014698      1\n",
      "Name: count, dtype: Int64\n",
      "SMM4H top 6                             ade  soc_code  label\n",
      "3                            AD  10037175      0\n",
      "4                         focus  10029205      2\n",
      "5                          died  10018065      1\n",
      "8                        dreams  10037175      0\n",
      "10                   withdrawal  10018065      1\n",
      "...                         ...       ...    ...\n",
      "1698     can't go back to sleep  10037175      0\n",
      "1703                 chest hurt  10018065      1\n",
      "1704   got ten minutes of sleep  10037175      0\n",
      "1708  never have another orgasm  10037175      0\n",
      "1710        gain so much weight  10022891      5\n",
      "\n",
      "[909 rows x 3 columns]\n",
      "CADEC top 6                             ade  soc_code  label\n",
      "299      bowel/uterine cramping  10017947      3\n",
      "300            Abdominal cramps  10017947      3\n",
      "301          abdominal cramping  10017947      3\n",
      "302   abdominal cramps and pain  10017947      3\n",
      "303            abdominal cramps  10017947      3\n",
      "...                         ...       ...    ...\n",
      "5326  short term memory lacking  10037175      0\n",
      "5328      couldn't eat or drink  10037175      0\n",
      "5329              Could not eat  10037175      0\n",
      "5331           can't eat normal  10037175      0\n",
      "5332   Disturbed sleep patterns  10037175      0\n",
      "\n",
      "[2685 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2888: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch Progress:   0%|                                                                           | 0/40 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|                                                                                 | 0/135 [00:00<?, ?it/s]\u001b[AC:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Epoch 1:   0%|                                                            | 0/135 [00:00<?, ?it/s, training_loss=0.553]\u001b[A\n",
      "Epoch 1:   1%|▍                                                   | 1/135 [00:00<01:07,  1.97it/s, training_loss=0.553]\u001b[A\n",
      "Epoch 1:   1%|▍                                                   | 1/135 [00:00<01:07,  1.97it/s, training_loss=0.562]\u001b[A\n",
      "Epoch 1:   1%|▊                                                   | 2/135 [00:00<00:41,  3.24it/s, training_loss=0.562]\u001b[A\n",
      "Epoch 1:   1%|▊                                                   | 2/135 [00:00<00:41,  3.24it/s, training_loss=0.577]\u001b[A\n",
      "Epoch 1:   2%|█▏                                                  | 3/135 [00:00<00:32,  4.11it/s, training_loss=0.577]\u001b[A\n",
      "Epoch 1:   2%|█▏                                                  | 3/135 [00:01<00:32,  4.11it/s, training_loss=0.593]\u001b[A\n",
      "Epoch 1:   3%|█▌                                                  | 4/135 [00:01<00:27,  4.71it/s, training_loss=0.593]\u001b[A\n",
      "Epoch 1:   3%|█▌                                                  | 4/135 [00:01<00:27,  4.71it/s, training_loss=0.640]\u001b[A\n",
      "Epoch 1:   4%|█▉                                                  | 5/135 [00:01<00:25,  5.12it/s, training_loss=0.640]\u001b[A\n",
      "Epoch 1:   4%|█▉                                                  | 5/135 [00:01<00:25,  5.12it/s, training_loss=0.616]\u001b[A\n",
      "Epoch 1:   4%|██▎                                                 | 6/135 [00:01<00:23,  5.39it/s, training_loss=0.616]\u001b[A\n",
      "Epoch 1:   4%|██▎                                                 | 6/135 [00:01<00:23,  5.39it/s, training_loss=0.492]\u001b[A\n",
      "Epoch 1:   5%|██▋                                                 | 7/135 [00:01<00:22,  5.60it/s, training_loss=0.492]\u001b[A\n",
      "Epoch 1:   5%|██▋                                                 | 7/135 [00:01<00:22,  5.60it/s, training_loss=0.563]\u001b[A\n",
      "Epoch 1:   6%|███                                                 | 8/135 [00:01<00:22,  5.72it/s, training_loss=0.563]\u001b[A\n",
      "Epoch 1:   6%|███                                                 | 8/135 [00:01<00:22,  5.72it/s, training_loss=0.522]\u001b[A\n",
      "Epoch 1:   7%|███▍                                                | 9/135 [00:01<00:21,  5.81it/s, training_loss=0.522]\u001b[A\n",
      "Epoch 1:   7%|███▍                                                | 9/135 [00:02<00:21,  5.81it/s, training_loss=0.494]\u001b[A\n",
      "Epoch 1:   7%|███▊                                               | 10/135 [00:02<00:21,  5.88it/s, training_loss=0.494]\u001b[A\n",
      "Epoch 1:   7%|███▊                                               | 10/135 [00:02<00:21,  5.88it/s, training_loss=0.470]\u001b[A\n",
      "Epoch 1:   8%|████▏                                              | 11/135 [00:02<00:20,  5.93it/s, training_loss=0.470]\u001b[A\n",
      "Epoch 1:   8%|████▏                                              | 11/135 [00:02<00:20,  5.93it/s, training_loss=0.581]\u001b[A\n",
      "Epoch 1:   9%|████▌                                              | 12/135 [00:02<00:20,  5.96it/s, training_loss=0.581]\u001b[A\n",
      "Epoch 1:   9%|████▌                                              | 12/135 [00:02<00:20,  5.96it/s, training_loss=0.534]\u001b[A\n",
      "Epoch 1:  10%|████▉                                              | 13/135 [00:02<00:20,  5.96it/s, training_loss=0.534]\u001b[A\n",
      "Epoch 1:  10%|████▉                                              | 13/135 [00:02<00:20,  5.96it/s, training_loss=0.536]\u001b[A\n",
      "Epoch 1:  10%|█████▎                                             | 14/135 [00:02<00:20,  6.00it/s, training_loss=0.536]\u001b[A\n",
      "Epoch 1:  10%|█████▎                                             | 14/135 [00:02<00:20,  6.00it/s, training_loss=0.494]\u001b[A\n",
      "Epoch 1:  11%|█████▋                                             | 15/135 [00:02<00:19,  6.02it/s, training_loss=0.494]\u001b[A\n",
      "Epoch 1:  11%|█████▋                                             | 15/135 [00:02<00:19,  6.02it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  12%|██████                                             | 16/135 [00:02<00:19,  6.00it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  12%|██████                                             | 16/135 [00:03<00:19,  6.00it/s, training_loss=0.519]\u001b[A\n",
      "Epoch 1:  13%|██████▍                                            | 17/135 [00:03<00:19,  6.03it/s, training_loss=0.519]\u001b[A\n",
      "Epoch 1:  13%|██████▍                                            | 17/135 [00:03<00:19,  6.03it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  13%|██████▊                                            | 18/135 [00:03<00:19,  6.03it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  13%|██████▊                                            | 18/135 [00:03<00:19,  6.03it/s, training_loss=0.547]\u001b[A\n",
      "Epoch 1:  14%|███████▏                                           | 19/135 [00:03<00:19,  6.00it/s, training_loss=0.547]\u001b[A\n",
      "Epoch 1:  14%|███████▏                                           | 19/135 [00:03<00:19,  6.00it/s, training_loss=0.552]\u001b[A\n",
      "Epoch 1:  15%|███████▌                                           | 20/135 [00:03<00:19,  6.02it/s, training_loss=0.552]\u001b[A\n",
      "Epoch 1:  15%|███████▌                                           | 20/135 [00:03<00:19,  6.02it/s, training_loss=0.510]\u001b[A\n",
      "Epoch 1:  16%|███████▉                                           | 21/135 [00:03<00:18,  6.03it/s, training_loss=0.510]\u001b[A\n",
      "Epoch 1:  16%|███████▉                                           | 21/135 [00:03<00:18,  6.03it/s, training_loss=0.483]\u001b[A\n",
      "Epoch 1:  16%|████████▎                                          | 22/135 [00:03<00:18,  6.02it/s, training_loss=0.483]\u001b[A\n",
      "Epoch 1:  16%|████████▎                                          | 22/135 [00:04<00:18,  6.02it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  17%|████████▋                                          | 23/135 [00:04<00:18,  6.02it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  17%|████████▋                                          | 23/135 [00:04<00:18,  6.02it/s, training_loss=0.393]\u001b[A\n",
      "Epoch 1:  18%|█████████                                          | 24/135 [00:04<00:18,  6.01it/s, training_loss=0.393]\u001b[A\n",
      "Epoch 1:  18%|█████████                                          | 24/135 [00:04<00:18,  6.01it/s, training_loss=0.529]\u001b[A\n",
      "Epoch 1:  19%|█████████▍                                         | 25/135 [00:04<00:18,  6.01it/s, training_loss=0.529]\u001b[A\n",
      "Epoch 1:  19%|█████████▍                                         | 25/135 [00:04<00:18,  6.01it/s, training_loss=0.552]\u001b[A\n",
      "Epoch 1:  19%|█████████▊                                         | 26/135 [00:04<00:18,  6.00it/s, training_loss=0.552]\u001b[A\n",
      "Epoch 1:  19%|█████████▊                                         | 26/135 [00:04<00:18,  6.00it/s, training_loss=0.557]\u001b[A\n",
      "Epoch 1:  20%|██████████▏                                        | 27/135 [00:04<00:17,  6.01it/s, training_loss=0.557]\u001b[A\n",
      "Epoch 1:  20%|██████████▏                                        | 27/135 [00:04<00:17,  6.01it/s, training_loss=0.356]\u001b[A\n",
      "Epoch 1:  21%|██████████▌                                        | 28/135 [00:04<00:17,  6.02it/s, training_loss=0.356]\u001b[A\n",
      "Epoch 1:  21%|██████████▌                                        | 28/135 [00:05<00:17,  6.02it/s, training_loss=0.479]\u001b[A\n",
      "Epoch 1:  21%|██████████▉                                        | 29/135 [00:05<00:17,  6.00it/s, training_loss=0.479]\u001b[A\n",
      "Epoch 1:  21%|██████████▉                                        | 29/135 [00:05<00:17,  6.00it/s, training_loss=0.520]\u001b[A\n",
      "Epoch 1:  22%|███████████▎                                       | 30/135 [00:05<00:17,  6.00it/s, training_loss=0.520]\u001b[A\n",
      "Epoch 1:  22%|███████████▎                                       | 30/135 [00:05<00:17,  6.00it/s, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  23%|███████████▋                                       | 31/135 [00:05<00:17,  6.00it/s, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  23%|███████████▋                                       | 31/135 [00:05<00:17,  6.00it/s, training_loss=0.402]\u001b[A\n",
      "Epoch 1:  24%|████████████                                       | 32/135 [00:05<00:17,  6.00it/s, training_loss=0.402]\u001b[A\n",
      "Epoch 1:  24%|████████████                                       | 32/135 [00:05<00:17,  6.00it/s, training_loss=0.457]\u001b[A\n",
      "Epoch 1:  24%|████████████▍                                      | 33/135 [00:05<00:16,  6.01it/s, training_loss=0.457]\u001b[A\n",
      "Epoch 1:  24%|████████████▍                                      | 33/135 [00:05<00:16,  6.01it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  25%|████████████▊                                      | 34/135 [00:05<00:16,  6.02it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  25%|████████████▊                                      | 34/135 [00:06<00:16,  6.02it/s, training_loss=0.499]\u001b[A\n",
      "Epoch 1:  26%|█████████████▏                                     | 35/135 [00:06<00:16,  6.00it/s, training_loss=0.499]\u001b[A\n",
      "Epoch 1:  26%|█████████████▏                                     | 35/135 [00:06<00:16,  6.00it/s, training_loss=0.404]\u001b[A\n",
      "Epoch 1:  27%|█████████████▌                                     | 36/135 [00:06<00:16,  6.02it/s, training_loss=0.404]\u001b[A\n",
      "Epoch 1:  27%|█████████████▌                                     | 36/135 [00:06<00:16,  6.02it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  27%|█████████████▉                                     | 37/135 [00:06<00:16,  6.01it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  27%|█████████████▉                                     | 37/135 [00:06<00:16,  6.01it/s, training_loss=0.508]\u001b[A\n",
      "Epoch 1:  28%|██████████████▎                                    | 38/135 [00:06<00:16,  5.99it/s, training_loss=0.508]\u001b[A\n",
      "Epoch 1:  28%|██████████████▎                                    | 38/135 [00:06<00:16,  5.99it/s, training_loss=0.518]\u001b[A\n",
      "Epoch 1:  29%|██████████████▋                                    | 39/135 [00:06<00:15,  6.01it/s, training_loss=0.518]\u001b[A\n",
      "Epoch 1:  29%|██████████████▋                                    | 39/135 [00:06<00:15,  6.01it/s, training_loss=0.355]\u001b[A\n",
      "Epoch 1:  30%|███████████████                                    | 40/135 [00:06<00:15,  6.01it/s, training_loss=0.355]\u001b[A\n",
      "Epoch 1:  30%|███████████████                                    | 40/135 [00:07<00:15,  6.01it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  30%|███████████████▍                                   | 41/135 [00:07<00:15,  6.00it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  30%|███████████████▍                                   | 41/135 [00:07<00:15,  6.00it/s, training_loss=0.433]\u001b[A\n",
      "Epoch 1:  31%|███████████████▊                                   | 42/135 [00:07<00:15,  6.01it/s, training_loss=0.433]\u001b[A\n",
      "Epoch 1:  31%|███████████████▊                                   | 42/135 [00:07<00:15,  6.01it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  32%|████████████████▏                                  | 43/135 [00:07<00:15,  6.01it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  32%|████████████████▏                                  | 43/135 [00:07<00:15,  6.01it/s, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  33%|████████████████▌                                  | 44/135 [00:07<00:15,  6.00it/s, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  33%|████████████████▌                                  | 44/135 [00:07<00:15,  6.00it/s, training_loss=0.416]\u001b[A\n",
      "Epoch 1:  33%|█████████████████                                  | 45/135 [00:07<00:15,  6.00it/s, training_loss=0.416]\u001b[A\n",
      "Epoch 1:  33%|█████████████████                                  | 45/135 [00:07<00:15,  6.00it/s, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  34%|█████████████████▍                                 | 46/135 [00:07<00:14,  5.99it/s, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  34%|█████████████████▍                                 | 46/135 [00:08<00:14,  5.99it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  35%|█████████████████▊                                 | 47/135 [00:08<00:14,  5.98it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  35%|█████████████████▊                                 | 47/135 [00:08<00:14,  5.98it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  36%|██████████████████▏                                | 48/135 [00:08<00:14,  5.97it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  36%|██████████████████▏                                | 48/135 [00:08<00:14,  5.97it/s, training_loss=0.400]\u001b[A\n",
      "Epoch 1:  36%|██████████████████▌                                | 49/135 [00:08<00:14,  5.97it/s, training_loss=0.400]\u001b[A\n",
      "Epoch 1:  36%|██████████████████▌                                | 49/135 [00:08<00:14,  5.97it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  37%|██████████████████▉                                | 50/135 [00:08<00:14,  5.99it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  37%|██████████████████▉                                | 50/135 [00:08<00:14,  5.99it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  38%|███████████████████▎                               | 51/135 [00:08<00:14,  5.99it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  38%|███████████████████▎                               | 51/135 [00:08<00:14,  5.99it/s, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  39%|███████████████████▋                               | 52/135 [00:08<00:13,  5.99it/s, training_loss=0.394]\u001b[A\n",
      "Epoch 1:  39%|███████████████████▋                               | 52/135 [00:09<00:13,  5.99it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  39%|████████████████████                               | 53/135 [00:09<00:13,  5.99it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  39%|████████████████████                               | 53/135 [00:09<00:13,  5.99it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  40%|████████████████████▍                              | 54/135 [00:09<00:13,  6.00it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  40%|████████████████████▍                              | 54/135 [00:09<00:13,  6.00it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  41%|████████████████████▊                              | 55/135 [00:09<00:13,  5.99it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  41%|████████████████████▊                              | 55/135 [00:09<00:13,  5.99it/s, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  41%|█████████████████████▏                             | 56/135 [00:09<00:13,  6.00it/s, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  41%|█████████████████████▏                             | 56/135 [00:09<00:13,  6.00it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  42%|█████████████████████▌                             | 57/135 [00:09<00:12,  6.01it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  42%|█████████████████████▌                             | 57/135 [00:09<00:12,  6.01it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  43%|█████████████████████▉                             | 58/135 [00:09<00:12,  6.00it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  43%|█████████████████████▉                             | 58/135 [00:10<00:12,  6.00it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  44%|██████████████████████▎                            | 59/135 [00:10<00:12,  5.99it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  44%|██████████████████████▎                            | 59/135 [00:10<00:12,  5.99it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  44%|██████████████████████▋                            | 60/135 [00:10<00:12,  6.01it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  44%|██████████████████████▋                            | 60/135 [00:10<00:12,  6.01it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  45%|███████████████████████                            | 61/135 [00:10<00:12,  5.97it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  45%|███████████████████████                            | 61/135 [00:10<00:12,  5.97it/s, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  46%|███████████████████████▍                           | 62/135 [00:10<00:12,  5.97it/s, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  46%|███████████████████████▍                           | 62/135 [00:10<00:12,  5.97it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  47%|███████████████████████▊                           | 63/135 [00:10<00:12,  5.98it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  47%|███████████████████████▊                           | 63/135 [00:10<00:12,  5.98it/s, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  47%|████████████████████████▏                          | 64/135 [00:10<00:11,  5.98it/s, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  47%|████████████████████████▏                          | 64/135 [00:11<00:11,  5.98it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  48%|████████████████████████▌                          | 65/135 [00:11<00:11,  5.98it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  48%|████████████████████████▌                          | 65/135 [00:11<00:11,  5.98it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  49%|████████████████████████▉                          | 66/135 [00:11<00:11,  5.97it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  49%|████████████████████████▉                          | 66/135 [00:11<00:11,  5.97it/s, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  50%|█████████████████████████▎                         | 67/135 [00:11<00:11,  5.97it/s, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  50%|█████████████████████████▎                         | 67/135 [00:11<00:11,  5.97it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  50%|█████████████████████████▋                         | 68/135 [00:11<00:11,  5.98it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  50%|█████████████████████████▋                         | 68/135 [00:11<00:11,  5.98it/s, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  51%|██████████████████████████                         | 69/135 [00:11<00:11,  5.97it/s, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  51%|██████████████████████████                         | 69/135 [00:12<00:11,  5.97it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  52%|██████████████████████████▍                        | 70/135 [00:12<00:10,  5.97it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  52%|██████████████████████████▍                        | 70/135 [00:12<00:10,  5.97it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  53%|██████████████████████████▊                        | 71/135 [00:12<00:10,  5.98it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  53%|██████████████████████████▊                        | 71/135 [00:12<00:10,  5.98it/s, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  53%|███████████████████████████▏                       | 72/135 [00:12<00:10,  5.98it/s, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  53%|███████████████████████████▏                       | 72/135 [00:12<00:10,  5.98it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 1:  54%|███████████████████████████▌                       | 73/135 [00:12<00:10,  5.97it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 1:  54%|███████████████████████████▌                       | 73/135 [00:12<00:10,  5.97it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  55%|███████████████████████████▉                       | 74/135 [00:12<00:10,  5.99it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  55%|███████████████████████████▉                       | 74/135 [00:12<00:10,  5.99it/s, training_loss=0.375]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████▎                      | 75/135 [00:12<00:10,  5.96it/s, training_loss=0.375]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████▎                      | 75/135 [00:13<00:10,  5.96it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████▋                      | 76/135 [00:13<00:09,  5.99it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████▋                      | 76/135 [00:13<00:09,  5.99it/s, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  57%|█████████████████████████████                      | 77/135 [00:13<00:09,  5.99it/s, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  57%|█████████████████████████████                      | 77/135 [00:13<00:09,  5.99it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  58%|█████████████████████████████▍                     | 78/135 [00:13<00:09,  5.99it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  58%|█████████████████████████████▍                     | 78/135 [00:13<00:09,  5.99it/s, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  59%|█████████████████████████████▊                     | 79/135 [00:13<00:09,  6.01it/s, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  59%|█████████████████████████████▊                     | 79/135 [00:13<00:09,  6.01it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  59%|██████████████████████████████▏                    | 80/135 [00:13<00:09,  5.99it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  59%|██████████████████████████████▏                    | 80/135 [00:13<00:09,  5.99it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  60%|██████████████████████████████▌                    | 81/135 [00:13<00:08,  6.00it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  60%|██████████████████████████████▌                    | 81/135 [00:14<00:08,  6.00it/s, training_loss=0.402]\u001b[A\n",
      "Epoch 1:  61%|██████████████████████████████▉                    | 82/135 [00:14<00:08,  5.97it/s, training_loss=0.402]\u001b[A\n",
      "Epoch 1:  61%|██████████████████████████████▉                    | 82/135 [00:14<00:08,  5.97it/s, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  61%|███████████████████████████████▎                   | 83/135 [00:14<00:08,  5.96it/s, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  61%|███████████████████████████████▎                   | 83/135 [00:14<00:08,  5.96it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 1:  62%|███████████████████████████████▋                   | 84/135 [00:14<00:08,  5.97it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 1:  62%|███████████████████████████████▋                   | 84/135 [00:14<00:08,  5.97it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  63%|████████████████████████████████                   | 85/135 [00:14<00:08,  5.98it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  63%|████████████████████████████████                   | 85/135 [00:14<00:08,  5.98it/s, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  64%|████████████████████████████████▍                  | 86/135 [00:14<00:08,  5.98it/s, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  64%|████████████████████████████████▍                  | 86/135 [00:14<00:08,  5.98it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  64%|████████████████████████████████▊                  | 87/135 [00:14<00:07,  6.01it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  64%|████████████████████████████████▊                  | 87/135 [00:15<00:07,  6.01it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 1:  65%|█████████████████████████████████▏                 | 88/135 [00:15<00:07,  6.01it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 1:  65%|█████████████████████████████████▏                 | 88/135 [00:15<00:07,  6.01it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  66%|█████████████████████████████████▌                 | 89/135 [00:15<00:07,  5.98it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  66%|█████████████████████████████████▌                 | 89/135 [00:15<00:07,  5.98it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  67%|██████████████████████████████████                 | 90/135 [00:15<00:07,  5.98it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  67%|██████████████████████████████████                 | 90/135 [00:15<00:07,  5.98it/s, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  67%|██████████████████████████████████▍                | 91/135 [00:15<00:07,  5.97it/s, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  67%|██████████████████████████████████▍                | 91/135 [00:15<00:07,  5.97it/s, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  68%|██████████████████████████████████▊                | 92/135 [00:15<00:07,  5.96it/s, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  68%|██████████████████████████████████▊                | 92/135 [00:15<00:07,  5.96it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  69%|███████████████████████████████████▏               | 93/135 [00:15<00:07,  5.99it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  69%|███████████████████████████████████▏               | 93/135 [00:16<00:07,  5.99it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  70%|███████████████████████████████████▌               | 94/135 [00:16<00:06,  5.99it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  70%|███████████████████████████████████▌               | 94/135 [00:16<00:06,  5.99it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  70%|███████████████████████████████████▉               | 95/135 [00:16<00:06,  6.00it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  70%|███████████████████████████████████▉               | 95/135 [00:16<00:06,  6.00it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  71%|████████████████████████████████████▎              | 96/135 [00:16<00:06,  6.02it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  71%|████████████████████████████████████▎              | 96/135 [00:16<00:06,  6.02it/s, training_loss=0.366]\u001b[A\n",
      "Epoch 1:  72%|████████████████████████████████████▋              | 97/135 [00:16<00:06,  6.03it/s, training_loss=0.366]\u001b[A\n",
      "Epoch 1:  72%|████████████████████████████████████▋              | 97/135 [00:16<00:06,  6.03it/s, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  73%|█████████████████████████████████████              | 98/135 [00:16<00:06,  6.01it/s, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  73%|█████████████████████████████████████              | 98/135 [00:16<00:06,  6.01it/s, training_loss=0.420]\u001b[A\n",
      "Epoch 1:  73%|█████████████████████████████████████▍             | 99/135 [00:16<00:05,  6.01it/s, training_loss=0.420]\u001b[A\n",
      "Epoch 1:  73%|█████████████████████████████████████▍             | 99/135 [00:17<00:05,  6.01it/s, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  74%|█████████████████████████████████████             | 100/135 [00:17<00:05,  6.04it/s, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  74%|█████████████████████████████████████             | 100/135 [00:17<00:05,  6.04it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  75%|█████████████████████████████████████▍            | 101/135 [00:17<00:05,  6.02it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 1:  75%|█████████████████████████████████████▍            | 101/135 [00:17<00:05,  6.02it/s, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  76%|█████████████████████████████████████▊            | 102/135 [00:17<00:05,  6.01it/s, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  76%|█████████████████████████████████████▊            | 102/135 [00:17<00:05,  6.01it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  76%|██████████████████████████████████████▏           | 103/135 [00:17<00:05,  6.01it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  76%|██████████████████████████████████████▏           | 103/135 [00:17<00:05,  6.01it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  77%|██████████████████████████████████████▌           | 104/135 [00:17<00:05,  6.01it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  77%|██████████████████████████████████████▌           | 104/135 [00:17<00:05,  6.01it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  78%|██████████████████████████████████████▉           | 105/135 [00:17<00:04,  6.01it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  78%|██████████████████████████████████████▉           | 105/135 [00:18<00:04,  6.01it/s, training_loss=0.502]\u001b[A\n",
      "Epoch 1:  79%|███████████████████████████████████████▎          | 106/135 [00:18<00:04,  5.98it/s, training_loss=0.502]\u001b[A\n",
      "Epoch 1:  79%|███████████████████████████████████████▎          | 106/135 [00:18<00:04,  5.98it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  79%|███████████████████████████████████████▋          | 107/135 [00:18<00:04,  6.01it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  79%|███████████████████████████████████████▋          | 107/135 [00:18<00:04,  6.01it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  80%|████████████████████████████████████████          | 108/135 [00:18<00:04,  6.01it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  80%|████████████████████████████████████████          | 108/135 [00:18<00:04,  6.01it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  81%|████████████████████████████████████████▎         | 109/135 [00:18<00:04,  6.01it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  81%|████████████████████████████████████████▎         | 109/135 [00:18<00:04,  6.01it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 1:  81%|████████████████████████████████████████▋         | 110/135 [00:18<00:04,  6.01it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 1:  81%|████████████████████████████████████████▋         | 110/135 [00:18<00:04,  6.01it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  82%|█████████████████████████████████████████         | 111/135 [00:18<00:03,  6.01it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  82%|█████████████████████████████████████████         | 111/135 [00:19<00:03,  6.01it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  83%|█████████████████████████████████████████▍        | 112/135 [00:19<00:03,  6.02it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  83%|█████████████████████████████████████████▍        | 112/135 [00:19<00:03,  6.02it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  84%|█████████████████████████████████████████▊        | 113/135 [00:19<00:03,  6.01it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  84%|█████████████████████████████████████████▊        | 113/135 [00:19<00:03,  6.01it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  84%|██████████████████████████████████████████▏       | 114/135 [00:19<00:03,  6.01it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  84%|██████████████████████████████████████████▏       | 114/135 [00:19<00:03,  6.01it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 1:  85%|██████████████████████████████████████████▌       | 115/135 [00:19<00:03,  6.02it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 1:  85%|██████████████████████████████████████████▌       | 115/135 [00:19<00:03,  6.02it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  86%|██████████████████████████████████████████▉       | 116/135 [00:19<00:03,  6.02it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 1:  86%|██████████████████████████████████████████▉       | 116/135 [00:19<00:03,  6.02it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████████████████████▎      | 117/135 [00:19<00:02,  6.02it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████████████████████▎      | 117/135 [00:20<00:02,  6.02it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████████████████████▋      | 118/135 [00:20<00:02,  6.00it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████████████████████▋      | 118/135 [00:20<00:02,  6.00it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████████████████████      | 119/135 [00:20<00:02,  6.00it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████████████████████      | 119/135 [00:20<00:02,  6.00it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████████████████████▍     | 120/135 [00:20<00:02,  5.99it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████████████████████▍     | 120/135 [00:20<00:02,  5.99it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  90%|████████████████████████████████████████████▊     | 121/135 [00:20<00:02,  6.01it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  90%|████████████████████████████████████████████▊     | 121/135 [00:20<00:02,  6.01it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  90%|█████████████████████████████████████████████▏    | 122/135 [00:20<00:02,  6.01it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  90%|█████████████████████████████████████████████▏    | 122/135 [00:20<00:02,  6.01it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████▌    | 123/135 [00:20<00:02,  5.99it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████▌    | 123/135 [00:21<00:02,  5.99it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 1:  92%|█████████████████████████████████████████████▉    | 124/135 [00:21<00:01,  5.99it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 1:  92%|█████████████████████████████████████████████▉    | 124/135 [00:21<00:01,  5.99it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 1:  93%|██████████████████████████████████████████████▎   | 125/135 [00:21<00:01,  5.99it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 1:  93%|██████████████████████████████████████████████▎   | 125/135 [00:21<00:01,  5.99it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  93%|██████████████████████████████████████████████▋   | 126/135 [00:21<00:01,  6.01it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  93%|██████████████████████████████████████████████▋   | 126/135 [00:21<00:01,  6.01it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  94%|███████████████████████████████████████████████   | 127/135 [00:21<00:01,  5.99it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  94%|███████████████████████████████████████████████   | 127/135 [00:21<00:01,  5.99it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  95%|███████████████████████████████████████████████▍  | 128/135 [00:21<00:01,  6.00it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  95%|███████████████████████████████████████████████▍  | 128/135 [00:21<00:01,  6.00it/s, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  96%|███████████████████████████████████████████████▊  | 129/135 [00:21<00:01,  6.00it/s, training_loss=0.300]\u001b[A\n",
      "Epoch 1:  96%|███████████████████████████████████████████████▊  | 129/135 [00:22<00:01,  6.00it/s, training_loss=0.185]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████▏ | 130/135 [00:22<00:00,  6.01it/s, training_loss=0.185]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████▏ | 130/135 [00:22<00:00,  6.01it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  97%|████████████████████████████████████████████████▌ | 131/135 [00:22<00:00,  6.00it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  97%|████████████████████████████████████████████████▌ | 131/135 [00:22<00:00,  6.00it/s, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  98%|████████████████████████████████████████████████▉ | 132/135 [00:22<00:00,  6.01it/s, training_loss=0.331]\u001b[A\n",
      "Epoch 1:  98%|████████████████████████████████████████████████▉ | 132/135 [00:22<00:00,  6.01it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████████████████████████████████▎| 133/135 [00:22<00:00,  6.03it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████████████████████████████████▎| 133/135 [00:22<00:00,  6.03it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████████████████████████████████▋| 134/135 [00:22<00:00,  6.00it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████████████████████████████████▋| 134/135 [00:22<00:00,  6.00it/s, training_loss=0.257]\u001b[A\n",
      "Epoch Progress:   2%|█▋                                                                 | 1/40 [00:22<14:46, 22.73s/it]\u001b[A\n",
      "Epoch 2:   0%|                                                                                 | 0/135 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|                                                            | 0/135 [00:00<?, ?it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 2:   1%|▍                                                   | 1/135 [00:00<00:21,  6.11it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 2:   1%|▍                                                   | 1/135 [00:00<00:21,  6.11it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 2:   1%|▊                                                   | 2/135 [00:00<00:21,  6.07it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 2:   1%|▊                                                   | 2/135 [00:00<00:21,  6.07it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 2:   2%|█▏                                                  | 3/135 [00:00<00:21,  6.02it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 2:   2%|█▏                                                  | 3/135 [00:00<00:21,  6.02it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 2:   3%|█▌                                                  | 4/135 [00:00<00:21,  6.07it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 2:   3%|█▌                                                  | 4/135 [00:00<00:21,  6.07it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:   4%|█▉                                                  | 5/135 [00:00<00:21,  6.06it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:   4%|█▉                                                  | 5/135 [00:00<00:21,  6.06it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 2:   4%|██▎                                                 | 6/135 [00:00<00:21,  6.04it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 2:   4%|██▎                                                 | 6/135 [00:01<00:21,  6.04it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 2:   5%|██▋                                                 | 7/135 [00:01<00:21,  6.02it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 2:   5%|██▋                                                 | 7/135 [00:01<00:21,  6.02it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 2:   6%|███                                                 | 8/135 [00:01<00:21,  6.01it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 2:   6%|███                                                 | 8/135 [00:01<00:21,  6.01it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:   7%|███▍                                                | 9/135 [00:01<00:21,  6.00it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:   7%|███▍                                                | 9/135 [00:01<00:21,  6.00it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 2:   7%|███▊                                               | 10/135 [00:01<00:20,  6.00it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 2:   7%|███▊                                               | 10/135 [00:01<00:20,  6.00it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 2:   8%|████▏                                              | 11/135 [00:01<00:20,  5.99it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 2:   8%|████▏                                              | 11/135 [00:01<00:20,  5.99it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 2:   9%|████▌                                              | 12/135 [00:01<00:20,  5.97it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 2:   9%|████▌                                              | 12/135 [00:02<00:20,  5.97it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 2:  10%|████▉                                              | 13/135 [00:02<00:20,  5.97it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 2:  10%|████▉                                              | 13/135 [00:02<00:20,  5.97it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  10%|█████▎                                             | 14/135 [00:02<00:20,  5.98it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  10%|█████▎                                             | 14/135 [00:02<00:20,  5.98it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  11%|█████▋                                             | 15/135 [00:02<00:20,  5.96it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  11%|█████▋                                             | 15/135 [00:02<00:20,  5.96it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  12%|██████                                             | 16/135 [00:02<00:19,  5.98it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  12%|██████                                             | 16/135 [00:02<00:19,  5.98it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 2:  13%|██████▍                                            | 17/135 [00:02<00:19,  5.98it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 2:  13%|██████▍                                            | 17/135 [00:02<00:19,  5.98it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 2:  13%|██████▊                                            | 18/135 [00:03<00:19,  5.98it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 2:  13%|██████▊                                            | 18/135 [00:03<00:19,  5.98it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  14%|███████▏                                           | 19/135 [00:03<00:19,  5.98it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  14%|███████▏                                           | 19/135 [00:03<00:19,  5.98it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 2:  15%|███████▌                                           | 20/135 [00:03<00:19,  5.97it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 2:  15%|███████▌                                           | 20/135 [00:03<00:19,  5.97it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  16%|███████▉                                           | 21/135 [00:03<00:19,  5.98it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  16%|███████▉                                           | 21/135 [00:03<00:19,  5.98it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  16%|████████▎                                          | 22/135 [00:03<00:18,  5.95it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  16%|████████▎                                          | 22/135 [00:03<00:18,  5.95it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  17%|████████▋                                          | 23/135 [00:03<00:18,  5.97it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  17%|████████▋                                          | 23/135 [00:04<00:18,  5.97it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  18%|█████████                                          | 24/135 [00:04<00:18,  5.97it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  18%|█████████                                          | 24/135 [00:04<00:18,  5.97it/s, training_loss=0.268]\u001b[A\n",
      "Epoch 2:  19%|█████████▍                                         | 25/135 [00:04<00:18,  5.96it/s, training_loss=0.268]\u001b[A\n",
      "Epoch 2:  19%|█████████▍                                         | 25/135 [00:04<00:18,  5.96it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  19%|█████████▊                                         | 26/135 [00:04<00:18,  5.95it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  19%|█████████▊                                         | 26/135 [00:04<00:18,  5.95it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  20%|██████████▏                                        | 27/135 [00:04<00:18,  5.96it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  20%|██████████▏                                        | 27/135 [00:04<00:18,  5.96it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  21%|██████████▌                                        | 28/135 [00:04<00:18,  5.94it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  21%|██████████▌                                        | 28/135 [00:04<00:18,  5.94it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  21%|██████████▉                                        | 29/135 [00:04<00:17,  5.95it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  21%|██████████▉                                        | 29/135 [00:05<00:17,  5.95it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  22%|███████████▎                                       | 30/135 [00:05<00:17,  5.94it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  22%|███████████▎                                       | 30/135 [00:05<00:17,  5.94it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  23%|███████████▋                                       | 31/135 [00:05<00:17,  5.95it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  23%|███████████▋                                       | 31/135 [00:05<00:17,  5.95it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 2:  24%|████████████                                       | 32/135 [00:05<00:17,  5.95it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 2:  24%|████████████                                       | 32/135 [00:05<00:17,  5.95it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  24%|████████████▍                                      | 33/135 [00:05<00:17,  5.96it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  24%|████████████▍                                      | 33/135 [00:05<00:17,  5.96it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 2:  25%|████████████▊                                      | 34/135 [00:05<00:16,  5.95it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 2:  25%|████████████▊                                      | 34/135 [00:05<00:16,  5.95it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  26%|█████████████▏                                     | 35/135 [00:05<00:16,  5.96it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  26%|█████████████▏                                     | 35/135 [00:06<00:16,  5.96it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  27%|█████████████▌                                     | 36/135 [00:06<00:16,  5.95it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  27%|█████████████▌                                     | 36/135 [00:06<00:16,  5.95it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  27%|█████████████▉                                     | 37/135 [00:06<00:16,  5.95it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  27%|█████████████▉                                     | 37/135 [00:06<00:16,  5.95it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  28%|██████████████▎                                    | 38/135 [00:06<00:16,  5.95it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  28%|██████████████▎                                    | 38/135 [00:06<00:16,  5.95it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  29%|██████████████▋                                    | 39/135 [00:06<00:16,  5.96it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  29%|██████████████▋                                    | 39/135 [00:06<00:16,  5.96it/s, training_loss=0.298]\u001b[A\n",
      "Epoch 2:  30%|███████████████                                    | 40/135 [00:06<00:15,  5.94it/s, training_loss=0.298]\u001b[A\n",
      "Epoch 2:  30%|███████████████                                    | 40/135 [00:06<00:15,  5.94it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  30%|███████████████▍                                   | 41/135 [00:06<00:15,  5.97it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  30%|███████████████▍                                   | 41/135 [00:07<00:15,  5.97it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 2:  31%|███████████████▊                                   | 42/135 [00:07<00:15,  5.97it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 2:  31%|███████████████▊                                   | 42/135 [00:07<00:15,  5.97it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 2:  32%|████████████████▏                                  | 43/135 [00:07<00:15,  5.96it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 2:  32%|████████████████▏                                  | 43/135 [00:07<00:15,  5.96it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  33%|████████████████▌                                  | 44/135 [00:07<00:15,  5.95it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  33%|████████████████▌                                  | 44/135 [00:07<00:15,  5.95it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  33%|█████████████████                                  | 45/135 [00:07<00:15,  5.96it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  33%|█████████████████                                  | 45/135 [00:07<00:15,  5.96it/s, training_loss=0.186]\u001b[A\n",
      "Epoch 2:  34%|█████████████████▍                                 | 46/135 [00:07<00:14,  5.95it/s, training_loss=0.186]\u001b[A\n",
      "Epoch 2:  34%|█████████████████▍                                 | 46/135 [00:07<00:14,  5.95it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  35%|█████████████████▊                                 | 47/135 [00:07<00:14,  5.95it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  35%|█████████████████▊                                 | 47/135 [00:08<00:14,  5.95it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  36%|██████████████████▏                                | 48/135 [00:08<00:14,  5.95it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  36%|██████████████████▏                                | 48/135 [00:08<00:14,  5.95it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  36%|██████████████████▌                                | 49/135 [00:08<00:14,  5.98it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  36%|██████████████████▌                                | 49/135 [00:08<00:14,  5.98it/s, training_loss=0.254]\u001b[A\n",
      "Epoch 2:  37%|██████████████████▉                                | 50/135 [00:08<00:14,  5.95it/s, training_loss=0.254]\u001b[A\n",
      "Epoch 2:  37%|██████████████████▉                                | 50/135 [00:08<00:14,  5.95it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  38%|███████████████████▎                               | 51/135 [00:08<00:14,  5.97it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  38%|███████████████████▎                               | 51/135 [00:08<00:14,  5.97it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 2:  39%|███████████████████▋                               | 52/135 [00:08<00:13,  5.96it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 2:  39%|███████████████████▋                               | 52/135 [00:08<00:13,  5.96it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  39%|████████████████████                               | 53/135 [00:08<00:13,  5.94it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  39%|████████████████████                               | 53/135 [00:09<00:13,  5.94it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  40%|████████████████████▍                              | 54/135 [00:09<00:13,  5.96it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  40%|████████████████████▍                              | 54/135 [00:09<00:13,  5.96it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 2:  41%|████████████████████▊                              | 55/135 [00:09<00:13,  5.95it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 2:  41%|████████████████████▊                              | 55/135 [00:09<00:13,  5.95it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  41%|█████████████████████▏                             | 56/135 [00:09<00:13,  5.94it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  41%|█████████████████████▏                             | 56/135 [00:09<00:13,  5.94it/s, training_loss=0.224]\u001b[A\n",
      "Epoch 2:  42%|█████████████████████▌                             | 57/135 [00:09<00:13,  5.94it/s, training_loss=0.224]\u001b[A\n",
      "Epoch 2:  42%|█████████████████████▌                             | 57/135 [00:09<00:13,  5.94it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 2:  43%|█████████████████████▉                             | 58/135 [00:09<00:12,  5.97it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 2:  43%|█████████████████████▉                             | 58/135 [00:09<00:12,  5.97it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 2:  44%|██████████████████████▎                            | 59/135 [00:09<00:12,  5.97it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 2:  44%|██████████████████████▎                            | 59/135 [00:10<00:12,  5.97it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 2:  44%|██████████████████████▋                            | 60/135 [00:10<00:12,  5.96it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 2:  44%|██████████████████████▋                            | 60/135 [00:10<00:12,  5.96it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  45%|███████████████████████                            | 61/135 [00:10<00:12,  5.96it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  45%|███████████████████████                            | 61/135 [00:10<00:12,  5.96it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  46%|███████████████████████▍                           | 62/135 [00:10<00:12,  5.96it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  46%|███████████████████████▍                           | 62/135 [00:10<00:12,  5.96it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  47%|███████████████████████▊                           | 63/135 [00:10<00:12,  5.96it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  47%|███████████████████████▊                           | 63/135 [00:10<00:12,  5.96it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 2:  47%|████████████████████████▏                          | 64/135 [00:10<00:11,  5.93it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 2:  47%|████████████████████████▏                          | 64/135 [00:10<00:11,  5.93it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  48%|████████████████████████▌                          | 65/135 [00:10<00:11,  5.94it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  48%|████████████████████████▌                          | 65/135 [00:11<00:11,  5.94it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 2:  49%|████████████████████████▉                          | 66/135 [00:11<00:11,  5.94it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 2:  49%|████████████████████████▉                          | 66/135 [00:11<00:11,  5.94it/s, training_loss=0.286]\u001b[A\n",
      "Epoch 2:  50%|█████████████████████████▎                         | 67/135 [00:11<00:11,  5.94it/s, training_loss=0.286]\u001b[A\n",
      "Epoch 2:  50%|█████████████████████████▎                         | 67/135 [00:11<00:11,  5.94it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  50%|█████████████████████████▋                         | 68/135 [00:11<00:11,  5.92it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  50%|█████████████████████████▋                         | 68/135 [00:11<00:11,  5.92it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 2:  51%|██████████████████████████                         | 69/135 [00:11<00:11,  5.91it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 2:  51%|██████████████████████████                         | 69/135 [00:11<00:11,  5.91it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  52%|██████████████████████████▍                        | 70/135 [00:11<00:10,  5.93it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  52%|██████████████████████████▍                        | 70/135 [00:11<00:10,  5.93it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  53%|██████████████████████████▊                        | 71/135 [00:11<00:10,  5.93it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  53%|██████████████████████████▊                        | 71/135 [00:12<00:10,  5.93it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 2:  53%|███████████████████████████▏                       | 72/135 [00:12<00:10,  5.93it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 2:  53%|███████████████████████████▏                       | 72/135 [00:12<00:10,  5.93it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  54%|███████████████████████████▌                       | 73/135 [00:12<00:10,  5.94it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  54%|███████████████████████████▌                       | 73/135 [00:12<00:10,  5.94it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 2:  55%|███████████████████████████▉                       | 74/135 [00:12<00:10,  5.95it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 2:  55%|███████████████████████████▉                       | 74/135 [00:12<00:10,  5.95it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████▎                      | 75/135 [00:12<00:10,  5.92it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████▎                      | 75/135 [00:12<00:10,  5.92it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████▋                      | 76/135 [00:12<00:09,  5.93it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████▋                      | 76/135 [00:12<00:09,  5.93it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 2:  57%|█████████████████████████████                      | 77/135 [00:12<00:09,  5.94it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 2:  57%|█████████████████████████████                      | 77/135 [00:13<00:09,  5.94it/s, training_loss=0.179]\u001b[A\n",
      "Epoch 2:  58%|█████████████████████████████▍                     | 78/135 [00:13<00:09,  5.94it/s, training_loss=0.179]\u001b[A\n",
      "Epoch 2:  58%|█████████████████████████████▍                     | 78/135 [00:13<00:09,  5.94it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  59%|█████████████████████████████▊                     | 79/135 [00:13<00:09,  5.95it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  59%|█████████████████████████████▊                     | 79/135 [00:13<00:09,  5.95it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  59%|██████████████████████████████▏                    | 80/135 [00:13<00:09,  5.94it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  59%|██████████████████████████████▏                    | 80/135 [00:13<00:09,  5.94it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 2:  60%|██████████████████████████████▌                    | 81/135 [00:13<00:09,  5.94it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 2:  60%|██████████████████████████████▌                    | 81/135 [00:13<00:09,  5.94it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 2:  61%|██████████████████████████████▉                    | 82/135 [00:13<00:08,  5.95it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 2:  61%|██████████████████████████████▉                    | 82/135 [00:13<00:08,  5.95it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 2:  61%|███████████████████████████████▎                   | 83/135 [00:13<00:08,  5.95it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 2:  61%|███████████████████████████████▎                   | 83/135 [00:14<00:08,  5.95it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 2:  62%|███████████████████████████████▋                   | 84/135 [00:14<00:08,  5.95it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 2:  62%|███████████████████████████████▋                   | 84/135 [00:14<00:08,  5.95it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 2:  63%|████████████████████████████████                   | 85/135 [00:14<00:08,  5.96it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 2:  63%|████████████████████████████████                   | 85/135 [00:14<00:08,  5.96it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  64%|████████████████████████████████▍                  | 86/135 [00:14<00:08,  5.95it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  64%|████████████████████████████████▍                  | 86/135 [00:14<00:08,  5.95it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 2:  64%|████████████████████████████████▊                  | 87/135 [00:14<00:08,  5.97it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 2:  64%|████████████████████████████████▊                  | 87/135 [00:14<00:08,  5.97it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  65%|█████████████████████████████████▏                 | 88/135 [00:14<00:07,  5.95it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  65%|█████████████████████████████████▏                 | 88/135 [00:14<00:07,  5.95it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 2:  66%|█████████████████████████████████▌                 | 89/135 [00:14<00:07,  5.93it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 2:  66%|█████████████████████████████████▌                 | 89/135 [00:15<00:07,  5.93it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 2:  67%|██████████████████████████████████                 | 90/135 [00:15<00:07,  5.95it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 2:  67%|██████████████████████████████████                 | 90/135 [00:15<00:07,  5.95it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  67%|██████████████████████████████████▍                | 91/135 [00:15<00:07,  5.94it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  67%|██████████████████████████████████▍                | 91/135 [00:15<00:07,  5.94it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 2:  68%|██████████████████████████████████▊                | 92/135 [00:15<00:07,  5.92it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 2:  68%|██████████████████████████████████▊                | 92/135 [00:15<00:07,  5.92it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  69%|███████████████████████████████████▏               | 93/135 [00:15<00:07,  5.94it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  69%|███████████████████████████████████▏               | 93/135 [00:15<00:07,  5.94it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 2:  70%|███████████████████████████████████▌               | 94/135 [00:15<00:06,  5.94it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 2:  70%|███████████████████████████████████▌               | 94/135 [00:15<00:06,  5.94it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  70%|███████████████████████████████████▉               | 95/135 [00:15<00:06,  5.94it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  70%|███████████████████████████████████▉               | 95/135 [00:16<00:06,  5.94it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  71%|████████████████████████████████████▎              | 96/135 [00:16<00:06,  5.95it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  71%|████████████████████████████████████▎              | 96/135 [00:16<00:06,  5.95it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 2:  72%|████████████████████████████████████▋              | 97/135 [00:16<00:06,  5.94it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 2:  72%|████████████████████████████████████▋              | 97/135 [00:16<00:06,  5.94it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 2:  73%|█████████████████████████████████████              | 98/135 [00:16<00:06,  5.95it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 2:  73%|█████████████████████████████████████              | 98/135 [00:16<00:06,  5.95it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 2:  73%|█████████████████████████████████████▍             | 99/135 [00:16<00:06,  5.97it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 2:  73%|█████████████████████████████████████▍             | 99/135 [00:16<00:06,  5.97it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 2:  74%|█████████████████████████████████████             | 100/135 [00:16<00:05,  5.93it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 2:  74%|█████████████████████████████████████             | 100/135 [00:16<00:05,  5.93it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 2:  75%|█████████████████████████████████████▍            | 101/135 [00:16<00:05,  5.93it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 2:  75%|█████████████████████████████████████▍            | 101/135 [00:17<00:05,  5.93it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  76%|█████████████████████████████████████▊            | 102/135 [00:17<00:05,  5.94it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  76%|█████████████████████████████████████▊            | 102/135 [00:17<00:05,  5.94it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  76%|██████████████████████████████████████▏           | 103/135 [00:17<00:05,  5.93it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  76%|██████████████████████████████████████▏           | 103/135 [00:17<00:05,  5.93it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 2:  77%|██████████████████████████████████████▌           | 104/135 [00:17<00:05,  5.95it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 2:  77%|██████████████████████████████████████▌           | 104/135 [00:17<00:05,  5.95it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  78%|██████████████████████████████████████▉           | 105/135 [00:17<00:05,  5.96it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  78%|██████████████████████████████████████▉           | 105/135 [00:17<00:05,  5.96it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  79%|███████████████████████████████████████▎          | 106/135 [00:17<00:04,  5.95it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  79%|███████████████████████████████████████▎          | 106/135 [00:17<00:04,  5.95it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  79%|███████████████████████████████████████▋          | 107/135 [00:17<00:04,  5.94it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  79%|███████████████████████████████████████▋          | 107/135 [00:18<00:04,  5.94it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  80%|████████████████████████████████████████          | 108/135 [00:18<00:04,  5.92it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  80%|████████████████████████████████████████          | 108/135 [00:18<00:04,  5.92it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  81%|████████████████████████████████████████▎         | 109/135 [00:18<00:04,  5.94it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  81%|████████████████████████████████████████▎         | 109/135 [00:18<00:04,  5.94it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  81%|████████████████████████████████████████▋         | 110/135 [00:18<00:04,  5.90it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  81%|████████████████████████████████████████▋         | 110/135 [00:18<00:04,  5.90it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 2:  82%|█████████████████████████████████████████         | 111/135 [00:18<00:04,  5.92it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 2:  82%|█████████████████████████████████████████         | 111/135 [00:18<00:04,  5.92it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 2:  83%|█████████████████████████████████████████▍        | 112/135 [00:18<00:03,  5.93it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 2:  83%|█████████████████████████████████████████▍        | 112/135 [00:18<00:03,  5.93it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 2:  84%|█████████████████████████████████████████▊        | 113/135 [00:18<00:03,  5.93it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 2:  84%|█████████████████████████████████████████▊        | 113/135 [00:19<00:03,  5.93it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 2:  84%|██████████████████████████████████████████▏       | 114/135 [00:19<00:03,  5.93it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 2:  84%|██████████████████████████████████████████▏       | 114/135 [00:19<00:03,  5.93it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  85%|██████████████████████████████████████████▌       | 115/135 [00:19<00:03,  5.93it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  85%|██████████████████████████████████████████▌       | 115/135 [00:19<00:03,  5.93it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  86%|██████████████████████████████████████████▉       | 116/135 [00:19<00:03,  5.93it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  86%|██████████████████████████████████████████▉       | 116/135 [00:19<00:03,  5.93it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████████████████████▎      | 117/135 [00:19<00:03,  5.94it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████████████████████▎      | 117/135 [00:19<00:03,  5.94it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████████████████████▋      | 118/135 [00:19<00:02,  5.93it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████████████████████▋      | 118/135 [00:19<00:02,  5.93it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████████████████████      | 119/135 [00:19<00:02,  5.92it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████████████████████      | 119/135 [00:20<00:02,  5.92it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████████████████████▍     | 120/135 [00:20<00:02,  5.94it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████████████████████▍     | 120/135 [00:20<00:02,  5.94it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  90%|████████████████████████████████████████████▊     | 121/135 [00:20<00:02,  5.93it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  90%|████████████████████████████████████████████▊     | 121/135 [00:20<00:02,  5.93it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  90%|█████████████████████████████████████████████▏    | 122/135 [00:20<00:02,  5.93it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  90%|█████████████████████████████████████████████▏    | 122/135 [00:20<00:02,  5.93it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████▌    | 123/135 [00:20<00:02,  5.93it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████▌    | 123/135 [00:20<00:02,  5.93it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 2:  92%|█████████████████████████████████████████████▉    | 124/135 [00:20<00:01,  5.93it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 2:  92%|█████████████████████████████████████████████▉    | 124/135 [00:20<00:01,  5.93it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 2:  93%|██████████████████████████████████████████████▎   | 125/135 [00:20<00:01,  5.94it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 2:  93%|██████████████████████████████████████████████▎   | 125/135 [00:21<00:01,  5.94it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 2:  93%|██████████████████████████████████████████████▋   | 126/135 [00:21<00:01,  5.93it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 2:  93%|██████████████████████████████████████████████▋   | 126/135 [00:21<00:01,  5.93it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  94%|███████████████████████████████████████████████   | 127/135 [00:21<00:01,  5.93it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  94%|███████████████████████████████████████████████   | 127/135 [00:21<00:01,  5.93it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 2:  95%|███████████████████████████████████████████████▍  | 128/135 [00:21<00:01,  5.92it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 2:  95%|███████████████████████████████████████████████▍  | 128/135 [00:21<00:01,  5.92it/s, training_loss=0.213]\u001b[A\n",
      "Epoch 2:  96%|███████████████████████████████████████████████▊  | 129/135 [00:21<00:01,  5.91it/s, training_loss=0.213]\u001b[A\n",
      "Epoch 2:  96%|███████████████████████████████████████████████▊  | 129/135 [00:21<00:01,  5.91it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████▏ | 130/135 [00:21<00:00,  5.92it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████▏ | 130/135 [00:22<00:00,  5.92it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  97%|████████████████████████████████████████████████▌ | 131/135 [00:22<00:00,  5.92it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  97%|████████████████████████████████████████████████▌ | 131/135 [00:22<00:00,  5.92it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  98%|████████████████████████████████████████████████▉ | 132/135 [00:22<00:00,  5.92it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  98%|████████████████████████████████████████████████▉ | 132/135 [00:22<00:00,  5.92it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  99%|█████████████████████████████████████████████████▎| 133/135 [00:22<00:00,  5.91it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  99%|█████████████████████████████████████████████████▎| 133/135 [00:22<00:00,  5.91it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  99%|█████████████████████████████████████████████████▋| 134/135 [00:22<00:00,  5.93it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  99%|█████████████████████████████████████████████████▋| 134/135 [00:22<00:00,  5.93it/s, training_loss=0.019]\u001b[A\n",
      "Epoch Progress:   5%|███▎                                                               | 2/40 [00:45<14:20, 22.65s/it]\u001b[A\n",
      "Epoch 3:   0%|                                                                                 | 0/135 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|                                                            | 0/135 [00:00<?, ?it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:   1%|▍                                                   | 1/135 [00:00<00:22,  5.97it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:   1%|▍                                                   | 1/135 [00:00<00:22,  5.97it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:   1%|▊                                                   | 2/135 [00:00<00:22,  5.91it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:   1%|▊                                                   | 2/135 [00:00<00:22,  5.91it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 3:   2%|█▏                                                  | 3/135 [00:00<00:22,  5.93it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 3:   2%|█▏                                                  | 3/135 [00:00<00:22,  5.93it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:   3%|█▌                                                  | 4/135 [00:00<00:22,  5.93it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:   3%|█▌                                                  | 4/135 [00:00<00:22,  5.93it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 3:   4%|█▉                                                  | 5/135 [00:00<00:21,  5.95it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 3:   4%|█▉                                                  | 5/135 [00:01<00:21,  5.95it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:   4%|██▎                                                 | 6/135 [00:01<00:21,  5.93it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:   4%|██▎                                                 | 6/135 [00:01<00:21,  5.93it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 3:   5%|██▋                                                 | 7/135 [00:01<00:21,  5.91it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 3:   5%|██▋                                                 | 7/135 [00:01<00:21,  5.91it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 3:   6%|███                                                 | 8/135 [00:01<00:21,  5.90it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 3:   6%|███                                                 | 8/135 [00:01<00:21,  5.90it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:   7%|███▍                                                | 9/135 [00:01<00:21,  5.90it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:   7%|███▍                                                | 9/135 [00:01<00:21,  5.90it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:   7%|███▊                                               | 10/135 [00:01<00:21,  5.91it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:   7%|███▊                                               | 10/135 [00:01<00:21,  5.91it/s, training_loss=0.213]\u001b[A\n",
      "Epoch 3:   8%|████▏                                              | 11/135 [00:01<00:21,  5.90it/s, training_loss=0.213]\u001b[A\n",
      "Epoch 3:   8%|████▏                                              | 11/135 [00:02<00:21,  5.90it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:   9%|████▌                                              | 12/135 [00:02<00:20,  5.89it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:   9%|████▌                                              | 12/135 [00:02<00:20,  5.89it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  10%|████▉                                              | 13/135 [00:02<00:20,  5.88it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  10%|████▉                                              | 13/135 [00:02<00:20,  5.88it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  10%|█████▎                                             | 14/135 [00:02<00:20,  5.91it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  10%|█████▎                                             | 14/135 [00:02<00:20,  5.91it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  11%|█████▋                                             | 15/135 [00:02<00:20,  5.90it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  11%|█████▋                                             | 15/135 [00:02<00:20,  5.90it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  12%|██████                                             | 16/135 [00:02<00:20,  5.90it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  12%|██████                                             | 16/135 [00:02<00:20,  5.90it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 3:  13%|██████▍                                            | 17/135 [00:02<00:19,  5.91it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 3:  13%|██████▍                                            | 17/135 [00:03<00:19,  5.91it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  13%|██████▊                                            | 18/135 [00:03<00:19,  5.92it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  13%|██████▊                                            | 18/135 [00:03<00:19,  5.92it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  14%|███████▏                                           | 19/135 [00:03<00:19,  5.92it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  14%|███████▏                                           | 19/135 [00:03<00:19,  5.92it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  15%|███████▌                                           | 20/135 [00:03<00:19,  5.93it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  15%|███████▌                                           | 20/135 [00:03<00:19,  5.93it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  16%|███████▉                                           | 21/135 [00:03<00:19,  5.90it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  16%|███████▉                                           | 21/135 [00:03<00:19,  5.90it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 3:  16%|████████▎                                          | 22/135 [00:03<00:19,  5.92it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 3:  16%|████████▎                                          | 22/135 [00:03<00:19,  5.92it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  17%|████████▋                                          | 23/135 [00:03<00:18,  5.93it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  17%|████████▋                                          | 23/135 [00:04<00:18,  5.93it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  18%|█████████                                          | 24/135 [00:04<00:18,  5.94it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  18%|█████████                                          | 24/135 [00:04<00:18,  5.94it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 3:  19%|█████████▍                                         | 25/135 [00:04<00:18,  5.95it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 3:  19%|█████████▍                                         | 25/135 [00:04<00:18,  5.95it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  19%|█████████▊                                         | 26/135 [00:04<00:18,  5.94it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  19%|█████████▊                                         | 26/135 [00:04<00:18,  5.94it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  20%|██████████▏                                        | 27/135 [00:04<00:18,  5.96it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  20%|██████████▏                                        | 27/135 [00:04<00:18,  5.96it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 3:  21%|██████████▌                                        | 28/135 [00:04<00:17,  5.96it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 3:  21%|██████████▌                                        | 28/135 [00:04<00:17,  5.96it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 3:  21%|██████████▉                                        | 29/135 [00:04<00:17,  5.95it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 3:  21%|██████████▉                                        | 29/135 [00:05<00:17,  5.95it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 3:  22%|███████████▎                                       | 30/135 [00:05<00:17,  5.96it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 3:  22%|███████████▎                                       | 30/135 [00:05<00:17,  5.96it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 3:  23%|███████████▋                                       | 31/135 [00:05<00:17,  5.97it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 3:  23%|███████████▋                                       | 31/135 [00:05<00:17,  5.97it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  24%|████████████                                       | 32/135 [00:05<00:17,  5.92it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  24%|████████████                                       | 32/135 [00:05<00:17,  5.92it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  24%|████████████▍                                      | 33/135 [00:05<00:17,  5.92it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  24%|████████████▍                                      | 33/135 [00:05<00:17,  5.92it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 3:  25%|████████████▊                                      | 34/135 [00:05<00:17,  5.93it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 3:  25%|████████████▊                                      | 34/135 [00:05<00:17,  5.93it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  26%|█████████████▏                                     | 35/135 [00:05<00:16,  5.92it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  26%|█████████████▏                                     | 35/135 [00:06<00:16,  5.92it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  27%|█████████████▌                                     | 36/135 [00:06<00:16,  5.92it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  27%|█████████████▌                                     | 36/135 [00:06<00:16,  5.92it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  27%|█████████████▉                                     | 37/135 [00:06<00:16,  5.94it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  27%|█████████████▉                                     | 37/135 [00:06<00:16,  5.94it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  28%|██████████████▎                                    | 38/135 [00:06<00:16,  5.91it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  28%|██████████████▎                                    | 38/135 [00:06<00:16,  5.91it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  29%|██████████████▋                                    | 39/135 [00:06<00:16,  5.94it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  29%|██████████████▋                                    | 39/135 [00:06<00:16,  5.94it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  30%|███████████████                                    | 40/135 [00:06<00:16,  5.93it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  30%|███████████████                                    | 40/135 [00:06<00:16,  5.93it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  30%|███████████████▍                                   | 41/135 [00:06<00:15,  5.92it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  30%|███████████████▍                                   | 41/135 [00:07<00:15,  5.92it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  31%|███████████████▊                                   | 42/135 [00:07<00:15,  5.92it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  31%|███████████████▊                                   | 42/135 [00:07<00:15,  5.92it/s, training_loss=0.275]\u001b[A\n",
      "Epoch 3:  32%|████████████████▏                                  | 43/135 [00:07<00:15,  5.94it/s, training_loss=0.275]\u001b[A\n",
      "Epoch 3:  32%|████████████████▏                                  | 43/135 [00:07<00:15,  5.94it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  33%|████████████████▌                                  | 44/135 [00:07<00:15,  5.93it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  33%|████████████████▌                                  | 44/135 [00:07<00:15,  5.93it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  33%|█████████████████                                  | 45/135 [00:07<00:15,  5.94it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  33%|█████████████████                                  | 45/135 [00:07<00:15,  5.94it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  34%|█████████████████▍                                 | 46/135 [00:07<00:14,  5.94it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  34%|█████████████████▍                                 | 46/135 [00:07<00:14,  5.94it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 3:  35%|█████████████████▊                                 | 47/135 [00:07<00:14,  5.93it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 3:  35%|█████████████████▊                                 | 47/135 [00:08<00:14,  5.93it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  36%|██████████████████▏                                | 48/135 [00:08<00:14,  5.94it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  36%|██████████████████▏                                | 48/135 [00:08<00:14,  5.94it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  36%|██████████████████▌                                | 49/135 [00:08<00:14,  5.96it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  36%|██████████████████▌                                | 49/135 [00:08<00:14,  5.96it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  37%|██████████████████▉                                | 50/135 [00:08<00:14,  5.94it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  37%|██████████████████▉                                | 50/135 [00:08<00:14,  5.94it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  38%|███████████████████▎                               | 51/135 [00:08<00:14,  5.93it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  38%|███████████████████▎                               | 51/135 [00:08<00:14,  5.93it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  39%|███████████████████▋                               | 52/135 [00:08<00:13,  5.93it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  39%|███████████████████▋                               | 52/135 [00:08<00:13,  5.93it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  39%|████████████████████                               | 53/135 [00:08<00:13,  5.93it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  39%|████████████████████                               | 53/135 [00:09<00:13,  5.93it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  40%|████████████████████▍                              | 54/135 [00:09<00:13,  5.92it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  40%|████████████████████▍                              | 54/135 [00:09<00:13,  5.92it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  41%|████████████████████▊                              | 55/135 [00:09<00:13,  5.91it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  41%|████████████████████▊                              | 55/135 [00:09<00:13,  5.91it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 3:  41%|█████████████████████▏                             | 56/135 [00:09<00:13,  5.91it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 3:  41%|█████████████████████▏                             | 56/135 [00:09<00:13,  5.91it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 3:  42%|█████████████████████▌                             | 57/135 [00:09<00:13,  5.90it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 3:  42%|█████████████████████▌                             | 57/135 [00:09<00:13,  5.90it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  43%|█████████████████████▉                             | 58/135 [00:09<00:13,  5.90it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  43%|█████████████████████▉                             | 58/135 [00:09<00:13,  5.90it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  44%|██████████████████████▎                            | 59/135 [00:09<00:12,  5.90it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  44%|██████████████████████▎                            | 59/135 [00:10<00:12,  5.90it/s, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  44%|██████████████████████▋                            | 60/135 [00:10<00:12,  5.90it/s, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  44%|██████████████████████▋                            | 60/135 [00:10<00:12,  5.90it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  45%|███████████████████████                            | 61/135 [00:10<00:12,  5.91it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  45%|███████████████████████                            | 61/135 [00:10<00:12,  5.91it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 3:  46%|███████████████████████▍                           | 62/135 [00:10<00:12,  5.93it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 3:  46%|███████████████████████▍                           | 62/135 [00:10<00:12,  5.93it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 3:  47%|███████████████████████▊                           | 63/135 [00:10<00:12,  5.92it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 3:  47%|███████████████████████▊                           | 63/135 [00:10<00:12,  5.92it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 3:  47%|████████████████████████▏                          | 64/135 [00:10<00:11,  5.93it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 3:  47%|████████████████████████▏                          | 64/135 [00:10<00:11,  5.93it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  48%|████████████████████████▌                          | 65/135 [00:10<00:11,  5.94it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  48%|████████████████████████▌                          | 65/135 [00:11<00:11,  5.94it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  49%|████████████████████████▉                          | 66/135 [00:11<00:11,  5.92it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  49%|████████████████████████▉                          | 66/135 [00:11<00:11,  5.92it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  50%|█████████████████████████▎                         | 67/135 [00:11<00:11,  5.92it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  50%|█████████████████████████▎                         | 67/135 [00:11<00:11,  5.92it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 3:  50%|█████████████████████████▋                         | 68/135 [00:11<00:11,  5.93it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 3:  50%|█████████████████████████▋                         | 68/135 [00:11<00:11,  5.93it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 3:  51%|██████████████████████████                         | 69/135 [00:11<00:11,  5.91it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 3:  51%|██████████████████████████                         | 69/135 [00:11<00:11,  5.91it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 3:  52%|██████████████████████████▍                        | 70/135 [00:11<00:11,  5.90it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 3:  52%|██████████████████████████▍                        | 70/135 [00:11<00:11,  5.90it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  53%|██████████████████████████▊                        | 71/135 [00:11<00:10,  5.91it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  53%|██████████████████████████▊                        | 71/135 [00:12<00:10,  5.91it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 3:  53%|███████████████████████████▏                       | 72/135 [00:12<00:10,  5.91it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 3:  53%|███████████████████████████▏                       | 72/135 [00:12<00:10,  5.91it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  54%|███████████████████████████▌                       | 73/135 [00:12<00:10,  5.91it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  54%|███████████████████████████▌                       | 73/135 [00:12<00:10,  5.91it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  55%|███████████████████████████▉                       | 74/135 [00:12<00:10,  5.91it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  55%|███████████████████████████▉                       | 74/135 [00:12<00:10,  5.91it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████▎                      | 75/135 [00:12<00:10,  5.91it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████▎                      | 75/135 [00:12<00:10,  5.91it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████▋                      | 76/135 [00:12<00:10,  5.88it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████▋                      | 76/135 [00:13<00:10,  5.88it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  57%|█████████████████████████████                      | 77/135 [00:13<00:09,  5.85it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  57%|█████████████████████████████                      | 77/135 [00:13<00:09,  5.85it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 3:  58%|█████████████████████████████▍                     | 78/135 [00:13<00:09,  5.87it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 3:  58%|█████████████████████████████▍                     | 78/135 [00:13<00:09,  5.87it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 3:  59%|█████████████████████████████▊                     | 79/135 [00:13<00:09,  5.88it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 3:  59%|█████████████████████████████▊                     | 79/135 [00:13<00:09,  5.88it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 3:  59%|██████████████████████████████▏                    | 80/135 [00:13<00:09,  5.89it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 3:  59%|██████████████████████████████▏                    | 80/135 [00:13<00:09,  5.89it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  60%|██████████████████████████████▌                    | 81/135 [00:13<00:09,  5.89it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  60%|██████████████████████████████▌                    | 81/135 [00:13<00:09,  5.89it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  61%|██████████████████████████████▉                    | 82/135 [00:13<00:08,  5.89it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  61%|██████████████████████████████▉                    | 82/135 [00:14<00:08,  5.89it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  61%|███████████████████████████████▎                   | 83/135 [00:14<00:08,  5.90it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  61%|███████████████████████████████▎                   | 83/135 [00:14<00:08,  5.90it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 3:  62%|███████████████████████████████▋                   | 84/135 [00:14<00:08,  5.90it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 3:  62%|███████████████████████████████▋                   | 84/135 [00:14<00:08,  5.90it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 3:  63%|████████████████████████████████                   | 85/135 [00:14<00:08,  5.90it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 3:  63%|████████████████████████████████                   | 85/135 [00:14<00:08,  5.90it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 3:  64%|████████████████████████████████▍                  | 86/135 [00:14<00:08,  5.90it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 3:  64%|████████████████████████████████▍                  | 86/135 [00:14<00:08,  5.90it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  64%|████████████████████████████████▊                  | 87/135 [00:14<00:08,  5.89it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  64%|████████████████████████████████▊                  | 87/135 [00:14<00:08,  5.89it/s, training_loss=0.308]\u001b[A\n",
      "Epoch 3:  65%|█████████████████████████████████▏                 | 88/135 [00:14<00:07,  5.89it/s, training_loss=0.308]\u001b[A\n",
      "Epoch 3:  65%|█████████████████████████████████▏                 | 88/135 [00:15<00:07,  5.89it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  66%|█████████████████████████████████▌                 | 89/135 [00:15<00:07,  5.89it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  66%|█████████████████████████████████▌                 | 89/135 [00:15<00:07,  5.89it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  67%|██████████████████████████████████                 | 90/135 [00:15<00:07,  5.88it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  67%|██████████████████████████████████                 | 90/135 [00:15<00:07,  5.88it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  67%|██████████████████████████████████▍                | 91/135 [00:15<00:07,  5.91it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  67%|██████████████████████████████████▍                | 91/135 [00:15<00:07,  5.91it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  68%|██████████████████████████████████▊                | 92/135 [00:15<00:07,  5.92it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  68%|██████████████████████████████████▊                | 92/135 [00:15<00:07,  5.92it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  69%|███████████████████████████████████▏               | 93/135 [00:15<00:07,  5.91it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  69%|███████████████████████████████████▏               | 93/135 [00:15<00:07,  5.91it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  70%|███████████████████████████████████▌               | 94/135 [00:15<00:06,  5.91it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  70%|███████████████████████████████████▌               | 94/135 [00:16<00:06,  5.91it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 3:  70%|███████████████████████████████████▉               | 95/135 [00:16<00:06,  5.89it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 3:  70%|███████████████████████████████████▉               | 95/135 [00:16<00:06,  5.89it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 3:  71%|████████████████████████████████████▎              | 96/135 [00:16<00:06,  5.90it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 3:  71%|████████████████████████████████████▎              | 96/135 [00:16<00:06,  5.90it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  72%|████████████████████████████████████▋              | 97/135 [00:16<00:06,  5.89it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  72%|████████████████████████████████████▋              | 97/135 [00:16<00:06,  5.89it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 3:  73%|█████████████████████████████████████              | 98/135 [00:16<00:06,  5.89it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 3:  73%|█████████████████████████████████████              | 98/135 [00:16<00:06,  5.89it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  73%|█████████████████████████████████████▍             | 99/135 [00:16<00:06,  5.89it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  73%|█████████████████████████████████████▍             | 99/135 [00:16<00:06,  5.89it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  74%|█████████████████████████████████████             | 100/135 [00:16<00:05,  5.89it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  74%|█████████████████████████████████████             | 100/135 [00:17<00:05,  5.89it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 3:  75%|█████████████████████████████████████▍            | 101/135 [00:17<00:05,  5.90it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 3:  75%|█████████████████████████████████████▍            | 101/135 [00:17<00:05,  5.90it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:  76%|█████████████████████████████████████▊            | 102/135 [00:17<00:05,  5.90it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:  76%|█████████████████████████████████████▊            | 102/135 [00:17<00:05,  5.90it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  76%|██████████████████████████████████████▏           | 103/135 [00:17<00:05,  5.90it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  76%|██████████████████████████████████████▏           | 103/135 [00:17<00:05,  5.90it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 3:  77%|██████████████████████████████████████▌           | 104/135 [00:17<00:05,  5.88it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 3:  77%|██████████████████████████████████████▌           | 104/135 [00:17<00:05,  5.88it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 3:  78%|██████████████████████████████████████▉           | 105/135 [00:17<00:05,  5.88it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 3:  78%|██████████████████████████████████████▉           | 105/135 [00:17<00:05,  5.88it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  79%|███████████████████████████████████████▎          | 106/135 [00:17<00:04,  5.91it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  79%|███████████████████████████████████████▎          | 106/135 [00:18<00:04,  5.91it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  79%|███████████████████████████████████████▋          | 107/135 [00:18<00:04,  5.89it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  79%|███████████████████████████████████████▋          | 107/135 [00:18<00:04,  5.89it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 3:  80%|████████████████████████████████████████          | 108/135 [00:18<00:04,  5.89it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 3:  80%|████████████████████████████████████████          | 108/135 [00:18<00:04,  5.89it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  81%|████████████████████████████████████████▎         | 109/135 [00:18<00:04,  5.90it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  81%|████████████████████████████████████████▎         | 109/135 [00:18<00:04,  5.90it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  81%|████████████████████████████████████████▋         | 110/135 [00:18<00:04,  5.89it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  81%|████████████████████████████████████████▋         | 110/135 [00:18<00:04,  5.89it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  82%|█████████████████████████████████████████         | 111/135 [00:18<00:04,  5.88it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  82%|█████████████████████████████████████████         | 111/135 [00:18<00:04,  5.88it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  83%|█████████████████████████████████████████▍        | 112/135 [00:18<00:03,  5.92it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  83%|█████████████████████████████████████████▍        | 112/135 [00:19<00:03,  5.92it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  84%|█████████████████████████████████████████▊        | 113/135 [00:19<00:03,  5.90it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  84%|█████████████████████████████████████████▊        | 113/135 [00:19<00:03,  5.90it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  84%|██████████████████████████████████████████▏       | 114/135 [00:19<00:03,  5.89it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  84%|██████████████████████████████████████████▏       | 114/135 [00:19<00:03,  5.89it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  85%|██████████████████████████████████████████▌       | 115/135 [00:19<00:03,  5.89it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  85%|██████████████████████████████████████████▌       | 115/135 [00:19<00:03,  5.89it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  86%|██████████████████████████████████████████▉       | 116/135 [00:19<00:03,  5.90it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  86%|██████████████████████████████████████████▉       | 116/135 [00:19<00:03,  5.90it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  87%|███████████████████████████████████████████▎      | 117/135 [00:19<00:03,  5.90it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  87%|███████████████████████████████████████████▎      | 117/135 [00:19<00:03,  5.90it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 3:  87%|███████████████████████████████████████████▋      | 118/135 [00:19<00:02,  5.89it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 3:  87%|███████████████████████████████████████████▋      | 118/135 [00:20<00:02,  5.89it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  88%|████████████████████████████████████████████      | 119/135 [00:20<00:02,  5.87it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  88%|████████████████████████████████████████████      | 119/135 [00:20<00:02,  5.87it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  89%|████████████████████████████████████████████▍     | 120/135 [00:20<00:02,  5.88it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  89%|████████████████████████████████████████████▍     | 120/135 [00:20<00:02,  5.88it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 3:  90%|████████████████████████████████████████████▊     | 121/135 [00:20<00:02,  5.90it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 3:  90%|████████████████████████████████████████████▊     | 121/135 [00:20<00:02,  5.90it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 3:  90%|█████████████████████████████████████████████▏    | 122/135 [00:20<00:02,  5.89it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 3:  90%|█████████████████████████████████████████████▏    | 122/135 [00:20<00:02,  5.89it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  91%|█████████████████████████████████████████████▌    | 123/135 [00:20<00:02,  5.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  91%|█████████████████████████████████████████████▌    | 123/135 [00:20<00:02,  5.88it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  92%|█████████████████████████████████████████████▉    | 124/135 [00:20<00:01,  5.90it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  92%|█████████████████████████████████████████████▉    | 124/135 [00:21<00:01,  5.90it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  93%|██████████████████████████████████████████████▎   | 125/135 [00:21<00:01,  5.89it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  93%|██████████████████████████████████████████████▎   | 125/135 [00:21<00:01,  5.89it/s, training_loss=0.289]\u001b[A\n",
      "Epoch 3:  93%|██████████████████████████████████████████████▋   | 126/135 [00:21<00:01,  5.86it/s, training_loss=0.289]\u001b[A\n",
      "Epoch 3:  93%|██████████████████████████████████████████████▋   | 126/135 [00:21<00:01,  5.86it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  94%|███████████████████████████████████████████████   | 127/135 [00:21<00:01,  5.86it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  94%|███████████████████████████████████████████████   | 127/135 [00:21<00:01,  5.86it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  95%|███████████████████████████████████████████████▍  | 128/135 [00:21<00:01,  5.86it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  95%|███████████████████████████████████████████████▍  | 128/135 [00:21<00:01,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  96%|███████████████████████████████████████████████▊  | 129/135 [00:21<00:01,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  96%|███████████████████████████████████████████████▊  | 129/135 [00:22<00:01,  5.85it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 3:  96%|████████████████████████████████████████████████▏ | 130/135 [00:22<00:00,  5.86it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 3:  96%|████████████████████████████████████████████████▏ | 130/135 [00:22<00:00,  5.86it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  97%|████████████████████████████████████████████████▌ | 131/135 [00:22<00:00,  5.86it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  97%|████████████████████████████████████████████████▌ | 131/135 [00:22<00:00,  5.86it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 3:  98%|████████████████████████████████████████████████▉ | 132/135 [00:22<00:00,  5.86it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 3:  98%|████████████████████████████████████████████████▉ | 132/135 [00:22<00:00,  5.86it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  99%|█████████████████████████████████████████████████▎| 133/135 [00:22<00:00,  5.87it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  99%|█████████████████████████████████████████████████▎| 133/135 [00:22<00:00,  5.87it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 3:  99%|█████████████████████████████████████████████████▋| 134/135 [00:22<00:00,  5.86it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 3:  99%|█████████████████████████████████████████████████▋| 134/135 [00:22<00:00,  5.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch Progress:   8%|█████                                                              | 3/40 [01:08<13:59, 22.70s/it]\u001b[A\n",
      "Epoch 4:   0%|                                                                                 | 0/135 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:   0%|                                                            | 0/135 [00:00<?, ?it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:   1%|▍                                                   | 1/135 [00:00<00:22,  6.00it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:   1%|▍                                                   | 1/135 [00:00<00:22,  6.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:   1%|▊                                                   | 2/135 [00:00<00:22,  5.92it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:   1%|▊                                                   | 2/135 [00:00<00:22,  5.92it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:   2%|█▏                                                  | 3/135 [00:00<00:22,  5.93it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:   2%|█▏                                                  | 3/135 [00:00<00:22,  5.93it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 4:   3%|█▌                                                  | 4/135 [00:00<00:22,  5.85it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 4:   3%|█▌                                                  | 4/135 [00:00<00:22,  5.85it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 4:   4%|█▉                                                  | 5/135 [00:00<00:22,  5.85it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 4:   4%|█▉                                                  | 5/135 [00:01<00:22,  5.85it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:   4%|██▎                                                 | 6/135 [00:01<00:21,  5.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:   4%|██▎                                                 | 6/135 [00:01<00:21,  5.88it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 4:   5%|██▋                                                 | 7/135 [00:01<00:21,  5.87it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 4:   5%|██▋                                                 | 7/135 [00:01<00:21,  5.87it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 4:   6%|███                                                 | 8/135 [00:01<00:21,  5.88it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 4:   6%|███                                                 | 8/135 [00:01<00:21,  5.88it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:   7%|███▍                                                | 9/135 [00:01<00:21,  5.90it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:   7%|███▍                                                | 9/135 [00:01<00:21,  5.90it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:   7%|███▊                                               | 10/135 [00:01<00:21,  5.90it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:   7%|███▊                                               | 10/135 [00:01<00:21,  5.90it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 4:   8%|████▏                                              | 11/135 [00:01<00:21,  5.90it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 4:   8%|████▏                                              | 11/135 [00:02<00:21,  5.90it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 4:   9%|████▌                                              | 12/135 [00:02<00:20,  5.88it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 4:   9%|████▌                                              | 12/135 [00:02<00:20,  5.88it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  10%|████▉                                              | 13/135 [00:02<00:20,  5.88it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  10%|████▉                                              | 13/135 [00:02<00:20,  5.88it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  10%|█████▎                                             | 14/135 [00:02<00:20,  5.89it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  10%|█████▎                                             | 14/135 [00:02<00:20,  5.89it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:  11%|█████▋                                             | 15/135 [00:02<00:20,  5.88it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:  11%|█████▋                                             | 15/135 [00:02<00:20,  5.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  12%|██████                                             | 16/135 [00:02<00:20,  5.87it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  12%|██████                                             | 16/135 [00:02<00:20,  5.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  13%|██████▍                                            | 17/135 [00:02<00:20,  5.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  13%|██████▍                                            | 17/135 [00:03<00:20,  5.87it/s, training_loss=0.143]\u001b[A\n",
      "Epoch 4:  13%|██████▊                                            | 18/135 [00:03<00:19,  5.86it/s, training_loss=0.143]\u001b[A\n",
      "Epoch 4:  13%|██████▊                                            | 18/135 [00:03<00:19,  5.86it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  14%|███████▏                                           | 19/135 [00:03<00:19,  5.86it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  14%|███████▏                                           | 19/135 [00:03<00:19,  5.86it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  15%|███████▌                                           | 20/135 [00:03<00:19,  5.87it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  15%|███████▌                                           | 20/135 [00:03<00:19,  5.87it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  16%|███████▉                                           | 21/135 [00:03<00:19,  5.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  16%|███████▉                                           | 21/135 [00:03<00:19,  5.88it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 4:  16%|████████▎                                          | 22/135 [00:03<00:19,  5.89it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 4:  16%|████████▎                                          | 22/135 [00:03<00:19,  5.89it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  17%|████████▋                                          | 23/135 [00:03<00:19,  5.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  17%|████████▋                                          | 23/135 [00:04<00:19,  5.88it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 4:  18%|█████████                                          | 24/135 [00:04<00:18,  5.88it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 4:  18%|█████████                                          | 24/135 [00:04<00:18,  5.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  19%|█████████▍                                         | 25/135 [00:04<00:18,  5.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  19%|█████████▍                                         | 25/135 [00:04<00:18,  5.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  19%|█████████▊                                         | 26/135 [00:04<00:18,  5.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  19%|█████████▊                                         | 26/135 [00:04<00:18,  5.88it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 4:  20%|██████████▏                                        | 27/135 [00:04<00:18,  5.88it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 4:  20%|██████████▏                                        | 27/135 [00:04<00:18,  5.88it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 4:  21%|██████████▌                                        | 28/135 [00:04<00:18,  5.88it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 4:  21%|██████████▌                                        | 28/135 [00:04<00:18,  5.88it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  21%|██████████▉                                        | 29/135 [00:04<00:18,  5.88it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  21%|██████████▉                                        | 29/135 [00:05<00:18,  5.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  22%|███████████▎                                       | 30/135 [00:05<00:17,  5.84it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  22%|███████████▎                                       | 30/135 [00:05<00:17,  5.84it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 4:  23%|███████████▋                                       | 31/135 [00:05<00:17,  5.83it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 4:  23%|███████████▋                                       | 31/135 [00:05<00:17,  5.83it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  24%|████████████                                       | 32/135 [00:05<00:17,  5.82it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  24%|████████████                                       | 32/135 [00:05<00:17,  5.82it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  24%|████████████▍                                      | 33/135 [00:05<00:17,  5.84it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  24%|████████████▍                                      | 33/135 [00:05<00:17,  5.84it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 4:  25%|████████████▊                                      | 34/135 [00:05<00:17,  5.84it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 4:  25%|████████████▊                                      | 34/135 [00:05<00:17,  5.84it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  26%|█████████████▏                                     | 35/135 [00:05<00:17,  5.84it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  26%|█████████████▏                                     | 35/135 [00:06<00:17,  5.84it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 4:  27%|█████████████▌                                     | 36/135 [00:06<00:16,  5.82it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 4:  27%|█████████████▌                                     | 36/135 [00:06<00:16,  5.82it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  27%|█████████████▉                                     | 37/135 [00:06<00:16,  5.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  27%|█████████████▉                                     | 37/135 [00:06<00:16,  5.87it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 4:  28%|██████████████▎                                    | 38/135 [00:06<00:16,  5.82it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 4:  28%|██████████████▎                                    | 38/135 [00:06<00:16,  5.82it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 4:  29%|██████████████▋                                    | 39/135 [00:06<00:16,  5.85it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 4:  29%|██████████████▋                                    | 39/135 [00:06<00:16,  5.85it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 4:  30%|███████████████                                    | 40/135 [00:06<00:16,  5.83it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 4:  30%|███████████████                                    | 40/135 [00:06<00:16,  5.83it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 4:  30%|███████████████▍                                   | 41/135 [00:06<00:16,  5.85it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 4:  30%|███████████████▍                                   | 41/135 [00:07<00:16,  5.85it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  31%|███████████████▊                                   | 42/135 [00:07<00:15,  5.85it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  31%|███████████████▊                                   | 42/135 [00:07<00:15,  5.85it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 4:  32%|████████████████▏                                  | 43/135 [00:07<00:15,  5.86it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 4:  32%|████████████████▏                                  | 43/135 [00:07<00:15,  5.86it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  33%|████████████████▌                                  | 44/135 [00:07<00:15,  5.87it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  33%|████████████████▌                                  | 44/135 [00:07<00:15,  5.87it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 4:  33%|█████████████████                                  | 45/135 [00:07<00:15,  5.86it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 4:  33%|█████████████████                                  | 45/135 [00:07<00:15,  5.86it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 4:  34%|█████████████████▍                                 | 46/135 [00:07<00:15,  5.87it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 4:  34%|█████████████████▍                                 | 46/135 [00:08<00:15,  5.87it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 4:  35%|█████████████████▊                                 | 47/135 [00:08<00:14,  5.87it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 4:  35%|█████████████████▊                                 | 47/135 [00:08<00:14,  5.87it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  36%|██████████████████▏                                | 48/135 [00:08<00:14,  5.86it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  36%|██████████████████▏                                | 48/135 [00:08<00:14,  5.86it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  36%|██████████████████▌                                | 49/135 [00:08<00:14,  5.86it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  36%|██████████████████▌                                | 49/135 [00:08<00:14,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  37%|██████████████████▉                                | 50/135 [00:08<00:14,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  37%|██████████████████▉                                | 50/135 [00:08<00:14,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  38%|███████████████████▎                               | 51/135 [00:08<00:14,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  38%|███████████████████▎                               | 51/135 [00:08<00:14,  5.85it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  39%|███████████████████▋                               | 52/135 [00:08<00:14,  5.86it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  39%|███████████████████▋                               | 52/135 [00:09<00:14,  5.86it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  39%|████████████████████                               | 53/135 [00:09<00:13,  5.87it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  39%|████████████████████                               | 53/135 [00:09<00:13,  5.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  40%|████████████████████▍                              | 54/135 [00:09<00:13,  5.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  40%|████████████████████▍                              | 54/135 [00:09<00:13,  5.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  41%|████████████████████▊                              | 55/135 [00:09<00:13,  5.88it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  41%|████████████████████▊                              | 55/135 [00:09<00:13,  5.88it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  41%|█████████████████████▏                             | 56/135 [00:09<00:13,  5.89it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  41%|█████████████████████▏                             | 56/135 [00:09<00:13,  5.89it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  42%|█████████████████████▌                             | 57/135 [00:09<00:13,  5.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  42%|█████████████████████▌                             | 57/135 [00:09<00:13,  5.88it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  43%|█████████████████████▉                             | 58/135 [00:09<00:13,  5.87it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  43%|█████████████████████▉                             | 58/135 [00:10<00:13,  5.87it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  44%|██████████████████████▎                            | 59/135 [00:10<00:12,  5.87it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  44%|██████████████████████▎                            | 59/135 [00:10<00:12,  5.87it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 4:  44%|██████████████████████▋                            | 60/135 [00:10<00:12,  5.88it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 4:  44%|██████████████████████▋                            | 60/135 [00:10<00:12,  5.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  45%|███████████████████████                            | 61/135 [00:10<00:12,  5.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  45%|███████████████████████                            | 61/135 [00:10<00:12,  5.86it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 4:  46%|███████████████████████▍                           | 62/135 [00:10<00:12,  5.83it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 4:  46%|███████████████████████▍                           | 62/135 [00:10<00:12,  5.83it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 4:  47%|███████████████████████▊                           | 63/135 [00:10<00:12,  5.83it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 4:  47%|███████████████████████▊                           | 63/135 [00:10<00:12,  5.83it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 4:  47%|████████████████████████▏                          | 64/135 [00:10<00:12,  5.84it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 4:  47%|████████████████████████▏                          | 64/135 [00:11<00:12,  5.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  48%|████████████████████████▌                          | 65/135 [00:11<00:11,  5.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  48%|████████████████████████▌                          | 65/135 [00:11<00:11,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  49%|████████████████████████▉                          | 66/135 [00:11<00:11,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  49%|████████████████████████▉                          | 66/135 [00:11<00:11,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  50%|█████████████████████████▎                         | 67/135 [00:11<00:11,  5.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  50%|█████████████████████████▎                         | 67/135 [00:11<00:11,  5.87it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  50%|█████████████████████████▋                         | 68/135 [00:11<00:11,  5.87it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  50%|█████████████████████████▋                         | 68/135 [00:11<00:11,  5.87it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 4:  51%|██████████████████████████                         | 69/135 [00:11<00:11,  5.88it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 4:  51%|██████████████████████████                         | 69/135 [00:11<00:11,  5.88it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  52%|██████████████████████████▍                        | 70/135 [00:11<00:11,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  52%|██████████████████████████▍                        | 70/135 [00:12<00:11,  5.85it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 4:  53%|██████████████████████████▊                        | 71/135 [00:12<00:10,  5.87it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 4:  53%|██████████████████████████▊                        | 71/135 [00:12<00:10,  5.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  53%|███████████████████████████▏                       | 72/135 [00:12<00:10,  5.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  53%|███████████████████████████▏                       | 72/135 [00:12<00:10,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  54%|███████████████████████████▌                       | 73/135 [00:12<00:10,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  54%|███████████████████████████▌                       | 73/135 [00:12<00:10,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  55%|███████████████████████████▉                       | 74/135 [00:12<00:10,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  55%|███████████████████████████▉                       | 74/135 [00:12<00:10,  5.86it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  56%|████████████████████████████▎                      | 75/135 [00:12<00:10,  5.85it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  56%|████████████████████████████▎                      | 75/135 [00:12<00:10,  5.85it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 4:  56%|████████████████████████████▋                      | 76/135 [00:12<00:10,  5.85it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 4:  56%|████████████████████████████▋                      | 76/135 [00:13<00:10,  5.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  57%|█████████████████████████████                      | 77/135 [00:13<00:09,  5.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  57%|█████████████████████████████                      | 77/135 [00:13<00:09,  5.87it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 4:  58%|█████████████████████████████▍                     | 78/135 [00:13<00:09,  5.87it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 4:  58%|█████████████████████████████▍                     | 78/135 [00:13<00:09,  5.87it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 4:  59%|█████████████████████████████▊                     | 79/135 [00:13<00:09,  5.87it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 4:  59%|█████████████████████████████▊                     | 79/135 [00:13<00:09,  5.87it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  59%|██████████████████████████████▏                    | 80/135 [00:13<00:09,  5.86it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  59%|██████████████████████████████▏                    | 80/135 [00:13<00:09,  5.86it/s, training_loss=0.185]\u001b[A\n",
      "Epoch 4:  60%|██████████████████████████████▌                    | 81/135 [00:13<00:09,  5.86it/s, training_loss=0.185]\u001b[A\n",
      "Epoch 4:  60%|██████████████████████████████▌                    | 81/135 [00:13<00:09,  5.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  61%|██████████████████████████████▉                    | 82/135 [00:13<00:09,  5.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  61%|██████████████████████████████▉                    | 82/135 [00:14<00:09,  5.86it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 4:  61%|███████████████████████████████▎                   | 83/135 [00:14<00:08,  5.86it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 4:  61%|███████████████████████████████▎                   | 83/135 [00:14<00:08,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  62%|███████████████████████████████▋                   | 84/135 [00:14<00:08,  5.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  62%|███████████████████████████████▋                   | 84/135 [00:14<00:08,  5.87it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  63%|████████████████████████████████                   | 85/135 [00:14<00:08,  5.86it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  63%|████████████████████████████████                   | 85/135 [00:14<00:08,  5.86it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  64%|████████████████████████████████▍                  | 86/135 [00:14<00:08,  5.85it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  64%|████████████████████████████████▍                  | 86/135 [00:14<00:08,  5.85it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 4:  64%|████████████████████████████████▊                  | 87/135 [00:14<00:08,  5.86it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 4:  64%|████████████████████████████████▊                  | 87/135 [00:15<00:08,  5.86it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 4:  65%|█████████████████████████████████▏                 | 88/135 [00:15<00:08,  5.87it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 4:  65%|█████████████████████████████████▏                 | 88/135 [00:15<00:08,  5.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  66%|█████████████████████████████████▌                 | 89/135 [00:15<00:07,  5.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  66%|█████████████████████████████████▌                 | 89/135 [00:15<00:07,  5.85it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  67%|██████████████████████████████████                 | 90/135 [00:15<00:07,  5.82it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  67%|██████████████████████████████████                 | 90/135 [00:15<00:07,  5.82it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  67%|██████████████████████████████████▍                | 91/135 [00:15<00:07,  5.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  67%|██████████████████████████████████▍                | 91/135 [00:15<00:07,  5.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  68%|██████████████████████████████████▊                | 92/135 [00:15<00:07,  5.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  68%|██████████████████████████████████▊                | 92/135 [00:15<00:07,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  69%|███████████████████████████████████▏               | 93/135 [00:15<00:07,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  69%|███████████████████████████████████▏               | 93/135 [00:16<00:07,  5.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  70%|███████████████████████████████████▌               | 94/135 [00:16<00:07,  5.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  70%|███████████████████████████████████▌               | 94/135 [00:16<00:07,  5.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  70%|███████████████████████████████████▉               | 95/135 [00:16<00:06,  5.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  70%|███████████████████████████████████▉               | 95/135 [00:16<00:06,  5.85it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 4:  71%|████████████████████████████████████▎              | 96/135 [00:16<00:06,  5.85it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 4:  71%|████████████████████████████████████▎              | 96/135 [00:16<00:06,  5.85it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  72%|████████████████████████████████████▋              | 97/135 [00:16<00:06,  5.86it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  72%|████████████████████████████████████▋              | 97/135 [00:16<00:06,  5.86it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 4:  73%|█████████████████████████████████████              | 98/135 [00:16<00:06,  5.84it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 4:  73%|█████████████████████████████████████              | 98/135 [00:16<00:06,  5.84it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  73%|█████████████████████████████████████▍             | 99/135 [00:16<00:06,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  73%|█████████████████████████████████████▍             | 99/135 [00:17<00:06,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  74%|█████████████████████████████████████             | 100/135 [00:17<00:06,  5.75it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  74%|█████████████████████████████████████             | 100/135 [00:17<00:06,  5.75it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  75%|█████████████████████████████████████▍            | 101/135 [00:17<00:05,  5.78it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  75%|█████████████████████████████████████▍            | 101/135 [00:17<00:05,  5.78it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 4:  76%|█████████████████████████████████████▊            | 102/135 [00:17<00:05,  5.81it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 4:  76%|█████████████████████████████████████▊            | 102/135 [00:17<00:05,  5.81it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  76%|██████████████████████████████████████▏           | 103/135 [00:17<00:05,  5.66it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  76%|██████████████████████████████████████▏           | 103/135 [00:17<00:05,  5.66it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 4:  77%|██████████████████████████████████████▌           | 104/135 [00:17<00:05,  5.67it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 4:  77%|██████████████████████████████████████▌           | 104/135 [00:17<00:05,  5.67it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  78%|██████████████████████████████████████▉           | 105/135 [00:17<00:05,  5.73it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  78%|██████████████████████████████████████▉           | 105/135 [00:18<00:05,  5.73it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  79%|███████████████████████████████████████▎          | 106/135 [00:18<00:05,  5.71it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  79%|███████████████████████████████████████▎          | 106/135 [00:18<00:05,  5.71it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 4:  79%|███████████████████████████████████████▋          | 107/135 [00:18<00:04,  5.72it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 4:  79%|███████████████████████████████████████▋          | 107/135 [00:18<00:04,  5.72it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 4:  80%|████████████████████████████████████████          | 108/135 [00:18<00:04,  5.70it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 4:  80%|████████████████████████████████████████          | 108/135 [00:18<00:04,  5.70it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:  81%|████████████████████████████████████████▎         | 109/135 [00:18<00:04,  5.67it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:  81%|████████████████████████████████████████▎         | 109/135 [00:18<00:04,  5.67it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  81%|████████████████████████████████████████▋         | 110/135 [00:18<00:04,  5.72it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  81%|████████████████████████████████████████▋         | 110/135 [00:18<00:04,  5.72it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  82%|█████████████████████████████████████████         | 111/135 [00:18<00:04,  5.74it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  82%|█████████████████████████████████████████         | 111/135 [00:19<00:04,  5.74it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 4:  83%|█████████████████████████████████████████▍        | 112/135 [00:19<00:03,  5.76it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 4:  83%|█████████████████████████████████████████▍        | 112/135 [00:19<00:03,  5.76it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 4:  84%|█████████████████████████████████████████▊        | 113/135 [00:19<00:03,  5.77it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 4:  84%|█████████████████████████████████████████▊        | 113/135 [00:19<00:03,  5.77it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  84%|██████████████████████████████████████████▏       | 114/135 [00:19<00:03,  5.80it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  84%|██████████████████████████████████████████▏       | 114/135 [00:19<00:03,  5.80it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  85%|██████████████████████████████████████████▌       | 115/135 [00:19<00:03,  5.84it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  85%|██████████████████████████████████████████▌       | 115/135 [00:19<00:03,  5.84it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  86%|██████████████████████████████████████████▉       | 116/135 [00:19<00:03,  5.81it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  86%|██████████████████████████████████████████▉       | 116/135 [00:20<00:03,  5.81it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  87%|███████████████████████████████████████████▎      | 117/135 [00:20<00:03,  5.81it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  87%|███████████████████████████████████████████▎      | 117/135 [00:20<00:03,  5.81it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  87%|███████████████████████████████████████████▋      | 118/135 [00:20<00:02,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  87%|███████████████████████████████████████████▋      | 118/135 [00:20<00:02,  5.78it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 4:  88%|████████████████████████████████████████████      | 119/135 [00:20<00:02,  5.74it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 4:  88%|████████████████████████████████████████████      | 119/135 [00:20<00:02,  5.74it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 4:  89%|████████████████████████████████████████████▍     | 120/135 [00:20<00:02,  5.79it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 4:  89%|████████████████████████████████████████████▍     | 120/135 [00:20<00:02,  5.79it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 4:  90%|████████████████████████████████████████████▊     | 121/135 [00:20<00:02,  5.81it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 4:  90%|████████████████████████████████████████████▊     | 121/135 [00:20<00:02,  5.81it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  90%|█████████████████████████████████████████████▏    | 122/135 [00:20<00:02,  5.82it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  90%|█████████████████████████████████████████████▏    | 122/135 [00:21<00:02,  5.82it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  91%|█████████████████████████████████████████████▌    | 123/135 [00:21<00:02,  5.80it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  91%|█████████████████████████████████████████████▌    | 123/135 [00:21<00:02,  5.80it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 4:  92%|█████████████████████████████████████████████▉    | 124/135 [00:21<00:01,  5.82it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 4:  92%|█████████████████████████████████████████████▉    | 124/135 [00:21<00:01,  5.82it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  93%|██████████████████████████████████████████████▎   | 125/135 [00:21<00:01,  5.82it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  93%|██████████████████████████████████████████████▎   | 125/135 [00:21<00:01,  5.82it/s, training_loss=0.283]\u001b[A\n",
      "Epoch 4:  93%|██████████████████████████████████████████████▋   | 126/135 [00:21<00:01,  5.84it/s, training_loss=0.283]\u001b[A\n",
      "Epoch 4:  93%|██████████████████████████████████████████████▋   | 126/135 [00:21<00:01,  5.84it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 4:  94%|███████████████████████████████████████████████   | 127/135 [00:21<00:01,  5.83it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 4:  94%|███████████████████████████████████████████████   | 127/135 [00:21<00:01,  5.83it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 4:  95%|███████████████████████████████████████████████▍  | 128/135 [00:21<00:01,  5.84it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 4:  95%|███████████████████████████████████████████████▍  | 128/135 [00:22<00:01,  5.84it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 4:  96%|███████████████████████████████████████████████▊  | 129/135 [00:22<00:01,  5.84it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 4:  96%|███████████████████████████████████████████████▊  | 129/135 [00:22<00:01,  5.84it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 4:  96%|████████████████████████████████████████████████▏ | 130/135 [00:22<00:00,  5.86it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 4:  96%|████████████████████████████████████████████████▏ | 130/135 [00:22<00:00,  5.86it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  97%|████████████████████████████████████████████████▌ | 131/135 [00:22<00:00,  5.84it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  97%|████████████████████████████████████████████████▌ | 131/135 [00:22<00:00,  5.84it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  98%|████████████████████████████████████████████████▉ | 132/135 [00:22<00:00,  5.83it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  98%|████████████████████████████████████████████████▉ | 132/135 [00:22<00:00,  5.83it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  99%|█████████████████████████████████████████████████▎| 133/135 [00:22<00:00,  5.84it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  99%|█████████████████████████████████████████████████▎| 133/135 [00:22<00:00,  5.84it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 4:  99%|█████████████████████████████████████████████████▋| 134/135 [00:22<00:00,  5.86it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 4:  99%|█████████████████████████████████████████████████▋| 134/135 [00:23<00:00,  5.86it/s, training_loss=0.004]\u001b[A\n",
      "Epoch Progress:  10%|██████▋                                                            | 4/40 [01:31<13:41, 22.82s/it]\u001b[A\n",
      "Epoch 5:   0%|                                                                                 | 0/135 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:   0%|                                                            | 0/135 [00:00<?, ?it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 5:   1%|▍                                                   | 1/135 [00:00<00:22,  5.90it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 5:   1%|▍                                                   | 1/135 [00:00<00:22,  5.90it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:   1%|▊                                                   | 2/135 [00:00<00:22,  5.90it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:   1%|▊                                                   | 2/135 [00:00<00:22,  5.90it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 5:   2%|█▏                                                  | 3/135 [00:00<00:22,  5.90it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 5:   2%|█▏                                                  | 3/135 [00:00<00:22,  5.90it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 5:   3%|█▌                                                  | 4/135 [00:00<00:22,  5.86it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 5:   3%|█▌                                                  | 4/135 [00:00<00:22,  5.86it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:   4%|█▉                                                  | 5/135 [00:00<00:22,  5.86it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:   4%|█▉                                                  | 5/135 [00:01<00:22,  5.86it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:   4%|██▎                                                 | 6/135 [00:01<00:21,  5.87it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:   4%|██▎                                                 | 6/135 [00:01<00:21,  5.87it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:   5%|██▋                                                 | 7/135 [00:01<00:21,  5.86it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:   5%|██▋                                                 | 7/135 [00:01<00:21,  5.86it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   6%|███                                                 | 8/135 [00:01<00:21,  5.87it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   6%|███                                                 | 8/135 [00:01<00:21,  5.87it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:   7%|███▍                                                | 9/135 [00:01<00:21,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:   7%|███▍                                                | 9/135 [00:01<00:21,  5.86it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 5:   7%|███▊                                               | 10/135 [00:01<00:21,  5.86it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 5:   7%|███▊                                               | 10/135 [00:01<00:21,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:   8%|████▏                                              | 11/135 [00:01<00:21,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:   8%|████▏                                              | 11/135 [00:02<00:21,  5.85it/s, training_loss=0.085]\u001b[A\n",
      "Epoch 5:   9%|████▌                                              | 12/135 [00:02<00:21,  5.85it/s, training_loss=0.085]\u001b[A\n",
      "Epoch 5:   9%|████▌                                              | 12/135 [00:02<00:21,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  10%|████▉                                              | 13/135 [00:02<00:20,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  10%|████▉                                              | 13/135 [00:02<00:20,  5.86it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  10%|█████▎                                             | 14/135 [00:02<00:20,  5.85it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  10%|█████▎                                             | 14/135 [00:02<00:20,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  11%|█████▋                                             | 15/135 [00:02<00:20,  5.84it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  11%|█████▋                                             | 15/135 [00:02<00:20,  5.84it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 5:  12%|██████                                             | 16/135 [00:02<00:20,  5.86it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 5:  12%|██████                                             | 16/135 [00:02<00:20,  5.86it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 5:  13%|██████▍                                            | 17/135 [00:02<00:20,  5.86it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 5:  13%|██████▍                                            | 17/135 [00:03<00:20,  5.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  13%|██████▊                                            | 18/135 [00:03<00:20,  5.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  13%|██████▊                                            | 18/135 [00:03<00:20,  5.84it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 5:  14%|███████▏                                           | 19/135 [00:03<00:19,  5.86it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 5:  14%|███████▏                                           | 19/135 [00:03<00:19,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  15%|███████▌                                           | 20/135 [00:03<00:19,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  15%|███████▌                                           | 20/135 [00:03<00:19,  5.85it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 5:  16%|███████▉                                           | 21/135 [00:03<00:19,  5.86it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 5:  16%|███████▉                                           | 21/135 [00:03<00:19,  5.86it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 5:  16%|████████▎                                          | 22/135 [00:03<00:19,  5.84it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 5:  16%|████████▎                                          | 22/135 [00:03<00:19,  5.84it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5:  17%|████████▋                                          | 23/135 [00:03<00:19,  5.85it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5:  17%|████████▋                                          | 23/135 [00:04<00:19,  5.85it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 5:  18%|█████████                                          | 24/135 [00:04<00:18,  5.84it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 5:  18%|█████████                                          | 24/135 [00:04<00:18,  5.84it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5:  19%|█████████▍                                         | 25/135 [00:04<00:18,  5.84it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5:  19%|█████████▍                                         | 25/135 [00:04<00:18,  5.84it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  19%|█████████▊                                         | 26/135 [00:04<00:18,  5.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  19%|█████████▊                                         | 26/135 [00:04<00:18,  5.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  20%|██████████▏                                        | 27/135 [00:04<00:18,  5.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  20%|██████████▏                                        | 27/135 [00:04<00:18,  5.84it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  21%|██████████▌                                        | 28/135 [00:04<00:18,  5.84it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  21%|██████████▌                                        | 28/135 [00:04<00:18,  5.84it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 5:  21%|██████████▉                                        | 29/135 [00:04<00:18,  5.82it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 5:  21%|██████████▉                                        | 29/135 [00:05<00:18,  5.82it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  22%|███████████▎                                       | 30/135 [00:05<00:17,  5.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  22%|███████████▎                                       | 30/135 [00:05<00:17,  5.85it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  23%|███████████▋                                       | 31/135 [00:05<00:17,  5.84it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  23%|███████████▋                                       | 31/135 [00:05<00:17,  5.84it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5:  24%|████████████                                       | 32/135 [00:05<00:17,  5.84it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5:  24%|████████████                                       | 32/135 [00:05<00:17,  5.84it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 5:  24%|████████████▍                                      | 33/135 [00:05<00:17,  5.85it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 5:  24%|████████████▍                                      | 33/135 [00:05<00:17,  5.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  25%|████████████▊                                      | 34/135 [00:05<00:17,  5.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  25%|████████████▊                                      | 34/135 [00:05<00:17,  5.85it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 5:  26%|█████████████▏                                     | 35/135 [00:05<00:17,  5.84it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 5:  26%|█████████████▏                                     | 35/135 [00:06<00:17,  5.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  27%|█████████████▌                                     | 36/135 [00:06<00:16,  5.85it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  27%|█████████████▌                                     | 36/135 [00:06<00:16,  5.85it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 5:  27%|█████████████▉                                     | 37/135 [00:06<00:16,  5.85it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 5:  27%|█████████████▉                                     | 37/135 [00:06<00:16,  5.85it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 5:  28%|██████████████▎                                    | 38/135 [00:06<00:16,  5.85it/s, training_loss=0.153]\u001b[A"
     ]
    }
   ],
   "source": [
    " #install packages\n",
    "!pip install transformers\n",
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import logging\n",
    "import random\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def custom_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    if test_size == 0:\n",
    "        return X, [], y, []\n",
    "    # Find classes with only one or two instances\n",
    "    small_classes = classes[counts < 5]\n",
    "\n",
    "    # Separate out the instances of small classes\n",
    "    large_class_mask = ~np.isin(y, small_classes)\n",
    "    X_large = X[large_class_mask]\n",
    "    y_large = y[large_class_mask]\n",
    "    X_small = X[~large_class_mask]\n",
    "    y_small = y[~large_class_mask]\n",
    "\n",
    "    # Perform stratified split on the larger classes dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_large, y_large, test_size=test_size, random_state=random_state, stratify=y_large\n",
    "    )\n",
    "\n",
    "    # Randomly assign instances of small classes to training or testing sets\n",
    "    for i in range(len(X_small)):\n",
    "        if np.random.rand() < test_size:\n",
    "            X_test = np.vstack([X_test, X_small[i]])\n",
    "            y_test = np.hstack([y_test, y_small[i]])\n",
    "        else:\n",
    "            X_train = np.vstack([X_train, X_small[i]])\n",
    "            y_train = np.hstack([y_train, y_small[i]])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#evaluation\n",
    "def accuracy_per_class(predictions, true_vals):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "\n",
    "    accuracy_dict = {}\n",
    "    count_dict = {}\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = pred_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        accuracy_dict[label] = np.sum(y_preds == y_true) / len(y_true) if len(y_true) > 0 else 0\n",
    "        count_dict[label] = len(y_true)\n",
    "\n",
    "    return accuracy_dict, count_dict\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "\n",
    "# Function to calculate precision, recall, and F1 for each label\n",
    "def calculate_metrics(predictions, true_vals):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score per label\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels_flat, pred_flat, average=None, labels=np.unique(labels_flat))\n",
    "    \n",
    "    return precision, recall, f1\n",
    "    \n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='cadec_top6_training_40ep_16bs_5e-5lr_log.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class TQDMLoggingWrapper(tqdm):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.logger = logger\n",
    "\n",
    "    def display(self, msg=None, pos=None):\n",
    "        if msg is not None:\n",
    "            self.logger.info(msg)\n",
    "        super().display(msg, pos)\n",
    "\n",
    "    def update(self, n=1):\n",
    "        super().update(n)\n",
    "        desc = self.format_dict.get('desc', 'No description')\n",
    "        postfix = self.format_dict.get('postfix', '')\n",
    "        self.logger.info(f'{desc} - {postfix}')\n",
    "\n",
    "    def set_description(self, desc=None, refresh=True):\n",
    "        super().set_description(desc, refresh)\n",
    "        if desc:\n",
    "            self.logger.info(f'Set description: {desc}')\n",
    "\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "#Read data from git:\n",
    "#https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\n",
    "# URL of the CSV file\n",
    "cadec_csv_url = \"https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\"\n",
    "# read data from smm4h\n",
    "smm4h_csv_url = \"https://raw.githubusercontent.com/FANMISUA/ADE_Norm/main/Data/smm4h_soc.tsv\"\n",
    "\n",
    "top6SMM4H = [10037175, 10018065,10029205, 10017947, 10028395, 10022891]\n",
    "top6label_dict = {\n",
    "    10037175: 0,\n",
    "    10018065: 1,\n",
    "    10029205: 2,\n",
    "    10017947: 3,\n",
    "    10028395: 4,\n",
    "    10022891: 5\n",
    "}\n",
    "\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"ade\", \"soc_code\"]\n",
    "smm4h_all = pd.read_csv(smm4h_csv_url,names=column_names, sep = '\\t', header=None)\n",
    "\n",
    "smm4h_all = smm4h_all[smm4h_all['soc_code'] != 0]\n",
    "smm4h_all['soc_code'] = pd.to_numeric(smm4h_all['soc_code'], errors='coerce').astype('Int64')\n",
    "smm4h_unique = smm4h_all.drop_duplicates(subset='ade')\n",
    "\n",
    "# print(\"smm4h data:\",smm4h_all.shape)\n",
    "smm4h_soc_code_counts = smm4h_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "print(\"SOC count in CADEC: \",smm4h_soc_code_counts)\n",
    "# Filter DataFrame\n",
    "smm4h_filtered_data3 = smm4h_unique[smm4h_unique['soc_code'].isin(top6SMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "top6inSMM4H = smm4h_filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"TT\", \"llt_code\", \"ade\", \"soc_code\"]\n",
    "cadec_all = pd.read_csv(cadec_csv_url,names=column_names, header=None)\n",
    "\n",
    "# Remove duplicate rows based on the 'ade' column\n",
    "cadec_unique = cadec_all.drop_duplicates(subset='ade')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "# print(\"clean cadec data:\",cadec_unique.shape)\n",
    "# Count occurrences of each 'soc_code'\n",
    "cadec_soc_code_counts = cadec_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "# print(\"SOC count in CADEC: \",cadec_soc_code_counts)\n",
    "\n",
    "\n",
    "# Filter DataFrame\n",
    "cadec_filtered_data3 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "CADECtop6inSMM4H = cadec_filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "\n",
    "# For SMM4H data\n",
    "df1 = top6inSMM4H.copy()\n",
    "df1.loc[:, 'label'] = df1['soc_code'].map(top6label_dict)\n",
    "\n",
    "# For CADEC data\n",
    "df2 = CADECtop6inSMM4H.copy()\n",
    "df2.loc[:, 'label'] = df2['soc_code'].map(top6label_dict)\n",
    "\n",
    "print(\"SMM4H top 6\",df1)\n",
    "print(\"CADEC top 6\",df2)\n",
    "\n",
    "#cadec data\n",
    "df = df2\n",
    "\n",
    "# Define the random seeds and other parameters\n",
    "seed_values = list(range(2, 42, 2))\n",
    "batch_size = 16\n",
    "epochs = 40\n",
    "learningrate = 5e-5\n",
    "\n",
    "# Placeholder for accuracies\n",
    "all_accuracies = {label: [] for label in range(len(top6label_dict))}\n",
    "\n",
    "# Initialize dictionaries to hold metrics for each seed\n",
    "seed_metrics = {seed_val: {'precision': [], 'recall': [], 'f1': []} for seed_val in seed_values}\n",
    "\n",
    "\n",
    "# Main loop over seed values\n",
    "for seed_val in seed_values:\n",
    "    # Set seeds\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    # Data preparation\n",
    "    X_train, X_val, y_train, y_val = custom_train_test_split(df.index.values, df.label.values, test_size=0.2, random_state=seed_val)\n",
    "    df['data_type'] = ['not_set'] * df.shape[0]\n",
    "    df.loc[X_train, 'data_type'] = 'train'\n",
    "    df.loc[X_val, 'data_type'] = 'val'\n",
    "    # logger.info(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    encoded_data_train = tokenizer.batch_encode_plus(\n",
    "        df[df.data_type == 'train'].ade.values,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    encoded_data_val = tokenizer.batch_encode_plus(\n",
    "        df[df.data_type == 'val'].ade.values,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids_train = encoded_data_train['input_ids']\n",
    "    attention_masks_train = encoded_data_train['attention_mask']\n",
    "    labels_train = torch.tensor(df[df.data_type == 'train'].label.values)\n",
    "\n",
    "    input_ids_val = encoded_data_val['input_ids']\n",
    "    attention_masks_val = encoded_data_val['attention_mask']\n",
    "    labels_val = torch.tensor(df[df.data_type == 'val'].label.values)\n",
    "\n",
    "    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(top6label_dict), output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "    dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learningrate, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train) * epochs)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    logger.info(f\"Device used: {device}\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in TQDMLoggingWrapper(range(1, epochs+1), desc='Epoch Progress'):\n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "\n",
    "        progress_bar = TQDMLoggingWrapper(dataloader_train, desc=f'Epoch {epoch}', leave=False, disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            progress_bar.set_postfix({'training_loss': f'{loss.item()/len(batch):.3f}'})\n",
    "\n",
    "        # torch.save(model.state_dict(), f'./ADENorm_top3_epoch_{epoch}.model')\n",
    "\n",
    "        logger.info(f'\\nEpoch {epoch}')\n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        logger.info(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_vals.flatten(), np.argmax(predictions, axis=1).flatten(), average=None, labels=np.unique(true_vals.flatten()))\n",
    "\n",
    "    for label in np.unique(true_vals):\n",
    "        seed_metrics[seed_val]['precision'].append((label, precision[label]))\n",
    "        seed_metrics[seed_val]['recall'].append((label, recall[label]))\n",
    "        seed_metrics[seed_val]['f1'].append((label, f1[label]))\n",
    "\n",
    "# Write the precision, recall, F1 scores, and seed values to a file\n",
    "with open('cadec_top6_20times_results_with_seeds.txt', 'w') as f:\n",
    "    f.write('Seed\\tLabel\\tPrecision\\tRecall\\tF1\\n')\n",
    "    for seed_val in seed_values:\n",
    "        for label, precision_val in seed_metrics[seed_val]['precision']:\n",
    "            recall_val = next(val for lbl, val in seed_metrics[seed_val]['recall'] if lbl == label)\n",
    "            f1_val = next(val for lbl, val in seed_metrics[seed_val]['f1'] if lbl == label)\n",
    "            f.write(f'{seed_val}\\t{label}\\t{precision_val:.4f}\\t{recall_val:.4f}\\t{f1_val:.4f}\\n')\n",
    "\n",
    "# Initialize lists for storing the mean and standard deviation\n",
    "mean_precision = []\n",
    "std_precision = []\n",
    "mean_recall = []\n",
    "std_recall = []\n",
    "mean_f1 = []\n",
    "std_f1 = []\n",
    "\n",
    "# Extract unique labels\n",
    "unique_labels = np.unique(true_vals.flatten())\n",
    "\n",
    "for label in unique_labels:\n",
    "    # Collect precision, recall, and f1 scores for each label across all seeds\n",
    "    precisions = [val for lbl, val in seed_metrics[seed_val]['precision'] if lbl == label]\n",
    "    recalls = [val for lbl, val in seed_metrics[seed_val]['recall'] if lbl == label]\n",
    "    f1s = [val for lbl, val in seed_metrics[seed_val]['f1'] if lbl == label]\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    mean_precision.append(np.mean(precisions))\n",
    "    std_precision.append(np.std(precisions))\n",
    "    mean_recall.append(np.mean(recalls))\n",
    "    std_recall.append(np.std(recalls))\n",
    "    mean_f1.append(np.mean(f1s))\n",
    "    std_f1.append(np.std(f1s))\n",
    "\n",
    "# Convert lists to numpy arrays for easier plotting\n",
    "mean_precision = np.array(mean_precision)\n",
    "std_precision = np.array(std_precision)\n",
    "mean_recall = np.array(mean_recall)\n",
    "std_recall = np.array(std_recall)\n",
    "mean_f1 = np.array(mean_f1)\n",
    "std_f1 = np.array(std_f1)\n",
    "\n",
    "# Plotting\n",
    "x = np.arange(len(unique_labels))  # Label locations\n",
    "width = 0.25  # Width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "rects1 = ax.bar(x - width, mean_precision, width, yerr=std_precision, capsize=5, label='Precision', color='blue', alpha=0.7)\n",
    "rects2 = ax.bar(x, mean_recall, width, yerr=std_recall, capsize=5, label='Recall', color='green', alpha=0.7)\n",
    "rects3 = ax.bar(x + width, mean_f1, width, yerr=std_f1, capsize=5, label='F1 Score', color='red', alpha=0.7)\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Labels')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Mean and Standard Deviation of Precision, Recall, and F1 Scores by Label')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(unique_labels)\n",
    "ax.legend()\n",
    "\n",
    "# Save and show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('cadec_top6_20times_results_plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337473be-759b-4ac3-b2bd-5bd87d7094fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
