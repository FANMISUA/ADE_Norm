{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c2b8b-caed-4d77-8143-799791ce8a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "SMM4H top 3                             ade  soc_code  label\n",
      "3                            AD  10037175      0\n",
      "4                         focus  10029205      2\n",
      "5                          died  10018065      1\n",
      "8                        dreams  10037175      0\n",
      "10                   withdrawal  10018065      1\n",
      "...                         ...       ...    ...\n",
      "1695       talk a mile a minute  10037175      0\n",
      "1698     can't go back to sleep  10037175      0\n",
      "1703                 chest hurt  10018065      1\n",
      "1704   got ten minutes of sleep  10037175      0\n",
      "1708  never have another orgasm  10037175      0\n",
      "\n",
      "[734 rows x 3 columns]\n",
      "CADEC top 3                             ade  soc_code  label\n",
      "926            voracious hunger  10018065      1\n",
      "927            loss of appetite  10018065      1\n",
      "929            lack of appetite  10018065      1\n",
      "931                    anorexia  10018065      1\n",
      "932                    anorexic  10018065      1\n",
      "...                         ...       ...    ...\n",
      "5326  short term memory lacking  10037175      0\n",
      "5328      couldn't eat or drink  10037175      0\n",
      "5329              Could not eat  10037175      0\n",
      "5331           can't eat normal  10037175      0\n",
      "5332   Disturbed sleep patterns  10037175      0\n",
      "\n",
      "[1341 rows x 3 columns]\n",
      "df:                              ade  soc_code  label data_type\n",
      "3                            AD  10037175      0     train\n",
      "4                         focus  10029205      2     train\n",
      "5                          died  10018065      1     train\n",
      "8                        dreams  10037175      0     train\n",
      "10                   withdrawal  10018065      1     train\n",
      "...                         ...       ...    ...       ...\n",
      "5326  short term memory lacking  10037175      0     train\n",
      "5328      couldn't eat or drink  10037175      0     train\n",
      "5329              Could not eat  10037175      0       val\n",
      "5331           can't eat normal  10037175      0     train\n",
      "5332   Disturbed sleep patterns  10037175      0       val\n",
      "\n",
      "[2075 rows x 4 columns]\n",
      "                          ade\n",
      "soc_code label data_type     \n",
      "10018065 1     train      711\n",
      "               val        178\n",
      "10029205 2     train      399\n",
      "               val         99\n",
      "10037175 0     train      549\n",
      "               val        139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2888: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch Progress:   0%|                                                                           | 0/40 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|                                                                                 | 0/104 [00:00<?, ?it/s]\u001b[AC:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Epoch 1:   0%|                                                            | 0/104 [00:02<?, ?it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   1%|▌                                                   | 1/104 [00:02<03:29,  2.03s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 1:   1%|▌                                                   | 1/104 [00:02<03:29,  2.03s/it, training_loss=0.411]\u001b[A\n",
      "Epoch 1:   2%|█                                                   | 2/104 [00:02<01:38,  1.03it/s, training_loss=0.411]\u001b[A\n",
      "Epoch 1:   2%|█                                                   | 2/104 [00:02<01:38,  1.03it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   3%|█▌                                                  | 3/104 [00:02<01:00,  1.66it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   3%|█▌                                                  | 3/104 [00:02<01:00,  1.66it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   4%|██                                                  | 4/104 [00:02<00:43,  2.32it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:   4%|██                                                  | 4/104 [00:02<00:43,  2.32it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 1:   5%|██▌                                                 | 5/104 [00:02<00:33,  2.98it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 1:   5%|██▌                                                 | 5/104 [00:02<00:33,  2.98it/s, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   6%|███                                                 | 6/104 [00:02<00:27,  3.60it/s, training_loss=0.338]\u001b[A\n",
      "Epoch 1:   6%|███                                                 | 6/104 [00:03<00:27,  3.60it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 1:   7%|███▌                                                | 7/104 [00:03<00:23,  4.14it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 1:   7%|███▌                                                | 7/104 [00:03<00:23,  4.14it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:   8%|████                                                | 8/104 [00:03<00:21,  4.53it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:   8%|████                                                | 8/104 [00:03<00:21,  4.53it/s, training_loss=0.358]\u001b[A\n",
      "Epoch 1:   9%|████▌                                               | 9/104 [00:03<00:19,  4.91it/s, training_loss=0.358]\u001b[A\n",
      "Epoch 1:   9%|████▌                                               | 9/104 [00:03<00:19,  4.91it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  10%|████▉                                              | 10/104 [00:03<00:18,  5.20it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  10%|████▉                                              | 10/104 [00:03<00:18,  5.20it/s, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  11%|█████▍                                             | 11/104 [00:03<00:17,  5.43it/s, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  11%|█████▍                                             | 11/104 [00:03<00:17,  5.43it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  12%|█████▉                                             | 12/104 [00:03<00:16,  5.62it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  12%|█████▉                                             | 12/104 [00:04<00:16,  5.62it/s, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  12%|██████▍                                            | 13/104 [00:04<00:15,  5.75it/s, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  12%|██████▍                                            | 13/104 [00:04<00:15,  5.75it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  13%|██████▊                                            | 14/104 [00:04<00:15,  5.85it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  13%|██████▊                                            | 14/104 [00:04<00:15,  5.85it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  14%|███████▎                                           | 15/104 [00:04<00:15,  5.91it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  14%|███████▎                                           | 15/104 [00:04<00:15,  5.91it/s, training_loss=0.355]\u001b[A\n",
      "Epoch 1:  15%|███████▊                                           | 16/104 [00:04<00:14,  5.96it/s, training_loss=0.355]\u001b[A\n",
      "Epoch 1:  15%|███████▊                                           | 16/104 [00:04<00:14,  5.96it/s, training_loss=0.380]\u001b[A\n",
      "Epoch 1:  16%|████████▎                                          | 17/104 [00:04<00:14,  5.99it/s, training_loss=0.380]\u001b[A\n",
      "Epoch 1:  16%|████████▎                                          | 17/104 [00:04<00:14,  5.99it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  17%|████████▊                                          | 18/104 [00:04<00:14,  6.02it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  17%|████████▊                                          | 18/104 [00:05<00:14,  6.02it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  18%|█████████▎                                         | 19/104 [00:05<00:14,  6.05it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  18%|█████████▎                                         | 19/104 [00:05<00:14,  6.05it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  19%|█████████▊                                         | 20/104 [00:05<00:13,  6.06it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  19%|█████████▊                                         | 20/104 [00:05<00:13,  6.06it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  20%|██████████▎                                        | 21/104 [00:05<00:13,  6.06it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  20%|██████████▎                                        | 21/104 [00:05<00:13,  6.06it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  21%|██████████▊                                        | 22/104 [00:05<00:13,  6.07it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  21%|██████████▊                                        | 22/104 [00:05<00:13,  6.07it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  22%|███████████▎                                       | 23/104 [00:05<00:13,  6.05it/s, training_loss=0.334]\u001b[A\n",
      "Epoch 1:  22%|███████████▎                                       | 23/104 [00:05<00:13,  6.05it/s, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  23%|███████████▊                                       | 24/104 [00:05<00:13,  6.07it/s, training_loss=0.305]\u001b[A\n",
      "Epoch 1:  23%|███████████▊                                       | 24/104 [00:06<00:13,  6.07it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  24%|████████████▎                                      | 25/104 [00:06<00:13,  6.03it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  24%|████████████▎                                      | 25/104 [00:06<00:13,  6.03it/s, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  25%|████████████▊                                      | 26/104 [00:06<00:13,  5.99it/s, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  25%|████████████▊                                      | 26/104 [00:06<00:13,  5.99it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  26%|█████████████▏                                     | 27/104 [00:06<00:12,  5.94it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  26%|█████████████▏                                     | 27/104 [00:06<00:12,  5.94it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  27%|█████████████▋                                     | 28/104 [00:06<00:12,  5.93it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  27%|█████████████▋                                     | 28/104 [00:06<00:12,  5.93it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  28%|██████████████▏                                    | 29/104 [00:06<00:12,  5.91it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  28%|██████████████▏                                    | 29/104 [00:06<00:12,  5.91it/s, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  29%|██████████████▋                                    | 30/104 [00:06<00:12,  5.89it/s, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  29%|██████████████▋                                    | 30/104 [00:07<00:12,  5.89it/s, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  30%|███████████████▏                                   | 31/104 [00:07<00:12,  5.84it/s, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  30%|███████████████▏                                   | 31/104 [00:07<00:12,  5.84it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  31%|███████████████▋                                   | 32/104 [00:07<00:12,  5.80it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  31%|███████████████▋                                   | 32/104 [00:07<00:12,  5.80it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  32%|████████████████▏                                  | 33/104 [00:07<00:12,  5.74it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  32%|████████████████▏                                  | 33/104 [00:07<00:12,  5.74it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  33%|████████████████▋                                  | 34/104 [00:07<00:12,  5.71it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  33%|████████████████▋                                  | 34/104 [00:07<00:12,  5.71it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  34%|█████████████████▏                                 | 35/104 [00:07<00:12,  5.68it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  34%|█████████████████▏                                 | 35/104 [00:07<00:12,  5.68it/s, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  35%|█████████████████▋                                 | 36/104 [00:07<00:11,  5.67it/s, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  35%|█████████████████▋                                 | 36/104 [00:08<00:11,  5.67it/s, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  36%|██████████████████▏                                | 37/104 [00:08<00:11,  5.67it/s, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  36%|██████████████████▏                                | 37/104 [00:08<00:11,  5.67it/s, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  37%|██████████████████▋                                | 38/104 [00:08<00:11,  5.66it/s, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  37%|██████████████████▋                                | 38/104 [00:08<00:11,  5.66it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  38%|███████████████████▏                               | 39/104 [00:08<00:11,  5.66it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  38%|███████████████████▏                               | 39/104 [00:08<00:11,  5.66it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  38%|███████████████████▌                               | 40/104 [00:08<00:11,  5.62it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  38%|███████████████████▌                               | 40/104 [00:08<00:11,  5.62it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  39%|████████████████████                               | 41/104 [00:08<00:11,  5.59it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  39%|████████████████████                               | 41/104 [00:09<00:11,  5.59it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  40%|████████████████████▌                              | 42/104 [00:09<00:11,  5.58it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  40%|████████████████████▌                              | 42/104 [00:09<00:11,  5.58it/s, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  41%|█████████████████████                              | 43/104 [00:09<00:10,  5.58it/s, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  41%|█████████████████████                              | 43/104 [00:09<00:10,  5.58it/s, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  42%|█████████████████████▌                             | 44/104 [00:09<00:10,  5.56it/s, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  42%|█████████████████████▌                             | 44/104 [00:09<00:10,  5.56it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  43%|██████████████████████                             | 45/104 [00:09<00:10,  5.55it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  43%|██████████████████████                             | 45/104 [00:09<00:10,  5.55it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  44%|██████████████████████▌                            | 46/104 [00:09<00:10,  5.54it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  44%|██████████████████████▌                            | 46/104 [00:09<00:10,  5.54it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  45%|███████████████████████                            | 47/104 [00:09<00:10,  5.54it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  45%|███████████████████████                            | 47/104 [00:10<00:10,  5.54it/s, training_loss=0.362]\u001b[A\n",
      "Epoch 1:  46%|███████████████████████▌                           | 48/104 [00:10<00:10,  5.53it/s, training_loss=0.362]\u001b[A\n",
      "Epoch 1:  46%|███████████████████████▌                           | 48/104 [00:10<00:10,  5.53it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  47%|████████████████████████                           | 49/104 [00:10<00:09,  5.53it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  47%|████████████████████████                           | 49/104 [00:10<00:09,  5.53it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  48%|████████████████████████▌                          | 50/104 [00:10<00:09,  5.50it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  48%|████████████████████████▌                          | 50/104 [00:10<00:09,  5.50it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  49%|█████████████████████████                          | 51/104 [00:10<00:09,  5.47it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  49%|█████████████████████████                          | 51/104 [00:10<00:09,  5.47it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  50%|█████████████████████████▌                         | 52/104 [00:10<00:09,  5.46it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  50%|█████████████████████████▌                         | 52/104 [00:11<00:09,  5.46it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  51%|█████████████████████████▉                         | 53/104 [00:11<00:09,  5.44it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  51%|█████████████████████████▉                         | 53/104 [00:11<00:09,  5.44it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  52%|██████████████████████████▍                        | 54/104 [00:11<00:09,  5.44it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  52%|██████████████████████████▍                        | 54/104 [00:11<00:09,  5.44it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  53%|██████████████████████████▉                        | 55/104 [00:11<00:08,  5.45it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  53%|██████████████████████████▉                        | 55/104 [00:11<00:08,  5.45it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  54%|███████████████████████████▍                       | 56/104 [00:11<00:08,  5.47it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  54%|███████████████████████████▍                       | 56/104 [00:11<00:08,  5.47it/s, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  55%|███████████████████████████▉                       | 57/104 [00:11<00:08,  5.48it/s, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  55%|███████████████████████████▉                       | 57/104 [00:11<00:08,  5.48it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.46it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████▍                      | 58/104 [00:12<00:08,  5.46it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 1:  57%|████████████████████████████▉                      | 59/104 [00:12<00:08,  5.46it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 1:  57%|████████████████████████████▉                      | 59/104 [00:12<00:08,  5.46it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  58%|█████████████████████████████▍                     | 60/104 [00:12<00:08,  5.46it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  58%|█████████████████████████████▍                     | 60/104 [00:12<00:08,  5.46it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 1:  59%|█████████████████████████████▉                     | 61/104 [00:12<00:07,  5.46it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 1:  59%|█████████████████████████████▉                     | 61/104 [00:12<00:07,  5.46it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:07,  5.42it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:07,  5.42it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:07,  5.36it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  61%|██████████████████████████████▉                    | 63/104 [00:13<00:07,  5.36it/s, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  62%|███████████████████████████████▍                   | 64/104 [00:13<00:07,  5.34it/s, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  62%|███████████████████████████████▍                   | 64/104 [00:13<00:07,  5.34it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  62%|███████████████████████████████▉                   | 65/104 [00:13<00:07,  5.33it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  62%|███████████████████████████████▉                   | 65/104 [00:13<00:07,  5.33it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 1:  63%|████████████████████████████████▎                  | 66/104 [00:13<00:07,  5.32it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 1:  63%|████████████████████████████████▎                  | 66/104 [00:13<00:07,  5.32it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:06,  5.32it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:06,  5.32it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:06,  5.31it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  65%|█████████████████████████████████▎                 | 68/104 [00:14<00:06,  5.31it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 1:  66%|█████████████████████████████████▊                 | 69/104 [00:14<00:06,  5.29it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 1:  66%|█████████████████████████████████▊                 | 69/104 [00:14<00:06,  5.29it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  67%|██████████████████████████████████▎                | 70/104 [00:14<00:06,  5.30it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  67%|██████████████████████████████████▎                | 70/104 [00:14<00:06,  5.30it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  68%|██████████████████████████████████▊                | 71/104 [00:14<00:06,  5.30it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  68%|██████████████████████████████████▊                | 71/104 [00:14<00:06,  5.30it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  5.32it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  5.32it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:05,  5.31it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 1:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:05,  5.31it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.31it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  71%|████████████████████████████████████▎              | 74/104 [00:15<00:05,  5.31it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 1:  72%|████████████████████████████████████▊              | 75/104 [00:15<00:05,  5.32it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 1:  72%|████████████████████████████████████▊              | 75/104 [00:15<00:05,  5.32it/s, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  73%|█████████████████████████████████████▎             | 76/104 [00:15<00:05,  5.32it/s, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  73%|█████████████████████████████████████▎             | 76/104 [00:15<00:05,  5.32it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  5.31it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  5.31it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:04,  5.33it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:04,  5.33it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.29it/s, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  76%|██████████████████████████████████████▋            | 79/104 [00:16<00:04,  5.29it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  77%|███████████████████████████████████████▏           | 80/104 [00:16<00:04,  5.28it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  77%|███████████████████████████████████████▏           | 80/104 [00:16<00:04,  5.28it/s, training_loss=0.185]\u001b[A\n",
      "Epoch 1:  78%|███████████████████████████████████████▋           | 81/104 [00:16<00:04,  5.27it/s, training_loss=0.185]\u001b[A\n",
      "Epoch 1:  78%|███████████████████████████████████████▋           | 81/104 [00:16<00:04,  5.27it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  5.24it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  5.24it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.24it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.24it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.25it/s, training_loss=0.295]\u001b[A\n",
      "Epoch 1:  81%|█████████████████████████████████████████▏         | 84/104 [00:17<00:03,  5.25it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  82%|█████████████████████████████████████████▋         | 85/104 [00:17<00:03,  5.25it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  82%|█████████████████████████████████████████▋         | 85/104 [00:17<00:03,  5.25it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  83%|██████████████████████████████████████████▏        | 86/104 [00:17<00:03,  5.25it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  83%|██████████████████████████████████████████▏        | 86/104 [00:17<00:03,  5.25it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  84%|██████████████████████████████████████████▋        | 87/104 [00:17<00:03,  5.25it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  84%|██████████████████████████████████████████▋        | 87/104 [00:17<00:03,  5.25it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 1:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.25it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 1:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.25it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 1:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.27it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 1:  86%|███████████████████████████████████████████▋       | 89/104 [00:18<00:02,  5.27it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 1:  87%|████████████████████████████████████████████▏      | 90/104 [00:18<00:02,  5.25it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 1:  87%|████████████████████████████████████████████▏      | 90/104 [00:18<00:02,  5.25it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████████████████████▋      | 91/104 [00:18<00:02,  5.26it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████████████████████▋      | 91/104 [00:18<00:02,  5.26it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 1:  88%|█████████████████████████████████████████████      | 92/104 [00:18<00:02,  5.28it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 1:  88%|█████████████████████████████████████████████      | 92/104 [00:18<00:02,  5.28it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  5.27it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  5.27it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 1:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:01,  5.25it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 1:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:01,  5.25it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  91%|██████████████████████████████████████████████▌    | 95/104 [00:18<00:01,  5.27it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  91%|██████████████████████████████████████████████▌    | 95/104 [00:19<00:01,  5.27it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  92%|███████████████████████████████████████████████    | 96/104 [00:19<00:01,  5.28it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  92%|███████████████████████████████████████████████    | 96/104 [00:19<00:01,  5.28it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  93%|███████████████████████████████████████████████▌   | 97/104 [00:19<00:01,  5.27it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  93%|███████████████████████████████████████████████▌   | 97/104 [00:19<00:01,  5.27it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  5.29it/s, training_loss=0.354]\u001b[A\n",
      "Epoch 1:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  5.29it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:00,  5.30it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:00,  5.30it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████  | 100/104 [00:19<00:00,  5.26it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████  | 100/104 [00:20<00:00,  5.26it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  97%|████████████████████████████████████████████████▌ | 101/104 [00:20<00:00,  5.25it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  97%|████████████████████████████████████████████████▌ | 101/104 [00:20<00:00,  5.25it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████████████████████████████████ | 102/104 [00:20<00:00,  5.24it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  98%|█████████████████████████████████████████████████ | 102/104 [00:20<00:00,  5.24it/s, training_loss=0.090]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  5.21it/s, training_loss=0.090]\u001b[A\n",
      "Epoch 1:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  5.21it/s, training_loss=0.284]\u001b[A\n",
      "Epoch 1: 100%|██████████████████████████████████████████████████| 104/104 [00:20<00:00,  5.59it/s, training_loss=0.284]\u001b[A\n",
      "Epoch Progress:   2%|█▋                                                                 | 1/40 [00:20<13:25, 20.65s/it]\u001b[A\n",
      "Epoch 2:   0%|                                                                                 | 0/104 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|                                                            | 0/104 [00:00<?, ?it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 2:   1%|▌                                                   | 1/104 [00:00<00:20,  5.04it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 2:   1%|▌                                                   | 1/104 [00:00<00:20,  5.04it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 2:   2%|█                                                   | 2/104 [00:00<00:20,  5.01it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 2:   2%|█                                                   | 2/104 [00:00<00:20,  5.01it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 2:   3%|█▌                                                  | 3/104 [00:00<00:20,  4.99it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 2:   3%|█▌                                                  | 3/104 [00:00<00:20,  4.99it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:   4%|██                                                  | 4/104 [00:00<00:20,  4.99it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:   4%|██                                                  | 4/104 [00:01<00:20,  4.99it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 2:   5%|██▌                                                 | 5/104 [00:01<00:19,  4.99it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 2:   5%|██▌                                                 | 5/104 [00:01<00:19,  4.99it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 2:   6%|███                                                 | 6/104 [00:01<00:19,  5.00it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 2:   6%|███                                                 | 6/104 [00:01<00:19,  5.00it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 2:   7%|███▌                                                | 7/104 [00:01<00:19,  5.03it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 2:   7%|███▌                                                | 7/104 [00:01<00:19,  5.03it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 2:   8%|████                                                | 8/104 [00:01<00:19,  5.03it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 2:   8%|████                                                | 8/104 [00:01<00:19,  5.03it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 2:   9%|████▌                                               | 9/104 [00:01<00:18,  5.03it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 2:   9%|████▌                                               | 9/104 [00:01<00:18,  5.03it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 2:  10%|████▉                                              | 10/104 [00:01<00:18,  5.00it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 2:  10%|████▉                                              | 10/104 [00:02<00:18,  5.00it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  11%|█████▍                                             | 11/104 [00:02<00:18,  4.99it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  11%|█████▍                                             | 11/104 [00:02<00:18,  4.99it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  12%|█████▉                                             | 12/104 [00:02<00:18,  5.01it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  12%|█████▉                                             | 12/104 [00:02<00:18,  5.01it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  12%|██████▍                                            | 13/104 [00:02<00:18,  5.00it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  12%|██████▍                                            | 13/104 [00:02<00:18,  5.00it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 2:  13%|██████▊                                            | 14/104 [00:02<00:18,  4.98it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 2:  13%|██████▊                                            | 14/104 [00:02<00:18,  4.98it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 2:  14%|███████▎                                           | 15/104 [00:02<00:17,  4.99it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 2:  14%|███████▎                                           | 15/104 [00:03<00:17,  4.99it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 2:  15%|███████▊                                           | 16/104 [00:03<00:17,  5.03it/s, training_loss=0.202]\u001b[A\n",
      "Epoch 2:  15%|███████▊                                           | 16/104 [00:03<00:17,  5.03it/s, training_loss=0.231]\u001b[A\n",
      "Epoch 2:  16%|████████▎                                          | 17/104 [00:03<00:17,  5.04it/s, training_loss=0.231]\u001b[A\n",
      "Epoch 2:  16%|████████▎                                          | 17/104 [00:03<00:17,  5.04it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 2:  17%|████████▊                                          | 18/104 [00:03<00:17,  5.05it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 2:  17%|████████▊                                          | 18/104 [00:03<00:17,  5.05it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 2:  18%|█████████▎                                         | 19/104 [00:03<00:16,  5.07it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 2:  18%|█████████▎                                         | 19/104 [00:03<00:16,  5.07it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 2:  19%|█████████▊                                         | 20/104 [00:03<00:16,  5.08it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 2:  19%|█████████▊                                         | 20/104 [00:04<00:16,  5.08it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 2:  20%|██████████▎                                        | 21/104 [00:04<00:16,  5.10it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 2:  20%|██████████▎                                        | 21/104 [00:04<00:16,  5.10it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  21%|██████████▊                                        | 22/104 [00:04<00:16,  5.04it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  21%|██████████▊                                        | 22/104 [00:04<00:16,  5.04it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  22%|███████████▎                                       | 23/104 [00:04<00:16,  5.03it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  22%|███████████▎                                       | 23/104 [00:04<00:16,  5.03it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 2:  23%|███████████▊                                       | 24/104 [00:04<00:15,  5.03it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 2:  23%|███████████▊                                       | 24/104 [00:04<00:15,  5.03it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  24%|████████████▎                                      | 25/104 [00:04<00:15,  5.02it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  24%|████████████▎                                      | 25/104 [00:05<00:15,  5.02it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 2:  25%|████████████▊                                      | 26/104 [00:05<00:15,  5.04it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 2:  25%|████████████▊                                      | 26/104 [00:05<00:15,  5.04it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 2:  26%|█████████████▏                                     | 27/104 [00:05<00:15,  5.04it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 2:  26%|█████████████▏                                     | 27/104 [00:05<00:15,  5.04it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  27%|█████████████▋                                     | 28/104 [00:05<00:15,  5.07it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  27%|█████████████▋                                     | 28/104 [00:05<00:15,  5.07it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  28%|██████████████▏                                    | 29/104 [00:05<00:14,  5.07it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  28%|██████████████▏                                    | 29/104 [00:05<00:14,  5.07it/s, training_loss=0.230]\u001b[A\n",
      "Epoch 2:  29%|██████████████▋                                    | 30/104 [00:05<00:14,  5.07it/s, training_loss=0.230]\u001b[A\n",
      "Epoch 2:  29%|██████████████▋                                    | 30/104 [00:06<00:14,  5.07it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  5.08it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  5.08it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  31%|███████████████▋                                   | 32/104 [00:06<00:14,  5.11it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 2:  31%|███████████████▋                                   | 32/104 [00:06<00:14,  5.11it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 2:  32%|████████████████▏                                  | 33/104 [00:06<00:13,  5.11it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 2:  32%|████████████████▏                                  | 33/104 [00:06<00:13,  5.11it/s, training_loss=0.351]\u001b[A\n",
      "Epoch 2:  33%|████████████████▋                                  | 34/104 [00:06<00:13,  5.11it/s, training_loss=0.351]\u001b[A\n",
      "Epoch 2:  33%|████████████████▋                                  | 34/104 [00:06<00:13,  5.11it/s, training_loss=0.257]\u001b[A\n",
      "Epoch 2:  34%|█████████████████▏                                 | 35/104 [00:06<00:13,  5.13it/s, training_loss=0.257]\u001b[A\n",
      "Epoch 2:  34%|█████████████████▏                                 | 35/104 [00:07<00:13,  5.13it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  35%|█████████████████▋                                 | 36/104 [00:07<00:13,  5.14it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  35%|█████████████████▋                                 | 36/104 [00:07<00:13,  5.14it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 2:  36%|██████████████████▏                                | 37/104 [00:07<00:13,  5.14it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 2:  36%|██████████████████▏                                | 37/104 [00:07<00:13,  5.14it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 2:  37%|██████████████████▋                                | 38/104 [00:07<00:12,  5.13it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 2:  37%|██████████████████▋                                | 38/104 [00:07<00:12,  5.13it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  38%|███████████████████▏                               | 39/104 [00:07<00:12,  5.15it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  38%|███████████████████▏                               | 39/104 [00:07<00:12,  5.15it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 2:  38%|███████████████████▌                               | 40/104 [00:07<00:12,  5.17it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 2:  38%|███████████████████▌                               | 40/104 [00:08<00:12,  5.17it/s, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  39%|████████████████████                               | 41/104 [00:08<00:12,  5.17it/s, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  39%|████████████████████                               | 41/104 [00:08<00:12,  5.17it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 2:  40%|████████████████████▌                              | 42/104 [00:08<00:11,  5.19it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 2:  40%|████████████████████▌                              | 42/104 [00:08<00:11,  5.19it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  41%|█████████████████████                              | 43/104 [00:08<00:11,  5.19it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  41%|█████████████████████                              | 43/104 [00:08<00:11,  5.19it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.18it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.18it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  43%|██████████████████████                             | 45/104 [00:08<00:11,  5.14it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  43%|██████████████████████                             | 45/104 [00:09<00:11,  5.14it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 2:  44%|██████████████████████▌                            | 46/104 [00:09<00:11,  5.12it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 2:  44%|██████████████████████▌                            | 46/104 [00:09<00:11,  5.12it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 2:  45%|███████████████████████                            | 47/104 [00:09<00:11,  5.11it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 2:  45%|███████████████████████                            | 47/104 [00:09<00:11,  5.11it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  46%|███████████████████████▌                           | 48/104 [00:09<00:10,  5.11it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  46%|███████████████████████▌                           | 48/104 [00:09<00:10,  5.11it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.12it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.12it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  48%|████████████████████████▌                          | 50/104 [00:09<00:10,  5.12it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  48%|████████████████████████▌                          | 50/104 [00:10<00:10,  5.12it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 2:  49%|█████████████████████████                          | 51/104 [00:10<00:10,  5.09it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 2:  49%|█████████████████████████                          | 51/104 [00:10<00:10,  5.09it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 2:  50%|█████████████████████████▌                         | 52/104 [00:10<00:10,  5.10it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 2:  50%|█████████████████████████▌                         | 52/104 [00:10<00:10,  5.10it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  51%|█████████████████████████▉                         | 53/104 [00:10<00:10,  5.10it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  51%|█████████████████████████▉                         | 53/104 [00:10<00:10,  5.10it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.12it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.12it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 2:  53%|██████████████████████████▉                        | 55/104 [00:10<00:09,  5.13it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 2:  53%|██████████████████████████▉                        | 55/104 [00:11<00:09,  5.13it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 2:  54%|███████████████████████████▍                       | 56/104 [00:11<00:09,  5.14it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 2:  54%|███████████████████████████▍                       | 56/104 [00:11<00:09,  5.14it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 2:  55%|███████████████████████████▉                       | 57/104 [00:11<00:09,  5.16it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 2:  55%|███████████████████████████▉                       | 57/104 [00:11<00:09,  5.16it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.16it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.16it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 2:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.17it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 2:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.17it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  58%|█████████████████████████████▍                     | 60/104 [00:11<00:08,  5.19it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  58%|█████████████████████████████▍                     | 60/104 [00:11<00:08,  5.19it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 2:  59%|█████████████████████████████▉                     | 61/104 [00:11<00:08,  5.19it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 2:  59%|█████████████████████████████▉                     | 61/104 [00:12<00:08,  5.19it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:08,  5.20it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:08,  5.20it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 2:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:07,  5.20it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 2:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:07,  5.20it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 2:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:07,  5.21it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 2:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:07,  5.21it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 2:  62%|███████████████████████████████▉                   | 65/104 [00:12<00:07,  5.21it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 2:  62%|███████████████████████████████▉                   | 65/104 [00:12<00:07,  5.21it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 2:  63%|████████████████████████████████▎                  | 66/104 [00:12<00:07,  5.23it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 2:  63%|████████████████████████████████▎                  | 66/104 [00:13<00:07,  5.23it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 2:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:07,  5.24it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 2:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:07,  5.24it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:06,  5.25it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:06,  5.25it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 2:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:06,  5.25it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 2:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:06,  5.25it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 2:  67%|██████████████████████████████████▎                | 70/104 [00:13<00:06,  5.25it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 2:  67%|██████████████████████████████████▎                | 70/104 [00:13<00:06,  5.25it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 2:  68%|██████████████████████████████████▊                | 71/104 [00:13<00:06,  5.26it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 2:  68%|██████████████████████████████████▊                | 71/104 [00:14<00:06,  5.26it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 2:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  5.26it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 2:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  5.26it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 2:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:05,  5.26it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 2:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:05,  5.26it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.21it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.21it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  72%|████████████████████████████████████▊              | 75/104 [00:14<00:05,  5.17it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  72%|████████████████████████████████████▊              | 75/104 [00:14<00:05,  5.17it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 2:  73%|█████████████████████████████████████▎             | 76/104 [00:14<00:05,  5.16it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 2:  73%|█████████████████████████████████████▎             | 76/104 [00:15<00:05,  5.16it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  5.16it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  5.16it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:05,  5.15it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:05,  5.15it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.14it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.14it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  77%|███████████████████████████████████████▏           | 80/104 [00:15<00:04,  5.15it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  77%|███████████████████████████████████████▏           | 80/104 [00:15<00:04,  5.15it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 2:  78%|███████████████████████████████████████▋           | 81/104 [00:15<00:04,  5.14it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 2:  78%|███████████████████████████████████████▋           | 81/104 [00:16<00:04,  5.14it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 2:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  5.15it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 2:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  5.15it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 2:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.16it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 2:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.16it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.17it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.17it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 2:  82%|█████████████████████████████████████████▋         | 85/104 [00:16<00:03,  5.16it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 2:  82%|█████████████████████████████████████████▋         | 85/104 [00:16<00:03,  5.16it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  83%|██████████████████████████████████████████▏        | 86/104 [00:16<00:03,  5.17it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  83%|██████████████████████████████████████████▏        | 86/104 [00:16<00:03,  5.17it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  84%|██████████████████████████████████████████▋        | 87/104 [00:16<00:03,  5.19it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  84%|██████████████████████████████████████████▋        | 87/104 [00:17<00:03,  5.19it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.20it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.20it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.21it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.21it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  87%|████████████████████████████████████████████▏      | 90/104 [00:17<00:02,  5.22it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  87%|████████████████████████████████████████████▏      | 90/104 [00:17<00:02,  5.22it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████████████████████▋      | 91/104 [00:17<00:02,  5.22it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████████████████████▋      | 91/104 [00:17<00:02,  5.22it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  88%|█████████████████████████████████████████████      | 92/104 [00:17<00:02,  5.23it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  88%|█████████████████████████████████████████████      | 92/104 [00:18<00:02,  5.23it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  5.24it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  5.24it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:01,  5.25it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:01,  5.25it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 2:  91%|██████████████████████████████████████████████▌    | 95/104 [00:18<00:01,  5.26it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 2:  91%|██████████████████████████████████████████████▌    | 95/104 [00:18<00:01,  5.26it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 2:  92%|███████████████████████████████████████████████    | 96/104 [00:18<00:01,  5.24it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 2:  92%|███████████████████████████████████████████████    | 96/104 [00:18<00:01,  5.24it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  93%|███████████████████████████████████████████████▌   | 97/104 [00:18<00:01,  5.24it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  93%|███████████████████████████████████████████████▌   | 97/104 [00:19<00:01,  5.24it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 2:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  5.25it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 2:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  5.25it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:00,  5.24it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:00,  5.24it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████  | 100/104 [00:19<00:00,  5.24it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████  | 100/104 [00:19<00:00,  5.24it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  97%|████████████████████████████████████████████████▌ | 101/104 [00:19<00:00,  5.21it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  97%|████████████████████████████████████████████████▌ | 101/104 [00:19<00:00,  5.21it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 2:  98%|█████████████████████████████████████████████████ | 102/104 [00:19<00:00,  5.19it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 2:  98%|█████████████████████████████████████████████████ | 102/104 [00:20<00:00,  5.19it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 2:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  5.18it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 2:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  5.18it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 2: 100%|██████████████████████████████████████████████████| 104/104 [00:20<00:00,  5.60it/s, training_loss=0.157]\u001b[A\n",
      "Epoch Progress:   5%|███▎                                                               | 2/40 [00:40<12:54, 20.39s/it]\u001b[A\n",
      "Epoch 3:   0%|                                                                                 | 0/104 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|                                                            | 0/104 [00:00<?, ?it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 3:   1%|▌                                                   | 1/104 [00:00<00:20,  5.09it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 3:   1%|▌                                                   | 1/104 [00:00<00:20,  5.09it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 3:   2%|█                                                   | 2/104 [00:00<00:20,  5.01it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 3:   2%|█                                                   | 2/104 [00:00<00:20,  5.01it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 3:   3%|█▌                                                  | 3/104 [00:00<00:20,  5.04it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 3:   3%|█▌                                                  | 3/104 [00:00<00:20,  5.04it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 3:   4%|██                                                  | 4/104 [00:00<00:19,  5.06it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 3:   4%|██                                                  | 4/104 [00:00<00:19,  5.06it/s, training_loss=0.143]\u001b[A\n",
      "Epoch 3:   5%|██▌                                                 | 5/104 [00:00<00:19,  5.08it/s, training_loss=0.143]\u001b[A\n",
      "Epoch 3:   5%|██▌                                                 | 5/104 [00:01<00:19,  5.08it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:   6%|███                                                 | 6/104 [00:01<00:19,  5.09it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:   6%|███                                                 | 6/104 [00:01<00:19,  5.09it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 3:   7%|███▌                                                | 7/104 [00:01<00:19,  5.10it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 3:   7%|███▌                                                | 7/104 [00:01<00:19,  5.10it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:   8%|████                                                | 8/104 [00:01<00:18,  5.10it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:   8%|████                                                | 8/104 [00:01<00:18,  5.10it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 3:   9%|████▌                                               | 9/104 [00:01<00:18,  5.12it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 3:   9%|████▌                                               | 9/104 [00:01<00:18,  5.12it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  10%|████▉                                              | 10/104 [00:01<00:18,  5.13it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  10%|████▉                                              | 10/104 [00:02<00:18,  5.13it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 3:  11%|█████▍                                             | 11/104 [00:02<00:18,  5.12it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 3:  11%|█████▍                                             | 11/104 [00:02<00:18,  5.12it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  12%|█████▉                                             | 12/104 [00:02<00:17,  5.13it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  12%|█████▉                                             | 12/104 [00:02<00:17,  5.13it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  12%|██████▍                                            | 13/104 [00:02<00:17,  5.15it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  12%|██████▍                                            | 13/104 [00:02<00:17,  5.15it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 3:  13%|██████▊                                            | 14/104 [00:02<00:17,  5.17it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 3:  13%|██████▊                                            | 14/104 [00:02<00:17,  5.17it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  14%|███████▎                                           | 15/104 [00:02<00:17,  5.19it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  14%|███████▎                                           | 15/104 [00:03<00:17,  5.19it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  15%|███████▊                                           | 16/104 [00:03<00:16,  5.21it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  15%|███████▊                                           | 16/104 [00:03<00:16,  5.21it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  16%|████████▎                                          | 17/104 [00:03<00:16,  5.22it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  16%|████████▎                                          | 17/104 [00:03<00:16,  5.22it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  17%|████████▊                                          | 18/104 [00:03<00:16,  5.23it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  17%|████████▊                                          | 18/104 [00:03<00:16,  5.23it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  18%|█████████▎                                         | 19/104 [00:03<00:16,  5.24it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  18%|█████████▎                                         | 19/104 [00:03<00:16,  5.24it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  19%|█████████▊                                         | 20/104 [00:03<00:16,  5.23it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  19%|█████████▊                                         | 20/104 [00:04<00:16,  5.23it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 3:  20%|██████████▎                                        | 21/104 [00:04<00:15,  5.24it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 3:  20%|██████████▎                                        | 21/104 [00:04<00:15,  5.24it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  21%|██████████▊                                        | 22/104 [00:04<00:15,  5.23it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  21%|██████████▊                                        | 22/104 [00:04<00:15,  5.23it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 3:  22%|███████████▎                                       | 23/104 [00:04<00:15,  5.21it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 3:  22%|███████████▎                                       | 23/104 [00:04<00:15,  5.21it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 3:  23%|███████████▊                                       | 24/104 [00:04<00:15,  5.20it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 3:  23%|███████████▊                                       | 24/104 [00:04<00:15,  5.20it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  24%|████████████▎                                      | 25/104 [00:04<00:15,  5.17it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  24%|████████████▎                                      | 25/104 [00:05<00:15,  5.17it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  25%|████████████▊                                      | 26/104 [00:05<00:15,  5.18it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  25%|████████████▊                                      | 26/104 [00:05<00:15,  5.18it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  26%|█████████████▏                                     | 27/104 [00:05<00:14,  5.17it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  26%|█████████████▏                                     | 27/104 [00:05<00:14,  5.17it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  27%|█████████████▋                                     | 28/104 [00:05<00:14,  5.17it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  27%|█████████████▋                                     | 28/104 [00:05<00:14,  5.17it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  28%|██████████████▏                                    | 29/104 [00:05<00:14,  5.17it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  28%|██████████████▏                                    | 29/104 [00:05<00:14,  5.17it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 3:  29%|██████████████▋                                    | 30/104 [00:05<00:14,  5.17it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 3:  29%|██████████████▋                                    | 30/104 [00:06<00:14,  5.17it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  5.18it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  5.18it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  31%|███████████████▋                                   | 32/104 [00:06<00:13,  5.17it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  31%|███████████████▋                                   | 32/104 [00:06<00:13,  5.17it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  32%|████████████████▏                                  | 33/104 [00:06<00:13,  5.17it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  32%|████████████████▏                                  | 33/104 [00:06<00:13,  5.17it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  33%|████████████████▋                                  | 34/104 [00:06<00:13,  5.18it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  33%|████████████████▋                                  | 34/104 [00:06<00:13,  5.18it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  34%|█████████████████▏                                 | 35/104 [00:06<00:13,  5.17it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  34%|█████████████████▏                                 | 35/104 [00:06<00:13,  5.17it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  35%|█████████████████▋                                 | 36/104 [00:06<00:13,  5.18it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  35%|█████████████████▋                                 | 36/104 [00:07<00:13,  5.18it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  36%|██████████████████▏                                | 37/104 [00:07<00:12,  5.19it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  36%|██████████████████▏                                | 37/104 [00:07<00:12,  5.19it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 3:  37%|██████████████████▋                                | 38/104 [00:07<00:12,  5.19it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 3:  37%|██████████████████▋                                | 38/104 [00:07<00:12,  5.19it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  38%|███████████████████▏                               | 39/104 [00:07<00:12,  5.20it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  38%|███████████████████▏                               | 39/104 [00:07<00:12,  5.20it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  38%|███████████████████▌                               | 40/104 [00:07<00:12,  5.21it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  38%|███████████████████▌                               | 40/104 [00:07<00:12,  5.21it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 3:  39%|████████████████████                               | 41/104 [00:07<00:12,  5.22it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 3:  39%|████████████████████                               | 41/104 [00:08<00:12,  5.22it/s, training_loss=0.159]\u001b[A\n",
      "Epoch 3:  40%|████████████████████▌                              | 42/104 [00:08<00:11,  5.22it/s, training_loss=0.159]\u001b[A\n",
      "Epoch 3:  40%|████████████████████▌                              | 42/104 [00:08<00:11,  5.22it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  41%|█████████████████████                              | 43/104 [00:08<00:11,  5.22it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  41%|█████████████████████                              | 43/104 [00:08<00:11,  5.22it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.23it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.23it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 3:  43%|██████████████████████                             | 45/104 [00:08<00:11,  5.23it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 3:  43%|██████████████████████                             | 45/104 [00:08<00:11,  5.23it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  44%|██████████████████████▌                            | 46/104 [00:08<00:11,  5.23it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  44%|██████████████████████▌                            | 46/104 [00:09<00:11,  5.23it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 3:  45%|███████████████████████                            | 47/104 [00:09<00:10,  5.25it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 3:  45%|███████████████████████                            | 47/104 [00:09<00:10,  5.25it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  46%|███████████████████████▌                           | 48/104 [00:09<00:10,  5.26it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 3:  46%|███████████████████████▌                           | 48/104 [00:09<00:10,  5.26it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 3:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.22it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 3:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.22it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 3:  48%|████████████████████████▌                          | 50/104 [00:09<00:10,  5.19it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 3:  48%|████████████████████████▌                          | 50/104 [00:09<00:10,  5.19it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 3:  49%|█████████████████████████                          | 51/104 [00:09<00:10,  5.17it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 3:  49%|█████████████████████████                          | 51/104 [00:10<00:10,  5.17it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  50%|█████████████████████████▌                         | 52/104 [00:10<00:10,  5.15it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  50%|█████████████████████████▌                         | 52/104 [00:10<00:10,  5.15it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 3:  51%|█████████████████████████▉                         | 53/104 [00:10<00:09,  5.15it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 3:  51%|█████████████████████████▉                         | 53/104 [00:10<00:09,  5.15it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 3:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.15it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 3:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.15it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 3:  53%|██████████████████████████▉                        | 55/104 [00:10<00:09,  5.13it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 3:  53%|██████████████████████████▉                        | 55/104 [00:10<00:09,  5.13it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  54%|███████████████████████████▍                       | 56/104 [00:10<00:09,  5.13it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  54%|███████████████████████████▍                       | 56/104 [00:11<00:09,  5.13it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  55%|███████████████████████████▉                       | 57/104 [00:11<00:09,  5.12it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  55%|███████████████████████████▉                       | 57/104 [00:11<00:09,  5.12it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.12it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.12it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.12it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.12it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 3:  58%|█████████████████████████████▍                     | 60/104 [00:11<00:08,  5.13it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 3:  58%|█████████████████████████████▍                     | 60/104 [00:11<00:08,  5.13it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  59%|█████████████████████████████▉                     | 61/104 [00:11<00:08,  5.14it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  59%|█████████████████████████████▉                     | 61/104 [00:11<00:08,  5.14it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  60%|██████████████████████████████▍                    | 62/104 [00:11<00:08,  5.15it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:08,  5.15it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 3:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:07,  5.15it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 3:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:07,  5.15it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 3:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:07,  5.15it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 3:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:07,  5.15it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  62%|███████████████████████████████▉                   | 65/104 [00:12<00:07,  5.17it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  62%|███████████████████████████████▉                   | 65/104 [00:12<00:07,  5.17it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 3:  63%|████████████████████████████████▎                  | 66/104 [00:12<00:07,  5.17it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 3:  63%|████████████████████████████████▎                  | 66/104 [00:12<00:07,  5.17it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 3:  64%|████████████████████████████████▊                  | 67/104 [00:12<00:07,  5.19it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 3:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:07,  5.19it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:06,  5.20it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:06,  5.20it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 3:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:06,  5.20it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 3:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:06,  5.20it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  67%|██████████████████████████████████▎                | 70/104 [00:13<00:06,  5.20it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  67%|██████████████████████████████████▎                | 70/104 [00:13<00:06,  5.20it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 3:  68%|██████████████████████████████████▊                | 71/104 [00:13<00:06,  5.20it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 3:  68%|██████████████████████████████████▊                | 71/104 [00:13<00:06,  5.20it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  69%|███████████████████████████████████▎               | 72/104 [00:13<00:06,  5.21it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  5.21it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:05,  5.22it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:05,  5.22it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.22it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.22it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  72%|████████████████████████████████████▊              | 75/104 [00:14<00:05,  5.23it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  72%|████████████████████████████████████▊              | 75/104 [00:14<00:05,  5.23it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  73%|█████████████████████████████████████▎             | 76/104 [00:14<00:05,  5.24it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  73%|█████████████████████████████████████▎             | 76/104 [00:14<00:05,  5.24it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  74%|█████████████████████████████████████▊             | 77/104 [00:14<00:05,  5.22it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  5.22it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:04,  5.22it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:04,  5.22it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 3:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.19it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 3:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.19it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  77%|███████████████████████████████████████▏           | 80/104 [00:15<00:04,  5.18it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  77%|███████████████████████████████████████▏           | 80/104 [00:15<00:04,  5.18it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 3:  78%|███████████████████████████████████████▋           | 81/104 [00:15<00:04,  5.15it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 3:  78%|███████████████████████████████████████▋           | 81/104 [00:15<00:04,  5.15it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 3:  79%|████████████████████████████████████████▏          | 82/104 [00:15<00:04,  5.15it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 3:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  5.15it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.15it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.15it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 3:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.15it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 3:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.15it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  82%|█████████████████████████████████████████▋         | 85/104 [00:16<00:03,  5.16it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  82%|█████████████████████████████████████████▋         | 85/104 [00:16<00:03,  5.16it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  83%|██████████████████████████████████████████▏        | 86/104 [00:16<00:03,  5.15it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  83%|██████████████████████████████████████████▏        | 86/104 [00:16<00:03,  5.15it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  84%|██████████████████████████████████████████▋        | 87/104 [00:16<00:03,  5.16it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  84%|██████████████████████████████████████████▋        | 87/104 [00:17<00:03,  5.16it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.17it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.17it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.16it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.16it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  87%|████████████████████████████████████████████▏      | 90/104 [00:17<00:02,  5.17it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  87%|████████████████████████████████████████████▏      | 90/104 [00:17<00:02,  5.17it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 3:  88%|████████████████████████████████████████████▋      | 91/104 [00:17<00:02,  5.16it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 3:  88%|████████████████████████████████████████████▋      | 91/104 [00:17<00:02,  5.16it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  88%|█████████████████████████████████████████████      | 92/104 [00:17<00:02,  5.18it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  88%|█████████████████████████████████████████████      | 92/104 [00:17<00:02,  5.18it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  89%|█████████████████████████████████████████████▌     | 93/104 [00:17<00:02,  5.19it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  5.19it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 3:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:01,  5.21it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 3:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:01,  5.21it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  91%|██████████████████████████████████████████████▌    | 95/104 [00:18<00:01,  5.22it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  91%|██████████████████████████████████████████████▌    | 95/104 [00:18<00:01,  5.22it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 3:  92%|███████████████████████████████████████████████    | 96/104 [00:18<00:01,  5.22it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 3:  92%|███████████████████████████████████████████████    | 96/104 [00:18<00:01,  5.22it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 3:  93%|███████████████████████████████████████████████▌   | 97/104 [00:18<00:01,  5.22it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 3:  93%|███████████████████████████████████████████████▌   | 97/104 [00:18<00:01,  5.22it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  94%|████████████████████████████████████████████████   | 98/104 [00:18<00:01,  5.24it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  5.24it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 3:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:00,  5.24it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 3:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:00,  5.24it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  96%|████████████████████████████████████████████████  | 100/104 [00:19<00:00,  5.26it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  96%|████████████████████████████████████████████████  | 100/104 [00:19<00:00,  5.26it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 3:  97%|████████████████████████████████████████████████▌ | 101/104 [00:19<00:00,  5.27it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 3:  97%|████████████████████████████████████████████████▌ | 101/104 [00:19<00:00,  5.27it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 3:  98%|█████████████████████████████████████████████████ | 102/104 [00:19<00:00,  5.24it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 3:  98%|█████████████████████████████████████████████████ | 102/104 [00:19<00:00,  5.24it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  99%|█████████████████████████████████████████████████▌| 103/104 [00:19<00:00,  5.24it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  5.24it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 3: 100%|██████████████████████████████████████████████████| 104/104 [00:20<00:00,  5.67it/s, training_loss=0.169]\u001b[A\n",
      "Epoch Progress:   8%|█████                                                              | 3/40 [01:00<12:28, 20.22s/it]\u001b[A\n",
      "Epoch 4:   0%|                                                                                 | 0/104 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:   0%|                                                            | 0/104 [00:00<?, ?it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 4:   1%|▌                                                   | 1/104 [00:00<00:20,  5.09it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 4:   1%|▌                                                   | 1/104 [00:00<00:20,  5.09it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:   2%|█                                                   | 2/104 [00:00<00:20,  5.03it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:   2%|█                                                   | 2/104 [00:00<00:20,  5.03it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 4:   3%|█▌                                                  | 3/104 [00:00<00:20,  5.02it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 4:   3%|█▌                                                  | 3/104 [00:00<00:20,  5.02it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 4:   4%|██                                                  | 4/104 [00:00<00:19,  5.02it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 4:   4%|██                                                  | 4/104 [00:00<00:19,  5.02it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:   5%|██▌                                                 | 5/104 [00:00<00:19,  5.03it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:   5%|██▌                                                 | 5/104 [00:01<00:19,  5.03it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:   6%|███                                                 | 6/104 [00:01<00:19,  5.06it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:   6%|███                                                 | 6/104 [00:01<00:19,  5.06it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:   7%|███▌                                                | 7/104 [00:01<00:19,  5.08it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:   7%|███▌                                                | 7/104 [00:01<00:19,  5.08it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:   8%|████                                                | 8/104 [00:01<00:18,  5.09it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:   8%|████                                                | 8/104 [00:01<00:18,  5.09it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:   9%|████▌                                               | 9/104 [00:01<00:18,  5.12it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:   9%|████▌                                               | 9/104 [00:01<00:18,  5.12it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  10%|████▉                                              | 10/104 [00:01<00:18,  5.12it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  10%|████▉                                              | 10/104 [00:02<00:18,  5.12it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 4:  11%|█████▍                                             | 11/104 [00:02<00:18,  5.11it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 4:  11%|█████▍                                             | 11/104 [00:02<00:18,  5.11it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 4:  12%|█████▉                                             | 12/104 [00:02<00:17,  5.12it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 4:  12%|█████▉                                             | 12/104 [00:02<00:17,  5.12it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 4:  12%|██████▍                                            | 13/104 [00:02<00:17,  5.12it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 4:  12%|██████▍                                            | 13/104 [00:02<00:17,  5.12it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 4:  13%|██████▊                                            | 14/104 [00:02<00:17,  5.11it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 4:  13%|██████▊                                            | 14/104 [00:02<00:17,  5.11it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  14%|███████▎                                           | 15/104 [00:02<00:17,  5.12it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  14%|███████▎                                           | 15/104 [00:03<00:17,  5.12it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 4:  15%|███████▊                                           | 16/104 [00:03<00:17,  5.13it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 4:  15%|███████▊                                           | 16/104 [00:03<00:17,  5.13it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  16%|████████▎                                          | 17/104 [00:03<00:16,  5.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  16%|████████▎                                          | 17/104 [00:03<00:16,  5.14it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 4:  17%|████████▊                                          | 18/104 [00:03<00:16,  5.16it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 4:  17%|████████▊                                          | 18/104 [00:03<00:16,  5.16it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  18%|█████████▎                                         | 19/104 [00:03<00:16,  5.15it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  18%|█████████▎                                         | 19/104 [00:03<00:16,  5.15it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  19%|█████████▊                                         | 20/104 [00:03<00:16,  5.16it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  19%|█████████▊                                         | 20/104 [00:04<00:16,  5.16it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  20%|██████████▎                                        | 21/104 [00:04<00:16,  5.17it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  20%|██████████▎                                        | 21/104 [00:04<00:16,  5.17it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 4:  21%|██████████▊                                        | 22/104 [00:04<00:15,  5.18it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 4:  21%|██████████▊                                        | 22/104 [00:04<00:15,  5.18it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 4:  22%|███████████▎                                       | 23/104 [00:04<00:15,  5.19it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 4:  22%|███████████▎                                       | 23/104 [00:04<00:15,  5.19it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 4:  23%|███████████▊                                       | 24/104 [00:04<00:15,  5.19it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 4:  23%|███████████▊                                       | 24/104 [00:04<00:15,  5.19it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  24%|████████████▎                                      | 25/104 [00:04<00:15,  5.21it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  24%|████████████▎                                      | 25/104 [00:05<00:15,  5.21it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 4:  25%|████████████▊                                      | 26/104 [00:05<00:14,  5.20it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 4:  25%|████████████▊                                      | 26/104 [00:05<00:14,  5.20it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 4:  26%|█████████████▏                                     | 27/104 [00:05<00:14,  5.22it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 4:  26%|█████████████▏                                     | 27/104 [00:05<00:14,  5.22it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  27%|█████████████▋                                     | 28/104 [00:05<00:14,  5.22it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  27%|█████████████▋                                     | 28/104 [00:05<00:14,  5.22it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  28%|██████████████▏                                    | 29/104 [00:05<00:14,  5.23it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  28%|██████████████▏                                    | 29/104 [00:05<00:14,  5.23it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  29%|██████████████▋                                    | 30/104 [00:05<00:14,  5.23it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  29%|██████████████▋                                    | 30/104 [00:06<00:14,  5.23it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  5.18it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  5.18it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 4:  31%|███████████████▋                                   | 32/104 [00:06<00:13,  5.19it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 4:  31%|███████████████▋                                   | 32/104 [00:06<00:13,  5.19it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  32%|████████████████▏                                  | 33/104 [00:06<00:13,  5.20it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  32%|████████████████▏                                  | 33/104 [00:06<00:13,  5.20it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  33%|████████████████▋                                  | 34/104 [00:06<00:13,  5.21it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  33%|████████████████▋                                  | 34/104 [00:06<00:13,  5.21it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 4:  34%|█████████████████▏                                 | 35/104 [00:06<00:13,  5.19it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 4:  34%|█████████████████▏                                 | 35/104 [00:06<00:13,  5.19it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  35%|█████████████████▋                                 | 36/104 [00:06<00:13,  5.21it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  35%|█████████████████▋                                 | 36/104 [00:07<00:13,  5.21it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 4:  36%|██████████████████▏                                | 37/104 [00:07<00:12,  5.21it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 4:  36%|██████████████████▏                                | 37/104 [00:07<00:12,  5.21it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 4:  37%|██████████████████▋                                | 38/104 [00:07<00:12,  5.22it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 4:  37%|██████████████████▋                                | 38/104 [00:07<00:12,  5.22it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  38%|███████████████████▏                               | 39/104 [00:07<00:12,  5.21it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  38%|███████████████████▏                               | 39/104 [00:07<00:12,  5.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  38%|███████████████████▌                               | 40/104 [00:07<00:12,  5.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  38%|███████████████████▌                               | 40/104 [00:07<00:12,  5.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  39%|████████████████████                               | 41/104 [00:07<00:12,  5.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  39%|████████████████████                               | 41/104 [00:08<00:12,  5.22it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 4:  40%|████████████████████▌                              | 42/104 [00:08<00:11,  5.23it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 4:  40%|████████████████████▌                              | 42/104 [00:08<00:11,  5.23it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 4:  41%|█████████████████████                              | 43/104 [00:08<00:11,  5.25it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 4:  41%|█████████████████████                              | 43/104 [00:08<00:11,  5.25it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 4:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.24it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 4:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  43%|██████████████████████                             | 45/104 [00:08<00:11,  5.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  43%|██████████████████████                             | 45/104 [00:08<00:11,  5.26it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 4:  44%|██████████████████████▌                            | 46/104 [00:08<00:11,  5.25it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 4:  44%|██████████████████████▌                            | 46/104 [00:09<00:11,  5.25it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 4:  45%|███████████████████████                            | 47/104 [00:09<00:10,  5.26it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 4:  45%|███████████████████████                            | 47/104 [00:09<00:10,  5.26it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  46%|███████████████████████▌                           | 48/104 [00:09<00:10,  5.26it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  46%|███████████████████████▌                           | 48/104 [00:09<00:10,  5.26it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 4:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.27it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 4:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.27it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  48%|████████████████████████▌                          | 50/104 [00:09<00:10,  5.26it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  48%|████████████████████████▌                          | 50/104 [00:09<00:10,  5.26it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 4:  49%|█████████████████████████                          | 51/104 [00:09<00:10,  5.27it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 4:  49%|█████████████████████████                          | 51/104 [00:10<00:10,  5.27it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  50%|█████████████████████████▌                         | 52/104 [00:10<00:09,  5.28it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  50%|█████████████████████████▌                         | 52/104 [00:10<00:09,  5.28it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  51%|█████████████████████████▉                         | 53/104 [00:10<00:09,  5.24it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  51%|█████████████████████████▉                         | 53/104 [00:10<00:09,  5.24it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 4:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.24it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 4:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.24it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  53%|██████████████████████████▉                        | 55/104 [00:10<00:09,  5.24it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  53%|██████████████████████████▉                        | 55/104 [00:10<00:09,  5.24it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 4:  54%|███████████████████████████▍                       | 56/104 [00:10<00:09,  5.25it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 4:  54%|███████████████████████████▍                       | 56/104 [00:10<00:09,  5.25it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  55%|███████████████████████████▉                       | 57/104 [00:10<00:08,  5.23it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  55%|███████████████████████████▉                       | 57/104 [00:11<00:08,  5.23it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.25it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 4:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.26it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 4:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.26it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  58%|█████████████████████████████▍                     | 60/104 [00:11<00:08,  5.25it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  58%|█████████████████████████████▍                     | 60/104 [00:11<00:08,  5.25it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 4:  59%|█████████████████████████████▉                     | 61/104 [00:11<00:08,  5.24it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 4:  59%|█████████████████████████████▉                     | 61/104 [00:11<00:08,  5.24it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  60%|██████████████████████████████▍                    | 62/104 [00:11<00:08,  5.25it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:08,  5.25it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 4:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:07,  5.25it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 4:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:07,  5.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:07,  5.24it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:07,  5.24it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  62%|███████████████████████████████▉                   | 65/104 [00:12<00:07,  5.24it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  62%|███████████████████████████████▉                   | 65/104 [00:12<00:07,  5.24it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  63%|████████████████████████████████▎                  | 66/104 [00:12<00:07,  5.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  63%|████████████████████████████████▎                  | 66/104 [00:12<00:07,  5.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  64%|████████████████████████████████▊                  | 67/104 [00:12<00:07,  5.25it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:07,  5.25it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 4:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:06,  5.26it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 4:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:06,  5.26it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 4:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:06,  5.24it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 4:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:06,  5.24it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 4:  67%|██████████████████████████████████▎                | 70/104 [00:13<00:06,  5.24it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 4:  67%|██████████████████████████████████▎                | 70/104 [00:13<00:06,  5.24it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 4:  68%|██████████████████████████████████▊                | 71/104 [00:13<00:06,  5.23it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 4:  68%|██████████████████████████████████▊                | 71/104 [00:13<00:06,  5.23it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 4:  69%|███████████████████████████████████▎               | 72/104 [00:13<00:06,  5.23it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 4:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  5.23it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 4:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:05,  5.22it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 4:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:05,  5.22it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 4:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.21it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 4:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.21it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 4:  72%|████████████████████████████████████▊              | 75/104 [00:14<00:05,  5.19it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 4:  72%|████████████████████████████████████▊              | 75/104 [00:14<00:05,  5.19it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  73%|█████████████████████████████████████▎             | 76/104 [00:14<00:05,  5.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  73%|█████████████████████████████████████▎             | 76/104 [00:14<00:05,  5.17it/s, training_loss=0.253]\u001b[A\n",
      "Epoch 4:  74%|█████████████████████████████████████▊             | 77/104 [00:14<00:05,  5.18it/s, training_loss=0.253]\u001b[A\n",
      "Epoch 4:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  5.18it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 4:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:05,  5.17it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 4:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:05,  5.17it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 4:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.19it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 4:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.19it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  77%|███████████████████████████████████████▏           | 80/104 [00:15<00:04,  5.21it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  77%|███████████████████████████████████████▏           | 80/104 [00:15<00:04,  5.21it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 4:  78%|███████████████████████████████████████▋           | 81/104 [00:15<00:04,  5.16it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 4:  78%|███████████████████████████████████████▋           | 81/104 [00:15<00:04,  5.16it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 4:  79%|████████████████████████████████████████▏          | 82/104 [00:15<00:04,  5.17it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 4:  79%|████████████████████████████████████████▏          | 82/104 [00:15<00:04,  5.17it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 4:  80%|████████████████████████████████████████▋          | 83/104 [00:15<00:04,  5.16it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 4:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.16it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 4:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.16it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 4:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.16it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  82%|█████████████████████████████████████████▋         | 85/104 [00:16<00:03,  5.15it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  82%|█████████████████████████████████████████▋         | 85/104 [00:16<00:03,  5.15it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 4:  83%|██████████████████████████████████████████▏        | 86/104 [00:16<00:03,  5.15it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 4:  83%|██████████████████████████████████████████▏        | 86/104 [00:16<00:03,  5.15it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 4:  84%|██████████████████████████████████████████▋        | 87/104 [00:16<00:03,  5.15it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 4:  84%|██████████████████████████████████████████▋        | 87/104 [00:16<00:03,  5.15it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 4:  85%|███████████████████████████████████████████▏       | 88/104 [00:16<00:03,  5.10it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 4:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.10it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.11it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.11it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  87%|████████████████████████████████████████████▏      | 90/104 [00:17<00:02,  5.11it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  87%|████████████████████████████████████████████▏      | 90/104 [00:17<00:02,  5.11it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 4:  88%|████████████████████████████████████████████▋      | 91/104 [00:17<00:02,  5.10it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 4:  88%|████████████████████████████████████████████▋      | 91/104 [00:17<00:02,  5.10it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 4:  88%|█████████████████████████████████████████████      | 92/104 [00:17<00:02,  5.12it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 4:  88%|█████████████████████████████████████████████      | 92/104 [00:17<00:02,  5.12it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 4:  89%|█████████████████████████████████████████████▌     | 93/104 [00:17<00:02,  5.12it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 4:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  5.12it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 4:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:01,  5.14it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 4:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:01,  5.14it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  91%|██████████████████████████████████████████████▌    | 95/104 [00:18<00:01,  5.15it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  91%|██████████████████████████████████████████████▌    | 95/104 [00:18<00:01,  5.15it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 4:  92%|███████████████████████████████████████████████    | 96/104 [00:18<00:01,  5.13it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 4:  92%|███████████████████████████████████████████████    | 96/104 [00:18<00:01,  5.13it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 4:  93%|███████████████████████████████████████████████▌   | 97/104 [00:18<00:01,  5.14it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 4:  93%|███████████████████████████████████████████████▌   | 97/104 [00:18<00:01,  5.14it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  94%|████████████████████████████████████████████████   | 98/104 [00:18<00:01,  5.15it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  5.15it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:00,  5.10it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:00,  5.10it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  96%|████████████████████████████████████████████████  | 100/104 [00:19<00:00,  5.08it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  96%|████████████████████████████████████████████████  | 100/104 [00:19<00:00,  5.08it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 4:  97%|████████████████████████████████████████████████▌ | 101/104 [00:19<00:00,  5.08it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 4:  97%|████████████████████████████████████████████████▌ | 101/104 [00:19<00:00,  5.08it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 4:  98%|█████████████████████████████████████████████████ | 102/104 [00:19<00:00,  5.10it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 4:  98%|█████████████████████████████████████████████████ | 102/104 [00:19<00:00,  5.10it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  99%|█████████████████████████████████████████████████▌| 103/104 [00:19<00:00,  5.11it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  5.11it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 4: 100%|██████████████████████████████████████████████████| 104/104 [00:20<00:00,  5.56it/s, training_loss=0.015]\u001b[A\n",
      "Epoch Progress:  10%|██████▋                                                            | 4/40 [01:20<12:05, 20.15s/it]\u001b[A\n",
      "Epoch 5:   0%|                                                                                 | 0/104 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:   0%|                                                            | 0/104 [00:00<?, ?it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5:   1%|▌                                                   | 1/104 [00:00<00:20,  5.06it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5:   1%|▌                                                   | 1/104 [00:00<00:20,  5.06it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   2%|█                                                   | 2/104 [00:00<00:20,  5.02it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   2%|█                                                   | 2/104 [00:00<00:20,  5.02it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 5:   3%|█▌                                                  | 3/104 [00:00<00:20,  5.02it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 5:   3%|█▌                                                  | 3/104 [00:00<00:20,  5.02it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   4%|██                                                  | 4/104 [00:00<00:19,  5.02it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   4%|██                                                  | 4/104 [00:00<00:19,  5.02it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 5:   5%|██▌                                                 | 5/104 [00:00<00:19,  5.01it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 5:   5%|██▌                                                 | 5/104 [00:01<00:19,  5.01it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 5:   6%|███                                                 | 6/104 [00:01<00:19,  5.02it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 5:   6%|███                                                 | 6/104 [00:01<00:19,  5.02it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   7%|███▌                                                | 7/104 [00:01<00:19,  4.93it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   7%|███▌                                                | 7/104 [00:01<00:19,  4.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:   8%|████                                                | 8/104 [00:01<00:19,  4.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:   8%|████                                                | 8/104 [00:01<00:19,  4.96it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 5:   9%|████▌                                               | 9/104 [00:01<00:19,  4.93it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 5:   9%|████▌                                               | 9/104 [00:02<00:19,  4.93it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  10%|████▉                                              | 10/104 [00:02<00:19,  4.92it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  10%|████▉                                              | 10/104 [00:02<00:19,  4.92it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 5:  11%|█████▍                                             | 11/104 [00:02<00:18,  4.94it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 5:  11%|█████▍                                             | 11/104 [00:02<00:18,  4.94it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 5:  12%|█████▉                                             | 12/104 [00:02<00:18,  4.92it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 5:  12%|█████▉                                             | 12/104 [00:02<00:18,  4.92it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 5:  12%|██████▍                                            | 13/104 [00:02<00:18,  4.92it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 5:  12%|██████▍                                            | 13/104 [00:02<00:18,  4.92it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  13%|██████▊                                            | 14/104 [00:02<00:18,  4.95it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  13%|██████▊                                            | 14/104 [00:03<00:18,  4.95it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  14%|███████▎                                           | 15/104 [00:03<00:17,  4.97it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  14%|███████▎                                           | 15/104 [00:03<00:17,  4.97it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  15%|███████▊                                           | 16/104 [00:03<00:17,  4.99it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  15%|███████▊                                           | 16/104 [00:03<00:17,  4.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  16%|████████▎                                          | 17/104 [00:03<00:17,  5.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  16%|████████▎                                          | 17/104 [00:03<00:17,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  17%|████████▊                                          | 18/104 [00:03<00:17,  5.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  17%|████████▊                                          | 18/104 [00:03<00:17,  5.04it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5:  18%|█████████▎                                         | 19/104 [00:03<00:16,  5.07it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5:  18%|█████████▎                                         | 19/104 [00:04<00:16,  5.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  19%|█████████▊                                         | 20/104 [00:04<00:16,  5.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  19%|█████████▊                                         | 20/104 [00:04<00:16,  5.08it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  20%|██████████▎                                        | 21/104 [00:04<00:16,  5.11it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  20%|██████████▎                                        | 21/104 [00:04<00:16,  5.11it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 5:  21%|██████████▊                                        | 22/104 [00:04<00:15,  5.14it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 5:  21%|██████████▊                                        | 22/104 [00:04<00:15,  5.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  22%|███████████▎                                       | 23/104 [00:04<00:15,  5.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  22%|███████████▎                                       | 23/104 [00:04<00:15,  5.12it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 5:  23%|███████████▊                                       | 24/104 [00:04<00:15,  5.06it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 5:  23%|███████████▊                                       | 24/104 [00:04<00:15,  5.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  24%|████████████▎                                      | 25/104 [00:04<00:15,  5.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  24%|████████████▎                                      | 25/104 [00:05<00:15,  5.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  25%|████████████▊                                      | 26/104 [00:05<00:15,  5.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  25%|████████████▊                                      | 26/104 [00:05<00:15,  5.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  26%|█████████████▏                                     | 27/104 [00:05<00:15,  4.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  26%|█████████████▏                                     | 27/104 [00:05<00:15,  4.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  27%|█████████████▋                                     | 28/104 [00:05<00:15,  4.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  27%|█████████████▋                                     | 28/104 [00:05<00:15,  4.98it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 5:  28%|██████████████▏                                    | 29/104 [00:05<00:14,  5.01it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 5:  28%|██████████████▏                                    | 29/104 [00:05<00:14,  5.01it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 5:  29%|██████████████▋                                    | 30/104 [00:05<00:14,  5.00it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 5:  29%|██████████████▋                                    | 30/104 [00:06<00:14,  5.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  4.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  4.99it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  31%|███████████████▋                                   | 32/104 [00:06<00:14,  5.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  31%|███████████████▋                                   | 32/104 [00:06<00:14,  5.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  32%|████████████████▏                                  | 33/104 [00:06<00:14,  5.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  32%|████████████████▏                                  | 33/104 [00:06<00:14,  5.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  33%|████████████████▋                                  | 34/104 [00:06<00:13,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  33%|████████████████▋                                  | 34/104 [00:06<00:13,  5.02it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  34%|█████████████████▏                                 | 35/104 [00:06<00:13,  5.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  34%|█████████████████▏                                 | 35/104 [00:07<00:13,  5.03it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 5:  35%|█████████████████▋                                 | 36/104 [00:07<00:13,  4.99it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 5:  35%|█████████████████▋                                 | 36/104 [00:07<00:13,  4.99it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 5:  36%|██████████████████▏                                | 37/104 [00:07<00:13,  5.00it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 5:  36%|██████████████████▏                                | 37/104 [00:07<00:13,  5.00it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 5:  37%|██████████████████▋                                | 38/104 [00:07<00:13,  5.00it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 5:  37%|██████████████████▋                                | 38/104 [00:07<00:13,  5.00it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 5:  38%|███████████████████▏                               | 39/104 [00:07<00:13,  5.00it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 5:  38%|███████████████████▏                               | 39/104 [00:07<00:13,  5.00it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 5:  38%|███████████████████▌                               | 40/104 [00:07<00:12,  5.02it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 5:  38%|███████████████████▌                               | 40/104 [00:08<00:12,  5.02it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 5:  39%|████████████████████                               | 41/104 [00:08<00:12,  5.03it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 5:  39%|████████████████████                               | 41/104 [00:08<00:12,  5.03it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 5:  40%|████████████████████▌                              | 42/104 [00:08<00:12,  5.04it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 5:  40%|████████████████████▌                              | 42/104 [00:08<00:12,  5.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  41%|█████████████████████                              | 43/104 [00:08<00:12,  5.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  41%|█████████████████████                              | 43/104 [00:08<00:12,  5.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.06it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 5:  43%|██████████████████████                             | 45/104 [00:08<00:11,  5.07it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 5:  43%|██████████████████████                             | 45/104 [00:09<00:11,  5.07it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 5:  44%|██████████████████████▌                            | 46/104 [00:09<00:11,  5.10it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 5:  44%|██████████████████████▌                            | 46/104 [00:09<00:11,  5.10it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  45%|███████████████████████                            | 47/104 [00:09<00:11,  5.12it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  45%|███████████████████████                            | 47/104 [00:09<00:11,  5.12it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 5:  46%|███████████████████████▌                           | 48/104 [00:09<00:10,  5.13it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 5:  46%|███████████████████████▌                           | 48/104 [00:09<00:10,  5.13it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 5:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.09it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 5:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.09it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 5:  48%|████████████████████████▌                          | 50/104 [00:09<00:10,  5.11it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 5:  48%|████████████████████████▌                          | 50/104 [00:10<00:10,  5.11it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 5:  49%|█████████████████████████                          | 51/104 [00:10<00:10,  5.10it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 5:  49%|█████████████████████████                          | 51/104 [00:10<00:10,  5.10it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 5:  50%|█████████████████████████▌                         | 52/104 [00:10<00:10,  5.10it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 5:  50%|█████████████████████████▌                         | 52/104 [00:10<00:10,  5.10it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:  51%|█████████████████████████▉                         | 53/104 [00:10<00:09,  5.10it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:  51%|█████████████████████████▉                         | 53/104 [00:10<00:09,  5.10it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 5:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.11it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 5:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.11it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 5:  53%|██████████████████████████▉                        | 55/104 [00:10<00:09,  5.12it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 5:  53%|██████████████████████████▉                        | 55/104 [00:11<00:09,  5.12it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  54%|███████████████████████████▍                       | 56/104 [00:11<00:09,  5.12it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  54%|███████████████████████████▍                       | 56/104 [00:11<00:09,  5.12it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:  55%|███████████████████████████▉                       | 57/104 [00:11<00:09,  5.13it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:  55%|███████████████████████████▉                       | 57/104 [00:11<00:09,  5.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.13it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  58%|█████████████████████████████▍                     | 60/104 [00:11<00:08,  5.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  58%|█████████████████████████████▍                     | 60/104 [00:12<00:08,  5.08it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  59%|█████████████████████████████▉                     | 61/104 [00:12<00:08,  5.08it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  59%|█████████████████████████████▉                     | 61/104 [00:12<00:08,  5.08it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:08,  5.08it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:08,  5.08it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 5:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:08,  5.08it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 5:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:08,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 5:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:08,  4.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 5:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:08,  4.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 5:  62%|███████████████████████████████▉                   | 65/104 [00:12<00:07,  4.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 5:  62%|███████████████████████████████▉                   | 65/104 [00:13<00:07,  4.98it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  63%|████████████████████████████████▎                  | 66/104 [00:13<00:07,  4.91it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  63%|████████████████████████████████▎                  | 66/104 [00:13<00:07,  4.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:07,  4.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:07,  4.90it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 5:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:07,  4.83it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 5:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:07,  4.83it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:07,  4.83it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:07,  4.83it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  67%|██████████████████████████████████▎                | 70/104 [00:13<00:07,  4.83it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  67%|██████████████████████████████████▎                | 70/104 [00:14<00:07,  4.83it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 5:  68%|██████████████████████████████████▊                | 71/104 [00:14<00:06,  4.80it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 5:  68%|██████████████████████████████████▊                | 71/104 [00:14<00:06,  4.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  4.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  4.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:06,  4.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:06,  4.80it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 5:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:06,  4.78it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 5:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:06,  4.78it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:  72%|████████████████████████████████████▊              | 75/104 [00:14<00:06,  4.82it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:  72%|████████████████████████████████████▊              | 75/104 [00:15<00:06,  4.82it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 5:  73%|█████████████████████████████████████▎             | 76/104 [00:15<00:05,  4.86it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 5:  73%|█████████████████████████████████████▎             | 76/104 [00:15<00:05,  4.86it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 5:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  4.87it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 5:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  4.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:05,  4.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:05,  4.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:05,  4.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  76%|██████████████████████████████████████▋            | 79/104 [00:16<00:05,  4.88it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 5:  77%|███████████████████████████████████████▏           | 80/104 [00:16<00:04,  4.88it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 5:  77%|███████████████████████████████████████▏           | 80/104 [00:16<00:04,  4.88it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 5:  78%|███████████████████████████████████████▋           | 81/104 [00:16<00:04,  4.90it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 5:  78%|███████████████████████████████████████▋           | 81/104 [00:16<00:04,  4.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  4.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  4.90it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  4.86it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  4.86it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:04,  4.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  81%|█████████████████████████████████████████▏         | 84/104 [00:17<00:04,  4.89it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 5:  82%|█████████████████████████████████████████▋         | 85/104 [00:17<00:03,  4.88it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 5:  82%|█████████████████████████████████████████▋         | 85/104 [00:17<00:03,  4.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  83%|██████████████████████████████████████████▏        | 86/104 [00:17<00:03,  4.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  83%|██████████████████████████████████████████▏        | 86/104 [00:17<00:03,  4.88it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 5:  84%|██████████████████████████████████████████▋        | 87/104 [00:17<00:03,  4.84it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 5:  84%|██████████████████████████████████████████▋        | 87/104 [00:17<00:03,  4.84it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 5:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  4.83it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 5:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  4.83it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:03,  4.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  86%|███████████████████████████████████████████▋       | 89/104 [00:18<00:03,  4.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  87%|████████████████████████████████████████████▏      | 90/104 [00:18<00:02,  4.74it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  87%|████████████████████████████████████████████▏      | 90/104 [00:18<00:02,  4.74it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 5:  88%|████████████████████████████████████████████▋      | 91/104 [00:18<00:02,  4.72it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 5:  88%|████████████████████████████████████████████▋      | 91/104 [00:18<00:02,  4.72it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 5:  88%|█████████████████████████████████████████████      | 92/104 [00:18<00:02,  4.72it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 5:  88%|█████████████████████████████████████████████      | 92/104 [00:18<00:02,  4.72it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 5:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  4.75it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 5:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  4.75it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:02,  4.69it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  90%|██████████████████████████████████████████████     | 94/104 [00:19<00:02,  4.69it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  91%|██████████████████████████████████████████████▌    | 95/104 [00:19<00:01,  4.64it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  91%|██████████████████████████████████████████████▌    | 95/104 [00:19<00:01,  4.64it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  92%|███████████████████████████████████████████████    | 96/104 [00:19<00:01,  4.62it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  92%|███████████████████████████████████████████████    | 96/104 [00:19<00:01,  4.62it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  93%|███████████████████████████████████████████████▌   | 97/104 [00:19<00:01,  4.61it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  93%|███████████████████████████████████████████████▌   | 97/104 [00:19<00:01,  4.61it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  4.67it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  94%|████████████████████████████████████████████████   | 98/104 [00:20<00:01,  4.67it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  95%|████████████████████████████████████████████████▌  | 99/104 [00:20<00:01,  4.69it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  95%|████████████████████████████████████████████████▌  | 99/104 [00:20<00:01,  4.69it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:  96%|████████████████████████████████████████████████  | 100/104 [00:20<00:00,  4.70it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:  96%|████████████████████████████████████████████████  | 100/104 [00:20<00:00,  4.70it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 5:  97%|████████████████████████████████████████████████▌ | 101/104 [00:20<00:00,  4.73it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 5:  97%|████████████████████████████████████████████████▌ | 101/104 [00:20<00:00,  4.73it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 5:  98%|█████████████████████████████████████████████████ | 102/104 [00:20<00:00,  4.76it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 5:  98%|█████████████████████████████████████████████████ | 102/104 [00:20<00:00,  4.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  4.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  99%|█████████████████████████████████████████████████▌| 103/104 [00:21<00:00,  4.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5: 100%|██████████████████████████████████████████████████| 104/104 [00:21<00:00,  5.18it/s, training_loss=0.001]\u001b[A\n",
      "Epoch Progress:  12%|████████▍                                                          | 5/40 [01:41<11:56, 20.46s/it]\u001b[A\n",
      "Epoch 6:   0%|                                                                                 | 0/104 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:   0%|                                                            | 0/104 [00:00<?, ?it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:   1%|▌                                                   | 1/104 [00:00<00:21,  4.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:   1%|▌                                                   | 1/104 [00:00<00:21,  4.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:   2%|█                                                   | 2/104 [00:00<00:21,  4.70it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:   2%|█                                                   | 2/104 [00:00<00:21,  4.70it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 6:   3%|█▌                                                  | 3/104 [00:00<00:21,  4.65it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 6:   3%|█▌                                                  | 3/104 [00:00<00:21,  4.65it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   4%|██                                                  | 4/104 [00:00<00:21,  4.66it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   4%|██                                                  | 4/104 [00:01<00:21,  4.66it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   5%|██▌                                                 | 5/104 [00:01<00:21,  4.63it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   5%|██▌                                                 | 5/104 [00:01<00:21,  4.63it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   6%|███                                                 | 6/104 [00:01<00:21,  4.62it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   6%|███                                                 | 6/104 [00:01<00:21,  4.62it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   7%|███▌                                                | 7/104 [00:01<00:21,  4.62it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   7%|███▌                                                | 7/104 [00:01<00:21,  4.62it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:   8%|████                                                | 8/104 [00:01<00:20,  4.65it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:   8%|████                                                | 8/104 [00:01<00:20,  4.65it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:   9%|████▌                                               | 9/104 [00:01<00:20,  4.67it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:   9%|████▌                                               | 9/104 [00:02<00:20,  4.67it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  10%|████▉                                              | 10/104 [00:02<00:20,  4.66it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  10%|████▉                                              | 10/104 [00:02<00:20,  4.66it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  11%|█████▍                                             | 11/104 [00:02<00:19,  4.67it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  11%|█████▍                                             | 11/104 [00:02<00:19,  4.67it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 6:  12%|█████▉                                             | 12/104 [00:02<00:19,  4.69it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 6:  12%|█████▉                                             | 12/104 [00:02<00:19,  4.69it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  12%|██████▍                                            | 13/104 [00:02<00:19,  4.74it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  12%|██████▍                                            | 13/104 [00:02<00:19,  4.74it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 6:  13%|██████▊                                            | 14/104 [00:02<00:18,  4.79it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 6:  13%|██████▊                                            | 14/104 [00:03<00:18,  4.79it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  14%|███████▎                                           | 15/104 [00:03<00:18,  4.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  14%|███████▎                                           | 15/104 [00:03<00:18,  4.86it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  15%|███████▊                                           | 16/104 [00:03<00:17,  4.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  15%|███████▊                                           | 16/104 [00:03<00:17,  4.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  16%|████████▎                                          | 17/104 [00:03<00:17,  4.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  16%|████████▎                                          | 17/104 [00:03<00:17,  4.94it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 6:  17%|████████▊                                          | 18/104 [00:03<00:17,  4.96it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 6:  17%|████████▊                                          | 18/104 [00:03<00:17,  4.96it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 6:  18%|█████████▎                                         | 19/104 [00:03<00:17,  4.95it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 6:  18%|█████████▎                                         | 19/104 [00:04<00:17,  4.95it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 6:  19%|█████████▊                                         | 20/104 [00:04<00:16,  4.96it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 6:  19%|█████████▊                                         | 20/104 [00:04<00:16,  4.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  20%|██████████▎                                        | 21/104 [00:04<00:16,  4.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  20%|██████████▎                                        | 21/104 [00:04<00:16,  4.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  21%|██████████▊                                        | 22/104 [00:04<00:16,  4.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  21%|██████████▊                                        | 22/104 [00:04<00:16,  4.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  22%|███████████▎                                       | 23/104 [00:04<00:16,  5.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  22%|███████████▎                                       | 23/104 [00:04<00:16,  5.01it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 6:  23%|███████████▊                                       | 24/104 [00:04<00:15,  5.01it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 6:  23%|███████████▊                                       | 24/104 [00:05<00:15,  5.01it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 6:  24%|████████████▎                                      | 25/104 [00:05<00:15,  4.97it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 6:  24%|████████████▎                                      | 25/104 [00:05<00:15,  4.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  25%|████████████▊                                      | 26/104 [00:05<00:15,  4.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  25%|████████████▊                                      | 26/104 [00:05<00:15,  4.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  26%|█████████████▏                                     | 27/104 [00:05<00:15,  4.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  26%|█████████████▏                                     | 27/104 [00:05<00:15,  4.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  27%|█████████████▋                                     | 28/104 [00:05<00:15,  4.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  27%|█████████████▋                                     | 28/104 [00:05<00:15,  4.99it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 6:  28%|██████████████▏                                    | 29/104 [00:05<00:14,  5.01it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 6:  28%|██████████████▏                                    | 29/104 [00:06<00:14,  5.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  29%|██████████████▋                                    | 30/104 [00:06<00:14,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  29%|██████████████▋                                    | 30/104 [00:06<00:14,  5.02it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 6:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  5.03it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 6:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  5.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  31%|███████████████▋                                   | 32/104 [00:06<00:14,  5.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  31%|███████████████▋                                   | 32/104 [00:06<00:14,  5.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  32%|████████████████▏                                  | 33/104 [00:06<00:14,  5.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  32%|████████████████▏                                  | 33/104 [00:06<00:14,  5.06it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 6:  33%|████████████████▋                                  | 34/104 [00:06<00:13,  5.06it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 6:  33%|████████████████▋                                  | 34/104 [00:07<00:13,  5.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  34%|█████████████████▏                                 | 35/104 [00:07<00:13,  5.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  34%|█████████████████▏                                 | 35/104 [00:07<00:13,  5.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  35%|█████████████████▋                                 | 36/104 [00:07<00:13,  5.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  35%|█████████████████▋                                 | 36/104 [00:07<00:13,  5.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  36%|██████████████████▏                                | 37/104 [00:07<00:13,  5.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  36%|██████████████████▏                                | 37/104 [00:07<00:13,  5.05it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 6:  37%|██████████████████▋                                | 38/104 [00:07<00:13,  5.05it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 6:  37%|██████████████████▋                                | 38/104 [00:07<00:13,  5.05it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  38%|███████████████████▏                               | 39/104 [00:07<00:12,  5.04it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  38%|███████████████████▏                               | 39/104 [00:08<00:12,  5.04it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  38%|███████████████████▌                               | 40/104 [00:08<00:12,  5.04it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  38%|███████████████████▌                               | 40/104 [00:08<00:12,  5.04it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 6:  39%|████████████████████                               | 41/104 [00:08<00:12,  5.03it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 6:  39%|████████████████████                               | 41/104 [00:08<00:12,  5.03it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 6:  40%|████████████████████▌                              | 42/104 [00:08<00:12,  5.03it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 6:  40%|████████████████████▌                              | 42/104 [00:08<00:12,  5.03it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 6:  41%|█████████████████████                              | 43/104 [00:08<00:12,  5.05it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 6:  41%|█████████████████████                              | 43/104 [00:08<00:12,  5.05it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 6:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.07it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 6:  42%|█████████████████████▌                             | 44/104 [00:09<00:11,  5.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  43%|██████████████████████                             | 45/104 [00:09<00:11,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  43%|██████████████████████                             | 45/104 [00:09<00:11,  5.10it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 6:  44%|██████████████████████▌                            | 46/104 [00:09<00:11,  5.13it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 6:  44%|██████████████████████▌                            | 46/104 [00:09<00:11,  5.13it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 6:  45%|███████████████████████                            | 47/104 [00:09<00:11,  5.14it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 6:  45%|███████████████████████                            | 47/104 [00:09<00:11,  5.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  46%|███████████████████████▌                           | 48/104 [00:09<00:10,  5.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  46%|███████████████████████▌                           | 48/104 [00:09<00:10,  5.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  47%|████████████████████████                           | 49/104 [00:10<00:10,  5.16it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 6:  48%|████████████████████████▌                          | 50/104 [00:10<00:10,  5.16it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 6:  48%|████████████████████████▌                          | 50/104 [00:10<00:10,  5.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  49%|█████████████████████████                          | 51/104 [00:10<00:10,  5.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  49%|█████████████████████████                          | 51/104 [00:10<00:10,  5.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  50%|█████████████████████████▌                         | 52/104 [00:10<00:10,  5.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  50%|█████████████████████████▌                         | 52/104 [00:10<00:10,  5.16it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 6:  51%|█████████████████████████▉                         | 53/104 [00:10<00:09,  5.18it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 6:  51%|█████████████████████████▉                         | 53/104 [00:10<00:09,  5.18it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.18it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  52%|██████████████████████████▍                        | 54/104 [00:11<00:09,  5.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  53%|██████████████████████████▉                        | 55/104 [00:11<00:09,  5.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  53%|██████████████████████████▉                        | 55/104 [00:11<00:09,  5.18it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 6:  54%|███████████████████████████▍                       | 56/104 [00:11<00:09,  5.20it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 6:  54%|███████████████████████████▍                       | 56/104 [00:11<00:09,  5.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  55%|███████████████████████████▉                       | 57/104 [00:11<00:09,  5.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  55%|███████████████████████████▉                       | 57/104 [00:11<00:09,  5.21it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 6:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.21it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 6:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.21it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  57%|████████████████████████████▉                      | 59/104 [00:12<00:08,  5.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  58%|█████████████████████████████▍                     | 60/104 [00:12<00:08,  5.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  58%|█████████████████████████████▍                     | 60/104 [00:12<00:08,  5.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  59%|█████████████████████████████▉                     | 61/104 [00:12<00:08,  5.25it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  59%|█████████████████████████████▉                     | 61/104 [00:12<00:08,  5.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:08,  5.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:08,  5.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:07,  5.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:07,  5.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:07,  5.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:07,  5.26it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  62%|███████████████████████████████▉                   | 65/104 [00:12<00:07,  5.26it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  62%|███████████████████████████████▉                   | 65/104 [00:13<00:07,  5.26it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  63%|████████████████████████████████▎                  | 66/104 [00:13<00:07,  5.27it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  63%|████████████████████████████████▎                  | 66/104 [00:13<00:07,  5.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:07,  5.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:07,  5.24it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:06,  5.23it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:06,  5.23it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 6:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:06,  5.23it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 6:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:06,  5.23it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 6:  67%|██████████████████████████████████▎                | 70/104 [00:13<00:06,  5.22it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 6:  67%|██████████████████████████████████▎                | 70/104 [00:14<00:06,  5.22it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  68%|██████████████████████████████████▊                | 71/104 [00:14<00:06,  5.18it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  68%|██████████████████████████████████▊                | 71/104 [00:14<00:06,  5.18it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 6:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  5.17it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 6:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  5.17it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:06,  5.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:06,  5.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  72%|████████████████████████████████████▊              | 75/104 [00:14<00:05,  5.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  72%|████████████████████████████████████▊              | 75/104 [00:15<00:05,  5.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  73%|█████████████████████████████████████▎             | 76/104 [00:15<00:05,  5.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  73%|█████████████████████████████████████▎             | 76/104 [00:15<00:05,  5.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  5.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  5.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:05,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:05,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 6:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.07it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 6:  77%|███████████████████████████████████████▏           | 80/104 [00:15<00:04,  5.06it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 6:  77%|███████████████████████████████████████▏           | 80/104 [00:16<00:04,  5.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  78%|███████████████████████████████████████▋           | 81/104 [00:16<00:04,  5.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  78%|███████████████████████████████████████▋           | 81/104 [00:16<00:04,  5.05it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 6:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  5.05it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 6:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  5.05it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 6:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.06it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 6:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.06it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 6:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.06it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 6:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  82%|█████████████████████████████████████████▋         | 85/104 [00:16<00:03,  5.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  82%|█████████████████████████████████████████▋         | 85/104 [00:17<00:03,  5.08it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 6:  83%|██████████████████████████████████████████▏        | 86/104 [00:17<00:03,  5.09it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 6:  83%|██████████████████████████████████████████▏        | 86/104 [00:17<00:03,  5.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  84%|██████████████████████████████████████████▋        | 87/104 [00:17<00:03,  5.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  84%|██████████████████████████████████████████▋        | 87/104 [00:17<00:03,  5.08it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 6:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.10it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 6:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.10it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 6:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.03it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 6:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  87%|████████████████████████████████████████████▏      | 90/104 [00:17<00:02,  5.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  87%|████████████████████████████████████████████▏      | 90/104 [00:18<00:02,  5.04it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 6:  88%|████████████████████████████████████████████▋      | 91/104 [00:18<00:02,  5.02it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 6:  88%|████████████████████████████████████████████▋      | 91/104 [00:18<00:02,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  88%|█████████████████████████████████████████████      | 92/104 [00:18<00:02,  4.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  88%|█████████████████████████████████████████████      | 92/104 [00:18<00:02,  4.94it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  4.93it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  4.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:02,  4.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:02,  4.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  91%|██████████████████████████████████████████████▌    | 95/104 [00:18<00:01,  4.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  91%|██████████████████████████████████████████████▌    | 95/104 [00:19<00:01,  4.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  92%|███████████████████████████████████████████████    | 96/104 [00:19<00:01,  4.91it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  92%|███████████████████████████████████████████████    | 96/104 [00:19<00:01,  4.91it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 6:  93%|███████████████████████████████████████████████▌   | 97/104 [00:19<00:01,  4.92it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 6:  93%|███████████████████████████████████████████████▌   | 97/104 [00:19<00:01,  4.92it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 6:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  4.94it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 6:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  4.94it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:01,  4.97it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:01,  4.97it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  96%|████████████████████████████████████████████████  | 100/104 [00:19<00:00,  5.00it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  96%|████████████████████████████████████████████████  | 100/104 [00:20<00:00,  5.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  97%|████████████████████████████████████████████████▌ | 101/104 [00:20<00:00,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  97%|████████████████████████████████████████████████▌ | 101/104 [00:20<00:00,  5.02it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 6:  98%|█████████████████████████████████████████████████ | 102/104 [00:20<00:00,  5.00it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 6:  98%|█████████████████████████████████████████████████ | 102/104 [00:20<00:00,  5.00it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 6:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  5.01it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 6:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  5.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6: 100%|██████████████████████████████████████████████████| 104/104 [00:20<00:00,  5.45it/s, training_loss=0.001]\u001b[A\n",
      "Epoch Progress:  15%|██████████                                                         | 6/40 [02:02<11:37, 20.53s/it]\u001b[A\n",
      "Epoch 7:   0%|                                                                                 | 0/104 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:   0%|                                                            | 0/104 [00:00<?, ?it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:   1%|▌                                                   | 1/104 [00:00<00:20,  5.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:   1%|▌                                                   | 1/104 [00:00<00:20,  5.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:   2%|█                                                   | 2/104 [00:00<00:20,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:   2%|█                                                   | 2/104 [00:00<00:20,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:   3%|█▌                                                  | 3/104 [00:00<00:20,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:   3%|█▌                                                  | 3/104 [00:00<00:20,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:   4%|██                                                  | 4/104 [00:00<00:19,  5.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:   4%|██                                                  | 4/104 [00:00<00:19,  5.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:   5%|██▌                                                 | 5/104 [00:00<00:19,  5.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:   5%|██▌                                                 | 5/104 [00:01<00:19,  5.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:   6%|███                                                 | 6/104 [00:01<00:19,  5.04it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:   6%|███                                                 | 6/104 [00:01<00:19,  5.04it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 7:   7%|███▌                                                | 7/104 [00:01<00:19,  4.96it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 7:   7%|███▌                                                | 7/104 [00:01<00:19,  4.96it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 7:   8%|████                                                | 8/104 [00:01<00:19,  4.95it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 7:   8%|████                                                | 8/104 [00:01<00:19,  4.95it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:   9%|████▌                                               | 9/104 [00:01<00:19,  4.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:   9%|████▌                                               | 9/104 [00:02<00:19,  4.93it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  10%|████▉                                              | 10/104 [00:02<00:19,  4.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  10%|████▉                                              | 10/104 [00:02<00:19,  4.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  11%|█████▍                                             | 11/104 [00:02<00:18,  4.90it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  11%|█████▍                                             | 11/104 [00:02<00:18,  4.90it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  12%|█████▉                                             | 12/104 [00:02<00:18,  4.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  12%|█████▉                                             | 12/104 [00:02<00:18,  4.91it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 7:  12%|██████▍                                            | 13/104 [00:02<00:18,  4.94it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 7:  12%|██████▍                                            | 13/104 [00:02<00:18,  4.94it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 7:  13%|██████▊                                            | 14/104 [00:02<00:18,  4.96it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 7:  13%|██████▊                                            | 14/104 [00:03<00:18,  4.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  14%|███████▎                                           | 15/104 [00:03<00:17,  4.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  14%|███████▎                                           | 15/104 [00:03<00:17,  4.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  15%|███████▊                                           | 16/104 [00:03<00:17,  5.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  15%|███████▊                                           | 16/104 [00:03<00:17,  5.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  16%|████████▎                                          | 17/104 [00:03<00:17,  5.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  16%|████████▎                                          | 17/104 [00:03<00:17,  5.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  17%|████████▊                                          | 18/104 [00:03<00:17,  5.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  17%|████████▊                                          | 18/104 [00:03<00:17,  5.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  18%|█████████▎                                         | 19/104 [00:03<00:16,  5.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  18%|█████████▎                                         | 19/104 [00:04<00:16,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  19%|█████████▊                                         | 20/104 [00:04<00:16,  5.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  19%|█████████▊                                         | 20/104 [00:04<00:16,  5.06it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 7:  20%|██████████▎                                        | 21/104 [00:04<00:16,  5.00it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 7:  20%|██████████▎                                        | 21/104 [00:04<00:16,  5.00it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  21%|██████████▊                                        | 22/104 [00:04<00:16,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  21%|██████████▊                                        | 22/104 [00:04<00:16,  5.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  22%|███████████▎                                       | 23/104 [00:04<00:16,  5.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  22%|███████████▎                                       | 23/104 [00:04<00:16,  5.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  23%|███████████▊                                       | 24/104 [00:04<00:15,  5.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  23%|███████████▊                                       | 24/104 [00:05<00:15,  5.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  24%|████████████▎                                      | 25/104 [00:05<00:15,  5.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  24%|████████████▎                                      | 25/104 [00:05<00:15,  5.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  25%|████████████▊                                      | 26/104 [00:05<00:15,  5.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  25%|████████████▊                                      | 26/104 [00:05<00:15,  5.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  26%|█████████████▏                                     | 27/104 [00:05<00:15,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  26%|█████████████▏                                     | 27/104 [00:05<00:15,  5.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  27%|█████████████▋                                     | 28/104 [00:05<00:15,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  27%|█████████████▋                                     | 28/104 [00:05<00:15,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  28%|██████████████▏                                    | 29/104 [00:05<00:14,  5.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  28%|██████████████▏                                    | 29/104 [00:05<00:14,  5.05it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 7:  29%|██████████████▋                                    | 30/104 [00:05<00:14,  5.06it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 7:  29%|██████████████▋                                    | 30/104 [00:06<00:14,  5.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  5.07it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  5.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  31%|███████████████▋                                   | 32/104 [00:06<00:14,  5.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  31%|███████████████▋                                   | 32/104 [00:06<00:14,  5.09it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  32%|████████████████▏                                  | 33/104 [00:06<00:13,  5.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  32%|████████████████▏                                  | 33/104 [00:06<00:13,  5.10it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 7:  33%|████████████████▋                                  | 34/104 [00:06<00:13,  5.12it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 7:  33%|████████████████▋                                  | 34/104 [00:06<00:13,  5.12it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 7:  34%|█████████████████▏                                 | 35/104 [00:06<00:13,  5.05it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 7:  34%|█████████████████▏                                 | 35/104 [00:07<00:13,  5.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  35%|█████████████████▋                                 | 36/104 [00:07<00:13,  4.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  35%|█████████████████▋                                 | 36/104 [00:07<00:13,  4.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  36%|██████████████████▏                                | 37/104 [00:07<00:13,  4.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  36%|██████████████████▏                                | 37/104 [00:07<00:13,  4.98it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 7:  37%|██████████████████▋                                | 38/104 [00:07<00:13,  4.96it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 7:  37%|██████████████████▋                                | 38/104 [00:07<00:13,  4.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  38%|███████████████████▏                               | 39/104 [00:07<00:13,  4.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  38%|███████████████████▏                               | 39/104 [00:07<00:13,  4.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  38%|███████████████████▌                               | 40/104 [00:07<00:12,  4.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  38%|███████████████████▌                               | 40/104 [00:08<00:12,  4.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  39%|████████████████████                               | 41/104 [00:08<00:12,  4.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  39%|████████████████████                               | 41/104 [00:08<00:12,  4.99it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 7:  40%|████████████████████▌                              | 42/104 [00:08<00:12,  5.01it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 7:  40%|████████████████████▌                              | 42/104 [00:08<00:12,  5.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  41%|█████████████████████                              | 43/104 [00:08<00:12,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  41%|█████████████████████                              | 43/104 [00:08<00:12,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.06it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 7:  43%|██████████████████████                             | 45/104 [00:08<00:11,  5.09it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 7:  43%|██████████████████████                             | 45/104 [00:09<00:11,  5.09it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 7:  44%|██████████████████████▌                            | 46/104 [00:09<00:11,  5.02it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 7:  44%|██████████████████████▌                            | 46/104 [00:09<00:11,  5.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  45%|███████████████████████                            | 47/104 [00:09<00:11,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  45%|███████████████████████                            | 47/104 [00:09<00:11,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  46%|███████████████████████▌                           | 48/104 [00:09<00:11,  5.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  46%|███████████████████████▌                           | 48/104 [00:09<00:11,  5.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.01it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 7:  48%|████████████████████████▌                          | 50/104 [00:09<00:10,  5.03it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 7:  48%|████████████████████████▌                          | 50/104 [00:10<00:10,  5.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  49%|█████████████████████████                          | 51/104 [00:10<00:10,  5.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  49%|█████████████████████████                          | 51/104 [00:10<00:10,  5.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  50%|█████████████████████████▌                         | 52/104 [00:10<00:10,  5.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  50%|█████████████████████████▌                         | 52/104 [00:10<00:10,  5.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  51%|█████████████████████████▉                         | 53/104 [00:10<00:09,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  51%|█████████████████████████▉                         | 53/104 [00:10<00:09,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  53%|██████████████████████████▉                        | 55/104 [00:10<00:09,  5.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  53%|██████████████████████████▉                        | 55/104 [00:11<00:09,  5.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  54%|███████████████████████████▍                       | 56/104 [00:11<00:09,  5.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  54%|███████████████████████████▍                       | 56/104 [00:11<00:09,  5.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  55%|███████████████████████████▉                       | 57/104 [00:11<00:09,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  55%|███████████████████████████▉                       | 57/104 [00:11<00:09,  5.08it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 7:  56%|████████████████████████████▍                      | 58/104 [00:11<00:09,  5.07it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 7:  56%|████████████████████████████▍                      | 58/104 [00:11<00:09,  5.07it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 7:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.06it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 7:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.06it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 7:  58%|█████████████████████████████▍                     | 60/104 [00:11<00:08,  5.05it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 7:  58%|█████████████████████████████▍                     | 60/104 [00:12<00:08,  5.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  59%|█████████████████████████████▉                     | 61/104 [00:12<00:08,  5.06it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  59%|█████████████████████████████▉                     | 61/104 [00:12<00:08,  5.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:08,  5.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:08,  5.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:08,  5.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:08,  5.06it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 7:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:07,  5.08it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 7:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:07,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  62%|███████████████████████████████▉                   | 65/104 [00:12<00:07,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  62%|███████████████████████████████▉                   | 65/104 [00:13<00:07,  5.08it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 7:  63%|████████████████████████████████▎                  | 66/104 [00:13<00:07,  5.10it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 7:  63%|████████████████████████████████▎                  | 66/104 [00:13<00:07,  5.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:07,  5.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:07,  5.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:07,  5.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:07,  5.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:06,  5.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:06,  5.09it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 7:  67%|██████████████████████████████████▎                | 70/104 [00:13<00:06,  5.08it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 7:  67%|██████████████████████████████████▎                | 70/104 [00:14<00:06,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  68%|██████████████████████████████████▊                | 71/104 [00:14<00:06,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  68%|██████████████████████████████████▊                | 71/104 [00:14<00:06,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  5.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  5.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:06,  5.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:06,  5.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.05it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  72%|████████████████████████████████████▊              | 75/104 [00:14<00:05,  5.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  72%|████████████████████████████████████▊              | 75/104 [00:15<00:05,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  73%|█████████████████████████████████████▎             | 76/104 [00:15<00:05,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  73%|█████████████████████████████████████▎             | 76/104 [00:15<00:05,  5.08it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 7:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  5.09it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 7:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  5.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:05,  5.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:05,  5.09it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 7:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.12it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 7:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  77%|███████████████████████████████████████▏           | 80/104 [00:15<00:04,  5.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  77%|███████████████████████████████████████▏           | 80/104 [00:16<00:04,  5.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  78%|███████████████████████████████████████▋           | 81/104 [00:16<00:04,  5.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  78%|███████████████████████████████████████▋           | 81/104 [00:16<00:04,  5.16it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  5.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  5.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.03it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 7:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.05it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 7:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.05it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 7:  82%|█████████████████████████████████████████▋         | 85/104 [00:16<00:03,  5.05it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 7:  82%|█████████████████████████████████████████▋         | 85/104 [00:17<00:03,  5.05it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  83%|██████████████████████████████████████████▏        | 86/104 [00:17<00:03,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  83%|██████████████████████████████████████████▏        | 86/104 [00:17<00:03,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  84%|██████████████████████████████████████████▋        | 87/104 [00:17<00:03,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  84%|██████████████████████████████████████████▋        | 87/104 [00:17<00:03,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.08it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 7:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.08it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 7:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  87%|████████████████████████████████████████████▏      | 90/104 [00:17<00:02,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  87%|████████████████████████████████████████████▏      | 90/104 [00:18<00:02,  5.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  88%|████████████████████████████████████████████▋      | 91/104 [00:18<00:02,  5.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  88%|████████████████████████████████████████████▋      | 91/104 [00:18<00:02,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  88%|█████████████████████████████████████████████      | 92/104 [00:18<00:02,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  88%|█████████████████████████████████████████████      | 92/104 [00:18<00:02,  5.08it/s, training_loss=0.159]\u001b[A\n",
      "Epoch 7:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  5.08it/s, training_loss=0.159]\u001b[A\n",
      "Epoch 7:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  5.08it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:01,  5.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:01,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  91%|██████████████████████████████████████████████▌    | 95/104 [00:18<00:01,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  91%|██████████████████████████████████████████████▌    | 95/104 [00:19<00:01,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  92%|███████████████████████████████████████████████    | 96/104 [00:19<00:01,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  92%|███████████████████████████████████████████████    | 96/104 [00:19<00:01,  5.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  93%|███████████████████████████████████████████████▌   | 97/104 [00:19<00:01,  5.11it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  93%|███████████████████████████████████████████████▌   | 97/104 [00:19<00:01,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  5.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  5.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:00,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:00,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  96%|████████████████████████████████████████████████  | 100/104 [00:19<00:00,  5.02it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 7:  96%|████████████████████████████████████████████████  | 100/104 [00:20<00:00,  5.02it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  97%|████████████████████████████████████████████████▌ | 101/104 [00:20<00:00,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  97%|████████████████████████████████████████████████▌ | 101/104 [00:20<00:00,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  98%|█████████████████████████████████████████████████ | 102/104 [00:20<00:00,  5.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  98%|█████████████████████████████████████████████████ | 102/104 [00:20<00:00,  5.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  4.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 7:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  4.95it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 7: 100%|██████████████████████████████████████████████████| 104/104 [00:20<00:00,  5.36it/s, training_loss=0.004]\u001b[A\n",
      "Epoch Progress:  18%|███████████▋                                                       | 7/40 [02:23<11:18, 20.55s/it]\u001b[A\n",
      "Epoch 8:   0%|                                                                                 | 0/104 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:   0%|                                                            | 0/104 [00:00<?, ?it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:   1%|▌                                                   | 1/104 [00:00<00:20,  4.92it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:   1%|▌                                                   | 1/104 [00:00<00:20,  4.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   2%|█                                                   | 2/104 [00:00<00:20,  4.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   2%|█                                                   | 2/104 [00:00<00:20,  4.89it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 8:   3%|█▌                                                  | 3/104 [00:00<00:20,  4.87it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 8:   3%|█▌                                                  | 3/104 [00:00<00:20,  4.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   4%|██                                                  | 4/104 [00:00<00:20,  4.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   4%|██                                                  | 4/104 [00:01<00:20,  4.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   5%|██▌                                                 | 5/104 [00:01<00:20,  4.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   5%|██▌                                                 | 5/104 [00:01<00:20,  4.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   6%|███                                                 | 6/104 [00:01<00:19,  4.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   6%|███                                                 | 6/104 [00:01<00:19,  4.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   7%|███▌                                                | 7/104 [00:01<00:19,  4.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   7%|███▌                                                | 7/104 [00:01<00:19,  4.97it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   8%|████                                                | 8/104 [00:01<00:19,  4.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   8%|████                                                | 8/104 [00:01<00:19,  4.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   9%|████▌                                               | 9/104 [00:01<00:19,  4.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:   9%|████▌                                               | 9/104 [00:02<00:19,  4.96it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 8:  10%|████▉                                              | 10/104 [00:02<00:18,  4.96it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 8:  10%|████▉                                              | 10/104 [00:02<00:18,  4.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  11%|█████▍                                             | 11/104 [00:02<00:19,  4.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  11%|█████▍                                             | 11/104 [00:02<00:19,  4.89it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  12%|█████▉                                             | 12/104 [00:02<00:18,  4.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  12%|█████▉                                             | 12/104 [00:02<00:18,  4.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  12%|██████▍                                            | 13/104 [00:02<00:18,  4.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  12%|██████▍                                            | 13/104 [00:02<00:18,  4.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  13%|██████▊                                            | 14/104 [00:02<00:18,  4.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  13%|██████▊                                            | 14/104 [00:03<00:18,  4.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  14%|███████▎                                           | 15/104 [00:03<00:18,  4.89it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  14%|███████▎                                           | 15/104 [00:03<00:18,  4.89it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 8:  15%|███████▊                                           | 16/104 [00:03<00:17,  4.92it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 8:  15%|███████▊                                           | 16/104 [00:03<00:17,  4.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  16%|████████▎                                          | 17/104 [00:03<00:17,  4.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  16%|████████▎                                          | 17/104 [00:03<00:17,  4.87it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  17%|████████▊                                          | 18/104 [00:03<00:17,  4.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  17%|████████▊                                          | 18/104 [00:03<00:17,  4.88it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 8:  18%|█████████▎                                         | 19/104 [00:03<00:17,  4.87it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 8:  18%|█████████▎                                         | 19/104 [00:04<00:17,  4.87it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  19%|█████████▊                                         | 20/104 [00:04<00:17,  4.88it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  19%|█████████▊                                         | 20/104 [00:04<00:17,  4.88it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  20%|██████████▎                                        | 21/104 [00:04<00:16,  4.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  20%|██████████▎                                        | 21/104 [00:04<00:16,  4.91it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  21%|██████████▊                                        | 22/104 [00:04<00:16,  4.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  21%|██████████▊                                        | 22/104 [00:04<00:16,  4.92it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 8:  22%|███████████▎                                       | 23/104 [00:04<00:16,  4.95it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 8:  22%|███████████▎                                       | 23/104 [00:04<00:16,  4.95it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  23%|███████████▊                                       | 24/104 [00:04<00:16,  4.96it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  23%|███████████▊                                       | 24/104 [00:05<00:16,  4.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  24%|████████████▎                                      | 25/104 [00:05<00:15,  4.99it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  24%|████████████▎                                      | 25/104 [00:05<00:15,  4.99it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  25%|████████████▊                                      | 26/104 [00:05<00:15,  5.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  25%|████████████▊                                      | 26/104 [00:05<00:15,  5.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  26%|█████████████▏                                     | 27/104 [00:05<00:15,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  26%|█████████████▏                                     | 27/104 [00:05<00:15,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  27%|█████████████▋                                     | 28/104 [00:05<00:15,  5.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  27%|█████████████▋                                     | 28/104 [00:05<00:15,  5.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  28%|██████████████▏                                    | 29/104 [00:05<00:14,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  28%|██████████████▏                                    | 29/104 [00:06<00:14,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  29%|██████████████▋                                    | 30/104 [00:06<00:14,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  29%|██████████████▋                                    | 30/104 [00:06<00:14,  5.10it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 8:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  5.12it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 8:  30%|███████████████▏                                   | 31/104 [00:06<00:14,  5.12it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  31%|███████████████▋                                   | 32/104 [00:06<00:14,  5.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  31%|███████████████▋                                   | 32/104 [00:06<00:14,  5.14it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  32%|████████████████▏                                  | 33/104 [00:06<00:13,  5.15it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  32%|████████████████▏                                  | 33/104 [00:06<00:13,  5.15it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  33%|████████████████▋                                  | 34/104 [00:06<00:13,  5.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  33%|████████████████▋                                  | 34/104 [00:07<00:13,  5.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  34%|█████████████████▏                                 | 35/104 [00:07<00:13,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  34%|█████████████████▏                                 | 35/104 [00:07<00:13,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  35%|█████████████████▋                                 | 36/104 [00:07<00:13,  5.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  35%|█████████████████▋                                 | 36/104 [00:07<00:13,  5.12it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 8:  36%|██████████████████▏                                | 37/104 [00:07<00:13,  5.12it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 8:  36%|██████████████████▏                                | 37/104 [00:07<00:13,  5.12it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 8:  37%|██████████████████▋                                | 38/104 [00:07<00:12,  5.12it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 8:  37%|██████████████████▋                                | 38/104 [00:07<00:12,  5.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  38%|███████████████████▏                               | 39/104 [00:07<00:12,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  38%|███████████████████▏                               | 39/104 [00:08<00:12,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  38%|███████████████████▌                               | 40/104 [00:08<00:12,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  38%|███████████████████▌                               | 40/104 [00:08<00:12,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  39%|████████████████████                               | 41/104 [00:08<00:12,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  39%|████████████████████                               | 41/104 [00:08<00:12,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  40%|████████████████████▌                              | 42/104 [00:08<00:12,  5.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  40%|████████████████████▌                              | 42/104 [00:08<00:12,  5.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  41%|█████████████████████                              | 43/104 [00:08<00:11,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  41%|█████████████████████                              | 43/104 [00:08<00:11,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  42%|█████████████████████▌                             | 44/104 [00:08<00:11,  5.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  43%|██████████████████████                             | 45/104 [00:08<00:11,  5.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  43%|██████████████████████                             | 45/104 [00:09<00:11,  5.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  44%|██████████████████████▌                            | 46/104 [00:09<00:11,  5.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  44%|██████████████████████▌                            | 46/104 [00:09<00:11,  5.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  45%|███████████████████████                            | 47/104 [00:09<00:11,  5.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  45%|███████████████████████                            | 47/104 [00:09<00:11,  5.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  46%|███████████████████████▌                           | 48/104 [00:09<00:10,  5.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  46%|███████████████████████▌                           | 48/104 [00:09<00:10,  5.20it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 8:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.20it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 8:  47%|████████████████████████                           | 49/104 [00:09<00:10,  5.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  48%|████████████████████████▌                          | 50/104 [00:09<00:10,  5.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  48%|████████████████████████▌                          | 50/104 [00:10<00:10,  5.22it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 8:  49%|█████████████████████████                          | 51/104 [00:10<00:10,  5.24it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 8:  49%|█████████████████████████                          | 51/104 [00:10<00:10,  5.24it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 8:  50%|█████████████████████████▌                         | 52/104 [00:10<00:09,  5.26it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 8:  50%|█████████████████████████▌                         | 52/104 [00:10<00:09,  5.26it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  51%|█████████████████████████▉                         | 53/104 [00:10<00:09,  5.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  51%|█████████████████████████▉                         | 53/104 [00:10<00:09,  5.27it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  52%|██████████████████████████▍                        | 54/104 [00:10<00:09,  5.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  53%|██████████████████████████▉                        | 55/104 [00:10<00:09,  5.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  53%|██████████████████████████▉                        | 55/104 [00:11<00:09,  5.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  54%|███████████████████████████▍                       | 56/104 [00:11<00:09,  5.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  54%|███████████████████████████▍                       | 56/104 [00:11<00:09,  5.17it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  55%|███████████████████████████▉                       | 57/104 [00:11<00:09,  5.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  55%|███████████████████████████▉                       | 57/104 [00:11<00:09,  5.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.14it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  56%|████████████████████████████▍                      | 58/104 [00:11<00:08,  5.14it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 8:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.13it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 8:  57%|████████████████████████████▉                      | 59/104 [00:11<00:08,  5.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  58%|█████████████████████████████▍                     | 60/104 [00:11<00:08,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  58%|█████████████████████████████▍                     | 60/104 [00:12<00:08,  5.11it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 8:  59%|█████████████████████████████▉                     | 61/104 [00:12<00:08,  5.12it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 8:  59%|█████████████████████████████▉                     | 61/104 [00:12<00:08,  5.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:08,  5.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  60%|██████████████████████████████▍                    | 62/104 [00:12<00:08,  5.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:08,  5.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  61%|██████████████████████████████▉                    | 63/104 [00:12<00:08,  5.07it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:07,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  62%|███████████████████████████████▍                   | 64/104 [00:12<00:07,  5.04it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  62%|███████████████████████████████▉                   | 65/104 [00:12<00:07,  5.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  62%|███████████████████████████████▉                   | 65/104 [00:13<00:07,  5.00it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  63%|████████████████████████████████▎                  | 66/104 [00:13<00:07,  5.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  63%|████████████████████████████████▎                  | 66/104 [00:13<00:07,  5.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:07,  4.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  64%|████████████████████████████████▊                  | 67/104 [00:13<00:07,  4.94it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 8:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:07,  4.93it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 8:  65%|█████████████████████████████████▎                 | 68/104 [00:13<00:07,  4.93it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 8:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:07,  4.92it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 8:  66%|█████████████████████████████████▊                 | 69/104 [00:13<00:07,  4.92it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  67%|██████████████████████████████████▎                | 70/104 [00:13<00:06,  4.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  67%|██████████████████████████████████▎                | 70/104 [00:14<00:06,  4.93it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  68%|██████████████████████████████████▊                | 71/104 [00:14<00:06,  4.94it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  68%|██████████████████████████████████▊                | 71/104 [00:14<00:06,  4.94it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 8:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  4.96it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 8:  69%|███████████████████████████████████▎               | 72/104 [00:14<00:06,  4.96it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:06,  4.98it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  70%|███████████████████████████████████▊               | 73/104 [00:14<00:06,  4.98it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.01it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  71%|████████████████████████████████████▎              | 74/104 [00:14<00:05,  5.01it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  72%|████████████████████████████████████▊              | 75/104 [00:14<00:05,  5.03it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  72%|████████████████████████████████████▊              | 75/104 [00:15<00:05,  5.03it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  73%|█████████████████████████████████████▎             | 76/104 [00:15<00:05,  5.06it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  73%|█████████████████████████████████████▎             | 76/104 [00:15<00:05,  5.06it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 8:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  5.06it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 8:  74%|█████████████████████████████████████▊             | 77/104 [00:15<00:05,  5.06it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 8:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:05,  5.08it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 8:  75%|██████████████████████████████████████▎            | 78/104 [00:15<00:05,  5.08it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  76%|██████████████████████████████████████▋            | 79/104 [00:15<00:04,  5.10it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 8:  77%|███████████████████████████████████████▏           | 80/104 [00:15<00:04,  5.14it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 8:  77%|███████████████████████████████████████▏           | 80/104 [00:16<00:04,  5.14it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 8:  78%|███████████████████████████████████████▋           | 81/104 [00:16<00:04,  5.17it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 8:  78%|███████████████████████████████████████▋           | 81/104 [00:16<00:04,  5.17it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  5.10it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  79%|████████████████████████████████████████▏          | 82/104 [00:16<00:04,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.10it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  80%|████████████████████████████████████████▋          | 83/104 [00:16<00:04,  5.10it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 8:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.09it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 8:  81%|█████████████████████████████████████████▏         | 84/104 [00:16<00:03,  5.09it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  82%|█████████████████████████████████████████▋         | 85/104 [00:16<00:03,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  82%|█████████████████████████████████████████▋         | 85/104 [00:17<00:03,  5.11it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  83%|██████████████████████████████████████████▏        | 86/104 [00:17<00:03,  5.12it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  83%|██████████████████████████████████████████▏        | 86/104 [00:17<00:03,  5.12it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 8:  84%|██████████████████████████████████████████▋        | 87/104 [00:17<00:03,  5.13it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 8:  84%|██████████████████████████████████████████▋        | 87/104 [00:17<00:03,  5.13it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  85%|███████████████████████████████████████████▏       | 88/104 [00:17<00:03,  5.16it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  86%|███████████████████████████████████████████▋       | 89/104 [00:17<00:02,  5.18it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  87%|████████████████████████████████████████████▏      | 90/104 [00:17<00:02,  5.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  87%|████████████████████████████████████████████▏      | 90/104 [00:17<00:02,  5.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  88%|████████████████████████████████████████████▋      | 91/104 [00:17<00:02,  5.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  88%|████████████████████████████████████████████▋      | 91/104 [00:18<00:02,  5.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  88%|█████████████████████████████████████████████      | 92/104 [00:18<00:02,  5.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  88%|█████████████████████████████████████████████      | 92/104 [00:18<00:02,  5.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  5.20it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  89%|█████████████████████████████████████████████▌     | 93/104 [00:18<00:02,  5.20it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:01,  5.22it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 8:  90%|██████████████████████████████████████████████     | 94/104 [00:18<00:01,  5.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  91%|██████████████████████████████████████████████▌    | 95/104 [00:18<00:01,  5.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  91%|██████████████████████████████████████████████▌    | 95/104 [00:18<00:01,  5.23it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  92%|███████████████████████████████████████████████    | 96/104 [00:18<00:01,  5.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  92%|███████████████████████████████████████████████    | 96/104 [00:19<00:01,  5.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  93%|███████████████████████████████████████████████▌   | 97/104 [00:19<00:01,  5.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  93%|███████████████████████████████████████████████▌   | 97/104 [00:19<00:01,  5.24it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 8:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  5.25it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 8:  94%|████████████████████████████████████████████████   | 98/104 [00:19<00:01,  5.25it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:00,  5.28it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  95%|████████████████████████████████████████████████▌  | 99/104 [00:19<00:00,  5.28it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 8:  96%|████████████████████████████████████████████████  | 100/104 [00:19<00:00,  5.30it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 8:  96%|████████████████████████████████████████████████  | 100/104 [00:19<00:00,  5.30it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  97%|████████████████████████████████████████████████▌ | 101/104 [00:19<00:00,  5.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  97%|████████████████████████████████████████████████▌ | 101/104 [00:20<00:00,  5.24it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  98%|█████████████████████████████████████████████████ | 102/104 [00:20<00:00,  5.22it/s, training_loss=0.000]\u001b[A\n",
      "Epoch 8:  98%|█████████████████████████████████████████████████ | 102/104 [00:20<00:00,  5.22it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 8:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  5.20it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 8:  99%|█████████████████████████████████████████████████▌| 103/104 [00:20<00:00,  5.20it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 8: 100%|██████████████████████████████████████████████████| 104/104 [00:20<00:00,  5.62it/s, training_loss=0.003]\u001b[A\n",
      "Epoch Progress:  20%|█████████████▍                                                     | 8/40 [02:43<10:56, 20.51s/it]\u001b[A\n",
      "Epoch 9:   0%|                                                                                 | 0/104 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    " #install packages\n",
    "!pip install transformers\n",
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import logging\n",
    "import random\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def custom_train_test_split(df, test_size=0.2, random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X = df[['ade', 'soc_code']]\n",
    "    y = df['label']\n",
    "    \n",
    "    # Identify classes and their counts\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    \n",
    "    # Identify small classes\n",
    "    small_classes = classes[counts < 5]\n",
    "    \n",
    "    # Initialize lists for train and test sets\n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    X_test_list = []\n",
    "    y_test_list = []\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # Handle small classes separately\n",
    "    for cls in small_classes:\n",
    "        cls_mask = (y == cls)\n",
    "        cls_X = X[cls_mask]\n",
    "        cls_y = y[cls_mask]\n",
    "        cls_idx = df.index[cls_mask].tolist()\n",
    "        \n",
    "        if len(cls_X) == 1:\n",
    "            # If only one instance, put it in test set\n",
    "            test_indices.append(cls_idx[0])\n",
    "        else:\n",
    "            # Randomly choose one instance for testing\n",
    "            test_idx = np.random.choice(len(cls_X))\n",
    "            test_indices.append(cls_idx[test_idx])\n",
    "            \n",
    "            # Remaining instances go to training\n",
    "            train_indices.extend(np.delete(cls_idx, test_idx))\n",
    "    \n",
    "    # Combine the small class data into test and train sets\n",
    "    test_indices = np.array(test_indices)\n",
    "    train_indices = np.array(train_indices)\n",
    "    \n",
    "    X_test = df.loc[test_indices]\n",
    "    y_test = X_test['label']\n",
    "    \n",
    "    X_train = df.loc[train_indices]\n",
    "    y_train = X_train['label']\n",
    "    \n",
    "    # Handle large classes with stratified split\n",
    "    large_class_mask = ~np.isin(y, small_classes)\n",
    "    X_large = X[large_class_mask]\n",
    "    y_large = y[large_class_mask]\n",
    "    \n",
    "    X_train_large, X_test_large, y_train_large, y_test_large = train_test_split(\n",
    "        X_large, y_large, test_size=test_size, random_state=random_state, stratify=y_large\n",
    "    )\n",
    "    \n",
    "    # Combine large class data with the small class data\n",
    "    X_train = pd.concat([X_train, X_train_large], axis=0)\n",
    "    y_train = pd.concat([y_train, y_train_large], axis=0)\n",
    "    \n",
    "    X_test = pd.concat([X_test, X_test_large], axis=0)\n",
    "    y_test = pd.concat([y_test, y_test_large], axis=0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#evaluation\n",
    "def accuracy_per_class(predictions, true_vals):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "\n",
    "    accuracy_dict = {}\n",
    "    count_dict = {}\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = pred_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        accuracy_dict[label] = np.sum(y_preds == y_true) / len(y_true) if len(y_true) > 0 else 0\n",
    "        count_dict[label] = len(y_true)\n",
    "\n",
    "    return accuracy_dict, count_dict\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "\n",
    "# Function to calculate precision, recall, and F1 for each label\n",
    "def calculate_metrics(predictions, true_vals):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score per label\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels_flat, pred_flat, average=None, labels=np.unique(labels_flat))\n",
    "    \n",
    "    return precision, recall, f1\n",
    "    \n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='combine_top3_training_40ep_16bs_5e-5lr_log.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class TQDMLoggingWrapper(tqdm):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.logger = logger\n",
    "\n",
    "    def display(self, msg=None, pos=None):\n",
    "        if msg is not None:\n",
    "            self.logger.info(msg)\n",
    "        super().display(msg, pos)\n",
    "\n",
    "    def update(self, n=1):\n",
    "        super().update(n)\n",
    "        desc = self.format_dict.get('desc', 'No description')\n",
    "        postfix = self.format_dict.get('postfix', '')\n",
    "        self.logger.info(f'{desc} - {postfix}')\n",
    "\n",
    "    def set_description(self, desc=None, refresh=True):\n",
    "        super().set_description(desc, refresh)\n",
    "        if desc:\n",
    "            self.logger.info(f'Set description: {desc}')\n",
    "\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "#Read data from git:\n",
    "#https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\n",
    "# URL of the CSV file\n",
    "cadec_csv_url = \"https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\"\n",
    "# read data from smm4h\n",
    "smm4h_csv_url = \"https://raw.githubusercontent.com/FANMISUA/ADE_Norm/main/Data/smm4h_soc.tsv\"\n",
    "\n",
    "top3SMM4H = [10037175, 10018065,10029205]\n",
    "top3label_dict = {\n",
    "    10037175: 0,\n",
    "    10018065: 1,\n",
    "    10029205: 2\n",
    "}\n",
    "\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"ade\", \"soc_code\"]\n",
    "smm4h_all = pd.read_csv(smm4h_csv_url,names=column_names, sep = '\\t', header=None)\n",
    "\n",
    "smm4h_all = smm4h_all[smm4h_all['soc_code'] != 0]\n",
    "smm4h_all['soc_code'] = pd.to_numeric(smm4h_all['soc_code'], errors='coerce').astype('Int64')\n",
    "smm4h_unique = smm4h_all.drop_duplicates(subset='ade')\n",
    "\n",
    "# print(\"smm4h data:\",smm4h_all.shape)\n",
    "smm4h_soc_code_counts = smm4h_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "# print(\"SOC count in CADEC: \",smm4h_soc_code_counts)\n",
    "# Filter DataFrame\n",
    "smm4h_filtered_data3 = smm4h_unique[smm4h_unique['soc_code'].isin(top3SMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "top3inSMM4H = smm4h_filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "top3inSMM4H.loc[:, 'label'] = top3inSMM4H['soc_code'].map(top3label_dict)\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"TT\", \"llt_code\", \"ade\", \"soc_code\"]\n",
    "cadec_all = pd.read_csv(cadec_csv_url,names=column_names, header=None)\n",
    "\n",
    "# Remove duplicate rows based on the 'ade' column\n",
    "cadec_unique = cadec_all.drop_duplicates(subset='ade')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "# print(\"clean cadec data:\",cadec_unique.shape)\n",
    "# Count occurrences of each 'soc_code'\n",
    "cadec_soc_code_counts = cadec_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "# print(\"SOC count in CADEC: \",cadec_soc_code_counts)\n",
    "\n",
    "\n",
    "# Filter DataFrame\n",
    "cadec_filtered_data3 = cadec_unique[cadec_unique['soc_code'].isin(top3SMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "CADECtop3inSMM4H = cadec_filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "\n",
    "# print(\"CADEC top3 in SMM4H:\",CADECtop3inSMM4H)\n",
    "\n",
    "# For SMM4H data\n",
    "df1 = top3inSMM4H.copy()\n",
    "df1.loc[:, 'label'] = df1['soc_code'].map(top3label_dict)\n",
    "\n",
    "# For CADEC data\n",
    "df2 = CADECtop3inSMM4H.copy()\n",
    "df2.loc[:, 'label'] = df2['soc_code'].map(top3label_dict)\n",
    "\n",
    "print(\"SMM4H top 3\",df1)\n",
    "print(\"CADEC top 3\",df2)\n",
    "\n",
    "\n",
    "# Define the random seeds and other parameters\n",
    "seed_values = list(range(2, 42, 2))\n",
    "batch_size = 16\n",
    "epochs = 40\n",
    "learningrate = 5e-5\n",
    "\n",
    "# Placeholder for accuracies\n",
    "all_accuracies = {label: [] for label in range(len(top3label_dict))}\n",
    "\n",
    "# Initialize dictionaries to hold metrics for each seed\n",
    "seed_metrics = {seed_val: {'precision': [], 'recall': [], 'f1': []} for seed_val in seed_values}\n",
    "\n",
    "\n",
    "# Main loop over seed values\n",
    "for seed_val in seed_values:\n",
    "    # Set seeds\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    # Data preparation\n",
    "    # Apply the custom train-test split\n",
    "    # X_train, X_val, y_train, y_val = custom_train_test_split(df, test_size=0.2, random_state=seed_val)\n",
    "    \n",
    "    # # Add data_type column\n",
    "    # df['data_type'] = 'not_set'\n",
    "    # df.loc[X_train.index, 'data_type'] = 'train'\n",
    "    # df.loc[X_val.index, 'data_type'] = 'val'\n",
    "\n",
    "    # logger.info(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "    # print(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "    # Perform train-test split on df1\n",
    "    X_train_idx1, X_val_idx1, y_train1, y_val1 = custom_train_test_split(df1, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Perform train-test split on df2\n",
    "    X_train_idx2, X_val_idx2, y_train2, y_val2 = custom_train_test_split(df2, test_size=0.2, random_state=42)\n",
    "\n",
    "    #  set the 'data_type' column for df1 and df2\n",
    "    df1['data_type'] = 'not_set'\n",
    "    df2['data_type'] = 'not_set'\n",
    "\n",
    "    df1.loc[df1.index.isin(X_train_idx1.index), 'data_type'] = 'train'\n",
    "    df1.loc[df1.index.isin(X_val_idx1.index), 'data_type'] = 'val'\n",
    "\n",
    "    df2.loc[df2.index.isin(X_train_idx2.index), 'data_type'] = 'train'\n",
    "    df2.loc[df2.index.isin(X_val_idx2.index), 'data_type'] = 'val'\n",
    "\n",
    "\n",
    "    # If you want to combine df1 and df2 into a single dataframe:\n",
    "    df = pd.concat([df1, df2])\n",
    "    print(\"df: \",df)\n",
    "    logger.info(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "    print(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "\n",
    "    \n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    encoded_data_train = tokenizer.batch_encode_plus(\n",
    "        df[df.data_type == 'train'].ade.values,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    encoded_data_val = tokenizer.batch_encode_plus(\n",
    "        df[df.data_type == 'val'].ade.values,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids_train = encoded_data_train['input_ids']\n",
    "    attention_masks_train = encoded_data_train['attention_mask']\n",
    "    labels_train = torch.tensor(df[df.data_type == 'train'].label.values)\n",
    "\n",
    "    input_ids_val = encoded_data_val['input_ids']\n",
    "    attention_masks_val = encoded_data_val['attention_mask']\n",
    "    labels_val = torch.tensor(df[df.data_type == 'val'].label.values)\n",
    "\n",
    "    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(top3label_dict), output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "    dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learningrate, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train) * epochs)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    logger.info(f\"Device used: {device}\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in TQDMLoggingWrapper(range(1, epochs+1), desc='Epoch Progress'):\n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "\n",
    "        progress_bar = TQDMLoggingWrapper(dataloader_train, desc=f'Epoch {epoch}', leave=False, disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            progress_bar.set_postfix({'training_loss': f'{loss.item()/len(batch):.3f}'})\n",
    "\n",
    "        # torch.save(model.state_dict(), f'./ADENorm_top3_epoch_{epoch}.model')\n",
    "\n",
    "        logger.info(f'\\nEpoch {epoch}')\n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        logger.info(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_vals.flatten(), np.argmax(predictions, axis=1).flatten(), average=None, labels=np.unique(true_vals.flatten()))\n",
    "\n",
    "    for label in np.unique(true_vals):\n",
    "        seed_metrics[seed_val]['precision'].append((label, precision[label]))\n",
    "        seed_metrics[seed_val]['recall'].append((label, recall[label]))\n",
    "        seed_metrics[seed_val]['f1'].append((label, f1[label]))\n",
    "\n",
    "# Write the precision, recall, F1 scores, and seed values to a file\n",
    "with open('combine_top3_20times_results_with_seeds.txt', 'w') as f:\n",
    "    f.write('Seed\\tLabel\\tPrecision\\tRecall\\tF1\\n')\n",
    "    for seed_val in seed_values:\n",
    "        for label, precision_val in seed_metrics[seed_val]['precision']:\n",
    "            recall_val = next(val for lbl, val in seed_metrics[seed_val]['recall'] if lbl == label)\n",
    "            f1_val = next(val for lbl, val in seed_metrics[seed_val]['f1'] if lbl == label)\n",
    "            f.write(f'{seed_val}\\t{label}\\t{precision_val:.4f}\\t{recall_val:.4f}\\t{f1_val:.4f}\\n')\n",
    "\n",
    "\n",
    "# Initialize lists to hold precision, recall, and f1 values for each label\n",
    "precision_dict, recall_dict, f1_dict = {}, {}, {}\n",
    "\n",
    "# Collect metrics across seeds\n",
    "for seed in seed_metrics:\n",
    "    for label, value in seed_metrics[seed]['precision']:\n",
    "        precision_dict.setdefault(label, []).append(value)\n",
    "    for label, value in seed_metrics[seed]['recall']:\n",
    "        recall_dict.setdefault(label, []).append(value)\n",
    "    for label, value in seed_metrics[seed]['f1']:\n",
    "        f1_dict.setdefault(label, []).append(value)\n",
    "\n",
    "# Compute mean and std for precision, recall, and f1\n",
    "labels = sorted(precision_dict.keys())\n",
    "precision_mean = [np.mean(precision_dict[label]) for label in labels]\n",
    "precision_std = [np.std(precision_dict[label]) for label in labels]\n",
    "recall_mean = [np.mean(recall_dict[label]) for label in labels]\n",
    "recall_std = [np.std(recall_dict[label]) for label in labels]\n",
    "f1_mean = [np.mean(f1_dict[label]) for label in labels]\n",
    "f1_std = [np.std(f1_dict[label]) for label in labels]\n",
    "\n",
    "# Plotting\n",
    "x = np.arange(len(labels))  # label indices\n",
    "width = 0.25  # width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Bar plots with mean values\n",
    "bars_precision = ax.bar(x - width, precision_mean, width, label='Precision', color='b')\n",
    "bars_recall = ax.bar(x, recall_mean, width, label='Recall', color='g')\n",
    "bars_f1 = ax.bar(x + width, f1_mean, width, label='F1 Score', color='r')\n",
    "\n",
    "# Annotate bars with mean and std values\n",
    "# Annotate bars with mean and std values, with smaller font size\n",
    "for bars, means, stds in zip([bars_precision, bars_recall, bars_f1],\n",
    "                             [precision_mean, recall_mean, f1_mean],\n",
    "                             [precision_std, recall_std, f1_std]):\n",
    "    for bar, mean, std in zip(bars, means, stds):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2.0, height,\n",
    "                f'{mean:.2f}\\n±{std:.2f}', ha='center', va='bottom', fontsize=8)  # Smaller font size\n",
    "\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Label')\n",
    "ax.set_ylabel('Performance')\n",
    "ax.set_title('Mean and Standard Deviation of Precision, Recall, and F1 Score by Label')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "# Set y-axis limit to [0, 1]\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Move legend outside the plot\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust the plot to fit the legend\n",
    "plt.savefig('combine_top3_20times_results_plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea03ac-e3ce-45d7-ad9a-448c51fc523d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
