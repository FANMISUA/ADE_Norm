{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b12ce1e7-9457-457b-b7f7-ce44b3c66fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smm4h data: (1712, 2)\n",
      "smm4h data after filtering: (1710, 2)\n",
      "SOC count in SMM4H:  soc_code\n",
      "10037175    287\n",
      "10018065    235\n",
      "10029205    212\n",
      "10017947     63\n",
      "10028395     58\n",
      "10022891     54\n",
      "10027433     48\n",
      "10040785     28\n",
      "10038738     22\n",
      "10022117     16\n",
      "10015919     16\n",
      "10038604     10\n",
      "10047065     10\n",
      "10021428      8\n",
      "10041244      7\n",
      "10007541      7\n",
      "10038359      6\n",
      "10021881      5\n",
      "10013993      4\n",
      "10019805      2\n",
      "10042613      2\n",
      "10029104      2\n",
      "10077536      1\n",
      "10010331      1\n",
      "10014698      1\n",
      "Name: count, dtype: Int64\n",
      "SOC count in CADEC:  soc_code\n",
      "10028395    962\n",
      "10018065    654\n",
      "10037175    401\n",
      "10017947    300\n",
      "10029205    286\n",
      "10040785    184\n",
      "10007541     92\n",
      "10038738     91\n",
      "10022891     82\n",
      "10015919     67\n",
      "10038604     59\n",
      "10038359     50\n",
      "10022117     35\n",
      "10047065     25\n",
      "10013993     16\n",
      "10019805     15\n",
      "10041244      7\n",
      "10027433      6\n",
      "10021881      5\n",
      "10021428      4\n",
      "10014698      3\n",
      "10005329      3\n",
      "10029104      1\n",
      "Name: count, dtype: int64\n",
      "SMM4H :                             ade  soc_code  label\n",
      "1                     allergies  10021428     13\n",
      "2               HURT YOUR Liver  10019805     19\n",
      "3                            AD  10037175      0\n",
      "4                         focus  10029205      2\n",
      "5                          died  10018065      1\n",
      "...                         ...       ...    ...\n",
      "1703                 chest hurt  10018065      1\n",
      "1704   got ten minutes of sleep  10037175      0\n",
      "1706                  Nosebleed  10038738      8\n",
      "1708  never have another orgasm  10037175      0\n",
      "1710        gain so much weight  10022891      5\n",
      "\n",
      "[1105 rows x 3 columns]\n",
      "CADEC :                                    ade  soc_code  label\n",
      "3                      ankles swelling  10007541     15\n",
      "4             sever swelling of ankles  10007541     15\n",
      "5                      Edema of ankles  10007541     15\n",
      "6                    severe arrythmias  10007541     15\n",
      "7                            arrythmia  10007541     15\n",
      "...                                ...       ...    ...\n",
      "5955                      hypertension  10047065     12\n",
      "5956           Elevated blood pressure  10047065     12\n",
      "5959  LITTLE CIRCULATION IN MY FINGERS  10047065     12\n",
      "5960                  going into shock  10047065     12\n",
      "5961     vein in my one leg is bulging  10047065     12\n",
      "\n",
      "[3345 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def custom_train_test_split(df, test_size=0.2, random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X = df[['ade', 'soc_code']]\n",
    "    y = df['label']\n",
    "    \n",
    "    # Identify classes and their counts\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    \n",
    "    # Identify small classes\n",
    "    small_classes = classes[counts < 5]\n",
    "    \n",
    "    # Initialize lists for train and test sets\n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    X_test_list = []\n",
    "    y_test_list = []\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # Handle small classes separately\n",
    "    for cls in small_classes:\n",
    "        cls_mask = (y == cls)\n",
    "        cls_X = X[cls_mask]\n",
    "        cls_y = y[cls_mask]\n",
    "        cls_idx = df.index[cls_mask].tolist()\n",
    "        \n",
    "        if len(cls_X) == 1:\n",
    "            # If only one instance, put it in test set\n",
    "            test_indices.append(cls_idx[0])\n",
    "        else:\n",
    "            # Randomly choose one instance for testing\n",
    "            test_idx = np.random.choice(len(cls_X))\n",
    "            test_indices.append(cls_idx[test_idx])\n",
    "            \n",
    "            # Remaining instances go to training\n",
    "            train_indices.extend(np.delete(cls_idx, test_idx))\n",
    "    \n",
    "    # Combine the small class data into test and train sets\n",
    "    test_indices = np.array(test_indices)\n",
    "    train_indices = np.array(train_indices)\n",
    "    \n",
    "    X_test = df.loc[test_indices]\n",
    "    y_test = X_test['label']\n",
    "    \n",
    "    X_train = df.loc[train_indices]\n",
    "    y_train = X_train['label']\n",
    "    \n",
    "    # Handle large classes with stratified split\n",
    "    large_class_mask = ~np.isin(y, small_classes)\n",
    "    X_large = X[large_class_mask]\n",
    "    y_large = y[large_class_mask]\n",
    "    \n",
    "    X_train_large, X_test_large, y_train_large, y_test_large = train_test_split(\n",
    "        X_large, y_large, test_size=test_size, random_state=random_state, stratify=y_large\n",
    "    )\n",
    "    \n",
    "    # Combine large class data with the small class data\n",
    "    X_train = pd.concat([X_train, X_train_large], axis=0)\n",
    "    y_train = pd.concat([y_train, y_train_large], axis=0)\n",
    "    \n",
    "    X_test = pd.concat([X_test, X_test_large], axis=0)\n",
    "    y_test = pd.concat([y_test, y_test_large], axis=0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "#Read data from git:\n",
    "#https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\n",
    "# URL of the CSV file\n",
    "cadec_csv_url = \"https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\"\n",
    "# read data from smm4h\n",
    "smm4h_csv_url = \"https://raw.githubusercontent.com/FANMISUA/ADE_Norm/main/Data/smm4h_soc.tsv\"\n",
    "\n",
    "allSMM4H = [10037175, 10018065,10029205, 10017947, 10028395, 10022891, 10027433, 10040785, 10038738, 10022117, 10015919, 10038604, 10047065, \n",
    "            10021428,10041244, 10007541, 10038359, 10021881, 10013993, 10019805, 10042613, 10029104, 10077536, 10010331, 10014698]\n",
    "\n",
    "label_dict = {\n",
    "    10037175: 0,\n",
    "    10018065: 1,\n",
    "    10029205: 2,\n",
    "    10017947: 3,\n",
    "    10028395: 4,\n",
    "    10022891: 5,\n",
    "    10027433: 6,\n",
    "    10040785: 7,\n",
    "    10038738: 8,\n",
    "    10022117: 9,\n",
    "    10015919: 10,\n",
    "    10038604: 11,\n",
    "    10047065: 12,\n",
    "    10021428: 13,\n",
    "    10041244: 14,\n",
    "    10007541: 15,\n",
    "    10038359: 16,\n",
    "    10021881: 17,\n",
    "    10013993: 18,\n",
    "    10019805: 19,\n",
    "    10042613: 20,\n",
    "    10029104: 21,\n",
    "    10077536: 22,\n",
    "    10010331: 23,\n",
    "    10014698: 24\n",
    "}\n",
    "\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"ade\", \"soc_code\"]\n",
    "smm4h_all = pd.read_csv(smm4h_csv_url,names=column_names, sep = '\\t', header=None)\n",
    "print(\"smm4h data:\",smm4h_all.shape)\n",
    "\n",
    "smm4h_all['soc_code'] = pd.to_numeric(smm4h_all['soc_code'], errors='coerce').astype('Int64')\n",
    "smm4h_all = smm4h_all[smm4h_all['soc_code'] != 0]\n",
    "\n",
    "smm4h_unique = smm4h_all.drop_duplicates(subset='ade')\n",
    "\n",
    "print(\"smm4h data after filtering:\",smm4h_all.shape)\n",
    "smm4h_soc_code_counts = smm4h_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "print(\"SOC count in SMM4H: \",smm4h_soc_code_counts)\n",
    "# Filter DataFrame\n",
    "smm4h_filtered_data3 = smm4h_unique[smm4h_unique['soc_code'].isin(allSMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "allinSMM4H = smm4h_filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"TT\", \"llt_code\", \"ade\", \"soc_code\"]\n",
    "cadec_all = pd.read_csv(cadec_csv_url,names=column_names, header=None)\n",
    "\n",
    "# Remove duplicate rows based on the 'ade' column\n",
    "cadec_unique = cadec_all.drop_duplicates(subset='ade')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "# print(\"clean cadec data:\",cadec_unique.shape)\n",
    "# Count occurrences of each 'soc_code'\n",
    "cadec_soc_code_counts = cadec_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "print(\"SOC count in CADEC: \",cadec_soc_code_counts)\n",
    "\n",
    "\n",
    "# Filter DataFrame\n",
    "cadec_filtered_data3 = cadec_unique[cadec_unique['soc_code'].isin(allSMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "CADECallinSMM4H = cadec_filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "\n",
    "# For SMM4H data\n",
    "df1 = allinSMM4H.copy()\n",
    "df1.loc[:, 'label'] = df1['soc_code'].map(label_dict)\n",
    "\n",
    "# For CADEC data\n",
    "df2 = CADECallinSMM4H.copy()\n",
    "df2.loc[:, 'label'] = df2['soc_code'].map(label_dict)\n",
    "\n",
    "print(\"SMM4H :\",df1)\n",
    "print(\"CADEC :\",df2)\n",
    "\n",
    "#smm4h data\n",
    "df = df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6418720b-b83d-4320-af92-7ae7b1be4db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          ade\n",
      "soc_code label data_type     \n",
      "10007541 15    train        6\n",
      "               val          1\n",
      "10010331 23    val          1\n",
      "10013993 18    train        3\n",
      "               val          1\n",
      "10014698 24    val          1\n",
      "10015919 10    train       13\n",
      "               val          3\n",
      "10017947 3     train       50\n",
      "               val         13\n",
      "10018065 1     train      188\n",
      "               val         47\n",
      "10019805 19    train        1\n",
      "               val          1\n",
      "10021428 13    train        6\n",
      "               val          2\n",
      "10021881 17    train        4\n",
      "               val          1\n",
      "10022117 9     train       13\n",
      "               val          3\n",
      "10022891 5     train       43\n",
      "               val         11\n",
      "10027433 6     train       38\n",
      "               val         10\n",
      "10028395 4     train       46\n",
      "               val         12\n",
      "10029104 21    train        1\n",
      "               val          1\n",
      "10029205 2     train      170\n",
      "               val         42\n",
      "10037175 0     train      229\n",
      "               val         58\n",
      "10038359 16    train        5\n",
      "               val          1\n",
      "10038604 11    train        8\n",
      "               val          2\n",
      "10038738 8     train       18\n",
      "               val          4\n",
      "10040785 7     train       22\n",
      "               val          6\n",
      "10041244 14    train        6\n",
      "               val          1\n",
      "10042613 20    train        1\n",
      "               val          1\n",
      "10047065 12    train        8\n",
      "               val          2\n",
      "10077536 22    val          1\n"
     ]
    }
   ],
   "source": [
    "# Apply the custom train-test split\n",
    "X_train, X_val, y_train, y_val = custom_train_test_split(df, test_size=0.2, random_state=2)\n",
    "\n",
    "# Add data_type column\n",
    "df['data_type'] = 'not_set'\n",
    "df.loc[X_train.index, 'data_type'] = 'train'\n",
    "df.loc[X_val.index, 'data_type'] = 'val'\n",
    "\n",
    "\n",
    "print(df.groupby(['soc_code', 'label', 'data_type']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a8c825a-fe10-468c-a15f-81a5d3b9ec8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13 19  0 ...  8  0  5]\n"
     ]
    }
   ],
   "source": [
    "print(df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46998fd4-cba9-4099-9ceb-4a812e1d2ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
