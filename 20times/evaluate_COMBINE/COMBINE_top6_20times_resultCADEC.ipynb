{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9de312-b759-4b54-a1b1-db9b9fe9b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "SMM4H top 3                             ade  soc_code  label\n",
      "3                            AD  10037175      0\n",
      "4                         focus  10029205      2\n",
      "5                          died  10018065      1\n",
      "8                        dreams  10037175      0\n",
      "10                   withdrawal  10018065      1\n",
      "...                         ...       ...    ...\n",
      "1698     can't go back to sleep  10037175      0\n",
      "1703                 chest hurt  10018065      1\n",
      "1704   got ten minutes of sleep  10037175      0\n",
      "1708  never have another orgasm  10037175      0\n",
      "1710        gain so much weight  10022891      5\n",
      "\n",
      "[909 rows x 3 columns]\n",
      "CADEC top 3                             ade  soc_code  label\n",
      "299      bowel/uterine cramping  10017947      3\n",
      "300            Abdominal cramps  10017947      3\n",
      "301          abdominal cramping  10017947      3\n",
      "302   abdominal cramps and pain  10017947      3\n",
      "303            abdominal cramps  10017947      3\n",
      "...                         ...       ...    ...\n",
      "5326  short term memory lacking  10037175      0\n",
      "5328      couldn't eat or drink  10037175      0\n",
      "5329              Could not eat  10037175      0\n",
      "5331           can't eat normal  10037175      0\n",
      "5332   Disturbed sleep patterns  10037175      0\n",
      "\n",
      "[2685 rows x 3 columns]\n",
      "df:                              ade  soc_code  label data_type\n",
      "3                            AD  10037175      0     train\n",
      "4                         focus  10029205      2     train\n",
      "5                          died  10018065      1     train\n",
      "8                        dreams  10037175      0     train\n",
      "10                   withdrawal  10018065      1     train\n",
      "...                         ...       ...    ...       ...\n",
      "5326  short term memory lacking  10037175      0       val\n",
      "5328      couldn't eat or drink  10037175      0       val\n",
      "5329              Could not eat  10037175      0     train\n",
      "5331           can't eat normal  10037175      0     train\n",
      "5332   Disturbed sleep patterns  10037175      0     train\n",
      "\n",
      "[3594 rows x 4 columns]\n",
      "                          ade\n",
      "soc_code label data_type     \n",
      "10017947 3     train      290\n",
      "               val         60\n",
      "               val1        13\n",
      "10018065 1     train      711\n",
      "               val        131\n",
      "               val1        47\n",
      "10022891 5     train      108\n",
      "               val         17\n",
      "               val1        11\n",
      "10028395 4     train      816\n",
      "               val        192\n",
      "               val1        12\n",
      "10029205 2     train      399\n",
      "               val         57\n",
      "               val1        42\n",
      "10037175 0     train      551\n",
      "               val         80\n",
      "               val1        57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2888: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch Progress:   0%|                                                         | 0/40 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|                                                               | 0/180 [00:00<?, ?it/s]\u001b[AC:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Epoch 1:   0%|                                          | 0/180 [00:00<?, ?it/s, training_loss=0.629]\u001b[A\n",
      "Epoch 1:   1%|▏                                 | 1/180 [00:00<01:33,  1.92it/s, training_loss=0.629]\u001b[A\n",
      "Epoch 1:   1%|▏                                 | 1/180 [00:00<01:33,  1.92it/s, training_loss=0.574]\u001b[A\n",
      "Epoch 1:   1%|▍                                 | 2/180 [00:00<00:55,  3.20it/s, training_loss=0.574]\u001b[A\n",
      "Epoch 1:   1%|▍                                 | 2/180 [00:00<00:55,  3.20it/s, training_loss=0.563]\u001b[A\n",
      "Epoch 1:   2%|▌                                 | 3/180 [00:00<00:43,  4.06it/s, training_loss=0.563]\u001b[A\n",
      "Epoch 1:   2%|▌                                 | 3/180 [00:01<00:43,  4.06it/s, training_loss=0.563]\u001b[A\n",
      "Epoch 1:   2%|▊                                 | 4/180 [00:01<00:38,  4.61it/s, training_loss=0.563]\u001b[A\n",
      "Epoch 1:   2%|▊                                 | 4/180 [00:01<00:38,  4.61it/s, training_loss=0.604]\u001b[A\n",
      "Epoch 1:   3%|▉                                 | 5/180 [00:01<00:34,  5.08it/s, training_loss=0.604]\u001b[A\n",
      "Epoch 1:   3%|▉                                 | 5/180 [00:01<00:34,  5.08it/s, training_loss=0.578]\u001b[A\n",
      "Epoch 1:   3%|█▏                                | 6/180 [00:01<00:32,  5.36it/s, training_loss=0.578]\u001b[A\n",
      "Epoch 1:   3%|█▏                                | 6/180 [00:01<00:32,  5.36it/s, training_loss=0.579]\u001b[A\n",
      "Epoch 1:   4%|█▎                                | 7/180 [00:01<00:31,  5.55it/s, training_loss=0.579]\u001b[A\n",
      "Epoch 1:   4%|█▎                                | 7/180 [00:01<00:31,  5.55it/s, training_loss=0.597]\u001b[A\n",
      "Epoch 1:   4%|█▌                                | 8/180 [00:01<00:30,  5.68it/s, training_loss=0.597]\u001b[A\n",
      "Epoch 1:   4%|█▌                                | 8/180 [00:01<00:30,  5.68it/s, training_loss=0.517]\u001b[A\n",
      "Epoch 1:   5%|█▋                                | 9/180 [00:01<00:29,  5.77it/s, training_loss=0.517]\u001b[A\n",
      "Epoch 1:   5%|█▋                                | 9/180 [00:02<00:29,  5.77it/s, training_loss=0.513]\u001b[A\n",
      "Epoch 1:   6%|█▊                               | 10/180 [00:02<00:29,  5.80it/s, training_loss=0.513]\u001b[A\n",
      "Epoch 1:   6%|█▊                               | 10/180 [00:02<00:29,  5.80it/s, training_loss=0.520]\u001b[A\n",
      "Epoch 1:   6%|██                               | 11/180 [00:02<00:28,  5.89it/s, training_loss=0.520]\u001b[A\n",
      "Epoch 1:   6%|██                               | 11/180 [00:02<00:28,  5.89it/s, training_loss=0.569]\u001b[A\n",
      "Epoch 1:   7%|██▏                              | 12/180 [00:02<00:28,  5.93it/s, training_loss=0.569]\u001b[A\n",
      "Epoch 1:   7%|██▏                              | 12/180 [00:02<00:28,  5.93it/s, training_loss=0.566]\u001b[A\n",
      "Epoch 1:   7%|██▍                              | 13/180 [00:02<00:28,  5.95it/s, training_loss=0.566]\u001b[A\n",
      "Epoch 1:   7%|██▍                              | 13/180 [00:02<00:28,  5.95it/s, training_loss=0.572]\u001b[A\n",
      "Epoch 1:   8%|██▌                              | 14/180 [00:02<00:27,  5.96it/s, training_loss=0.572]\u001b[A\n",
      "Epoch 1:   8%|██▌                              | 14/180 [00:02<00:27,  5.96it/s, training_loss=0.575]\u001b[A\n",
      "Epoch 1:   8%|██▊                              | 15/180 [00:02<00:27,  5.97it/s, training_loss=0.575]\u001b[A\n",
      "Epoch 1:   8%|██▊                              | 15/180 [00:03<00:27,  5.97it/s, training_loss=0.480]\u001b[A\n",
      "Epoch 1:   9%|██▉                              | 16/180 [00:03<00:27,  5.94it/s, training_loss=0.480]\u001b[A\n",
      "Epoch 1:   9%|██▉                              | 16/180 [00:03<00:27,  5.94it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 1:   9%|███                              | 17/180 [00:03<00:27,  5.99it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 1:   9%|███                              | 17/180 [00:03<00:27,  5.99it/s, training_loss=0.562]\u001b[A\n",
      "Epoch 1:  10%|███▎                             | 18/180 [00:03<00:27,  5.99it/s, training_loss=0.562]\u001b[A\n",
      "Epoch 1:  10%|███▎                             | 18/180 [00:03<00:27,  5.99it/s, training_loss=0.538]\u001b[A\n",
      "Epoch 1:  11%|███▍                             | 19/180 [00:03<00:26,  5.99it/s, training_loss=0.538]\u001b[A\n",
      "Epoch 1:  11%|███▍                             | 19/180 [00:03<00:26,  5.99it/s, training_loss=0.500]\u001b[A\n",
      "Epoch 1:  11%|███▋                             | 20/180 [00:03<00:26,  5.99it/s, training_loss=0.500]\u001b[A\n",
      "Epoch 1:  11%|███▋                             | 20/180 [00:03<00:26,  5.99it/s, training_loss=0.494]\u001b[A\n",
      "Epoch 1:  12%|███▊                             | 21/180 [00:03<00:26,  6.00it/s, training_loss=0.494]\u001b[A\n",
      "Epoch 1:  12%|███▊                             | 21/180 [00:04<00:26,  6.00it/s, training_loss=0.506]\u001b[A\n",
      "Epoch 1:  12%|████                             | 22/180 [00:04<00:26,  5.98it/s, training_loss=0.506]\u001b[A\n",
      "Epoch 1:  12%|████                             | 22/180 [00:04<00:26,  5.98it/s, training_loss=0.528]\u001b[A\n",
      "Epoch 1:  13%|████▏                            | 23/180 [00:04<00:26,  6.00it/s, training_loss=0.528]\u001b[A\n",
      "Epoch 1:  13%|████▏                            | 23/180 [00:04<00:26,  6.00it/s, training_loss=0.448]\u001b[A\n",
      "Epoch 1:  13%|████▍                            | 24/180 [00:04<00:26,  5.99it/s, training_loss=0.448]\u001b[A\n",
      "Epoch 1:  13%|████▍                            | 24/180 [00:04<00:26,  5.99it/s, training_loss=0.488]\u001b[A\n",
      "Epoch 1:  14%|████▌                            | 25/180 [00:04<00:25,  5.99it/s, training_loss=0.488]\u001b[A\n",
      "Epoch 1:  14%|████▌                            | 25/180 [00:04<00:25,  5.99it/s, training_loss=0.472]\u001b[A\n",
      "Epoch 1:  14%|████▊                            | 26/180 [00:04<00:25,  5.99it/s, training_loss=0.472]\u001b[A\n",
      "Epoch 1:  14%|████▊                            | 26/180 [00:04<00:25,  5.99it/s, training_loss=0.486]\u001b[A\n",
      "Epoch 1:  15%|████▉                            | 27/180 [00:04<00:25,  5.99it/s, training_loss=0.486]\u001b[A\n",
      "Epoch 1:  15%|████▉                            | 27/180 [00:05<00:25,  5.99it/s, training_loss=0.426]\u001b[A\n",
      "Epoch 1:  16%|█████▏                           | 28/180 [00:05<00:25,  6.00it/s, training_loss=0.426]\u001b[A\n",
      "Epoch 1:  16%|█████▏                           | 28/180 [00:05<00:25,  6.00it/s, training_loss=0.471]\u001b[A\n",
      "Epoch 1:  16%|█████▎                           | 29/180 [00:05<00:24,  6.16it/s, training_loss=0.471]\u001b[A\n",
      "Epoch 1:  16%|█████▎                           | 29/180 [00:05<00:24,  6.16it/s, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  17%|█████▌                           | 30/180 [00:05<00:24,  6.11it/s, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  17%|█████▌                           | 30/180 [00:05<00:24,  6.11it/s, training_loss=0.457]\u001b[A\n",
      "Epoch 1:  17%|█████▋                           | 31/180 [00:05<00:24,  6.08it/s, training_loss=0.457]\u001b[A\n",
      "Epoch 1:  17%|█████▋                           | 31/180 [00:05<00:24,  6.08it/s, training_loss=0.510]\u001b[A\n",
      "Epoch 1:  18%|█████▊                           | 32/180 [00:05<00:24,  6.05it/s, training_loss=0.510]\u001b[A\n",
      "Epoch 1:  18%|█████▊                           | 32/180 [00:05<00:24,  6.05it/s, training_loss=0.530]\u001b[A\n",
      "Epoch 1:  18%|██████                           | 33/180 [00:05<00:24,  6.03it/s, training_loss=0.530]\u001b[A\n",
      "Epoch 1:  18%|██████                           | 33/180 [00:06<00:24,  6.03it/s, training_loss=0.547]\u001b[A\n",
      "Epoch 1:  19%|██████▏                          | 34/180 [00:06<00:24,  5.87it/s, training_loss=0.547]\u001b[A\n",
      "Epoch 1:  19%|██████▏                          | 34/180 [00:06<00:24,  5.87it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 1:  19%|██████▍                          | 35/180 [00:06<00:23,  6.06it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 1:  19%|██████▍                          | 35/180 [00:06<00:23,  6.06it/s, training_loss=0.539]\u001b[A\n",
      "Epoch 1:  20%|██████▌                          | 36/180 [00:06<00:24,  5.87it/s, training_loss=0.539]\u001b[A\n",
      "Epoch 1:  20%|██████▌                          | 36/180 [00:06<00:24,  5.87it/s, training_loss=0.541]\u001b[A\n",
      "Epoch 1:  21%|██████▊                          | 37/180 [00:06<00:23,  6.08it/s, training_loss=0.541]\u001b[A\n",
      "Epoch 1:  21%|██████▊                          | 37/180 [00:06<00:23,  6.08it/s, training_loss=0.483]\u001b[A\n",
      "Epoch 1:  21%|██████▉                          | 38/180 [00:06<00:23,  6.05it/s, training_loss=0.483]\u001b[A\n",
      "Epoch 1:  21%|██████▉                          | 38/180 [00:06<00:23,  6.05it/s, training_loss=0.562]\u001b[A\n",
      "Epoch 1:  22%|███████▏                         | 39/180 [00:06<00:23,  6.03it/s, training_loss=0.562]\u001b[A\n",
      "Epoch 1:  22%|███████▏                         | 39/180 [00:07<00:23,  6.03it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  22%|███████▎                         | 40/180 [00:07<00:23,  5.89it/s, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  22%|███████▎                         | 40/180 [00:07<00:23,  5.89it/s, training_loss=0.475]\u001b[A\n",
      "Epoch 1:  23%|███████▌                         | 41/180 [00:07<00:22,  6.05it/s, training_loss=0.475]\u001b[A\n",
      "Epoch 1:  23%|███████▌                         | 41/180 [00:07<00:22,  6.05it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  23%|███████▋                         | 42/180 [00:07<00:22,  6.03it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  23%|███████▋                         | 42/180 [00:07<00:22,  6.03it/s, training_loss=0.413]\u001b[A\n",
      "Epoch 1:  24%|███████▉                         | 43/180 [00:07<00:22,  6.02it/s, training_loss=0.413]\u001b[A\n",
      "Epoch 1:  24%|███████▉                         | 43/180 [00:07<00:22,  6.02it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  24%|████████                         | 44/180 [00:07<00:22,  6.01it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 1:  24%|████████                         | 44/180 [00:07<00:22,  6.01it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 1:  25%|████████▎                        | 45/180 [00:07<00:22,  6.01it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 1:  25%|████████▎                        | 45/180 [00:08<00:22,  6.01it/s, training_loss=0.406]\u001b[A\n",
      "Epoch 1:  26%|████████▍                        | 46/180 [00:08<00:22,  5.96it/s, training_loss=0.406]\u001b[A\n",
      "Epoch 1:  26%|████████▍                        | 46/180 [00:08<00:22,  5.96it/s, training_loss=0.385]\u001b[A\n",
      "Epoch 1:  26%|████████▌                        | 47/180 [00:08<00:22,  6.01it/s, training_loss=0.385]\u001b[A\n",
      "Epoch 1:  26%|████████▌                        | 47/180 [00:08<00:22,  6.01it/s, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  27%|████████▊                        | 48/180 [00:08<00:21,  6.01it/s, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  27%|████████▊                        | 48/180 [00:08<00:21,  6.01it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  27%|████████▉                        | 49/180 [00:08<00:21,  6.00it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  27%|████████▉                        | 49/180 [00:08<00:21,  6.00it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  28%|█████████▏                       | 50/180 [00:08<00:21,  6.00it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  28%|█████████▏                       | 50/180 [00:08<00:21,  6.00it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  28%|█████████▎                       | 51/180 [00:08<00:21,  5.99it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  28%|█████████▎                       | 51/180 [00:09<00:21,  5.99it/s, training_loss=0.443]\u001b[A\n",
      "Epoch 1:  29%|█████████▌                       | 52/180 [00:09<00:21,  5.96it/s, training_loss=0.443]\u001b[A\n",
      "Epoch 1:  29%|█████████▌                       | 52/180 [00:09<00:21,  5.96it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  29%|█████████▋                       | 53/180 [00:09<00:21,  6.02it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  29%|█████████▋                       | 53/180 [00:09<00:21,  6.02it/s, training_loss=0.346]\u001b[A\n",
      "Epoch 1:  30%|█████████▉                       | 54/180 [00:09<00:20,  6.00it/s, training_loss=0.346]\u001b[A\n",
      "Epoch 1:  30%|█████████▉                       | 54/180 [00:09<00:20,  6.00it/s, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  31%|██████████                       | 55/180 [00:09<00:20,  6.01it/s, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  31%|██████████                       | 55/180 [00:09<00:20,  6.01it/s, training_loss=0.474]\u001b[A\n",
      "Epoch 1:  31%|██████████▎                      | 56/180 [00:09<00:20,  5.99it/s, training_loss=0.474]\u001b[A\n",
      "Epoch 1:  31%|██████████▎                      | 56/180 [00:09<00:20,  5.99it/s, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  32%|██████████▍                      | 57/180 [00:09<00:20,  6.02it/s, training_loss=0.386]\u001b[A\n",
      "Epoch 1:  32%|██████████▍                      | 57/180 [00:10<00:20,  6.02it/s, training_loss=0.439]\u001b[A\n",
      "Epoch 1:  32%|██████████▋                      | 58/180 [00:10<00:20,  5.99it/s, training_loss=0.439]\u001b[A\n",
      "Epoch 1:  32%|██████████▋                      | 58/180 [00:10<00:20,  5.99it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  33%|██████████▊                      | 59/180 [00:10<00:19,  6.17it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  33%|██████████▊                      | 59/180 [00:10<00:19,  6.17it/s, training_loss=0.408]\u001b[A\n",
      "Epoch 1:  33%|███████████                      | 60/180 [00:10<00:19,  6.12it/s, training_loss=0.408]\u001b[A\n",
      "Epoch 1:  33%|███████████                      | 60/180 [00:10<00:19,  6.12it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  34%|███████████▏                     | 61/180 [00:10<00:19,  6.08it/s, training_loss=0.364]\u001b[A\n",
      "Epoch 1:  34%|███████████▏                     | 61/180 [00:10<00:19,  6.08it/s, training_loss=0.424]\u001b[A\n",
      "Epoch 1:  34%|███████████▎                     | 62/180 [00:10<00:19,  6.05it/s, training_loss=0.424]\u001b[A\n",
      "Epoch 1:  34%|███████████▎                     | 62/180 [00:10<00:19,  6.05it/s, training_loss=0.452]\u001b[A\n",
      "Epoch 1:  35%|███████████▌                     | 63/180 [00:10<00:19,  6.03it/s, training_loss=0.452]\u001b[A\n",
      "Epoch 1:  35%|███████████▌                     | 63/180 [00:11<00:19,  6.03it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  36%|███████████▋                     | 64/180 [00:11<00:19,  5.94it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  36%|███████████▋                     | 64/180 [00:11<00:19,  5.94it/s, training_loss=0.417]\u001b[A\n",
      "Epoch 1:  36%|███████████▉                     | 65/180 [00:11<00:19,  6.04it/s, training_loss=0.417]\u001b[A\n",
      "Epoch 1:  36%|███████████▉                     | 65/180 [00:11<00:19,  6.04it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  37%|████████████                     | 66/180 [00:11<00:18,  6.03it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  37%|████████████                     | 66/180 [00:11<00:18,  6.03it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  37%|████████████▎                    | 67/180 [00:11<00:18,  6.02it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  37%|████████████▎                    | 67/180 [00:11<00:18,  6.02it/s, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  38%|████████████▍                    | 68/180 [00:11<00:18,  6.01it/s, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  38%|████████████▍                    | 68/180 [00:11<00:18,  6.01it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  38%|████████████▋                    | 69/180 [00:11<00:18,  6.01it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  38%|████████████▋                    | 69/180 [00:12<00:18,  6.01it/s, training_loss=0.397]\u001b[A\n",
      "Epoch 1:  39%|████████████▊                    | 70/180 [00:12<00:18,  5.97it/s, training_loss=0.397]\u001b[A\n",
      "Epoch 1:  39%|████████████▊                    | 70/180 [00:12<00:18,  5.97it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  39%|█████████████                    | 71/180 [00:12<00:18,  6.01it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  39%|█████████████                    | 71/180 [00:12<00:18,  6.01it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  40%|█████████████▏                   | 72/180 [00:12<00:17,  6.00it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 1:  40%|█████████████▏                   | 72/180 [00:12<00:17,  6.00it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  41%|█████████████▍                   | 73/180 [00:12<00:17,  6.00it/s, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  41%|█████████████▍                   | 73/180 [00:12<00:17,  6.00it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  41%|█████████████▌                   | 74/180 [00:12<00:17,  6.00it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  41%|█████████████▌                   | 74/180 [00:12<00:17,  6.00it/s, training_loss=0.376]\u001b[A\n",
      "Epoch 1:  42%|█████████████▊                   | 75/180 [00:12<00:17,  6.00it/s, training_loss=0.376]\u001b[A\n",
      "Epoch 1:  42%|█████████████▊                   | 75/180 [00:13<00:17,  6.00it/s, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  42%|█████████████▉                   | 76/180 [00:13<00:17,  5.99it/s, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  42%|█████████████▉                   | 76/180 [00:13<00:17,  5.99it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  43%|██████████████                   | 77/180 [00:13<00:17,  6.00it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  43%|██████████████                   | 77/180 [00:13<00:17,  6.00it/s, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  43%|██████████████▎                  | 78/180 [00:13<00:17,  6.00it/s, training_loss=0.304]\u001b[A\n",
      "Epoch 1:  43%|██████████████▎                  | 78/180 [00:13<00:17,  6.00it/s, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  44%|██████████████▍                  | 79/180 [00:13<00:16,  6.17it/s, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  44%|██████████████▍                  | 79/180 [00:13<00:16,  6.17it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  44%|██████████████▋                  | 80/180 [00:13<00:16,  6.12it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  44%|██████████████▋                  | 80/180 [00:13<00:16,  6.12it/s, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  45%|██████████████▊                  | 81/180 [00:13<00:16,  6.08it/s, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  45%|██████████████▊                  | 81/180 [00:13<00:16,  6.08it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  46%|███████████████                  | 82/180 [00:13<00:16,  6.00it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  46%|███████████████                  | 82/180 [00:14<00:16,  6.00it/s, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  46%|███████████████▏                 | 83/180 [00:14<00:16,  6.05it/s, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  46%|███████████████▏                 | 83/180 [00:14<00:16,  6.05it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  47%|███████████████▍                 | 84/180 [00:14<00:16,  5.87it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  47%|███████████████▍                 | 84/180 [00:14<00:16,  5.87it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  47%|███████████████▌                 | 85/180 [00:14<00:16,  5.90it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  47%|███████████████▌                 | 85/180 [00:14<00:16,  5.90it/s, training_loss=0.443]\u001b[A\n",
      "Epoch 1:  48%|███████████████▊                 | 86/180 [00:14<00:15,  6.10it/s, training_loss=0.443]\u001b[A\n",
      "Epoch 1:  48%|███████████████▊                 | 86/180 [00:14<00:15,  6.10it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  48%|███████████████▉                 | 87/180 [00:14<00:15,  6.07it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  48%|███████████████▉                 | 87/180 [00:14<00:15,  6.07it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  49%|████████████████▏                | 88/180 [00:15<00:15,  6.05it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  49%|████████████████▏                | 88/180 [00:15<00:15,  6.05it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  49%|████████████████▎                | 89/180 [00:15<00:15,  6.03it/s, training_loss=0.332]\u001b[A\n",
      "Epoch 1:  49%|████████████████▎                | 89/180 [00:15<00:15,  6.03it/s, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  50%|████████████████▌                | 90/180 [00:15<00:14,  6.02it/s, training_loss=0.289]\u001b[A\n",
      "Epoch 1:  50%|████████████████▌                | 90/180 [00:15<00:14,  6.02it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  51%|████████████████▋                | 91/180 [00:15<00:14,  6.01it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  51%|████████████████▋                | 91/180 [00:15<00:14,  6.01it/s, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  51%|████████████████▊                | 92/180 [00:15<00:14,  6.01it/s, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  51%|████████████████▊                | 92/180 [00:15<00:14,  6.01it/s, training_loss=0.444]\u001b[A\n",
      "Epoch 1:  52%|█████████████████                | 93/180 [00:15<00:14,  6.00it/s, training_loss=0.444]\u001b[A\n",
      "Epoch 1:  52%|█████████████████                | 93/180 [00:16<00:14,  6.00it/s, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  52%|█████████████████▏               | 94/180 [00:16<00:14,  5.86it/s, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  52%|█████████████████▏               | 94/180 [00:16<00:14,  5.86it/s, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  53%|█████████████████▍               | 95/180 [00:16<00:14,  6.04it/s, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  53%|█████████████████▍               | 95/180 [00:16<00:14,  6.04it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  53%|█████████████████▌               | 96/180 [00:16<00:13,  6.03it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  53%|█████████████████▌               | 96/180 [00:16<00:13,  6.03it/s, training_loss=0.372]\u001b[A\n",
      "Epoch 1:  54%|█████████████████▊               | 97/180 [00:16<00:13,  6.02it/s, training_loss=0.372]\u001b[A\n",
      "Epoch 1:  54%|█████████████████▊               | 97/180 [00:16<00:13,  6.02it/s, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  54%|█████████████████▉               | 98/180 [00:16<00:13,  6.01it/s, training_loss=0.307]\u001b[A\n",
      "Epoch 1:  54%|█████████████████▉               | 98/180 [00:16<00:13,  6.01it/s, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  55%|██████████████████▏              | 99/180 [00:16<00:13,  5.84it/s, training_loss=0.274]\u001b[A\n",
      "Epoch 1:  55%|██████████████████▏              | 99/180 [00:16<00:13,  5.84it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  56%|█████████████████▊              | 100/180 [00:17<00:13,  5.87it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  56%|█████████████████▊              | 100/180 [00:17<00:13,  5.87it/s, training_loss=0.447]\u001b[A\n",
      "Epoch 1:  56%|█████████████████▉              | 101/180 [00:17<00:13,  5.92it/s, training_loss=0.447]\u001b[A\n",
      "Epoch 1:  56%|█████████████████▉              | 101/180 [00:17<00:13,  5.92it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  57%|██████████████████▏             | 102/180 [00:17<00:13,  5.94it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  57%|██████████████████▏             | 102/180 [00:17<00:13,  5.94it/s, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  57%|██████████████████▎             | 103/180 [00:17<00:12,  5.96it/s, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  57%|██████████████████▎             | 103/180 [00:17<00:12,  5.96it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  58%|██████████████████▍             | 104/180 [00:17<00:12,  5.97it/s, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  58%|██████████████████▍             | 104/180 [00:17<00:12,  5.97it/s, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  58%|██████████████████▋             | 105/180 [00:17<00:12,  5.98it/s, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  58%|██████████████████▋             | 105/180 [00:18<00:12,  5.98it/s, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  59%|██████████████████▊             | 106/180 [00:18<00:12,  5.96it/s, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  59%|██████████████████▊             | 106/180 [00:18<00:12,  5.96it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  59%|███████████████████             | 107/180 [00:18<00:12,  5.99it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  59%|███████████████████             | 107/180 [00:18<00:12,  5.99it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  60%|███████████████████▏            | 108/180 [00:18<00:12,  5.99it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  60%|███████████████████▏            | 108/180 [00:18<00:12,  5.99it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  61%|███████████████████▍            | 109/180 [00:18<00:11,  5.99it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  61%|███████████████████▍            | 109/180 [00:18<00:11,  5.99it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  61%|███████████████████▌            | 110/180 [00:18<00:11,  5.99it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  61%|███████████████████▌            | 110/180 [00:18<00:11,  5.99it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  62%|███████████████████▋            | 111/180 [00:18<00:11,  5.98it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  62%|███████████████████▋            | 111/180 [00:19<00:11,  5.98it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  62%|███████████████████▉            | 112/180 [00:19<00:11,  5.93it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  62%|███████████████████▉            | 112/180 [00:19<00:11,  5.93it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  63%|████████████████████            | 113/180 [00:19<00:11,  6.00it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  63%|████████████████████            | 113/180 [00:19<00:11,  6.00it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  63%|████████████████████▎           | 114/180 [00:19<00:11,  6.00it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 1:  63%|████████████████████▎           | 114/180 [00:19<00:11,  6.00it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  64%|████████████████████▍           | 115/180 [00:19<00:10,  6.00it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  64%|████████████████████▍           | 115/180 [00:19<00:10,  6.00it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  64%|████████████████████▌           | 116/180 [00:19<00:10,  6.00it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  64%|████████████████████▌           | 116/180 [00:19<00:10,  6.00it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  65%|████████████████████▊           | 117/180 [00:19<00:10,  5.99it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  65%|████████████████████▊           | 117/180 [00:20<00:10,  5.99it/s, training_loss=0.372]\u001b[A\n",
      "Epoch 1:  66%|████████████████████▉           | 118/180 [00:20<00:10,  5.86it/s, training_loss=0.372]\u001b[A\n",
      "Epoch 1:  66%|████████████████████▉           | 118/180 [00:20<00:10,  5.86it/s, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  66%|█████████████████████▏          | 119/180 [00:20<00:10,  5.87it/s, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  66%|█████████████████████▏          | 119/180 [00:20<00:10,  5.87it/s, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  67%|█████████████████████▎          | 120/180 [00:20<00:10,  5.90it/s, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  67%|█████████████████████▎          | 120/180 [00:20<00:10,  5.90it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  67%|█████████████████████▌          | 121/180 [00:20<00:09,  5.93it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  67%|█████████████████████▌          | 121/180 [00:20<00:09,  5.93it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  68%|█████████████████████▋          | 122/180 [00:20<00:09,  5.95it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  68%|█████████████████████▋          | 122/180 [00:20<00:09,  5.95it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  68%|█████████████████████▊          | 123/180 [00:20<00:09,  5.96it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  68%|█████████████████████▊          | 123/180 [00:21<00:09,  5.96it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  69%|██████████████████████          | 124/180 [00:21<00:09,  5.94it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  69%|██████████████████████          | 124/180 [00:21<00:09,  5.94it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 1:  69%|██████████████████████▏         | 125/180 [00:21<00:09,  5.99it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 1:  69%|██████████████████████▏         | 125/180 [00:21<00:09,  5.99it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  70%|██████████████████████▍         | 126/180 [00:21<00:09,  5.91it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 1:  70%|██████████████████████▍         | 126/180 [00:21<00:09,  5.91it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  71%|██████████████████████▌         | 127/180 [00:21<00:08,  6.01it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  71%|██████████████████████▌         | 127/180 [00:21<00:08,  6.01it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  71%|██████████████████████▊         | 128/180 [00:21<00:08,  6.01it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  71%|██████████████████████▊         | 128/180 [00:21<00:08,  6.01it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  72%|██████████████████████▉         | 129/180 [00:21<00:08,  6.00it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  72%|██████████████████████▉         | 129/180 [00:22<00:08,  6.00it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  72%|███████████████████████         | 130/180 [00:22<00:08,  5.92it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  72%|███████████████████████         | 130/180 [00:22<00:08,  5.92it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 1:  73%|███████████████████████▎        | 131/180 [00:22<00:08,  6.02it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 1:  73%|███████████████████████▎        | 131/180 [00:22<00:08,  6.02it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  73%|███████████████████████▍        | 132/180 [00:22<00:07,  6.01it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  73%|███████████████████████▍        | 132/180 [00:22<00:07,  6.01it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  74%|███████████████████████▋        | 133/180 [00:22<00:07,  6.01it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  74%|███████████████████████▋        | 133/180 [00:22<00:07,  6.01it/s, training_loss=0.179]\u001b[A\n",
      "Epoch 1:  74%|███████████████████████▊        | 134/180 [00:22<00:07,  6.00it/s, training_loss=0.179]\u001b[A\n",
      "Epoch 1:  74%|███████████████████████▊        | 134/180 [00:22<00:07,  6.00it/s, training_loss=0.414]\u001b[A\n",
      "Epoch 1:  75%|████████████████████████        | 135/180 [00:22<00:07,  5.99it/s, training_loss=0.414]\u001b[A\n",
      "Epoch 1:  75%|████████████████████████        | 135/180 [00:23<00:07,  5.99it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  76%|████████████████████████▏       | 136/180 [00:23<00:07,  5.95it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  76%|████████████████████████▏       | 136/180 [00:23<00:07,  5.95it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  76%|████████████████████████▎       | 137/180 [00:23<00:07,  6.00it/s, training_loss=0.318]\u001b[A\n",
      "Epoch 1:  76%|████████████████████████▎       | 137/180 [00:23<00:07,  6.00it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  77%|████████████████████████▌       | 138/180 [00:23<00:06,  6.00it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 1:  77%|████████████████████████▌       | 138/180 [00:23<00:06,  6.00it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 1:  77%|████████████████████████▋       | 139/180 [00:23<00:06,  6.00it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 1:  77%|████████████████████████▋       | 139/180 [00:23<00:06,  6.00it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  78%|████████████████████████▉       | 140/180 [00:23<00:06,  6.00it/s, training_loss=0.313]\u001b[A\n",
      "Epoch 1:  78%|████████████████████████▉       | 140/180 [00:23<00:06,  6.00it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  78%|█████████████████████████       | 141/180 [00:23<00:06,  5.84it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  78%|█████████████████████████       | 141/180 [00:24<00:06,  5.84it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 1:  79%|█████████████████████████▏      | 142/180 [00:24<00:06,  5.88it/s, training_loss=0.352]\u001b[A\n",
      "Epoch 1:  79%|█████████████████████████▏      | 142/180 [00:24<00:06,  5.88it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  79%|█████████████████████████▍      | 143/180 [00:24<00:06,  5.91it/s, training_loss=0.271]\u001b[A\n",
      "Epoch 1:  79%|█████████████████████████▍      | 143/180 [00:24<00:06,  5.91it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  80%|█████████████████████████▌      | 144/180 [00:24<00:06,  5.93it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  80%|█████████████████████████▌      | 144/180 [00:24<00:06,  5.93it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  81%|█████████████████████████▊      | 145/180 [00:24<00:05,  5.95it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  81%|█████████████████████████▊      | 145/180 [00:24<00:05,  5.95it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  81%|█████████████████████████▉      | 146/180 [00:24<00:05,  5.96it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 1:  81%|█████████████████████████▉      | 146/180 [00:24<00:05,  5.96it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 1:  82%|██████████████████████████▏     | 147/180 [00:24<00:05,  5.97it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 1:  82%|██████████████████████████▏     | 147/180 [00:25<00:05,  5.97it/s, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  82%|██████████████████████████▎     | 148/180 [00:25<00:05,  5.96it/s, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  82%|██████████████████████████▎     | 148/180 [00:25<00:05,  5.96it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 1:  83%|██████████████████████████▍     | 149/180 [00:25<00:05,  5.98it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 1:  83%|██████████████████████████▍     | 149/180 [00:25<00:05,  5.98it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  83%|██████████████████████████▋     | 150/180 [00:25<00:05,  5.98it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 1:  83%|██████████████████████████▋     | 150/180 [00:25<00:05,  5.98it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  84%|██████████████████████████▊     | 151/180 [00:25<00:04,  5.99it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 1:  84%|██████████████████████████▊     | 151/180 [00:25<00:04,  5.99it/s, training_loss=0.384]\u001b[A\n",
      "Epoch 1:  84%|███████████████████████████     | 152/180 [00:25<00:04,  5.99it/s, training_loss=0.384]\u001b[A\n",
      "Epoch 1:  84%|███████████████████████████     | 152/180 [00:25<00:04,  5.99it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  85%|███████████████████████████▏    | 153/180 [00:25<00:04,  5.99it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 1:  85%|███████████████████████████▏    | 153/180 [00:26<00:04,  5.99it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  86%|███████████████████████████▍    | 154/180 [00:26<00:04,  5.97it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  86%|███████████████████████████▍    | 154/180 [00:26<00:04,  5.97it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  86%|███████████████████████████▌    | 155/180 [00:26<00:04,  6.00it/s, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  86%|███████████████████████████▌    | 155/180 [00:26<00:04,  6.00it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████▋    | 156/180 [00:26<00:04,  5.83it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████▋    | 156/180 [00:26<00:04,  5.83it/s, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████▉    | 157/180 [00:26<00:03,  5.88it/s, training_loss=0.236]\u001b[A\n",
      "Epoch 1:  87%|███████████████████████████▉    | 157/180 [00:26<00:03,  5.88it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████    | 158/180 [00:26<00:03,  5.91it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████    | 158/180 [00:26<00:03,  5.91it/s, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████▎   | 159/180 [00:26<00:03,  5.94it/s, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  88%|████████████████████████████▎   | 159/180 [00:27<00:03,  5.94it/s, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████▍   | 160/180 [00:27<00:03,  5.95it/s, training_loss=0.254]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████▍   | 160/180 [00:27<00:03,  5.95it/s, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████▌   | 161/180 [00:27<00:03,  5.96it/s, training_loss=0.262]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████▌   | 161/180 [00:27<00:03,  5.96it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  90%|████████████████████████████▊   | 162/180 [00:27<00:03,  5.97it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  90%|████████████████████████████▊   | 162/180 [00:27<00:03,  5.97it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 1:  91%|████████████████████████████▉   | 163/180 [00:27<00:02,  5.97it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 1:  91%|████████████████████████████▉   | 163/180 [00:27<00:02,  5.97it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████▏  | 164/180 [00:27<00:02,  5.98it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████▏  | 164/180 [00:27<00:02,  5.98it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  92%|█████████████████████████████▎  | 165/180 [00:27<00:02,  5.98it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  92%|█████████████████████████████▎  | 165/180 [00:28<00:02,  5.98it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 1:  92%|█████████████████████████████▌  | 166/180 [00:28<00:02,  5.97it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 1:  92%|█████████████████████████████▌  | 166/180 [00:28<00:02,  5.97it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 1:  93%|█████████████████████████████▋  | 167/180 [00:28<00:02,  6.00it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 1:  93%|█████████████████████████████▋  | 167/180 [00:28<00:02,  6.00it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  93%|█████████████████████████████▊  | 168/180 [00:28<00:02,  5.99it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 1:  93%|█████████████████████████████▊  | 168/180 [00:28<00:02,  5.99it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 1:  94%|██████████████████████████████  | 169/180 [00:28<00:01,  5.99it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 1:  94%|██████████████████████████████  | 169/180 [00:28<00:01,  5.99it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 1:  94%|██████████████████████████████▏ | 170/180 [00:28<00:01,  5.99it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 1:  94%|██████████████████████████████▏ | 170/180 [00:28<00:01,  5.99it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  95%|██████████████████████████████▍ | 171/180 [00:28<00:01,  5.99it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  95%|██████████████████████████████▍ | 171/180 [00:29<00:01,  5.99it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  96%|██████████████████████████████▌ | 172/180 [00:29<00:01,  5.82it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  96%|██████████████████████████████▌ | 172/180 [00:29<00:01,  5.82it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  96%|██████████████████████████████▊ | 173/180 [00:29<00:01,  5.87it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  96%|██████████████████████████████▊ | 173/180 [00:29<00:01,  5.87it/s, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  97%|██████████████████████████████▉ | 174/180 [00:29<00:01,  5.93it/s, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  97%|██████████████████████████████▉ | 174/180 [00:29<00:01,  5.93it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  97%|███████████████████████████████ | 175/180 [00:29<00:00,  5.92it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  97%|███████████████████████████████ | 175/180 [00:29<00:00,  5.92it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  98%|███████████████████████████████▎| 176/180 [00:29<00:00,  5.94it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  98%|███████████████████████████████▎| 176/180 [00:29<00:00,  5.94it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  98%|███████████████████████████████▍| 177/180 [00:29<00:00,  5.96it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  98%|███████████████████████████████▍| 177/180 [00:30<00:00,  5.96it/s, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  99%|███████████████████████████████▋| 178/180 [00:30<00:00,  5.95it/s, training_loss=0.324]\u001b[A\n",
      "Epoch 1:  99%|███████████████████████████████▋| 178/180 [00:30<00:00,  5.95it/s, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  99%|███████████████████████████████▊| 179/180 [00:30<00:00,  5.98it/s, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  99%|███████████████████████████████▊| 179/180 [00:30<00:00,  5.98it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████| 180/180 [00:30<00:00,  6.54it/s, training_loss=0.245]\u001b[A\n",
      "Epoch Progress:   2%|█▏                                               | 1/40 [00:30<19:45, 30.41s/it]\u001b[A\n",
      "Epoch 2:   0%|                                                               | 0/180 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|                                          | 0/180 [00:00<?, ?it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 2:   1%|▏                                 | 1/180 [00:00<00:29,  6.00it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 2:   1%|▏                                 | 1/180 [00:00<00:29,  6.00it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 2:   1%|▍                                 | 2/180 [00:00<00:28,  6.14it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 2:   1%|▍                                 | 2/180 [00:00<00:28,  6.14it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 2:   2%|▌                                 | 3/180 [00:00<00:29,  6.07it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 2:   2%|▌                                 | 3/180 [00:00<00:29,  6.07it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 2:   2%|▊                                 | 4/180 [00:00<00:29,  6.03it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 2:   2%|▊                                 | 4/180 [00:00<00:29,  6.03it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:   3%|▉                                 | 5/180 [00:00<00:30,  5.83it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:   3%|▉                                 | 5/180 [00:01<00:30,  5.83it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 2:   3%|█▏                                | 6/180 [00:01<00:29,  5.87it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 2:   3%|█▏                                | 6/180 [00:01<00:29,  5.87it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 2:   4%|█▎                                | 7/180 [00:01<00:29,  5.91it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 2:   4%|█▎                                | 7/180 [00:01<00:29,  5.91it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 2:   4%|█▌                                | 8/180 [00:01<00:28,  5.94it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 2:   4%|█▌                                | 8/180 [00:01<00:28,  5.94it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 2:   5%|█▋                                | 9/180 [00:01<00:28,  5.95it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 2:   5%|█▋                                | 9/180 [00:01<00:28,  5.95it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 2:   6%|█▊                               | 10/180 [00:01<00:28,  5.90it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 2:   6%|█▊                               | 10/180 [00:01<00:28,  5.90it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:   6%|██                               | 11/180 [00:01<00:28,  5.99it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:   6%|██                               | 11/180 [00:02<00:28,  5.99it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 2:   7%|██▏                              | 12/180 [00:02<00:28,  5.99it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 2:   7%|██▏                              | 12/180 [00:02<00:28,  5.99it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:   7%|██▍                              | 13/180 [00:02<00:27,  5.99it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:   7%|██▍                              | 13/180 [00:02<00:27,  5.99it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 2:   8%|██▌                              | 14/180 [00:02<00:27,  5.99it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 2:   8%|██▌                              | 14/180 [00:02<00:27,  5.99it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:   8%|██▊                              | 15/180 [00:02<00:27,  5.99it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:   8%|██▊                              | 15/180 [00:02<00:27,  5.99it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 2:   9%|██▉                              | 16/180 [00:02<00:27,  6.00it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 2:   9%|██▉                              | 16/180 [00:02<00:27,  6.00it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 2:   9%|███                              | 17/180 [00:02<00:27,  5.99it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 2:   9%|███                              | 17/180 [00:03<00:27,  5.99it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  10%|███▎                             | 18/180 [00:03<00:27,  5.99it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  10%|███▎                             | 18/180 [00:03<00:27,  5.99it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 2:  11%|███▍                             | 19/180 [00:03<00:26,  5.98it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 2:  11%|███▍                             | 19/180 [00:03<00:26,  5.98it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  11%|███▋                             | 20/180 [00:03<00:26,  5.99it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  11%|███▋                             | 20/180 [00:03<00:26,  5.99it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 2:  12%|███▊                             | 21/180 [00:03<00:26,  5.99it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 2:  12%|███▊                             | 21/180 [00:03<00:26,  5.99it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 2:  12%|████                             | 22/180 [00:03<00:26,  6.00it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 2:  12%|████                             | 22/180 [00:03<00:26,  6.00it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 2:  13%|████▏                            | 23/180 [00:03<00:26,  5.99it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 2:  13%|████▏                            | 23/180 [00:04<00:26,  5.99it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 2:  13%|████▍                            | 24/180 [00:04<00:26,  5.99it/s, training_loss=0.124]\u001b[A\n",
      "Epoch 2:  13%|████▍                            | 24/180 [00:04<00:26,  5.99it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  14%|████▌                            | 25/180 [00:04<00:25,  5.97it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  14%|████▌                            | 25/180 [00:04<00:25,  5.97it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  14%|████▊                            | 26/180 [00:04<00:26,  5.83it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  14%|████▊                            | 26/180 [00:04<00:26,  5.83it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  15%|████▉                            | 27/180 [00:04<00:26,  5.88it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  15%|████▉                            | 27/180 [00:04<00:26,  5.88it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  16%|█████▏                           | 28/180 [00:04<00:25,  5.93it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  16%|█████▏                           | 28/180 [00:04<00:25,  5.93it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  16%|█████▎                           | 29/180 [00:04<00:25,  5.93it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  16%|█████▎                           | 29/180 [00:05<00:25,  5.93it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  17%|█████▌                           | 30/180 [00:05<00:25,  5.95it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  17%|█████▌                           | 30/180 [00:05<00:25,  5.95it/s, training_loss=0.294]\u001b[A\n",
      "Epoch 2:  17%|█████▋                           | 31/180 [00:05<00:24,  5.96it/s, training_loss=0.294]\u001b[A\n",
      "Epoch 2:  17%|█████▋                           | 31/180 [00:05<00:24,  5.96it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 2:  18%|█████▊                           | 32/180 [00:05<00:24,  5.97it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 2:  18%|█████▊                           | 32/180 [00:05<00:24,  5.97it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  18%|██████                           | 33/180 [00:05<00:24,  5.97it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  18%|██████                           | 33/180 [00:05<00:24,  5.97it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 2:  19%|██████▏                          | 34/180 [00:05<00:24,  5.99it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 2:  19%|██████▏                          | 34/180 [00:05<00:24,  5.99it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 2:  19%|██████▍                          | 35/180 [00:05<00:24,  6.01it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 2:  19%|██████▍                          | 35/180 [00:06<00:24,  6.01it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 2:  20%|██████▌                          | 36/180 [00:06<00:24,  5.97it/s, training_loss=0.223]\u001b[A\n",
      "Epoch 2:  20%|██████▌                          | 36/180 [00:06<00:24,  5.97it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 2:  21%|██████▊                          | 37/180 [00:06<00:23,  5.98it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 2:  21%|██████▊                          | 37/180 [00:06<00:23,  5.98it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 2:  21%|██████▉                          | 38/180 [00:06<00:23,  5.98it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 2:  21%|██████▉                          | 38/180 [00:06<00:23,  5.98it/s, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  22%|███████▏                         | 39/180 [00:06<00:23,  5.99it/s, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  22%|███████▏                         | 39/180 [00:06<00:23,  5.99it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 2:  22%|███████▎                         | 40/180 [00:06<00:23,  6.00it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 2:  22%|███████▎                         | 40/180 [00:06<00:23,  6.00it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 2:  23%|███████▌                         | 41/180 [00:06<00:23,  5.99it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 2:  23%|███████▌                         | 41/180 [00:07<00:23,  5.99it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  23%|███████▋                         | 42/180 [00:07<00:23,  5.98it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  23%|███████▋                         | 42/180 [00:07<00:23,  5.98it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 2:  24%|███████▉                         | 43/180 [00:07<00:22,  5.99it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 2:  24%|███████▉                         | 43/180 [00:07<00:22,  5.99it/s, training_loss=0.281]\u001b[A\n",
      "Epoch 2:  24%|████████                         | 44/180 [00:07<00:22,  5.99it/s, training_loss=0.281]\u001b[A\n",
      "Epoch 2:  24%|████████                         | 44/180 [00:07<00:22,  5.99it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  25%|████████▎                        | 45/180 [00:07<00:22,  5.99it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  25%|████████▎                        | 45/180 [00:07<00:22,  5.99it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 2:  26%|████████▍                        | 46/180 [00:07<00:22,  5.84it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 2:  26%|████████▍                        | 46/180 [00:07<00:22,  5.84it/s, training_loss=0.268]\u001b[A\n",
      "Epoch 2:  26%|████████▌                        | 47/180 [00:07<00:22,  5.86it/s, training_loss=0.268]\u001b[A\n",
      "Epoch 2:  26%|████████▌                        | 47/180 [00:08<00:22,  5.86it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 2:  27%|████████▊                        | 48/180 [00:08<00:22,  5.91it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 2:  27%|████████▊                        | 48/180 [00:08<00:22,  5.91it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  27%|████████▉                        | 49/180 [00:08<00:22,  5.90it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  27%|████████▉                        | 49/180 [00:08<00:22,  5.90it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 2:  28%|█████████▏                       | 50/180 [00:08<00:21,  5.98it/s, training_loss=0.177]\u001b[A\n",
      "Epoch 2:  28%|█████████▏                       | 50/180 [00:08<00:21,  5.98it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  28%|█████████▎                       | 51/180 [00:08<00:21,  5.96it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  28%|█████████▎                       | 51/180 [00:08<00:21,  5.96it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 2:  29%|█████████▌                       | 52/180 [00:08<00:21,  5.98it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 2:  29%|█████████▌                       | 52/180 [00:08<00:21,  5.98it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 2:  29%|█████████▋                       | 53/180 [00:08<00:21,  5.97it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 2:  29%|█████████▋                       | 53/180 [00:09<00:21,  5.97it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 2:  30%|█████████▉                       | 54/180 [00:09<00:21,  5.98it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 2:  30%|█████████▉                       | 54/180 [00:09<00:21,  5.98it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 2:  31%|██████████                       | 55/180 [00:09<00:20,  5.98it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 2:  31%|██████████                       | 55/180 [00:09<00:20,  5.98it/s, training_loss=0.260]\u001b[A\n",
      "Epoch 2:  31%|██████████▎                      | 56/180 [00:09<00:20,  5.98it/s, training_loss=0.260]\u001b[A\n",
      "Epoch 2:  31%|██████████▎                      | 56/180 [00:09<00:20,  5.98it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 2:  32%|██████████▍                      | 57/180 [00:09<00:20,  5.99it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 2:  32%|██████████▍                      | 57/180 [00:09<00:20,  5.99it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:  32%|██████████▋                      | 58/180 [00:09<00:20,  6.01it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:  32%|██████████▋                      | 58/180 [00:09<00:20,  6.01it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  33%|██████████▊                      | 59/180 [00:09<00:20,  5.99it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  33%|██████████▊                      | 59/180 [00:10<00:20,  5.99it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 2:  33%|███████████                      | 60/180 [00:10<00:20,  5.84it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 2:  33%|███████████                      | 60/180 [00:10<00:20,  5.84it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  34%|███████████▏                     | 61/180 [00:10<00:20,  5.86it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 2:  34%|███████████▏                     | 61/180 [00:10<00:20,  5.86it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  34%|███████████▎                     | 62/180 [00:10<00:20,  5.90it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  34%|███████████▎                     | 62/180 [00:10<00:20,  5.90it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 2:  35%|███████████▌                     | 63/180 [00:10<00:19,  5.93it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 2:  35%|███████████▌                     | 63/180 [00:10<00:19,  5.93it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  36%|███████████▋                     | 64/180 [00:10<00:19,  5.95it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  36%|███████████▋                     | 64/180 [00:10<00:19,  5.95it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 2:  36%|███████████▉                     | 65/180 [00:10<00:19,  5.95it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 2:  36%|███████████▉                     | 65/180 [00:11<00:19,  5.95it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  37%|████████████                     | 66/180 [00:11<00:19,  5.97it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  37%|████████████                     | 66/180 [00:11<00:19,  5.97it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 2:  37%|████████████▎                    | 67/180 [00:11<00:18,  5.97it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 2:  37%|████████████▎                    | 67/180 [00:11<00:18,  5.97it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 2:  38%|████████████▍                    | 68/180 [00:11<00:19,  5.81it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 2:  38%|████████████▍                    | 68/180 [00:11<00:19,  5.81it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  38%|████████████▋                    | 69/180 [00:11<00:18,  5.87it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  38%|████████████▋                    | 69/180 [00:11<00:18,  5.87it/s, training_loss=0.286]\u001b[A\n",
      "Epoch 2:  39%|████████████▊                    | 70/180 [00:11<00:18,  5.92it/s, training_loss=0.286]\u001b[A\n",
      "Epoch 2:  39%|████████████▊                    | 70/180 [00:11<00:18,  5.92it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 2:  39%|█████████████                    | 71/180 [00:11<00:18,  5.93it/s, training_loss=0.169]\u001b[A\n",
      "Epoch 2:  39%|█████████████                    | 71/180 [00:12<00:18,  5.93it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 2:  40%|█████████████▏                   | 72/180 [00:12<00:18,  5.96it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 2:  40%|█████████████▏                   | 72/180 [00:12<00:18,  5.96it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 2:  41%|█████████████▍                   | 73/180 [00:12<00:17,  5.97it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 2:  41%|█████████████▍                   | 73/180 [00:12<00:17,  5.97it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  41%|█████████████▌                   | 74/180 [00:12<00:17,  5.95it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  41%|█████████████▌                   | 74/180 [00:12<00:17,  5.95it/s, training_loss=0.171]\u001b[A\n",
      "Epoch 2:  42%|█████████████▊                   | 75/180 [00:12<00:17,  5.97it/s, training_loss=0.171]\u001b[A\n",
      "Epoch 2:  42%|█████████████▊                   | 75/180 [00:12<00:17,  5.97it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  42%|█████████████▉                   | 76/180 [00:12<00:17,  5.97it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  42%|█████████████▉                   | 76/180 [00:12<00:17,  5.97it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 2:  43%|██████████████                   | 77/180 [00:12<00:17,  5.98it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 2:  43%|██████████████                   | 77/180 [00:13<00:17,  5.98it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 2:  43%|██████████████▎                  | 78/180 [00:13<00:17,  5.82it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 2:  43%|██████████████▎                  | 78/180 [00:13<00:17,  5.82it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  44%|██████████████▍                  | 79/180 [00:13<00:17,  5.87it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  44%|██████████████▍                  | 79/180 [00:13<00:17,  5.87it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 2:  44%|██████████████▋                  | 80/180 [00:13<00:16,  5.91it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 2:  44%|██████████████▋                  | 80/180 [00:13<00:16,  5.91it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  45%|██████████████▊                  | 81/180 [00:13<00:16,  5.87it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  45%|██████████████▊                  | 81/180 [00:13<00:16,  5.87it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  46%|███████████████                  | 82/180 [00:13<00:16,  5.97it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  46%|███████████████                  | 82/180 [00:13<00:16,  5.97it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  46%|███████████████▏                 | 83/180 [00:13<00:16,  5.97it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  46%|███████████████▏                 | 83/180 [00:14<00:16,  5.97it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  47%|███████████████▍                 | 84/180 [00:14<00:16,  5.98it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  47%|███████████████▍                 | 84/180 [00:14<00:16,  5.98it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 2:  47%|███████████████▌                 | 85/180 [00:14<00:15,  5.98it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 2:  47%|███████████████▌                 | 85/180 [00:14<00:15,  5.98it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 2:  48%|███████████████▊                 | 86/180 [00:14<00:15,  5.98it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 2:  48%|███████████████▊                 | 86/180 [00:14<00:15,  5.98it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 2:  48%|███████████████▉                 | 87/180 [00:14<00:15,  5.82it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 2:  48%|███████████████▉                 | 87/180 [00:14<00:15,  5.82it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  49%|████████████████▏                | 88/180 [00:14<00:15,  5.85it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  49%|████████████████▏                | 88/180 [00:14<00:15,  5.85it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 2:  49%|████████████████▎                | 89/180 [00:14<00:15,  5.92it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 2:  49%|████████████████▎                | 89/180 [00:15<00:15,  5.92it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 2:  50%|████████████████▌                | 90/180 [00:15<00:15,  5.96it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 2:  50%|████████████████▌                | 90/180 [00:15<00:15,  5.96it/s, training_loss=0.259]\u001b[A\n",
      "Epoch 2:  51%|████████████████▋                | 91/180 [00:15<00:14,  5.94it/s, training_loss=0.259]\u001b[A\n",
      "Epoch 2:  51%|████████████████▋                | 91/180 [00:15<00:14,  5.94it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 2:  51%|████████████████▊                | 92/180 [00:15<00:14,  5.96it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 2:  51%|████████████████▊                | 92/180 [00:15<00:14,  5.96it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 2:  52%|█████████████████                | 93/180 [00:15<00:14,  5.84it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 2:  52%|█████████████████                | 93/180 [00:15<00:14,  5.84it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 2:  52%|█████████████████▏               | 94/180 [00:15<00:14,  6.01it/s, training_loss=0.233]\u001b[A\n",
      "Epoch 2:  52%|█████████████████▏               | 94/180 [00:15<00:14,  6.01it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 2:  53%|█████████████████▍               | 95/180 [00:15<00:14,  5.84it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 2:  53%|█████████████████▍               | 95/180 [00:16<00:14,  5.84it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 2:  53%|█████████████████▌               | 96/180 [00:16<00:14,  5.89it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 2:  53%|█████████████████▌               | 96/180 [00:16<00:14,  5.89it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  54%|█████████████████▊               | 97/180 [00:16<00:14,  5.92it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  54%|█████████████████▊               | 97/180 [00:16<00:14,  5.92it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  54%|█████████████████▉               | 98/180 [00:16<00:13,  5.93it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  54%|█████████████████▉               | 98/180 [00:16<00:13,  5.93it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 2:  55%|██████████████████▏              | 99/180 [00:16<00:13,  5.96it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 2:  55%|██████████████████▏              | 99/180 [00:16<00:13,  5.96it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 2:  56%|█████████████████▊              | 100/180 [00:16<00:13,  5.96it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 2:  56%|█████████████████▊              | 100/180 [00:16<00:13,  5.96it/s, training_loss=0.259]\u001b[A\n",
      "Epoch 2:  56%|█████████████████▉              | 101/180 [00:16<00:13,  5.97it/s, training_loss=0.259]\u001b[A\n",
      "Epoch 2:  56%|█████████████████▉              | 101/180 [00:17<00:13,  5.97it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  57%|██████████████████▏             | 102/180 [00:17<00:13,  5.97it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  57%|██████████████████▏             | 102/180 [00:17<00:13,  5.97it/s, training_loss=0.150]\u001b[A\n",
      "Epoch 2:  57%|██████████████████▎             | 103/180 [00:17<00:12,  5.98it/s, training_loss=0.150]\u001b[A\n",
      "Epoch 2:  57%|██████████████████▎             | 103/180 [00:17<00:12,  5.98it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  58%|██████████████████▍             | 104/180 [00:17<00:13,  5.81it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  58%|██████████████████▍             | 104/180 [00:17<00:13,  5.81it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 2:  58%|██████████████████▋             | 105/180 [00:17<00:12,  5.86it/s, training_loss=0.266]\u001b[A\n",
      "Epoch 2:  58%|██████████████████▋             | 105/180 [00:17<00:12,  5.86it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 2:  59%|██████████████████▊             | 106/180 [00:17<00:12,  5.90it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 2:  59%|██████████████████▊             | 106/180 [00:17<00:12,  5.90it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 2:  59%|███████████████████             | 107/180 [00:18<00:12,  5.93it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 2:  59%|███████████████████             | 107/180 [00:18<00:12,  5.93it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  60%|███████████████████▏            | 108/180 [00:18<00:12,  5.95it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  60%|███████████████████▏            | 108/180 [00:18<00:12,  5.95it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  61%|███████████████████▍            | 109/180 [00:18<00:11,  5.96it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  61%|███████████████████▍            | 109/180 [00:18<00:11,  5.96it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  61%|███████████████████▌            | 110/180 [00:18<00:11,  5.97it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  61%|███████████████████▌            | 110/180 [00:18<00:11,  5.97it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  62%|███████████████████▋            | 111/180 [00:18<00:11,  5.81it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  62%|███████████████████▋            | 111/180 [00:18<00:11,  5.81it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 2:  62%|███████████████████▉            | 112/180 [00:18<00:11,  5.86it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 2:  62%|███████████████████▉            | 112/180 [00:19<00:11,  5.86it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 2:  63%|████████████████████            | 113/180 [00:19<00:11,  5.90it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 2:  63%|████████████████████            | 113/180 [00:19<00:11,  5.90it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  63%|████████████████████▎           | 114/180 [00:19<00:11,  5.93it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  63%|████████████████████▎           | 114/180 [00:19<00:11,  5.93it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  64%|████████████████████▍           | 115/180 [00:19<00:10,  5.95it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  64%|████████████████████▍           | 115/180 [00:19<00:10,  5.95it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 2:  64%|████████████████████▌           | 116/180 [00:19<00:10,  5.95it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 2:  64%|████████████████████▌           | 116/180 [00:19<00:10,  5.95it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 2:  65%|████████████████████▊           | 117/180 [00:19<00:10,  5.77it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 2:  65%|████████████████████▊           | 117/180 [00:19<00:10,  5.77it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 2:  66%|████████████████████▉           | 118/180 [00:19<00:10,  5.87it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 2:  66%|████████████████████▉           | 118/180 [00:20<00:10,  5.87it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 2:  66%|█████████████████████▏          | 119/180 [00:20<00:10,  5.90it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 2:  66%|█████████████████████▏          | 119/180 [00:20<00:10,  5.90it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 2:  67%|█████████████████████▎          | 120/180 [00:20<00:10,  5.93it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 2:  67%|█████████████████████▎          | 120/180 [00:20<00:10,  5.93it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  67%|█████████████████████▌          | 121/180 [00:20<00:09,  5.95it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  67%|█████████████████████▌          | 121/180 [00:20<00:09,  5.95it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 2:  68%|█████████████████████▋          | 122/180 [00:20<00:09,  5.95it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 2:  68%|█████████████████████▋          | 122/180 [00:20<00:09,  5.95it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 2:  68%|█████████████████████▊          | 123/180 [00:20<00:09,  5.81it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 2:  68%|█████████████████████▊          | 123/180 [00:20<00:09,  5.81it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  69%|██████████████████████          | 124/180 [00:20<00:09,  5.85it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  69%|██████████████████████          | 124/180 [00:21<00:09,  5.85it/s, training_loss=0.254]\u001b[A\n",
      "Epoch 2:  69%|██████████████████████▏         | 125/180 [00:21<00:09,  5.90it/s, training_loss=0.254]\u001b[A\n",
      "Epoch 2:  69%|██████████████████████▏         | 125/180 [00:21<00:09,  5.90it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 2:  70%|██████████████████████▍         | 126/180 [00:21<00:09,  5.94it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 2:  70%|██████████████████████▍         | 126/180 [00:21<00:09,  5.94it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 2:  71%|██████████████████████▌         | 127/180 [00:21<00:08,  5.93it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 2:  71%|██████████████████████▌         | 127/180 [00:21<00:08,  5.93it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 2:  71%|██████████████████████▊         | 128/180 [00:21<00:08,  5.95it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 2:  71%|██████████████████████▊         | 128/180 [00:21<00:08,  5.95it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  72%|██████████████████████▉         | 129/180 [00:21<00:08,  5.81it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  72%|██████████████████████▉         | 129/180 [00:21<00:08,  5.81it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 2:  72%|███████████████████████         | 130/180 [00:21<00:08,  5.85it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 2:  72%|███████████████████████         | 130/180 [00:22<00:08,  5.85it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 2:  73%|███████████████████████▎        | 131/180 [00:22<00:08,  5.89it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 2:  73%|███████████████████████▎        | 131/180 [00:22<00:08,  5.89it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  73%|███████████████████████▍        | 132/180 [00:22<00:08,  5.92it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  73%|███████████████████████▍        | 132/180 [00:22<00:08,  5.92it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 2:  74%|███████████████████████▋        | 133/180 [00:22<00:07,  5.93it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 2:  74%|███████████████████████▋        | 133/180 [00:22<00:07,  5.93it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 2:  74%|███████████████████████▊        | 134/180 [00:22<00:07,  5.95it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 2:  74%|███████████████████████▊        | 134/180 [00:22<00:07,  5.95it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  75%|████████████████████████        | 135/180 [00:22<00:07,  5.80it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  75%|████████████████████████        | 135/180 [00:22<00:07,  5.80it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  76%|████████████████████████▏       | 136/180 [00:22<00:07,  5.85it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  76%|████████████████████████▏       | 136/180 [00:23<00:07,  5.85it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  76%|████████████████████████▎       | 137/180 [00:23<00:07,  5.89it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  76%|████████████████████████▎       | 137/180 [00:23<00:07,  5.89it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  77%|████████████████████████▌       | 138/180 [00:23<00:07,  5.92it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  77%|████████████████████████▌       | 138/180 [00:23<00:07,  5.92it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  77%|████████████████████████▋       | 139/180 [00:23<00:06,  5.94it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  77%|████████████████████████▋       | 139/180 [00:23<00:06,  5.94it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 2:  78%|████████████████████████▉       | 140/180 [00:23<00:06,  5.79it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 2:  78%|████████████████████████▉       | 140/180 [00:23<00:06,  5.79it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 2:  78%|█████████████████████████       | 141/180 [00:23<00:06,  5.85it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 2:  78%|█████████████████████████       | 141/180 [00:23<00:06,  5.85it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  79%|█████████████████████████▏      | 142/180 [00:23<00:06,  5.88it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  79%|█████████████████████████▏      | 142/180 [00:24<00:06,  5.88it/s, training_loss=0.300]\u001b[A\n",
      "Epoch 2:  79%|█████████████████████████▍      | 143/180 [00:24<00:06,  5.92it/s, training_loss=0.300]\u001b[A\n",
      "Epoch 2:  79%|█████████████████████████▍      | 143/180 [00:24<00:06,  5.92it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 2:  80%|█████████████████████████▌      | 144/180 [00:24<00:06,  5.94it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 2:  80%|█████████████████████████▌      | 144/180 [00:24<00:06,  5.94it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  81%|█████████████████████████▊      | 145/180 [00:24<00:05,  5.96it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  81%|█████████████████████████▊      | 145/180 [00:24<00:05,  5.96it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 2:  81%|█████████████████████████▉      | 146/180 [00:24<00:05,  5.80it/s, training_loss=0.264]\u001b[A\n",
      "Epoch 2:  81%|█████████████████████████▉      | 146/180 [00:24<00:05,  5.80it/s, training_loss=0.338]\u001b[A\n",
      "Epoch 2:  82%|██████████████████████████▏     | 147/180 [00:24<00:05,  5.86it/s, training_loss=0.338]\u001b[A\n",
      "Epoch 2:  82%|██████████████████████████▏     | 147/180 [00:24<00:05,  5.86it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 2:  82%|██████████████████████████▎     | 148/180 [00:24<00:05,  5.89it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 2:  82%|██████████████████████████▎     | 148/180 [00:25<00:05,  5.89it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  83%|██████████████████████████▍     | 149/180 [00:25<00:05,  5.92it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 2:  83%|██████████████████████████▍     | 149/180 [00:25<00:05,  5.92it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  83%|██████████████████████████▋     | 150/180 [00:25<00:05,  5.94it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  83%|██████████████████████████▋     | 150/180 [00:25<00:05,  5.94it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  84%|██████████████████████████▊     | 151/180 [00:25<00:05,  5.79it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  84%|██████████████████████████▊     | 151/180 [00:25<00:05,  5.79it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  84%|███████████████████████████     | 152/180 [00:25<00:04,  5.87it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 2:  84%|███████████████████████████     | 152/180 [00:25<00:04,  5.87it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 2:  85%|███████████████████████████▏    | 153/180 [00:25<00:04,  5.88it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 2:  85%|███████████████████████████▏    | 153/180 [00:25<00:04,  5.88it/s, training_loss=0.185]\u001b[A\n",
      "Epoch 2:  86%|███████████████████████████▍    | 154/180 [00:25<00:04,  5.91it/s, training_loss=0.185]\u001b[A\n",
      "Epoch 2:  86%|███████████████████████████▍    | 154/180 [00:26<00:04,  5.91it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 2:  86%|███████████████████████████▌    | 155/180 [00:26<00:04,  5.94it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 2:  86%|███████████████████████████▌    | 155/180 [00:26<00:04,  5.94it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████▋    | 156/180 [00:26<00:04,  5.79it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████▋    | 156/180 [00:26<00:04,  5.79it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████▉    | 157/180 [00:26<00:03,  5.84it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 2:  87%|███████████████████████████▉    | 157/180 [00:26<00:03,  5.84it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████    | 158/180 [00:26<00:03,  5.90it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████    | 158/180 [00:26<00:03,  5.90it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████▎   | 159/180 [00:26<00:03,  5.91it/s, training_loss=0.205]\u001b[A\n",
      "Epoch 2:  88%|████████████████████████████▎   | 159/180 [00:26<00:03,  5.91it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████▍   | 160/180 [00:26<00:03,  5.94it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████▍   | 160/180 [00:27<00:03,  5.94it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████▌   | 161/180 [00:27<00:03,  5.95it/s, training_loss=0.144]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████▌   | 161/180 [00:27<00:03,  5.95it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 2:  90%|████████████████████████████▊   | 162/180 [00:27<00:03,  5.79it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 2:  90%|████████████████████████████▊   | 162/180 [00:27<00:03,  5.79it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 2:  91%|████████████████████████████▉   | 163/180 [00:27<00:02,  5.85it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 2:  91%|████████████████████████████▉   | 163/180 [00:27<00:02,  5.85it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████▏  | 164/180 [00:27<00:02,  5.91it/s, training_loss=0.151]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████▏  | 164/180 [00:27<00:02,  5.91it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 2:  92%|█████████████████████████████▎  | 165/180 [00:27<00:02,  5.92it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 2:  92%|█████████████████████████████▎  | 165/180 [00:28<00:02,  5.92it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 2:  92%|█████████████████████████████▌  | 166/180 [00:28<00:02,  5.94it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 2:  92%|█████████████████████████████▌  | 166/180 [00:28<00:02,  5.94it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  93%|█████████████████████████████▋  | 167/180 [00:28<00:02,  5.78it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 2:  93%|█████████████████████████████▋  | 167/180 [00:28<00:02,  5.78it/s, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  93%|█████████████████████████████▊  | 168/180 [00:28<00:02,  5.85it/s, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  93%|█████████████████████████████▊  | 168/180 [00:28<00:02,  5.85it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  94%|██████████████████████████████  | 169/180 [00:28<00:01,  5.89it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  94%|██████████████████████████████  | 169/180 [00:28<00:01,  5.89it/s, training_loss=0.143]\u001b[A\n",
      "Epoch 2:  94%|██████████████████████████████▏ | 170/180 [00:28<00:01,  5.93it/s, training_loss=0.143]\u001b[A\n",
      "Epoch 2:  94%|██████████████████████████████▏ | 170/180 [00:28<00:01,  5.93it/s, training_loss=0.218]\u001b[A\n",
      "Epoch 2:  95%|██████████████████████████████▍ | 171/180 [00:28<00:01,  5.78it/s, training_loss=0.218]\u001b[A\n",
      "Epoch 2:  95%|██████████████████████████████▍ | 171/180 [00:29<00:01,  5.78it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 2:  96%|██████████████████████████████▌ | 172/180 [00:29<00:01,  5.80it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 2:  96%|██████████████████████████████▌ | 172/180 [00:29<00:01,  5.80it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  96%|██████████████████████████████▊ | 173/180 [00:29<00:01,  5.89it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 2:  96%|██████████████████████████████▊ | 173/180 [00:29<00:01,  5.89it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  97%|██████████████████████████████▉ | 174/180 [00:29<00:01,  5.83it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 2:  97%|██████████████████████████████▉ | 174/180 [00:29<00:01,  5.83it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  97%|███████████████████████████████ | 175/180 [00:29<00:00,  5.97it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  97%|███████████████████████████████ | 175/180 [00:29<00:00,  5.97it/s, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  98%|███████████████████████████████▎| 176/180 [00:29<00:00,  5.82it/s, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  98%|███████████████████████████████▎| 176/180 [00:29<00:00,  5.82it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 2:  98%|███████████████████████████████▍| 177/180 [00:29<00:00,  5.85it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 2:  98%|███████████████████████████████▍| 177/180 [00:30<00:00,  5.85it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 2:  99%|███████████████████████████████▋| 178/180 [00:30<00:00,  5.81it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 2:  99%|███████████████████████████████▋| 178/180 [00:30<00:00,  5.81it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 2:  99%|███████████████████████████████▊| 179/180 [00:30<00:00,  5.83it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 2:  99%|███████████████████████████████▊| 179/180 [00:30<00:00,  5.83it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████| 180/180 [00:30<00:00,  6.35it/s, training_loss=0.115]\u001b[A\n",
      "Epoch Progress:   5%|██▍                                              | 2/40 [01:00<19:14, 30.39s/it]\u001b[A\n",
      "Epoch 3:   0%|                                                               | 0/180 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|                                          | 0/180 [00:00<?, ?it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:   1%|▏                                 | 1/180 [00:00<00:32,  5.53it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:   1%|▏                                 | 1/180 [00:00<00:32,  5.53it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 3:   1%|▍                                 | 2/180 [00:00<00:31,  5.73it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 3:   1%|▍                                 | 2/180 [00:00<00:31,  5.73it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 3:   2%|▌                                 | 3/180 [00:00<00:30,  5.78it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 3:   2%|▌                                 | 3/180 [00:00<00:30,  5.78it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 3:   2%|▊                                 | 4/180 [00:00<00:30,  5.80it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 3:   2%|▊                                 | 4/180 [00:00<00:30,  5.80it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 3:   3%|▉                                 | 5/180 [00:00<00:30,  5.83it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 3:   3%|▉                                 | 5/180 [00:01<00:30,  5.83it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 3:   3%|█▏                                | 6/180 [00:01<00:29,  5.87it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 3:   3%|█▏                                | 6/180 [00:01<00:29,  5.87it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:   4%|█▎                                | 7/180 [00:01<00:29,  5.91it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:   4%|█▎                                | 7/180 [00:01<00:29,  5.91it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 3:   4%|█▌                                | 8/180 [00:01<00:28,  5.95it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 3:   4%|█▌                                | 8/180 [00:01<00:28,  5.95it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 3:   5%|█▋                                | 9/180 [00:01<00:29,  5.81it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 3:   5%|█▋                                | 9/180 [00:01<00:29,  5.81it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 3:   6%|█▊                               | 10/180 [00:01<00:29,  5.83it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 3:   6%|█▊                               | 10/180 [00:01<00:29,  5.83it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:   6%|██                               | 11/180 [00:01<00:29,  5.83it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:   6%|██                               | 11/180 [00:02<00:29,  5.83it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 3:   7%|██▏                              | 12/180 [00:02<00:28,  5.83it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 3:   7%|██▏                              | 12/180 [00:02<00:28,  5.83it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:   7%|██▍                              | 13/180 [00:02<00:28,  5.85it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:   7%|██▍                              | 13/180 [00:02<00:28,  5.85it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:   8%|██▌                              | 14/180 [00:02<00:28,  5.87it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:   8%|██▌                              | 14/180 [00:02<00:28,  5.87it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 3:   8%|██▊                              | 15/180 [00:02<00:28,  5.88it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 3:   8%|██▊                              | 15/180 [00:02<00:28,  5.88it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 3:   9%|██▉                              | 16/180 [00:02<00:27,  5.91it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 3:   9%|██▉                              | 16/180 [00:02<00:27,  5.91it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:   9%|███                              | 17/180 [00:02<00:27,  5.93it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:   9%|███                              | 17/180 [00:03<00:27,  5.93it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 3:  10%|███▎                             | 18/180 [00:03<00:27,  5.86it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 3:  10%|███▎                             | 18/180 [00:03<00:27,  5.86it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  11%|███▍                             | 19/180 [00:03<00:27,  5.87it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  11%|███▍                             | 19/180 [00:03<00:27,  5.87it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  11%|███▋                             | 20/180 [00:03<00:27,  5.86it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  11%|███▋                             | 20/180 [00:03<00:27,  5.86it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 3:  12%|███▊                             | 21/180 [00:03<00:26,  5.89it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 3:  12%|███▊                             | 21/180 [00:03<00:26,  5.89it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  12%|████                             | 22/180 [00:03<00:26,  5.87it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  12%|████                             | 22/180 [00:03<00:26,  5.87it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  13%|████▏                            | 23/180 [00:03<00:26,  5.88it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  13%|████▏                            | 23/180 [00:04<00:26,  5.88it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  13%|████▍                            | 24/180 [00:04<00:26,  5.88it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  13%|████▍                            | 24/180 [00:04<00:26,  5.88it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  14%|████▌                            | 25/180 [00:04<00:26,  5.86it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  14%|████▌                            | 25/180 [00:04<00:26,  5.86it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:  14%|████▊                            | 26/180 [00:04<00:26,  5.89it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:  14%|████▊                            | 26/180 [00:04<00:26,  5.89it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 3:  15%|████▉                            | 27/180 [00:04<00:26,  5.85it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 3:  15%|████▉                            | 27/180 [00:04<00:26,  5.85it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  16%|█████▏                           | 28/180 [00:04<00:25,  5.86it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  16%|█████▏                           | 28/180 [00:04<00:25,  5.86it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  16%|█████▎                           | 29/180 [00:04<00:25,  5.86it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  16%|█████▎                           | 29/180 [00:05<00:25,  5.86it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  17%|█████▌                           | 30/180 [00:05<00:25,  5.83it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  17%|█████▌                           | 30/180 [00:05<00:25,  5.83it/s, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  17%|█████▋                           | 31/180 [00:05<00:25,  5.84it/s, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  17%|█████▋                           | 31/180 [00:05<00:25,  5.84it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  18%|█████▊                           | 32/180 [00:05<00:25,  5.85it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  18%|█████▊                           | 32/180 [00:05<00:25,  5.85it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  18%|██████                           | 33/180 [00:05<00:25,  5.86it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  18%|██████                           | 33/180 [00:05<00:25,  5.86it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  19%|██████▏                          | 34/180 [00:05<00:24,  5.86it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  19%|██████▏                          | 34/180 [00:05<00:24,  5.86it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 3:  19%|██████▍                          | 35/180 [00:05<00:24,  5.84it/s, training_loss=0.058]\u001b[A\n",
      "Epoch 3:  19%|██████▍                          | 35/180 [00:06<00:24,  5.84it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 3:  20%|██████▌                          | 36/180 [00:06<00:24,  5.85it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 3:  20%|██████▌                          | 36/180 [00:06<00:24,  5.85it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 3:  21%|██████▊                          | 37/180 [00:06<00:24,  5.86it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 3:  21%|██████▊                          | 37/180 [00:06<00:24,  5.86it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 3:  21%|██████▉                          | 38/180 [00:06<00:24,  5.87it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 3:  21%|██████▉                          | 38/180 [00:06<00:24,  5.87it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 3:  22%|███████▏                         | 39/180 [00:06<00:23,  5.88it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 3:  22%|███████▏                         | 39/180 [00:06<00:23,  5.88it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  22%|███████▎                         | 40/180 [00:06<00:24,  5.80it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  22%|███████▎                         | 40/180 [00:07<00:24,  5.80it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 3:  23%|███████▌                         | 41/180 [00:07<00:23,  5.82it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 3:  23%|███████▌                         | 41/180 [00:07<00:23,  5.82it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  23%|███████▋                         | 42/180 [00:07<00:23,  5.83it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  23%|███████▋                         | 42/180 [00:07<00:23,  5.83it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  24%|███████▉                         | 43/180 [00:07<00:23,  5.85it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  24%|███████▉                         | 43/180 [00:07<00:23,  5.85it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 3:  24%|████████                         | 44/180 [00:07<00:23,  5.83it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 3:  24%|████████                         | 44/180 [00:07<00:23,  5.83it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  25%|████████▎                        | 45/180 [00:07<00:23,  5.80it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  25%|████████▎                        | 45/180 [00:07<00:23,  5.80it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 3:  26%|████████▍                        | 46/180 [00:07<00:23,  5.82it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 3:  26%|████████▍                        | 46/180 [00:08<00:23,  5.82it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  26%|████████▌                        | 47/180 [00:08<00:22,  5.82it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  26%|████████▌                        | 47/180 [00:08<00:22,  5.82it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  27%|████████▊                        | 48/180 [00:08<00:22,  5.83it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  27%|████████▊                        | 48/180 [00:08<00:22,  5.83it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  27%|████████▉                        | 49/180 [00:08<00:22,  5.83it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  27%|████████▉                        | 49/180 [00:08<00:22,  5.83it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 3:  28%|█████████▏                       | 50/180 [00:08<00:22,  5.85it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 3:  28%|█████████▏                       | 50/180 [00:08<00:22,  5.85it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  28%|█████████▎                       | 51/180 [00:08<00:22,  5.85it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  28%|█████████▎                       | 51/180 [00:08<00:22,  5.85it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  29%|█████████▌                       | 52/180 [00:08<00:21,  5.86it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  29%|█████████▌                       | 52/180 [00:09<00:21,  5.86it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 3:  29%|█████████▋                       | 53/180 [00:09<00:21,  5.84it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 3:  29%|█████████▋                       | 53/180 [00:09<00:21,  5.84it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  30%|█████████▉                       | 54/180 [00:09<00:21,  5.85it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  30%|█████████▉                       | 54/180 [00:09<00:21,  5.85it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  31%|██████████                       | 55/180 [00:09<00:21,  5.86it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  31%|██████████                       | 55/180 [00:09<00:21,  5.86it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  31%|██████████▎                      | 56/180 [00:09<00:20,  6.00it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  31%|██████████▎                      | 56/180 [00:09<00:20,  6.00it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 3:  32%|██████████▍                      | 57/180 [00:09<00:21,  5.73it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 3:  32%|██████████▍                      | 57/180 [00:09<00:21,  5.73it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 3:  32%|██████████▋                      | 58/180 [00:09<00:21,  5.78it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 3:  32%|██████████▋                      | 58/180 [00:10<00:21,  5.78it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 3:  33%|██████████▊                      | 59/180 [00:10<00:20,  5.80it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 3:  33%|██████████▊                      | 59/180 [00:10<00:20,  5.80it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 3:  33%|███████████                      | 60/180 [00:10<00:20,  5.79it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 3:  33%|███████████                      | 60/180 [00:10<00:20,  5.79it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  34%|███████████▏                     | 61/180 [00:10<00:20,  5.79it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  34%|███████████▏                     | 61/180 [00:10<00:20,  5.79it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 3:  34%|███████████▎                     | 62/180 [00:10<00:20,  5.81it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 3:  34%|███████████▎                     | 62/180 [00:10<00:20,  5.81it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 3:  35%|███████████▌                     | 63/180 [00:10<00:20,  5.80it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 3:  35%|███████████▌                     | 63/180 [00:10<00:20,  5.80it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 3:  36%|███████████▋                     | 64/180 [00:10<00:19,  5.82it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 3:  36%|███████████▋                     | 64/180 [00:11<00:19,  5.82it/s, training_loss=0.166]\u001b[A\n",
      "Epoch 3:  36%|███████████▉                     | 65/180 [00:11<00:19,  5.82it/s, training_loss=0.166]\u001b[A\n",
      "Epoch 3:  36%|███████████▉                     | 65/180 [00:11<00:19,  5.82it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 3:  37%|████████████                     | 66/180 [00:11<00:19,  5.82it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 3:  37%|████████████                     | 66/180 [00:11<00:19,  5.82it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  37%|████████████▎                    | 67/180 [00:11<00:19,  5.84it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  37%|████████████▎                    | 67/180 [00:11<00:19,  5.84it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  38%|████████████▍                    | 68/180 [00:11<00:19,  5.83it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  38%|████████████▍                    | 68/180 [00:11<00:19,  5.83it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 3:  38%|████████████▋                    | 69/180 [00:11<00:19,  5.81it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 3:  38%|████████████▋                    | 69/180 [00:11<00:19,  5.81it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  39%|████████████▊                    | 70/180 [00:11<00:18,  5.82it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  39%|████████████▊                    | 70/180 [00:12<00:18,  5.82it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  39%|█████████████                    | 71/180 [00:12<00:18,  5.83it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  39%|█████████████                    | 71/180 [00:12<00:18,  5.83it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 3:  40%|█████████████▏                   | 72/180 [00:12<00:18,  5.82it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 3:  40%|█████████████▏                   | 72/180 [00:12<00:18,  5.82it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 3:  41%|█████████████▍                   | 73/180 [00:12<00:18,  5.82it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 3:  41%|█████████████▍                   | 73/180 [00:12<00:18,  5.82it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  41%|█████████████▌                   | 74/180 [00:12<00:18,  5.81it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  41%|█████████████▌                   | 74/180 [00:12<00:18,  5.81it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  42%|█████████████▊                   | 75/180 [00:12<00:18,  5.82it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  42%|█████████████▊                   | 75/180 [00:13<00:18,  5.82it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  42%|█████████████▉                   | 76/180 [00:13<00:17,  5.83it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  42%|█████████████▉                   | 76/180 [00:13<00:17,  5.83it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 3:  43%|██████████████                   | 77/180 [00:13<00:17,  5.83it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 3:  43%|██████████████                   | 77/180 [00:13<00:17,  5.83it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 3:  43%|██████████████▎                  | 78/180 [00:13<00:17,  5.84it/s, training_loss=0.164]\u001b[A\n",
      "Epoch 3:  43%|██████████████▎                  | 78/180 [00:13<00:17,  5.84it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 3:  44%|██████████████▍                  | 79/180 [00:13<00:17,  5.84it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 3:  44%|██████████████▍                  | 79/180 [00:13<00:17,  5.84it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  44%|██████████████▋                  | 80/180 [00:13<00:17,  5.84it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  44%|██████████████▋                  | 80/180 [00:13<00:17,  5.84it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  45%|██████████████▊                  | 81/180 [00:13<00:16,  5.83it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  45%|██████████████▊                  | 81/180 [00:14<00:16,  5.83it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 3:  46%|███████████████                  | 82/180 [00:14<00:16,  5.83it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 3:  46%|███████████████                  | 82/180 [00:14<00:16,  5.83it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  46%|███████████████▏                 | 83/180 [00:14<00:16,  5.83it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  46%|███████████████▏                 | 83/180 [00:14<00:16,  5.83it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 3:  47%|███████████████▍                 | 84/180 [00:14<00:16,  5.83it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 3:  47%|███████████████▍                 | 84/180 [00:14<00:16,  5.83it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  47%|███████████████▌                 | 85/180 [00:14<00:16,  5.83it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  47%|███████████████▌                 | 85/180 [00:14<00:16,  5.83it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  48%|███████████████▊                 | 86/180 [00:14<00:16,  5.84it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  48%|███████████████▊                 | 86/180 [00:14<00:16,  5.84it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 3:  48%|███████████████▉                 | 87/180 [00:14<00:16,  5.77it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 3:  48%|███████████████▉                 | 87/180 [00:15<00:16,  5.77it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 3:  49%|████████████████▏                | 88/180 [00:15<00:15,  5.78it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 3:  49%|████████████████▏                | 88/180 [00:15<00:15,  5.78it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  49%|████████████████▎                | 89/180 [00:15<00:15,  5.80it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  49%|████████████████▎                | 89/180 [00:15<00:15,  5.80it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 3:  50%|████████████████▌                | 90/180 [00:15<00:15,  5.80it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 3:  50%|████████████████▌                | 90/180 [00:15<00:15,  5.80it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  51%|████████████████▋                | 91/180 [00:15<00:15,  5.82it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  51%|████████████████▋                | 91/180 [00:15<00:15,  5.82it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  51%|████████████████▊                | 92/180 [00:15<00:15,  5.83it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  51%|████████████████▊                | 92/180 [00:15<00:15,  5.83it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  52%|█████████████████                | 93/180 [00:15<00:14,  5.82it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  52%|█████████████████                | 93/180 [00:16<00:14,  5.82it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  52%|█████████████████▏               | 94/180 [00:16<00:14,  5.83it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  52%|█████████████████▏               | 94/180 [00:16<00:14,  5.83it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 3:  53%|█████████████████▍               | 95/180 [00:16<00:14,  5.82it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 3:  53%|█████████████████▍               | 95/180 [00:16<00:14,  5.82it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  53%|█████████████████▌               | 96/180 [00:16<00:14,  5.83it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  53%|█████████████████▌               | 96/180 [00:16<00:14,  5.83it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 3:  54%|█████████████████▊               | 97/180 [00:16<00:14,  5.84it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 3:  54%|█████████████████▊               | 97/180 [00:16<00:14,  5.84it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  54%|█████████████████▉               | 98/180 [00:16<00:14,  5.84it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  54%|█████████████████▉               | 98/180 [00:16<00:14,  5.84it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  55%|██████████████████▏              | 99/180 [00:16<00:13,  5.85it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  55%|██████████████████▏              | 99/180 [00:17<00:13,  5.85it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 3:  56%|█████████████████▊              | 100/180 [00:17<00:13,  5.84it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 3:  56%|█████████████████▊              | 100/180 [00:17<00:13,  5.84it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  56%|█████████████████▉              | 101/180 [00:17<00:13,  5.81it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  56%|█████████████████▉              | 101/180 [00:17<00:13,  5.81it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 3:  57%|██████████████████▏             | 102/180 [00:17<00:13,  5.81it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 3:  57%|██████████████████▏             | 102/180 [00:17<00:13,  5.81it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 3:  57%|██████████████████▎             | 103/180 [00:17<00:13,  5.87it/s, training_loss=0.188]\u001b[A\n",
      "Epoch 3:  57%|██████████████████▎             | 103/180 [00:17<00:13,  5.87it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 3:  58%|██████████████████▍             | 104/180 [00:17<00:13,  5.80it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 3:  58%|██████████████████▍             | 104/180 [00:17<00:13,  5.80it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  58%|██████████████████▋             | 105/180 [00:17<00:12,  5.82it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  58%|██████████████████▋             | 105/180 [00:18<00:12,  5.82it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 3:  59%|██████████████████▊             | 106/180 [00:18<00:12,  5.83it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 3:  59%|██████████████████▊             | 106/180 [00:18<00:12,  5.83it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  59%|███████████████████             | 107/180 [00:18<00:12,  5.83it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  59%|███████████████████             | 107/180 [00:18<00:12,  5.83it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  60%|███████████████████▏            | 108/180 [00:18<00:12,  5.84it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  60%|███████████████████▏            | 108/180 [00:18<00:12,  5.84it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  61%|███████████████████▍            | 109/180 [00:18<00:12,  5.84it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  61%|███████████████████▍            | 109/180 [00:18<00:12,  5.84it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  61%|███████████████████▌            | 110/180 [00:18<00:11,  5.84it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  61%|███████████████████▌            | 110/180 [00:19<00:11,  5.84it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  62%|███████████████████▋            | 111/180 [00:19<00:11,  5.81it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  62%|███████████████████▋            | 111/180 [00:19<00:11,  5.81it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 3:  62%|███████████████████▉            | 112/180 [00:19<00:11,  5.76it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 3:  62%|███████████████████▉            | 112/180 [00:19<00:11,  5.76it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 3:  63%|████████████████████            | 113/180 [00:19<00:11,  5.79it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 3:  63%|████████████████████            | 113/180 [00:19<00:11,  5.79it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 3:  63%|████████████████████▎           | 114/180 [00:19<00:11,  5.80it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 3:  63%|████████████████████▎           | 114/180 [00:19<00:11,  5.80it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  64%|████████████████████▍           | 115/180 [00:19<00:11,  5.77it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  64%|████████████████████▍           | 115/180 [00:19<00:11,  5.77it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  64%|████████████████████▌           | 116/180 [00:19<00:11,  5.78it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  64%|████████████████████▌           | 116/180 [00:20<00:11,  5.78it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  65%|████████████████████▊           | 117/180 [00:20<00:10,  5.78it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  65%|████████████████████▊           | 117/180 [00:20<00:10,  5.78it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  66%|████████████████████▉           | 118/180 [00:20<00:10,  5.72it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  66%|████████████████████▉           | 118/180 [00:20<00:10,  5.72it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 3:  66%|█████████████████████▏          | 119/180 [00:20<00:10,  5.73it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 3:  66%|█████████████████████▏          | 119/180 [00:20<00:10,  5.73it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  67%|█████████████████████▎          | 120/180 [00:20<00:10,  5.75it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  67%|█████████████████████▎          | 120/180 [00:20<00:10,  5.75it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 3:  67%|█████████████████████▌          | 121/180 [00:20<00:10,  5.73it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 3:  67%|█████████████████████▌          | 121/180 [00:20<00:10,  5.73it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 3:  68%|█████████████████████▋          | 122/180 [00:20<00:10,  5.72it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 3:  68%|█████████████████████▋          | 122/180 [00:21<00:10,  5.72it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  68%|█████████████████████▊          | 123/180 [00:21<00:10,  5.66it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  68%|█████████████████████▊          | 123/180 [00:21<00:10,  5.66it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  69%|██████████████████████          | 124/180 [00:21<00:09,  5.69it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  69%|██████████████████████          | 124/180 [00:21<00:09,  5.69it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 3:  69%|██████████████████████▏         | 125/180 [00:21<00:09,  5.71it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 3:  69%|██████████████████████▏         | 125/180 [00:21<00:09,  5.71it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  70%|██████████████████████▍         | 126/180 [00:21<00:09,  5.73it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  70%|██████████████████████▍         | 126/180 [00:21<00:09,  5.73it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  71%|██████████████████████▌         | 127/180 [00:21<00:09,  5.73it/s, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  71%|██████████████████████▌         | 127/180 [00:21<00:09,  5.73it/s, training_loss=0.186]\u001b[A\n",
      "Epoch 3:  71%|██████████████████████▊         | 128/180 [00:21<00:09,  5.78it/s, training_loss=0.186]\u001b[A\n",
      "Epoch 3:  71%|██████████████████████▊         | 128/180 [00:22<00:09,  5.78it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 3:  72%|██████████████████████▉         | 129/180 [00:22<00:08,  5.79it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 3:  72%|██████████████████████▉         | 129/180 [00:22<00:08,  5.79it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  72%|███████████████████████         | 130/180 [00:22<00:08,  5.81it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  72%|███████████████████████         | 130/180 [00:22<00:08,  5.81it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 3:  73%|███████████████████████▎        | 131/180 [00:22<00:08,  5.81it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 3:  73%|███████████████████████▎        | 131/180 [00:22<00:08,  5.81it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  73%|███████████████████████▍        | 132/180 [00:22<00:08,  5.82it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  73%|███████████████████████▍        | 132/180 [00:22<00:08,  5.82it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 3:  74%|███████████████████████▋        | 133/180 [00:22<00:08,  5.83it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 3:  74%|███████████████████████▋        | 133/180 [00:23<00:08,  5.83it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 3:  74%|███████████████████████▊        | 134/180 [00:23<00:07,  5.82it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 3:  74%|███████████████████████▊        | 134/180 [00:23<00:07,  5.82it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  75%|████████████████████████        | 135/180 [00:23<00:07,  5.83it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  75%|████████████████████████        | 135/180 [00:23<00:07,  5.83it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  76%|████████████████████████▏       | 136/180 [00:23<00:07,  5.81it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  76%|████████████████████████▏       | 136/180 [00:23<00:07,  5.81it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  76%|████████████████████████▎       | 137/180 [00:23<00:07,  5.83it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 3:  76%|████████████████████████▎       | 137/180 [00:23<00:07,  5.83it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 3:  77%|████████████████████████▌       | 138/180 [00:23<00:07,  5.83it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 3:  77%|████████████████████████▌       | 138/180 [00:23<00:07,  5.83it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 3:  77%|████████████████████████▋       | 139/180 [00:23<00:06,  5.95it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 3:  77%|████████████████████████▋       | 139/180 [00:24<00:06,  5.95it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  78%|████████████████████████▉       | 140/180 [00:24<00:06,  5.79it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 3:  78%|████████████████████████▉       | 140/180 [00:24<00:06,  5.79it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:  78%|█████████████████████████       | 141/180 [00:24<00:06,  5.80it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:  78%|█████████████████████████       | 141/180 [00:24<00:06,  5.80it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 3:  79%|█████████████████████████▏      | 142/180 [00:24<00:06,  5.81it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 3:  79%|█████████████████████████▏      | 142/180 [00:24<00:06,  5.81it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  79%|█████████████████████████▍      | 143/180 [00:24<00:06,  5.81it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 3:  79%|█████████████████████████▍      | 143/180 [00:24<00:06,  5.81it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 3:  80%|█████████████████████████▌      | 144/180 [00:24<00:06,  5.82it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 3:  80%|█████████████████████████▌      | 144/180 [00:24<00:06,  5.82it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 3:  81%|█████████████████████████▊      | 145/180 [00:24<00:06,  5.82it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 3:  81%|█████████████████████████▊      | 145/180 [00:25<00:06,  5.82it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 3:  81%|█████████████████████████▉      | 146/180 [00:25<00:05,  5.83it/s, training_loss=0.111]\u001b[A\n",
      "Epoch 3:  81%|█████████████████████████▉      | 146/180 [00:25<00:05,  5.83it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  82%|██████████████████████████▏     | 147/180 [00:25<00:05,  5.97it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  82%|██████████████████████████▏     | 147/180 [00:25<00:05,  5.97it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  82%|██████████████████████████▎     | 148/180 [00:25<00:05,  5.81it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  82%|██████████████████████████▎     | 148/180 [00:25<00:05,  5.81it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 3:  83%|██████████████████████████▍     | 149/180 [00:25<00:05,  5.83it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 3:  83%|██████████████████████████▍     | 149/180 [00:25<00:05,  5.83it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 3:  83%|██████████████████████████▋     | 150/180 [00:25<00:05,  5.82it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 3:  83%|██████████████████████████▋     | 150/180 [00:25<00:05,  5.82it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  84%|██████████████████████████▊     | 151/180 [00:25<00:04,  5.84it/s, training_loss=0.136]\u001b[A\n",
      "Epoch 3:  84%|██████████████████████████▊     | 151/180 [00:26<00:04,  5.84it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  84%|███████████████████████████     | 152/180 [00:26<00:04,  5.82it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  84%|███████████████████████████     | 152/180 [00:26<00:04,  5.82it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  85%|███████████████████████████▏    | 153/180 [00:26<00:04,  5.83it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  85%|███████████████████████████▏    | 153/180 [00:26<00:04,  5.83it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 3:  86%|███████████████████████████▍    | 154/180 [00:26<00:04,  5.81it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 3:  86%|███████████████████████████▍    | 154/180 [00:26<00:04,  5.81it/s, training_loss=0.224]\u001b[A\n",
      "Epoch 3:  86%|███████████████████████████▌    | 155/180 [00:26<00:04,  5.81it/s, training_loss=0.224]\u001b[A\n",
      "Epoch 3:  86%|███████████████████████████▌    | 155/180 [00:26<00:04,  5.81it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  87%|███████████████████████████▋    | 156/180 [00:26<00:04,  5.82it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  87%|███████████████████████████▋    | 156/180 [00:26<00:04,  5.82it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:  87%|███████████████████████████▉    | 157/180 [00:26<00:03,  5.77it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:  87%|███████████████████████████▉    | 157/180 [00:27<00:03,  5.77it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 3:  88%|████████████████████████████    | 158/180 [00:27<00:03,  5.80it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 3:  88%|████████████████████████████    | 158/180 [00:27<00:03,  5.80it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 3:  88%|████████████████████████████▎   | 159/180 [00:27<00:03,  5.58it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 3:  88%|████████████████████████████▎   | 159/180 [00:27<00:03,  5.58it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  89%|████████████████████████████▍   | 160/180 [00:27<00:03,  5.55it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  89%|████████████████████████████▍   | 160/180 [00:27<00:03,  5.55it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  89%|████████████████████████████▌   | 161/180 [00:27<00:03,  5.61it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  89%|████████████████████████████▌   | 161/180 [00:27<00:03,  5.61it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  90%|████████████████████████████▊   | 162/180 [00:27<00:03,  5.65it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  90%|████████████████████████████▊   | 162/180 [00:28<00:03,  5.65it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  91%|████████████████████████████▉   | 163/180 [00:28<00:02,  5.69it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  91%|████████████████████████████▉   | 163/180 [00:28<00:02,  5.69it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 3:  91%|█████████████████████████████▏  | 164/180 [00:28<00:02,  5.74it/s, training_loss=0.050]\u001b[A\n",
      "Epoch 3:  91%|█████████████████████████████▏  | 164/180 [00:28<00:02,  5.74it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 3:  92%|█████████████████████████████▎  | 165/180 [00:28<00:02,  5.74it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 3:  92%|█████████████████████████████▎  | 165/180 [00:28<00:02,  5.74it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 3:  92%|█████████████████████████████▌  | 166/180 [00:28<00:02,  5.74it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 3:  92%|█████████████████████████████▌  | 166/180 [00:28<00:02,  5.74it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  93%|█████████████████████████████▋  | 167/180 [00:28<00:02,  5.78it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  93%|█████████████████████████████▋  | 167/180 [00:28<00:02,  5.78it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 3:  93%|█████████████████████████████▊  | 168/180 [00:28<00:02,  5.78it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 3:  93%|█████████████████████████████▊  | 168/180 [00:29<00:02,  5.78it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 3:  94%|██████████████████████████████  | 169/180 [00:29<00:01,  5.81it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 3:  94%|██████████████████████████████  | 169/180 [00:29<00:01,  5.81it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 3:  94%|██████████████████████████████▏ | 170/180 [00:29<00:01,  5.80it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 3:  94%|██████████████████████████████▏ | 170/180 [00:29<00:01,  5.80it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 3:  95%|██████████████████████████████▍ | 171/180 [00:29<00:01,  5.81it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 3:  95%|██████████████████████████████▍ | 171/180 [00:29<00:01,  5.81it/s, training_loss=0.089]\u001b[A\n",
      "Epoch 3:  96%|██████████████████████████████▌ | 172/180 [00:29<00:01,  5.81it/s, training_loss=0.089]\u001b[A\n",
      "Epoch 3:  96%|██████████████████████████████▌ | 172/180 [00:29<00:01,  5.81it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  96%|██████████████████████████████▊ | 173/180 [00:29<00:01,  5.81it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  96%|██████████████████████████████▊ | 173/180 [00:29<00:01,  5.81it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  97%|██████████████████████████████▉ | 174/180 [00:29<00:01,  5.85it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  97%|██████████████████████████████▉ | 174/180 [00:30<00:01,  5.85it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  97%|███████████████████████████████ | 175/180 [00:30<00:00,  5.77it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  97%|███████████████████████████████ | 175/180 [00:30<00:00,  5.77it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  98%|███████████████████████████████▎| 176/180 [00:30<00:00,  5.78it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  98%|███████████████████████████████▎| 176/180 [00:30<00:00,  5.78it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  98%|███████████████████████████████▍| 177/180 [00:30<00:00,  5.79it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  98%|███████████████████████████████▍| 177/180 [00:30<00:00,  5.79it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  99%|███████████████████████████████▋| 178/180 [00:30<00:00,  5.80it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  99%|███████████████████████████████▋| 178/180 [00:30<00:00,  5.80it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  99%|███████████████████████████████▊| 179/180 [00:30<00:00,  5.80it/s, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  99%|███████████████████████████████▊| 179/180 [00:30<00:00,  5.80it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 3: 100%|████████████████████████████████| 180/180 [00:30<00:00,  6.17it/s, training_loss=0.062]\u001b[A\n",
      "Epoch Progress:   8%|███▋                                             | 3/40 [01:31<18:53, 30.63s/it]\u001b[A\n",
      "Epoch 4:   0%|                                                               | 0/180 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:   0%|                                          | 0/180 [00:00<?, ?it/s, training_loss=0.221]\u001b[A\n",
      "Epoch 4:   1%|▏                                 | 1/180 [00:00<00:30,  5.92it/s, training_loss=0.221]\u001b[A\n",
      "Epoch 4:   1%|▏                                 | 1/180 [00:00<00:30,  5.92it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:   1%|▍                                 | 2/180 [00:00<00:30,  5.86it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:   1%|▍                                 | 2/180 [00:00<00:30,  5.86it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 4:   2%|▌                                 | 3/180 [00:00<00:30,  5.84it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 4:   2%|▌                                 | 3/180 [00:00<00:30,  5.84it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:   2%|▊                                 | 4/180 [00:00<00:30,  5.84it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:   2%|▊                                 | 4/180 [00:00<00:30,  5.84it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 4:   3%|▉                                 | 5/180 [00:00<00:29,  5.84it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 4:   3%|▉                                 | 5/180 [00:01<00:29,  5.84it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:   3%|█▏                                | 6/180 [00:01<00:29,  5.85it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:   3%|█▏                                | 6/180 [00:01<00:29,  5.85it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:   4%|█▎                                | 7/180 [00:01<00:29,  5.84it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:   4%|█▎                                | 7/180 [00:01<00:29,  5.84it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 4:   4%|█▌                                | 8/180 [00:01<00:29,  5.84it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 4:   4%|█▌                                | 8/180 [00:01<00:29,  5.84it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 4:   5%|█▋                                | 9/180 [00:01<00:29,  5.83it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 4:   5%|█▋                                | 9/180 [00:01<00:29,  5.83it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 4:   6%|█▊                               | 10/180 [00:01<00:29,  5.83it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 4:   6%|█▊                               | 10/180 [00:01<00:29,  5.83it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 4:   6%|██                               | 11/180 [00:01<00:29,  5.83it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 4:   6%|██                               | 11/180 [00:02<00:29,  5.83it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 4:   7%|██▏                              | 12/180 [00:02<00:28,  5.82it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 4:   7%|██▏                              | 12/180 [00:02<00:28,  5.82it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 4:   7%|██▍                              | 13/180 [00:02<00:28,  5.83it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 4:   7%|██▍                              | 13/180 [00:02<00:28,  5.83it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 4:   8%|██▌                              | 14/180 [00:02<00:28,  5.83it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 4:   8%|██▌                              | 14/180 [00:02<00:28,  5.83it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 4:   8%|██▊                              | 15/180 [00:02<00:28,  5.84it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 4:   8%|██▊                              | 15/180 [00:02<00:28,  5.84it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 4:   9%|██▉                              | 16/180 [00:02<00:28,  5.82it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 4:   9%|██▉                              | 16/180 [00:02<00:28,  5.82it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:   9%|███                              | 17/180 [00:02<00:27,  5.82it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:   9%|███                              | 17/180 [00:03<00:27,  5.82it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 4:  10%|███▎                             | 18/180 [00:03<00:27,  5.95it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 4:  10%|███▎                             | 18/180 [00:03<00:27,  5.95it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 4:  11%|███▍                             | 19/180 [00:03<00:27,  5.79it/s, training_loss=0.034]\u001b[A\n",
      "Epoch 4:  11%|███▍                             | 19/180 [00:03<00:27,  5.79it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  11%|███▋                             | 20/180 [00:03<00:28,  5.70it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  11%|███▋                             | 20/180 [00:03<00:28,  5.70it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 4:  12%|███▊                             | 21/180 [00:03<00:27,  5.74it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 4:  12%|███▊                             | 21/180 [00:03<00:27,  5.74it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  12%|████                             | 22/180 [00:03<00:27,  5.77it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  12%|████                             | 22/180 [00:03<00:27,  5.77it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  13%|████▏                            | 23/180 [00:03<00:27,  5.79it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  13%|████▏                            | 23/180 [00:04<00:27,  5.79it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  13%|████▍                            | 24/180 [00:04<00:26,  5.80it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  13%|████▍                            | 24/180 [00:04<00:26,  5.80it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 4:  14%|████▌                            | 25/180 [00:04<00:26,  5.81it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 4:  14%|████▌                            | 25/180 [00:04<00:26,  5.81it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 4:  14%|████▊                            | 26/180 [00:04<00:25,  5.96it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 4:  14%|████▊                            | 26/180 [00:04<00:25,  5.96it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 4:  15%|████▉                            | 27/180 [00:04<00:26,  5.77it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 4:  15%|████▉                            | 27/180 [00:04<00:26,  5.77it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 4:  16%|█████▏                           | 28/180 [00:04<00:26,  5.78it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 4:  16%|█████▏                           | 28/180 [00:04<00:26,  5.78it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 4:  16%|█████▎                           | 29/180 [00:04<00:26,  5.79it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 4:  16%|█████▎                           | 29/180 [00:05<00:26,  5.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  17%|█████▌                           | 30/180 [00:05<00:25,  5.80it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  17%|█████▌                           | 30/180 [00:05<00:25,  5.80it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  17%|█████▋                           | 31/180 [00:05<00:25,  5.82it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  17%|█████▋                           | 31/180 [00:05<00:25,  5.82it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  18%|█████▊                           | 32/180 [00:05<00:25,  5.90it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  18%|█████▊                           | 32/180 [00:05<00:25,  5.90it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  18%|██████                           | 33/180 [00:05<00:25,  5.79it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  18%|██████                           | 33/180 [00:05<00:25,  5.79it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 4:  19%|██████▏                          | 34/180 [00:05<00:25,  5.84it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 4:  19%|██████▏                          | 34/180 [00:06<00:25,  5.84it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 4:  19%|██████▍                          | 35/180 [00:06<00:24,  5.80it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 4:  19%|██████▍                          | 35/180 [00:06<00:24,  5.80it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  20%|██████▌                          | 36/180 [00:06<00:24,  5.82it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  20%|██████▌                          | 36/180 [00:06<00:24,  5.82it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  21%|██████▊                          | 37/180 [00:06<00:24,  5.81it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  21%|██████▊                          | 37/180 [00:06<00:24,  5.81it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  21%|██████▉                          | 38/180 [00:06<00:24,  5.74it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  21%|██████▉                          | 38/180 [00:06<00:24,  5.74it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 4:  22%|███████▏                         | 39/180 [00:06<00:24,  5.75it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 4:  22%|███████▏                         | 39/180 [00:06<00:24,  5.75it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  22%|███████▎                         | 40/180 [00:06<00:24,  5.77it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  22%|███████▎                         | 40/180 [00:07<00:24,  5.77it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 4:  23%|███████▌                         | 41/180 [00:07<00:24,  5.75it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 4:  23%|███████▌                         | 41/180 [00:07<00:24,  5.75it/s, training_loss=0.143]\u001b[A\n",
      "Epoch 4:  23%|███████▋                         | 42/180 [00:07<00:23,  5.77it/s, training_loss=0.143]\u001b[A\n",
      "Epoch 4:  23%|███████▋                         | 42/180 [00:07<00:23,  5.77it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 4:  24%|███████▉                         | 43/180 [00:07<00:23,  5.78it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 4:  24%|███████▉                         | 43/180 [00:07<00:23,  5.78it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 4:  24%|████████                         | 44/180 [00:07<00:23,  5.80it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 4:  24%|████████                         | 44/180 [00:07<00:23,  5.80it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  25%|████████▎                        | 45/180 [00:07<00:23,  5.79it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  25%|████████▎                        | 45/180 [00:07<00:23,  5.79it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 4:  26%|████████▍                        | 46/180 [00:07<00:23,  5.81it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 4:  26%|████████▍                        | 46/180 [00:08<00:23,  5.81it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  26%|████████▌                        | 47/180 [00:08<00:22,  5.82it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  26%|████████▌                        | 47/180 [00:08<00:22,  5.82it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 4:  27%|████████▊                        | 48/180 [00:08<00:22,  5.81it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 4:  27%|████████▊                        | 48/180 [00:08<00:22,  5.81it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 4:  27%|████████▉                        | 49/180 [00:08<00:22,  5.81it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 4:  27%|████████▉                        | 49/180 [00:08<00:22,  5.81it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  28%|█████████▏                       | 50/180 [00:08<00:22,  5.81it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  28%|█████████▏                       | 50/180 [00:08<00:22,  5.81it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 4:  28%|█████████▎                       | 51/180 [00:08<00:22,  5.69it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 4:  28%|█████████▎                       | 51/180 [00:08<00:22,  5.69it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  29%|█████████▌                       | 52/180 [00:08<00:22,  5.73it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  29%|█████████▌                       | 52/180 [00:09<00:22,  5.73it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 4:  29%|█████████▋                       | 53/180 [00:09<00:22,  5.76it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 4:  29%|█████████▋                       | 53/180 [00:09<00:22,  5.76it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 4:  30%|█████████▉                       | 54/180 [00:09<00:21,  5.79it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 4:  30%|█████████▉                       | 54/180 [00:09<00:21,  5.79it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  31%|██████████                       | 55/180 [00:09<00:21,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  31%|██████████                       | 55/180 [00:09<00:21,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  31%|██████████▎                      | 56/180 [00:09<00:21,  5.80it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  31%|██████████▎                      | 56/180 [00:09<00:21,  5.80it/s, training_loss=0.251]\u001b[A\n",
      "Epoch 4:  32%|██████████▍                      | 57/180 [00:09<00:21,  5.79it/s, training_loss=0.251]\u001b[A\n",
      "Epoch 4:  32%|██████████▍                      | 57/180 [00:09<00:21,  5.79it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  32%|██████████▋                      | 58/180 [00:09<00:21,  5.75it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  32%|██████████▋                      | 58/180 [00:10<00:21,  5.75it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 4:  33%|██████████▊                      | 59/180 [00:10<00:20,  5.78it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 4:  33%|██████████▊                      | 59/180 [00:10<00:20,  5.78it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 4:  33%|███████████                      | 60/180 [00:10<00:20,  5.79it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 4:  33%|███████████                      | 60/180 [00:10<00:20,  5.79it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:  34%|███████████▏                     | 61/180 [00:10<00:20,  5.78it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:  34%|███████████▏                     | 61/180 [00:10<00:20,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  34%|███████████▎                     | 62/180 [00:10<00:20,  5.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 4:  34%|███████████▎                     | 62/180 [00:10<00:20,  5.80it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 4:  35%|███████████▌                     | 63/180 [00:10<00:20,  5.82it/s, training_loss=0.263]\u001b[A\n",
      "Epoch 4:  35%|███████████▌                     | 63/180 [00:11<00:20,  5.82it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 4:  36%|███████████▋                     | 64/180 [00:11<00:19,  5.88it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 4:  36%|███████████▋                     | 64/180 [00:11<00:19,  5.88it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  36%|███████████▉                     | 65/180 [00:11<00:19,  5.80it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  36%|███████████▉                     | 65/180 [00:11<00:19,  5.80it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  37%|████████████                     | 66/180 [00:11<00:19,  5.81it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  37%|████████████                     | 66/180 [00:11<00:19,  5.81it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  37%|████████████▎                    | 67/180 [00:11<00:19,  5.82it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  37%|████████████▎                    | 67/180 [00:11<00:19,  5.82it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 4:  38%|████████████▍                    | 68/180 [00:11<00:19,  5.82it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 4:  38%|████████████▍                    | 68/180 [00:11<00:19,  5.82it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 4:  38%|████████████▋                    | 69/180 [00:11<00:19,  5.83it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 4:  38%|████████████▋                    | 69/180 [00:12<00:19,  5.83it/s, training_loss=0.171]\u001b[A\n",
      "Epoch 4:  39%|████████████▊                    | 70/180 [00:12<00:18,  5.82it/s, training_loss=0.171]\u001b[A\n",
      "Epoch 4:  39%|████████████▊                    | 70/180 [00:12<00:18,  5.82it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  39%|█████████████                    | 71/180 [00:12<00:18,  5.83it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  39%|█████████████                    | 71/180 [00:12<00:18,  5.83it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 4:  40%|█████████████▏                   | 72/180 [00:12<00:18,  5.83it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 4:  40%|█████████████▏                   | 72/180 [00:12<00:18,  5.83it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 4:  41%|█████████████▍                   | 73/180 [00:12<00:18,  5.81it/s, training_loss=0.062]\u001b[A\n",
      "Epoch 4:  41%|█████████████▍                   | 73/180 [00:12<00:18,  5.81it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 4:  41%|█████████████▌                   | 74/180 [00:12<00:18,  5.83it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 4:  41%|█████████████▌                   | 74/180 [00:12<00:18,  5.83it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  42%|█████████████▊                   | 75/180 [00:12<00:18,  5.82it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  42%|█████████████▊                   | 75/180 [00:13<00:18,  5.82it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  42%|█████████████▉                   | 76/180 [00:13<00:17,  5.81it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  42%|█████████████▉                   | 76/180 [00:13<00:17,  5.81it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  43%|██████████████                   | 77/180 [00:13<00:17,  5.81it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  43%|██████████████                   | 77/180 [00:13<00:17,  5.81it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 4:  43%|██████████████▎                  | 78/180 [00:13<00:17,  5.82it/s, training_loss=0.102]\u001b[A\n",
      "Epoch 4:  43%|██████████████▎                  | 78/180 [00:13<00:17,  5.82it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  44%|██████████████▍                  | 79/180 [00:13<00:17,  5.81it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  44%|██████████████▍                  | 79/180 [00:13<00:17,  5.81it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  44%|██████████████▋                  | 80/180 [00:13<00:17,  5.79it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  44%|██████████████▋                  | 80/180 [00:13<00:17,  5.79it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 4:  45%|██████████████▊                  | 81/180 [00:13<00:17,  5.80it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 4:  45%|██████████████▊                  | 81/180 [00:14<00:17,  5.80it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 4:  46%|███████████████                  | 82/180 [00:14<00:16,  5.82it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 4:  46%|███████████████                  | 82/180 [00:14<00:16,  5.82it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 4:  46%|███████████████▏                 | 83/180 [00:14<00:16,  5.93it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 4:  46%|███████████████▏                 | 83/180 [00:14<00:16,  5.93it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 4:  47%|███████████████▍                 | 84/180 [00:14<00:16,  5.72it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 4:  47%|███████████████▍                 | 84/180 [00:14<00:16,  5.72it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 4:  47%|███████████████▌                 | 85/180 [00:14<00:16,  5.75it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 4:  47%|███████████████▌                 | 85/180 [00:14<00:16,  5.75it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 4:  48%|███████████████▊                 | 86/180 [00:14<00:16,  5.76it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 4:  48%|███████████████▊                 | 86/180 [00:14<00:16,  5.76it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 4:  48%|███████████████▉                 | 87/180 [00:14<00:16,  5.78it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 4:  48%|███████████████▉                 | 87/180 [00:15<00:16,  5.78it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:  49%|████████████████▏                | 88/180 [00:15<00:15,  5.79it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:  49%|████████████████▏                | 88/180 [00:15<00:15,  5.79it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 4:  49%|████████████████▎                | 89/180 [00:15<00:15,  5.81it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 4:  49%|████████████████▎                | 89/180 [00:15<00:15,  5.81it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  50%|████████████████▌                | 90/180 [00:15<00:15,  5.70it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  50%|████████████████▌                | 90/180 [00:15<00:15,  5.70it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 4:  51%|████████████████▋                | 91/180 [00:15<00:15,  5.74it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 4:  51%|████████████████▋                | 91/180 [00:15<00:15,  5.74it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  51%|████████████████▊                | 92/180 [00:15<00:15,  5.76it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  51%|████████████████▊                | 92/180 [00:16<00:15,  5.76it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 4:  52%|█████████████████                | 93/180 [00:16<00:15,  5.78it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 4:  52%|█████████████████                | 93/180 [00:16<00:15,  5.78it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  52%|█████████████████▏               | 94/180 [00:16<00:14,  5.77it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  52%|█████████████████▏               | 94/180 [00:16<00:14,  5.77it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 4:  53%|█████████████████▍               | 95/180 [00:16<00:14,  5.83it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 4:  53%|█████████████████▍               | 95/180 [00:16<00:14,  5.83it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  53%|█████████████████▌               | 96/180 [00:16<00:14,  5.77it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  53%|█████████████████▌               | 96/180 [00:16<00:14,  5.77it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  54%|█████████████████▊               | 97/180 [00:16<00:14,  5.78it/s, training_loss=0.013]\u001b[A\n",
      "Epoch 4:  54%|█████████████████▊               | 97/180 [00:16<00:14,  5.78it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 4:  54%|█████████████████▉               | 98/180 [00:16<00:14,  5.79it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 4:  54%|█████████████████▉               | 98/180 [00:17<00:14,  5.79it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 4:  55%|██████████████████▏              | 99/180 [00:17<00:13,  5.81it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 4:  55%|██████████████████▏              | 99/180 [00:17<00:13,  5.81it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 4:  56%|█████████████████▊              | 100/180 [00:17<00:13,  5.81it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 4:  56%|█████████████████▊              | 100/180 [00:17<00:13,  5.81it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  56%|█████████████████▉              | 101/180 [00:17<00:13,  5.81it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  56%|█████████████████▉              | 101/180 [00:17<00:13,  5.81it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 4:  57%|██████████████████▏             | 102/180 [00:17<00:13,  5.82it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 4:  57%|██████████████████▏             | 102/180 [00:17<00:13,  5.82it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 4:  57%|██████████████████▎             | 103/180 [00:17<00:13,  5.81it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 4:  57%|██████████████████▎             | 103/180 [00:17<00:13,  5.81it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 4:  58%|██████████████████▍             | 104/180 [00:17<00:13,  5.81it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 4:  58%|██████████████████▍             | 104/180 [00:18<00:13,  5.81it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 4:  58%|██████████████████▋             | 105/180 [00:18<00:12,  5.81it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 4:  58%|██████████████████▋             | 105/180 [00:18<00:12,  5.81it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 4:  59%|██████████████████▊             | 106/180 [00:18<00:12,  5.81it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 4:  59%|██████████████████▊             | 106/180 [00:18<00:12,  5.81it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  59%|███████████████████             | 107/180 [00:18<00:12,  5.81it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  59%|███████████████████             | 107/180 [00:18<00:12,  5.81it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  60%|███████████████████▏            | 108/180 [00:18<00:12,  5.80it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  60%|███████████████████▏            | 108/180 [00:18<00:12,  5.80it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 4:  61%|███████████████████▍            | 109/180 [00:18<00:12,  5.82it/s, training_loss=0.014]\u001b[A\n",
      "Epoch 4:  61%|███████████████████▍            | 109/180 [00:18<00:12,  5.82it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 4:  61%|███████████████████▌            | 110/180 [00:18<00:12,  5.81it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 4:  61%|███████████████████▌            | 110/180 [00:19<00:12,  5.81it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 4:  62%|███████████████████▋            | 111/180 [00:19<00:11,  5.81it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 4:  62%|███████████████████▋            | 111/180 [00:19<00:11,  5.81it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  62%|███████████████████▉            | 112/180 [00:19<00:11,  5.71it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  62%|███████████████████▉            | 112/180 [00:19<00:11,  5.71it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 4:  63%|████████████████████            | 113/180 [00:19<00:11,  5.74it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 4:  63%|████████████████████            | 113/180 [00:19<00:11,  5.74it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 4:  63%|████████████████████▎           | 114/180 [00:19<00:11,  5.76it/s, training_loss=0.037]\u001b[A\n",
      "Epoch 4:  63%|████████████████████▎           | 114/180 [00:19<00:11,  5.76it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 4:  64%|████████████████████▍           | 115/180 [00:19<00:11,  5.77it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 4:  64%|████████████████████▍           | 115/180 [00:19<00:11,  5.77it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  64%|████████████████████▌           | 116/180 [00:19<00:11,  5.77it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  64%|████████████████████▌           | 116/180 [00:20<00:11,  5.77it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 4:  65%|████████████████████▊           | 117/180 [00:20<00:10,  5.78it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 4:  65%|████████████████████▊           | 117/180 [00:20<00:10,  5.78it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 4:  66%|████████████████████▉           | 118/180 [00:20<00:10,  5.80it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 4:  66%|████████████████████▉           | 118/180 [00:20<00:10,  5.80it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  66%|█████████████████████▏          | 119/180 [00:20<00:10,  5.81it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  66%|█████████████████████▏          | 119/180 [00:20<00:10,  5.81it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 4:  67%|█████████████████████▎          | 120/180 [00:20<00:10,  5.79it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 4:  67%|█████████████████████▎          | 120/180 [00:20<00:10,  5.79it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 4:  67%|█████████████████████▌          | 121/180 [00:20<00:10,  5.81it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 4:  67%|█████████████████████▌          | 121/180 [00:21<00:10,  5.81it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 4:  68%|█████████████████████▋          | 122/180 [00:21<00:09,  5.80it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 4:  68%|█████████████████████▋          | 122/180 [00:21<00:09,  5.80it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 4:  68%|█████████████████████▊          | 123/180 [00:21<00:09,  5.78it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 4:  68%|█████████████████████▊          | 123/180 [00:21<00:09,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  69%|██████████████████████          | 124/180 [00:21<00:09,  5.80it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  69%|██████████████████████          | 124/180 [00:21<00:09,  5.80it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  69%|██████████████████████▏         | 125/180 [00:21<00:09,  5.79it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  69%|██████████████████████▏         | 125/180 [00:21<00:09,  5.79it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 4:  70%|██████████████████████▍         | 126/180 [00:21<00:09,  5.81it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 4:  70%|██████████████████████▍         | 126/180 [00:21<00:09,  5.81it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  71%|██████████████████████▌         | 127/180 [00:21<00:09,  5.80it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  71%|██████████████████████▌         | 127/180 [00:22<00:09,  5.80it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 4:  71%|██████████████████████▊         | 128/180 [00:22<00:09,  5.70it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 4:  71%|██████████████████████▊         | 128/180 [00:22<00:09,  5.70it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 4:  72%|██████████████████████▉         | 129/180 [00:22<00:08,  5.74it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 4:  72%|██████████████████████▉         | 129/180 [00:22<00:08,  5.74it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  72%|███████████████████████         | 130/180 [00:22<00:08,  5.77it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  72%|███████████████████████         | 130/180 [00:22<00:08,  5.77it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  73%|███████████████████████▎        | 131/180 [00:22<00:08,  5.66it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  73%|███████████████████████▎        | 131/180 [00:22<00:08,  5.66it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 4:  73%|███████████████████████▍        | 132/180 [00:22<00:08,  5.70it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 4:  73%|███████████████████████▍        | 132/180 [00:22<00:08,  5.70it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  74%|███████████████████████▋        | 133/180 [00:22<00:08,  5.72it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  74%|███████████████████████▋        | 133/180 [00:23<00:08,  5.72it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 4:  74%|███████████████████████▊        | 134/180 [00:23<00:07,  5.75it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 4:  74%|███████████████████████▊        | 134/180 [00:23<00:07,  5.75it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  75%|████████████████████████        | 135/180 [00:23<00:07,  5.75it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  75%|████████████████████████        | 135/180 [00:23<00:07,  5.75it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  76%|████████████████████████▏       | 136/180 [00:23<00:07,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  76%|████████████████████████▏       | 136/180 [00:23<00:07,  5.78it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  76%|████████████████████████▎       | 137/180 [00:23<00:07,  5.78it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  76%|████████████████████████▎       | 137/180 [00:23<00:07,  5.78it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  77%|████████████████████████▌       | 138/180 [00:23<00:07,  5.78it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 4:  77%|████████████████████████▌       | 138/180 [00:23<00:07,  5.78it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 4:  77%|████████████████████████▋       | 139/180 [00:23<00:07,  5.80it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 4:  77%|████████████████████████▋       | 139/180 [00:24<00:07,  5.80it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  78%|████████████████████████▉       | 140/180 [00:24<00:06,  5.80it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  78%|████████████████████████▉       | 140/180 [00:24<00:06,  5.80it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 4:  78%|█████████████████████████       | 141/180 [00:24<00:06,  5.81it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 4:  78%|█████████████████████████       | 141/180 [00:24<00:06,  5.81it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 4:  79%|█████████████████████████▏      | 142/180 [00:24<00:06,  5.80it/s, training_loss=0.139]\u001b[A\n",
      "Epoch 4:  79%|█████████████████████████▏      | 142/180 [00:24<00:06,  5.80it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  79%|█████████████████████████▍      | 143/180 [00:24<00:06,  5.81it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  79%|█████████████████████████▍      | 143/180 [00:24<00:06,  5.81it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  80%|█████████████████████████▌      | 144/180 [00:24<00:06,  5.81it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 4:  80%|█████████████████████████▌      | 144/180 [00:25<00:06,  5.81it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 4:  81%|█████████████████████████▊      | 145/180 [00:25<00:06,  5.81it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 4:  81%|█████████████████████████▊      | 145/180 [00:25<00:06,  5.81it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  81%|█████████████████████████▉      | 146/180 [00:25<00:05,  5.81it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  81%|█████████████████████████▉      | 146/180 [00:25<00:05,  5.81it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  82%|██████████████████████████▏     | 147/180 [00:25<00:05,  5.81it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 4:  82%|██████████████████████████▏     | 147/180 [00:25<00:05,  5.81it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 4:  82%|██████████████████████████▎     | 148/180 [00:25<00:05,  5.82it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 4:  82%|██████████████████████████▎     | 148/180 [00:25<00:05,  5.82it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  83%|██████████████████████████▍     | 149/180 [00:25<00:05,  5.81it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  83%|██████████████████████████▍     | 149/180 [00:25<00:05,  5.81it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 4:  83%|██████████████████████████▋     | 150/180 [00:25<00:05,  5.81it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 4:  83%|██████████████████████████▋     | 150/180 [00:26<00:05,  5.81it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  84%|██████████████████████████▊     | 151/180 [00:26<00:05,  5.78it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  84%|██████████████████████████▊     | 151/180 [00:26<00:05,  5.78it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 4:  84%|███████████████████████████     | 152/180 [00:26<00:04,  5.77it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 4:  84%|███████████████████████████     | 152/180 [00:26<00:04,  5.77it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 4:  85%|███████████████████████████▏    | 153/180 [00:26<00:04,  5.79it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 4:  85%|███████████████████████████▏    | 153/180 [00:26<00:04,  5.79it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  86%|███████████████████████████▍    | 154/180 [00:26<00:04,  5.79it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 4:  86%|███████████████████████████▍    | 154/180 [00:26<00:04,  5.79it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 4:  86%|███████████████████████████▌    | 155/180 [00:26<00:04,  5.81it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 4:  86%|███████████████████████████▌    | 155/180 [00:26<00:04,  5.81it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 4:  87%|███████████████████████████▋    | 156/180 [00:26<00:04,  5.80it/s, training_loss=0.112]\u001b[A\n",
      "Epoch 4:  87%|███████████████████████████▋    | 156/180 [00:27<00:04,  5.80it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 4:  87%|███████████████████████████▉    | 157/180 [00:27<00:03,  5.80it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 4:  87%|███████████████████████████▉    | 157/180 [00:27<00:03,  5.80it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 4:  88%|████████████████████████████    | 158/180 [00:27<00:03,  5.81it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 4:  88%|████████████████████████████    | 158/180 [00:27<00:03,  5.81it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 4:  88%|████████████████████████████▎   | 159/180 [00:27<00:03,  5.81it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 4:  88%|████████████████████████████▎   | 159/180 [00:27<00:03,  5.81it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 4:  89%|████████████████████████████▍   | 160/180 [00:27<00:03,  5.85it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 4:  89%|████████████████████████████▍   | 160/180 [00:27<00:03,  5.85it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  89%|████████████████████████████▌   | 161/180 [00:27<00:03,  5.82it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  89%|████████████████████████████▌   | 161/180 [00:27<00:03,  5.82it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 4:  90%|████████████████████████████▊   | 162/180 [00:27<00:03,  5.81it/s, training_loss=0.072]\u001b[A\n",
      "Epoch 4:  90%|████████████████████████████▊   | 162/180 [00:28<00:03,  5.81it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 4:  91%|████████████████████████████▉   | 163/180 [00:28<00:02,  5.82it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 4:  91%|████████████████████████████▉   | 163/180 [00:28<00:02,  5.82it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 4:  91%|█████████████████████████████▏  | 164/180 [00:28<00:02,  5.81it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 4:  91%|█████████████████████████████▏  | 164/180 [00:28<00:02,  5.81it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 4:  92%|█████████████████████████████▎  | 165/180 [00:28<00:02,  5.81it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 4:  92%|█████████████████████████████▎  | 165/180 [00:28<00:02,  5.81it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  92%|█████████████████████████████▌  | 166/180 [00:28<00:02,  5.80it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 4:  92%|█████████████████████████████▌  | 166/180 [00:28<00:02,  5.80it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 4:  93%|█████████████████████████████▋  | 167/180 [00:28<00:02,  5.79it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 4:  93%|█████████████████████████████▋  | 167/180 [00:28<00:02,  5.79it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:  93%|█████████████████████████████▊  | 168/180 [00:28<00:02,  5.79it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 4:  93%|█████████████████████████████▊  | 168/180 [00:29<00:02,  5.79it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 4:  94%|██████████████████████████████  | 169/180 [00:29<00:01,  5.77it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 4:  94%|██████████████████████████████  | 169/180 [00:29<00:01,  5.77it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  94%|██████████████████████████████▏ | 170/180 [00:29<00:01,  5.78it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  94%|██████████████████████████████▏ | 170/180 [00:29<00:01,  5.78it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 4:  95%|██████████████████████████████▍ | 171/180 [00:29<00:01,  5.78it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 4:  95%|██████████████████████████████▍ | 171/180 [00:29<00:01,  5.78it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 4:  96%|██████████████████████████████▌ | 172/180 [00:29<00:01,  5.77it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 4:  96%|██████████████████████████████▌ | 172/180 [00:29<00:01,  5.77it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 4:  96%|██████████████████████████████▊ | 173/180 [00:29<00:01,  5.78it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 4:  96%|██████████████████████████████▊ | 173/180 [00:30<00:01,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  97%|██████████████████████████████▉ | 174/180 [00:30<00:01,  5.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  97%|██████████████████████████████▉ | 174/180 [00:30<00:01,  5.77it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  97%|███████████████████████████████ | 175/180 [00:30<00:00,  5.79it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  97%|███████████████████████████████ | 175/180 [00:30<00:00,  5.79it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  98%|███████████████████████████████▎| 176/180 [00:30<00:00,  5.77it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 4:  98%|███████████████████████████████▎| 176/180 [00:30<00:00,  5.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  98%|███████████████████████████████▍| 177/180 [00:30<00:00,  5.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4:  98%|███████████████████████████████▍| 177/180 [00:30<00:00,  5.79it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 4:  99%|███████████████████████████████▋| 178/180 [00:30<00:00,  5.84it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 4:  99%|███████████████████████████████▋| 178/180 [00:30<00:00,  5.84it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  99%|███████████████████████████████▊| 179/180 [00:30<00:00,  5.75it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 4:  99%|███████████████████████████████▊| 179/180 [00:31<00:00,  5.75it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 4: 100%|████████████████████████████████| 180/180 [00:31<00:00,  6.26it/s, training_loss=0.002]\u001b[A\n",
      "Epoch Progress:  10%|████▉                                            | 4/40 [02:02<18:28, 30.79s/it]\u001b[A\n",
      "Epoch 5:   0%|                                                               | 0/180 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:   0%|                                          | 0/180 [00:00<?, ?it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 5:   1%|▏                                 | 1/180 [00:00<00:30,  5.82it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 5:   1%|▏                                 | 1/180 [00:00<00:30,  5.82it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:   1%|▍                                 | 2/180 [00:00<00:30,  5.80it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:   1%|▍                                 | 2/180 [00:00<00:30,  5.80it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:   2%|▌                                 | 3/180 [00:00<00:30,  5.81it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:   2%|▌                                 | 3/180 [00:00<00:30,  5.81it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:   2%|▊                                 | 4/180 [00:00<00:30,  5.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:   2%|▊                                 | 4/180 [00:00<00:30,  5.80it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   3%|▉                                 | 5/180 [00:00<00:29,  5.87it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   3%|▉                                 | 5/180 [00:01<00:29,  5.87it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 5:   3%|█▏                                | 6/180 [00:01<00:30,  5.77it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 5:   3%|█▏                                | 6/180 [00:01<00:30,  5.77it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 5:   4%|█▎                                | 7/180 [00:01<00:30,  5.69it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 5:   4%|█▎                                | 7/180 [00:01<00:30,  5.69it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 5:   4%|█▌                                | 8/180 [00:01<00:30,  5.67it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 5:   4%|█▌                                | 8/180 [00:01<00:30,  5.67it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:   5%|█▋                                | 9/180 [00:01<00:29,  5.71it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:   5%|█▋                                | 9/180 [00:01<00:29,  5.71it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:   6%|█▊                               | 10/180 [00:01<00:29,  5.73it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:   6%|█▊                               | 10/180 [00:01<00:29,  5.73it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:   6%|██                               | 11/180 [00:01<00:29,  5.74it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:   6%|██                               | 11/180 [00:02<00:29,  5.74it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   7%|██▏                              | 12/180 [00:02<00:29,  5.75it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   7%|██▏                              | 12/180 [00:02<00:29,  5.75it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 5:   7%|██▍                              | 13/180 [00:02<00:29,  5.76it/s, training_loss=0.067]\u001b[A\n",
      "Epoch 5:   7%|██▍                              | 13/180 [00:02<00:29,  5.76it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 5:   8%|██▌                              | 14/180 [00:02<00:28,  5.88it/s, training_loss=0.010]\u001b[A\n",
      "Epoch 5:   8%|██▌                              | 14/180 [00:02<00:28,  5.88it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   8%|██▊                              | 15/180 [00:02<00:28,  5.76it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   8%|██▊                              | 15/180 [00:02<00:28,  5.76it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   9%|██▉                              | 16/180 [00:02<00:28,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:   9%|██▉                              | 16/180 [00:02<00:28,  5.78it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:   9%|███                              | 17/180 [00:02<00:28,  5.76it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:   9%|███                              | 17/180 [00:03<00:28,  5.76it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 5:  10%|███▎                             | 18/180 [00:03<00:28,  5.74it/s, training_loss=0.080]\u001b[A\n",
      "Epoch 5:  10%|███▎                             | 18/180 [00:03<00:28,  5.74it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 5:  11%|███▍                             | 19/180 [00:03<00:27,  5.75it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 5:  11%|███▍                             | 19/180 [00:03<00:27,  5.75it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 5:  11%|███▋                             | 20/180 [00:03<00:27,  5.77it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 5:  11%|███▋                             | 20/180 [00:03<00:27,  5.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  12%|███▊                             | 21/180 [00:03<00:27,  5.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  12%|███▊                             | 21/180 [00:03<00:27,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  12%|████                             | 22/180 [00:03<00:27,  5.79it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  12%|████                             | 22/180 [00:03<00:27,  5.79it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:  13%|████▏                            | 23/180 [00:03<00:27,  5.78it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:  13%|████▏                            | 23/180 [00:04<00:27,  5.78it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 5:  13%|████▍                            | 24/180 [00:04<00:26,  5.79it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 5:  13%|████▍                            | 24/180 [00:04<00:26,  5.79it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 5:  14%|████▌                            | 25/180 [00:04<00:26,  5.79it/s, training_loss=0.048]\u001b[A\n",
      "Epoch 5:  14%|████▌                            | 25/180 [00:04<00:26,  5.79it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 5:  14%|████▊                            | 26/180 [00:04<00:26,  5.78it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 5:  14%|████▊                            | 26/180 [00:04<00:26,  5.78it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 5:  15%|████▉                            | 27/180 [00:04<00:26,  5.78it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 5:  15%|████▉                            | 27/180 [00:04<00:26,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  16%|█████▏                           | 28/180 [00:04<00:26,  5.80it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  16%|█████▏                           | 28/180 [00:05<00:26,  5.80it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 5:  16%|█████▎                           | 29/180 [00:05<00:26,  5.78it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 5:  16%|█████▎                           | 29/180 [00:05<00:26,  5.78it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5:  17%|█████▌                           | 30/180 [00:05<00:25,  5.80it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5:  17%|█████▌                           | 30/180 [00:05<00:25,  5.80it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 5:  17%|█████▋                           | 31/180 [00:05<00:25,  5.74it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 5:  17%|█████▋                           | 31/180 [00:05<00:25,  5.74it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 5:  18%|█████▊                           | 32/180 [00:05<00:25,  5.72it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 5:  18%|█████▊                           | 32/180 [00:05<00:25,  5.72it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  18%|██████                           | 33/180 [00:05<00:25,  5.75it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  18%|██████                           | 33/180 [00:05<00:25,  5.75it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 5:  19%|██████▏                          | 34/180 [00:05<00:25,  5.76it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 5:  19%|██████▏                          | 34/180 [00:06<00:25,  5.76it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 5:  19%|██████▍                          | 35/180 [00:06<00:25,  5.77it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 5:  19%|██████▍                          | 35/180 [00:06<00:25,  5.77it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 5:  20%|██████▌                          | 36/180 [00:06<00:24,  5.78it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 5:  20%|██████▌                          | 36/180 [00:06<00:24,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  21%|██████▊                          | 37/180 [00:06<00:24,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  21%|██████▊                          | 37/180 [00:06<00:24,  5.78it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 5:  21%|██████▉                          | 38/180 [00:06<00:24,  5.77it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 5:  21%|██████▉                          | 38/180 [00:06<00:24,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  22%|███████▏                         | 39/180 [00:06<00:24,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  22%|███████▏                         | 39/180 [00:06<00:24,  5.78it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 5:  22%|███████▎                         | 40/180 [00:06<00:24,  5.78it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 5:  22%|███████▎                         | 40/180 [00:07<00:24,  5.78it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 5:  23%|███████▌                         | 41/180 [00:07<00:24,  5.79it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 5:  23%|███████▌                         | 41/180 [00:07<00:24,  5.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  23%|███████▋                         | 42/180 [00:07<00:23,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  23%|███████▋                         | 42/180 [00:07<00:23,  5.78it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 5:  24%|███████▉                         | 43/180 [00:07<00:23,  5.77it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 5:  24%|███████▉                         | 43/180 [00:07<00:23,  5.77it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  24%|████████                         | 44/180 [00:07<00:23,  5.78it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  24%|████████                         | 44/180 [00:07<00:23,  5.78it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 5:  25%|████████▎                        | 45/180 [00:07<00:23,  5.78it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 5:  25%|████████▎                        | 45/180 [00:07<00:23,  5.78it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 5:  26%|████████▍                        | 46/180 [00:07<00:23,  5.78it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 5:  26%|████████▍                        | 46/180 [00:08<00:23,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  26%|████████▌                        | 47/180 [00:08<00:23,  5.71it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  26%|████████▌                        | 47/180 [00:08<00:23,  5.71it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 5:  27%|████████▊                        | 48/180 [00:08<00:23,  5.73it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 5:  27%|████████▊                        | 48/180 [00:08<00:23,  5.73it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 5:  27%|████████▉                        | 49/180 [00:08<00:22,  5.75it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 5:  27%|████████▉                        | 49/180 [00:08<00:22,  5.75it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  28%|█████████▏                       | 50/180 [00:08<00:22,  5.75it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  28%|█████████▏                       | 50/180 [00:08<00:22,  5.75it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:  28%|█████████▎                       | 51/180 [00:08<00:22,  5.76it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:  28%|█████████▎                       | 51/180 [00:09<00:22,  5.76it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 5:  29%|█████████▌                       | 52/180 [00:09<00:21,  5.84it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 5:  29%|█████████▌                       | 52/180 [00:09<00:21,  5.84it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  29%|█████████▋                       | 53/180 [00:09<00:22,  5.74it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  29%|█████████▋                       | 53/180 [00:09<00:22,  5.74it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 5:  30%|█████████▉                       | 54/180 [00:09<00:22,  5.65it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 5:  30%|█████████▉                       | 54/180 [00:09<00:22,  5.65it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  31%|██████████                       | 55/180 [00:09<00:22,  5.66it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  31%|██████████                       | 55/180 [00:09<00:22,  5.66it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 5:  31%|██████████▎                      | 56/180 [00:09<00:21,  5.71it/s, training_loss=0.043]\u001b[A\n",
      "Epoch 5:  31%|██████████▎                      | 56/180 [00:09<00:21,  5.71it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 5:  32%|██████████▍                      | 57/180 [00:09<00:21,  5.72it/s, training_loss=0.079]\u001b[A\n",
      "Epoch 5:  32%|██████████▍                      | 57/180 [00:10<00:21,  5.72it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  32%|██████████▋                      | 58/180 [00:10<00:21,  5.74it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  32%|██████████▋                      | 58/180 [00:10<00:21,  5.74it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 5:  33%|██████████▊                      | 59/180 [00:10<00:21,  5.76it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 5:  33%|██████████▊                      | 59/180 [00:10<00:21,  5.76it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  33%|███████████                      | 60/180 [00:10<00:20,  5.76it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  33%|███████████                      | 60/180 [00:10<00:20,  5.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  34%|███████████▏                     | 61/180 [00:10<00:20,  5.75it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  34%|███████████▏                     | 61/180 [00:10<00:20,  5.75it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 5:  34%|███████████▎                     | 62/180 [00:10<00:20,  5.76it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 5:  34%|███████████▎                     | 62/180 [00:10<00:20,  5.76it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  35%|███████████▌                     | 63/180 [00:10<00:20,  5.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  35%|███████████▌                     | 63/180 [00:11<00:20,  5.77it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:  36%|███████████▋                     | 64/180 [00:11<00:20,  5.69it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:  36%|███████████▋                     | 64/180 [00:11<00:20,  5.69it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 5:  36%|███████████▉                     | 65/180 [00:11<00:20,  5.70it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 5:  36%|███████████▉                     | 65/180 [00:11<00:20,  5.70it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  37%|████████████                     | 66/180 [00:11<00:20,  5.68it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  37%|████████████                     | 66/180 [00:11<00:20,  5.68it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 5:  37%|████████████▎                    | 67/180 [00:11<00:19,  5.71it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 5:  37%|████████████▎                    | 67/180 [00:11<00:19,  5.71it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  38%|████████████▍                    | 68/180 [00:11<00:19,  5.74it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  38%|████████████▍                    | 68/180 [00:11<00:19,  5.74it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  38%|████████████▋                    | 69/180 [00:11<00:19,  5.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  38%|████████████▋                    | 69/180 [00:12<00:19,  5.79it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 5:  39%|████████████▊                    | 70/180 [00:12<00:19,  5.75it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 5:  39%|████████████▊                    | 70/180 [00:12<00:19,  5.75it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  39%|█████████████                    | 71/180 [00:12<00:18,  5.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  39%|█████████████                    | 71/180 [00:12<00:18,  5.76it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 5:  40%|█████████████▏                   | 72/180 [00:12<00:18,  5.75it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 5:  40%|█████████████▏                   | 72/180 [00:12<00:18,  5.75it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  41%|█████████████▍                   | 73/180 [00:12<00:18,  5.76it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  41%|█████████████▍                   | 73/180 [00:12<00:18,  5.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  41%|█████████████▌                   | 74/180 [00:12<00:18,  5.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  41%|█████████████▌                   | 74/180 [00:13<00:18,  5.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  42%|█████████████▊                   | 75/180 [00:13<00:18,  5.70it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  42%|█████████████▊                   | 75/180 [00:13<00:18,  5.70it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 5:  42%|█████████████▉                   | 76/180 [00:13<00:18,  5.73it/s, training_loss=0.039]\u001b[A\n",
      "Epoch 5:  42%|█████████████▉                   | 76/180 [00:13<00:18,  5.73it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  43%|██████████████                   | 77/180 [00:13<00:17,  5.73it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  43%|██████████████                   | 77/180 [00:13<00:17,  5.73it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 5:  43%|██████████████▎                  | 78/180 [00:13<00:17,  5.75it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 5:  43%|██████████████▎                  | 78/180 [00:13<00:17,  5.75it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  44%|██████████████▍                  | 79/180 [00:13<00:17,  5.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  44%|██████████████▍                  | 79/180 [00:13<00:17,  5.77it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 5:  44%|██████████████▋                  | 80/180 [00:13<00:17,  5.77it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 5:  44%|██████████████▋                  | 80/180 [00:14<00:17,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  45%|██████████████▊                  | 81/180 [00:14<00:17,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  45%|██████████████▊                  | 81/180 [00:14<00:17,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  46%|███████████████                  | 82/180 [00:14<00:16,  5.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  46%|███████████████                  | 82/180 [00:14<00:16,  5.79it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 5:  46%|███████████████▏                 | 83/180 [00:14<00:16,  5.79it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 5:  46%|███████████████▏                 | 83/180 [00:14<00:16,  5.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  47%|███████████████▍                 | 84/180 [00:14<00:16,  5.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  47%|███████████████▍                 | 84/180 [00:14<00:16,  5.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  47%|███████████████▌                 | 85/180 [00:14<00:16,  5.80it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  47%|███████████████▌                 | 85/180 [00:14<00:16,  5.80it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 5:  48%|███████████████▊                 | 86/180 [00:14<00:16,  5.79it/s, training_loss=0.142]\u001b[A\n",
      "Epoch 5:  48%|███████████████▊                 | 86/180 [00:15<00:16,  5.79it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 5:  48%|███████████████▉                 | 87/180 [00:15<00:16,  5.79it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 5:  48%|███████████████▉                 | 87/180 [00:15<00:16,  5.79it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 5:  49%|████████████████▏                | 88/180 [00:15<00:15,  5.89it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 5:  49%|████████████████▏                | 88/180 [00:15<00:15,  5.89it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 5:  49%|████████████████▎                | 89/180 [00:15<00:15,  5.76it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 5:  49%|████████████████▎                | 89/180 [00:15<00:15,  5.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  50%|████████████████▌                | 90/180 [00:15<00:15,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  50%|████████████████▌                | 90/180 [00:15<00:15,  5.78it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 5:  51%|████████████████▋                | 91/180 [00:15<00:15,  5.76it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 5:  51%|████████████████▋                | 91/180 [00:15<00:15,  5.76it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  51%|████████████████▊                | 92/180 [00:15<00:15,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  51%|████████████████▊                | 92/180 [00:16<00:15,  5.78it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  52%|█████████████████                | 93/180 [00:16<00:15,  5.79it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  52%|█████████████████                | 93/180 [00:16<00:15,  5.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  52%|█████████████████▏               | 94/180 [00:16<00:14,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  52%|█████████████████▏               | 94/180 [00:16<00:14,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  53%|█████████████████▍               | 95/180 [00:16<00:14,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  53%|█████████████████▍               | 95/180 [00:16<00:14,  5.78it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 5:  53%|█████████████████▌               | 96/180 [00:16<00:14,  5.76it/s, training_loss=0.021]\u001b[A\n",
      "Epoch 5:  53%|█████████████████▌               | 96/180 [00:16<00:14,  5.76it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  54%|█████████████████▊               | 97/180 [00:16<00:14,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  54%|█████████████████▊               | 97/180 [00:17<00:14,  5.77it/s, training_loss=0.150]\u001b[A\n",
      "Epoch 5:  54%|█████████████████▉               | 98/180 [00:17<00:14,  5.77it/s, training_loss=0.150]\u001b[A\n",
      "Epoch 5:  54%|█████████████████▉               | 98/180 [00:17<00:14,  5.77it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 5:  55%|██████████████████▏              | 99/180 [00:17<00:14,  5.76it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 5:  55%|██████████████████▏              | 99/180 [00:17<00:14,  5.76it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  56%|█████████████████▊              | 100/180 [00:17<00:13,  5.75it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  56%|█████████████████▊              | 100/180 [00:17<00:13,  5.75it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 5:  56%|█████████████████▉              | 101/180 [00:17<00:13,  5.78it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 5:  56%|█████████████████▉              | 101/180 [00:17<00:13,  5.78it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 5:  57%|██████████████████▏             | 102/180 [00:17<00:13,  5.77it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 5:  57%|██████████████████▏             | 102/180 [00:17<00:13,  5.77it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 5:  57%|██████████████████▎             | 103/180 [00:17<00:13,  5.77it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 5:  57%|██████████████████▎             | 103/180 [00:18<00:13,  5.77it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 5:  58%|██████████████████▍             | 104/180 [00:18<00:13,  5.78it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 5:  58%|██████████████████▍             | 104/180 [00:18<00:13,  5.78it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 5:  58%|██████████████████▋             | 105/180 [00:18<00:12,  5.78it/s, training_loss=0.057]\u001b[A\n",
      "Epoch 5:  58%|██████████████████▋             | 105/180 [00:18<00:12,  5.78it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 5:  59%|██████████████████▊             | 106/180 [00:18<00:12,  5.79it/s, training_loss=0.015]\u001b[A\n",
      "Epoch 5:  59%|██████████████████▊             | 106/180 [00:18<00:12,  5.79it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  59%|███████████████████             | 107/180 [00:18<00:12,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  59%|███████████████████             | 107/180 [00:18<00:12,  5.78it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 5:  60%|███████████████████▏            | 108/180 [00:18<00:12,  5.78it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 5:  60%|███████████████████▏            | 108/180 [00:18<00:12,  5.78it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 5:  61%|███████████████████▍            | 109/180 [00:18<00:12,  5.79it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 5:  61%|███████████████████▍            | 109/180 [00:19<00:12,  5.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  61%|███████████████████▌            | 110/180 [00:19<00:12,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  61%|███████████████████▌            | 110/180 [00:19<00:12,  5.78it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 5:  62%|███████████████████▋            | 111/180 [00:19<00:11,  5.77it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 5:  62%|███████████████████▋            | 111/180 [00:19<00:11,  5.77it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:  62%|███████████████████▉            | 112/180 [00:19<00:11,  5.78it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:  62%|███████████████████▉            | 112/180 [00:19<00:11,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  63%|████████████████████            | 113/180 [00:19<00:11,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  63%|████████████████████            | 113/180 [00:19<00:11,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  63%|████████████████████▎           | 114/180 [00:19<00:11,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  63%|████████████████████▎           | 114/180 [00:19<00:11,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  64%|████████████████████▍           | 115/180 [00:19<00:11,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  64%|████████████████████▍           | 115/180 [00:20<00:11,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  64%|████████████████████▌           | 116/180 [00:20<00:11,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  64%|████████████████████▌           | 116/180 [00:20<00:11,  5.78it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 5:  65%|████████████████████▊           | 117/180 [00:20<00:10,  5.77it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 5:  65%|████████████████████▊           | 117/180 [00:20<00:10,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  66%|████████████████████▉           | 118/180 [00:20<00:10,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  66%|████████████████████▉           | 118/180 [00:20<00:10,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  66%|█████████████████████▏          | 119/180 [00:20<00:10,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  66%|█████████████████████▏          | 119/180 [00:20<00:10,  5.78it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 5:  67%|█████████████████████▎          | 120/180 [00:20<00:10,  5.78it/s, training_loss=0.113]\u001b[A\n",
      "Epoch 5:  67%|█████████████████████▎          | 120/180 [00:20<00:10,  5.78it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 5:  67%|█████████████████████▌          | 121/180 [00:20<00:10,  5.79it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 5:  67%|█████████████████████▌          | 121/180 [00:21<00:10,  5.79it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 5:  68%|█████████████████████▋          | 122/180 [00:21<00:10,  5.78it/s, training_loss=0.017]\u001b[A\n",
      "Epoch 5:  68%|█████████████████████▋          | 122/180 [00:21<00:10,  5.78it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 5:  68%|█████████████████████▊          | 123/180 [00:21<00:09,  5.78it/s, training_loss=0.012]\u001b[A\n",
      "Epoch 5:  68%|█████████████████████▊          | 123/180 [00:21<00:09,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  69%|██████████████████████          | 124/180 [00:21<00:09,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  69%|██████████████████████          | 124/180 [00:21<00:09,  5.78it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 5:  69%|██████████████████████▏         | 125/180 [00:21<00:09,  5.79it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 5:  69%|██████████████████████▏         | 125/180 [00:21<00:09,  5.79it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 5:  70%|██████████████████████▍         | 126/180 [00:21<00:09,  5.78it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 5:  70%|██████████████████████▍         | 126/180 [00:22<00:09,  5.78it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 5:  71%|██████████████████████▌         | 127/180 [00:22<00:09,  5.77it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 5:  71%|██████████████████████▌         | 127/180 [00:22<00:09,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  71%|██████████████████████▊         | 128/180 [00:22<00:09,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  71%|██████████████████████▊         | 128/180 [00:22<00:09,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  72%|██████████████████████▉         | 129/180 [00:22<00:08,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  72%|██████████████████████▉         | 129/180 [00:22<00:08,  5.78it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 5:  72%|███████████████████████         | 130/180 [00:22<00:08,  5.78it/s, training_loss=0.009]\u001b[A\n",
      "Epoch 5:  72%|███████████████████████         | 130/180 [00:22<00:08,  5.78it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:  73%|███████████████████████▎        | 131/180 [00:22<00:08,  5.78it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:  73%|███████████████████████▎        | 131/180 [00:22<00:08,  5.78it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 5:  73%|███████████████████████▍        | 132/180 [00:22<00:08,  5.77it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 5:  73%|███████████████████████▍        | 132/180 [00:23<00:08,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  74%|███████████████████████▋        | 133/180 [00:23<00:08,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  74%|███████████████████████▋        | 133/180 [00:23<00:08,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  74%|███████████████████████▊        | 134/180 [00:23<00:07,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  74%|███████████████████████▊        | 134/180 [00:23<00:07,  5.78it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 5:  75%|████████████████████████        | 135/180 [00:23<00:07,  5.77it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 5:  75%|████████████████████████        | 135/180 [00:23<00:07,  5.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  76%|████████████████████████▏       | 136/180 [00:23<00:07,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  76%|████████████████████████▏       | 136/180 [00:23<00:07,  5.78it/s, training_loss=0.137]\u001b[A\n",
      "Epoch 5:  76%|████████████████████████▎       | 137/180 [00:23<00:07,  5.78it/s, training_loss=0.137]\u001b[A\n",
      "Epoch 5:  76%|████████████████████████▎       | 137/180 [00:23<00:07,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  77%|████████████████████████▌       | 138/180 [00:23<00:07,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  77%|████████████████████████▌       | 138/180 [00:24<00:07,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  77%|████████████████████████▋       | 139/180 [00:24<00:07,  5.78it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 5:  77%|████████████████████████▋       | 139/180 [00:24<00:07,  5.78it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 5:  78%|████████████████████████▉       | 140/180 [00:24<00:06,  5.79it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 5:  78%|████████████████████████▉       | 140/180 [00:24<00:06,  5.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  78%|█████████████████████████       | 141/180 [00:24<00:06,  5.79it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  78%|█████████████████████████       | 141/180 [00:24<00:06,  5.79it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 5:  79%|█████████████████████████▏      | 142/180 [00:24<00:06,  5.74it/s, training_loss=0.098]\u001b[A\n",
      "Epoch 5:  79%|█████████████████████████▏      | 142/180 [00:24<00:06,  5.74it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:  79%|█████████████████████████▍      | 143/180 [00:24<00:06,  5.74it/s, training_loss=0.005]\u001b[A\n",
      "Epoch 5:  79%|█████████████████████████▍      | 143/180 [00:24<00:06,  5.74it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  80%|█████████████████████████▌      | 144/180 [00:24<00:06,  5.75it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  80%|█████████████████████████▌      | 144/180 [00:25<00:06,  5.75it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  81%|█████████████████████████▊      | 145/180 [00:25<00:06,  5.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  81%|█████████████████████████▊      | 145/180 [00:25<00:06,  5.76it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  81%|█████████████████████████▉      | 146/180 [00:25<00:05,  5.76it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  81%|█████████████████████████▉      | 146/180 [00:25<00:05,  5.76it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 5:  82%|██████████████████████████▏     | 147/180 [00:25<00:05,  5.77it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 5:  82%|██████████████████████████▏     | 147/180 [00:25<00:05,  5.77it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 5:  82%|██████████████████████████▎     | 148/180 [00:25<00:05,  5.77it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 5:  82%|██████████████████████████▎     | 148/180 [00:25<00:05,  5.77it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 5:  83%|██████████████████████████▍     | 149/180 [00:25<00:05,  5.78it/s, training_loss=0.165]\u001b[A\n",
      "Epoch 5:  83%|██████████████████████████▍     | 149/180 [00:26<00:05,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  83%|██████████████████████████▋     | 150/180 [00:26<00:05,  5.76it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  83%|██████████████████████████▋     | 150/180 [00:26<00:05,  5.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  84%|██████████████████████████▊     | 151/180 [00:26<00:05,  5.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  84%|██████████████████████████▊     | 151/180 [00:26<00:05,  5.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  84%|███████████████████████████     | 152/180 [00:26<00:04,  5.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  84%|███████████████████████████     | 152/180 [00:26<00:04,  5.79it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  85%|███████████████████████████▏    | 153/180 [00:26<00:04,  5.74it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  85%|███████████████████████████▏    | 153/180 [00:26<00:04,  5.74it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  86%|███████████████████████████▍    | 154/180 [00:26<00:04,  5.73it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  86%|███████████████████████████▍    | 154/180 [00:26<00:04,  5.73it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  86%|███████████████████████████▌    | 155/180 [00:26<00:04,  5.74it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 5:  86%|███████████████████████████▌    | 155/180 [00:27<00:04,  5.74it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 5:  87%|███████████████████████████▋    | 156/180 [00:27<00:04,  5.75it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 5:  87%|███████████████████████████▋    | 156/180 [00:27<00:04,  5.75it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 5:  87%|███████████████████████████▉    | 157/180 [00:27<00:03,  5.76it/s, training_loss=0.022]\u001b[A\n",
      "Epoch 5:  87%|███████████████████████████▉    | 157/180 [00:27<00:03,  5.76it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 5:  88%|████████████████████████████    | 158/180 [00:27<00:03,  5.76it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 5:  88%|████████████████████████████    | 158/180 [00:27<00:03,  5.76it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 5:  88%|████████████████████████████▎   | 159/180 [00:27<00:03,  5.76it/s, training_loss=0.127]\u001b[A\n",
      "Epoch 5:  88%|████████████████████████████▎   | 159/180 [00:27<00:03,  5.76it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 5:  89%|████████████████████████████▍   | 160/180 [00:27<00:03,  5.76it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 5:  89%|████████████████████████████▍   | 160/180 [00:27<00:03,  5.76it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 5:  89%|████████████████████████████▌   | 161/180 [00:27<00:03,  5.77it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 5:  89%|████████████████████████████▌   | 161/180 [00:28<00:03,  5.77it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 5:  90%|████████████████████████████▊   | 162/180 [00:28<00:03,  5.78it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 5:  90%|████████████████████████████▊   | 162/180 [00:28<00:03,  5.78it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:  91%|████████████████████████████▉   | 163/180 [00:28<00:02,  5.78it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:  91%|████████████████████████████▉   | 163/180 [00:28<00:02,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  91%|█████████████████████████████▏  | 164/180 [00:28<00:02,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  91%|█████████████████████████████▏  | 164/180 [00:28<00:02,  5.78it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 5:  92%|█████████████████████████████▎  | 165/180 [00:28<00:02,  5.78it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 5:  92%|█████████████████████████████▎  | 165/180 [00:28<00:02,  5.78it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 5:  92%|█████████████████████████████▌  | 166/180 [00:28<00:02,  5.78it/s, training_loss=0.147]\u001b[A\n",
      "Epoch 5:  92%|█████████████████████████████▌  | 166/180 [00:28<00:02,  5.78it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 5:  93%|█████████████████████████████▋  | 167/180 [00:28<00:02,  5.77it/s, training_loss=0.049]\u001b[A\n",
      "Epoch 5:  93%|█████████████████████████████▋  | 167/180 [00:29<00:02,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  93%|█████████████████████████████▊  | 168/180 [00:29<00:02,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  93%|█████████████████████████████▊  | 168/180 [00:29<00:02,  5.78it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 5:  94%|██████████████████████████████  | 169/180 [00:29<00:01,  5.79it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 5:  94%|██████████████████████████████  | 169/180 [00:29<00:01,  5.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  94%|██████████████████████████████▏ | 170/180 [00:29<00:01,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  94%|██████████████████████████████▏ | 170/180 [00:29<00:01,  5.77it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 5:  95%|██████████████████████████████▍ | 171/180 [00:29<00:01,  5.78it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 5:  95%|██████████████████████████████▍ | 171/180 [00:29<00:01,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  96%|██████████████████████████████▌ | 172/180 [00:29<00:01,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  96%|██████████████████████████████▌ | 172/180 [00:30<00:01,  5.77it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 5:  96%|██████████████████████████████▊ | 173/180 [00:30<00:01,  5.75it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 5:  96%|██████████████████████████████▊ | 173/180 [00:30<00:01,  5.75it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  97%|██████████████████████████████▉ | 174/180 [00:30<00:01,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 5:  97%|██████████████████████████████▉ | 174/180 [00:30<00:01,  5.77it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 5:  97%|███████████████████████████████ | 175/180 [00:30<00:00,  5.78it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 5:  97%|███████████████████████████████ | 175/180 [00:30<00:00,  5.78it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 5:  98%|███████████████████████████████▎| 176/180 [00:30<00:00,  5.77it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 5:  98%|███████████████████████████████▎| 176/180 [00:30<00:00,  5.77it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 5:  98%|███████████████████████████████▍| 177/180 [00:30<00:00,  5.78it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 5:  98%|███████████████████████████████▍| 177/180 [00:30<00:00,  5.78it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:  99%|███████████████████████████████▋| 178/180 [00:30<00:00,  5.78it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 5:  99%|███████████████████████████████▋| 178/180 [00:31<00:00,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  99%|███████████████████████████████▊| 179/180 [00:31<00:00,  5.83it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 5:  99%|███████████████████████████████▊| 179/180 [00:31<00:00,  5.83it/s, training_loss=0.008]\u001b[A\n",
      "Epoch 5: 100%|████████████████████████████████| 180/180 [00:31<00:00,  6.23it/s, training_loss=0.008]\u001b[A\n",
      "Epoch Progress:  12%|██████▏                                          | 5/40 [02:33<18:02, 30.93s/it]\u001b[A\n",
      "Epoch 6:   0%|                                                               | 0/180 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:   0%|                                          | 0/180 [00:00<?, ?it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 6:   1%|▏                                 | 1/180 [00:00<00:31,  5.63it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 6:   1%|▏                                 | 1/180 [00:00<00:31,  5.63it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:   1%|▍                                 | 2/180 [00:00<00:31,  5.73it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:   1%|▍                                 | 2/180 [00:00<00:31,  5.73it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   2%|▌                                 | 3/180 [00:00<00:30,  5.77it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   2%|▌                                 | 3/180 [00:00<00:30,  5.77it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 6:   2%|▊                                 | 4/180 [00:00<00:30,  5.77it/s, training_loss=0.004]\u001b[A\n",
      "Epoch 6:   2%|▊                                 | 4/180 [00:00<00:30,  5.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:   3%|▉                                 | 5/180 [00:00<00:30,  5.75it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:   3%|▉                                 | 5/180 [00:01<00:30,  5.75it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:   3%|█▏                                | 6/180 [00:01<00:30,  5.76it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:   3%|█▏                                | 6/180 [00:01<00:30,  5.76it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   4%|█▎                                | 7/180 [00:01<00:29,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   4%|█▎                                | 7/180 [00:01<00:29,  5.78it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 6:   4%|█▌                                | 8/180 [00:01<00:29,  5.85it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 6:   4%|█▌                                | 8/180 [00:01<00:29,  5.85it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:   5%|█▋                                | 9/180 [00:01<00:29,  5.73it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:   5%|█▋                                | 9/180 [00:01<00:29,  5.73it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 6:   6%|█▊                               | 10/180 [00:01<00:29,  5.76it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 6:   6%|█▊                               | 10/180 [00:01<00:29,  5.76it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 6:   6%|██                               | 11/180 [00:01<00:29,  5.71it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 6:   6%|██                               | 11/180 [00:02<00:29,  5.71it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   7%|██▏                              | 12/180 [00:02<00:29,  5.72it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   7%|██▏                              | 12/180 [00:02<00:29,  5.72it/s, training_loss=0.307]\u001b[A\n",
      "Epoch 6:   7%|██▍                              | 13/180 [00:02<00:29,  5.74it/s, training_loss=0.307]\u001b[A\n",
      "Epoch 6:   7%|██▍                              | 13/180 [00:02<00:29,  5.74it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:   8%|██▌                              | 14/180 [00:02<00:28,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:   8%|██▌                              | 14/180 [00:02<00:28,  5.77it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 6:   8%|██▊                              | 15/180 [00:02<00:28,  5.77it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 6:   8%|██▊                              | 15/180 [00:02<00:28,  5.77it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 6:   9%|██▉                              | 16/180 [00:02<00:28,  5.78it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 6:   9%|██▉                              | 16/180 [00:02<00:28,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   9%|███                              | 17/180 [00:02<00:28,  5.79it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:   9%|███                              | 17/180 [00:03<00:28,  5.79it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 6:  10%|███▎                             | 18/180 [00:03<00:27,  5.79it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 6:  10%|███▎                             | 18/180 [00:03<00:27,  5.79it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 6:  11%|███▍                             | 19/180 [00:03<00:27,  5.78it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 6:  11%|███▍                             | 19/180 [00:03<00:27,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  11%|███▋                             | 20/180 [00:03<00:27,  5.78it/s, training_loss=0.001]\u001b[A\n",
      "Epoch 6:  11%|███▋                             | 20/180 [00:03<00:27,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  12%|███▊                             | 21/180 [00:03<00:27,  5.78it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  12%|███▊                             | 21/180 [00:03<00:27,  5.78it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 6:  12%|████                             | 22/180 [00:03<00:27,  5.80it/s, training_loss=0.145]\u001b[A\n",
      "Epoch 6:  12%|████                             | 22/180 [00:03<00:27,  5.80it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 6:  13%|████▏                            | 23/180 [00:03<00:27,  5.74it/s, training_loss=0.007]\u001b[A\n",
      "Epoch 6:  13%|████▏                            | 23/180 [00:04<00:27,  5.74it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 6:  13%|████▍                            | 24/180 [00:04<00:27,  5.75it/s, training_loss=0.028]\u001b[A\n",
      "Epoch 6:  13%|████▍                            | 24/180 [00:04<00:27,  5.75it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 6:  14%|████▌                            | 25/180 [00:04<00:26,  5.75it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 6:  14%|████▌                            | 25/180 [00:04<00:26,  5.75it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  14%|████▊                            | 26/180 [00:04<00:26,  5.76it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  14%|████▊                            | 26/180 [00:04<00:26,  5.76it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  15%|████▉                            | 27/180 [00:04<00:26,  5.76it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  15%|████▉                            | 27/180 [00:04<00:26,  5.76it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  16%|█████▏                           | 28/180 [00:04<00:26,  5.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  16%|█████▏                           | 28/180 [00:05<00:26,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  16%|█████▎                           | 29/180 [00:05<00:26,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  16%|█████▎                           | 29/180 [00:05<00:26,  5.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  17%|█████▌                           | 30/180 [00:05<00:25,  5.77it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 6:  17%|█████▌                           | 30/180 [00:05<00:25,  5.77it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 6:  17%|█████▋                           | 31/180 [00:05<00:25,  5.79it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 6:  17%|█████▋                           | 31/180 [00:05<00:25,  5.79it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 6:  18%|█████▊                           | 32/180 [00:05<00:25,  5.78it/s, training_loss=0.031]\u001b[A\n",
      "Epoch 6:  18%|█████▊                           | 32/180 [00:05<00:25,  5.78it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 6:  18%|██████                           | 33/180 [00:05<00:25,  5.77it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 6:  18%|██████                           | 33/180 [00:05<00:25,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  19%|██████▏                          | 34/180 [00:05<00:25,  5.77it/s, training_loss=0.003]\u001b[A\n",
      "Epoch 6:  19%|██████▏                          | 34/180 [00:06<00:25,  5.77it/s, training_loss=0.006]\u001b[A\n",
      "Epoch 6:  19%|██████▍                          | 35/180 [00:06<00:25,  5.78it/s, training_loss=0.006]\u001b[A"
     ]
    }
   ],
   "source": [
    " #install packages\n",
    "!pip install transformers\n",
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import logging\n",
    "import random\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "def custom_train_test_split(df, test_size=0.2, random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X = df[['ade', 'soc_code']]\n",
    "    y = df['label']\n",
    "    \n",
    "    # Identify classes and their counts\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    \n",
    "    # Identify small classes\n",
    "    small_classes = classes[counts < 5]\n",
    "    \n",
    "    # Initialize lists for train and test sets\n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    X_test_list = []\n",
    "    y_test_list = []\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # Handle small classes separately\n",
    "    for cls in small_classes:\n",
    "        cls_mask = (y == cls)\n",
    "        cls_X = X[cls_mask]\n",
    "        cls_y = y[cls_mask]\n",
    "        cls_idx = df.index[cls_mask].tolist()\n",
    "        \n",
    "        if len(cls_X) == 1:\n",
    "            # If only one instance, put it in test set\n",
    "            test_indices.append(cls_idx[0])\n",
    "        else:\n",
    "            # Randomly choose one instance for testing\n",
    "            test_idx = np.random.choice(len(cls_X))\n",
    "            test_indices.append(cls_idx[test_idx])\n",
    "            \n",
    "            # Remaining instances go to training\n",
    "            train_indices.extend(np.delete(cls_idx, test_idx))\n",
    "    \n",
    "    # Combine the small class data into test and train sets\n",
    "    test_indices = np.array(test_indices)\n",
    "    train_indices = np.array(train_indices)\n",
    "    \n",
    "    X_test = df.loc[test_indices]\n",
    "    y_test = X_test['label']\n",
    "    \n",
    "    X_train = df.loc[train_indices]\n",
    "    y_train = X_train['label']\n",
    "    \n",
    "    # Handle large classes with stratified split\n",
    "    large_class_mask = ~np.isin(y, small_classes)\n",
    "    X_large = X[large_class_mask]\n",
    "    y_large = y[large_class_mask]\n",
    "    \n",
    "    X_train_large, X_test_large, y_train_large, y_test_large = train_test_split(\n",
    "        X_large, y_large, test_size=test_size, random_state=random_state, stratify=y_large\n",
    "    )\n",
    "    \n",
    "    # Combine large class data with the small class data\n",
    "    X_train = pd.concat([X_train, X_train_large], axis=0)\n",
    "    y_train = pd.concat([y_train, y_train_large], axis=0)\n",
    "    \n",
    "    X_test = pd.concat([X_test, X_test_large], axis=0)\n",
    "    y_test = pd.concat([y_test, y_test_large], axis=0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#evaluation\n",
    "def accuracy_per_class(predictions, true_vals):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "\n",
    "    accuracy_dict = {}\n",
    "    count_dict = {}\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = pred_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        accuracy_dict[label] = np.sum(y_preds == y_true) / len(y_true) if len(y_true) > 0 else 0\n",
    "        count_dict[label] = len(y_true)\n",
    "\n",
    "    return accuracy_dict, count_dict\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "\n",
    "# Function to calculate precision, recall, and F1 for each label\n",
    "def calculate_metrics(predictions, true_vals):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score per label\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels_flat, pred_flat, average=None, labels=np.unique(labels_flat))\n",
    "    \n",
    "    return precision, recall, f1\n",
    "    \n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='combine_top6_training_40ep_16bs_5e-5lr_log_Ev_CADEC.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class TQDMLoggingWrapper(tqdm):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.logger = logger\n",
    "\n",
    "    def display(self, msg=None, pos=None):\n",
    "        if msg is not None:\n",
    "            self.logger.info(msg)\n",
    "        super().display(msg, pos)\n",
    "\n",
    "    def update(self, n=1):\n",
    "        super().update(n)\n",
    "        desc = self.format_dict.get('desc', 'No description')\n",
    "        postfix = self.format_dict.get('postfix', '')\n",
    "        self.logger.info(f'{desc} - {postfix}')\n",
    "\n",
    "    def set_description(self, desc=None, refresh=True):\n",
    "        super().set_description(desc, refresh)\n",
    "        if desc:\n",
    "            self.logger.info(f'Set description: {desc}')\n",
    "\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "#Read data from git:\n",
    "#https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\n",
    "# URL of the CSV file\n",
    "cadec_csv_url = \"https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\"\n",
    "# read data from smm4h\n",
    "smm4h_csv_url = \"https://raw.githubusercontent.com/FANMISUA/ADE_Norm/main/Data/smm4h_soc.tsv\"\n",
    "\n",
    "top6SMM4H = [10037175, 10018065,10029205, 10017947, 10028395, 10022891]\n",
    "top6label_dict = {\n",
    "    10037175: 0,\n",
    "    10018065: 1,\n",
    "    10029205: 2,\n",
    "    10017947: 3,\n",
    "    10028395: 4,\n",
    "    10022891: 5\n",
    "}\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"ade\", \"soc_code\"]\n",
    "smm4h_all = pd.read_csv(smm4h_csv_url,names=column_names, sep = '\\t', header=None)\n",
    "\n",
    "smm4h_all = smm4h_all[smm4h_all['soc_code'] != 0]\n",
    "smm4h_all['soc_code'] = pd.to_numeric(smm4h_all['soc_code'], errors='coerce').astype('Int64')\n",
    "smm4h_unique = smm4h_all.drop_duplicates(subset='ade')\n",
    "\n",
    "# print(\"smm4h data:\",smm4h_all.shape)\n",
    "smm4h_soc_code_counts = smm4h_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "# print(\"SOC count in CADEC: \",smm4h_soc_code_counts)\n",
    "# Filter DataFrame\n",
    "smm4h_filtered_data3 = smm4h_unique[smm4h_unique['soc_code'].isin(top6SMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "top3inSMM4H = smm4h_filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "top3inSMM4H.loc[:, 'label'] = top3inSMM4H['soc_code'].map(top6label_dict)\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"TT\", \"llt_code\", \"ade\", \"soc_code\"]\n",
    "cadec_all = pd.read_csv(cadec_csv_url,names=column_names, header=None)\n",
    "\n",
    "# Remove duplicate rows based on the 'ade' column\n",
    "cadec_unique = cadec_all.drop_duplicates(subset='ade')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "# print(\"clean cadec data:\",cadec_unique.shape)\n",
    "# Count occurrences of each 'soc_code'\n",
    "cadec_soc_code_counts = cadec_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "# print(\"SOC count in CADEC: \",cadec_soc_code_counts)\n",
    "\n",
    "\n",
    "# Filter DataFrame\n",
    "cadec_filtered_data3 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "CADECtop3inSMM4H = cadec_filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "\n",
    "# print(\"CADEC top3 in SMM4H:\",CADECtop3inSMM4H)\n",
    "\n",
    "# For SMM4H data\n",
    "df1 = top3inSMM4H.copy()\n",
    "df1.loc[:, 'label'] = df1['soc_code'].map(top6label_dict)\n",
    "\n",
    "# For CADEC data\n",
    "df2 = CADECtop3inSMM4H.copy()\n",
    "df2.loc[:, 'label'] = df2['soc_code'].map(top6label_dict)\n",
    "\n",
    "print(\"SMM4H top 3\",df1)\n",
    "print(\"CADEC top 3\",df2)\n",
    "\n",
    "\n",
    "# Define the random seeds and other parameters\n",
    "seed_values = list(range(2, 42, 2))\n",
    "batch_size = 16\n",
    "epochs = 40\n",
    "learningrate = 5e-5\n",
    "\n",
    "# Placeholder for accuracies\n",
    "all_accuracies = {label: [] for label in range(len(top6label_dict))}\n",
    "\n",
    "# Initialize dictionaries to hold metrics for each seed\n",
    "# seed_metrics = {seed_val: {'precision': [], 'recall': [], 'f1': []} for seed_val in seed_values}\n",
    "seed_metrics = {seed_val: {'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'confusion_matrix': []} for seed_val in seed_values}\n",
    "\n",
    "\n",
    "# Main loop over seed values\n",
    "for seed_val in seed_values:\n",
    "    # Set seeds\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    # Data preparation\n",
    "    # Apply the custom train-test split\n",
    "    # X_train, X_val, y_train, y_val = custom_train_test_split(df, test_size=0.2, random_state=seed_val)\n",
    "    \n",
    "    # # Add data_type column\n",
    "    # df['data_type'] = 'not_set'\n",
    "    # df.loc[X_train.index, 'data_type'] = 'train'\n",
    "    # df.loc[X_val.index, 'data_type'] = 'val'\n",
    "\n",
    "    # logger.info(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "    # print(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "    # Perform train-test split on df1\n",
    "    X_train_idx1, X_val_idx1, y_train1, y_val1 = custom_train_test_split(df1, test_size=0.2, random_state=seed_val)\n",
    "\n",
    "    # Perform train-test split on df2\n",
    "    X_train_idx2, X_val_idx2, y_train2, y_val2 = custom_train_test_split(df2, test_size=0.2, random_state=seed_val)\n",
    "\n",
    "    #  set the 'data_type' column for df1 and df2\n",
    "    df1['data_type'] = 'not_set'\n",
    "    df2['data_type'] = 'not_set'\n",
    "\n",
    "    df1.loc[df1.index.isin(X_train_idx1.index), 'data_type'] = 'train'\n",
    "    df1.loc[df1.index.isin(X_val_idx1.index), 'data_type'] = 'val1'\n",
    "\n",
    "    df2.loc[df2.index.isin(X_train_idx2.index), 'data_type'] = 'train'\n",
    "    df2.loc[df2.index.isin(X_val_idx2.index), 'data_type'] = 'val'\n",
    "\n",
    "\n",
    "    # If you want to combine df1 and df2 into a single dataframe:\n",
    "    df = pd.concat([df1, df2])\n",
    "    print(\"df: \",df)\n",
    "    logger.info(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "    print(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "\n",
    "    \n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    encoded_data_train = tokenizer.batch_encode_plus(\n",
    "        df[df.data_type == 'train'].ade.values,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    encoded_data_val = tokenizer.batch_encode_plus(\n",
    "        df[df.data_type == 'val'].ade.values,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids_train = encoded_data_train['input_ids']\n",
    "    attention_masks_train = encoded_data_train['attention_mask']\n",
    "    labels_train = torch.tensor(df[df.data_type == 'train'].label.values)\n",
    "\n",
    "    input_ids_val = encoded_data_val['input_ids']\n",
    "    attention_masks_val = encoded_data_val['attention_mask']\n",
    "    labels_val = torch.tensor(df[df.data_type == 'val'].label.values)\n",
    "\n",
    "    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(top6label_dict), output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "    dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learningrate, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train) * epochs)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    logger.info(f\"Device used: {device}\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in TQDMLoggingWrapper(range(1, epochs+1), desc='Epoch Progress'):\n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "\n",
    "        progress_bar = TQDMLoggingWrapper(dataloader_train, desc=f'Epoch {epoch}', leave=False, disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            progress_bar.set_postfix({'training_loss': f'{loss.item()/len(batch):.3f}'})\n",
    "\n",
    "        # torch.save(model.state_dict(), f'./ADENorm_top3_epoch_{epoch}.model')\n",
    "\n",
    "        logger.info(f'\\nEpoch {epoch}')\n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        logger.info(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_vals.flatten(), np.argmax(predictions, axis=1).flatten(), average=None, labels=np.unique(true_vals.flatten()))\n",
    "\n",
    "     # Ensure that you use `true_vals` for the true labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1).flatten()\n",
    "    true_labels = true_vals.flatten()\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    seed_metrics[seed_val]['accuracy'] = accuracy\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=np.unique(true_labels))\n",
    "    seed_metrics[seed_val]['confusion_matrix'] = conf_matrix\n",
    "    \n",
    "    for label in np.unique(true_vals):\n",
    "        seed_metrics[seed_val]['precision'].append((label, precision[label]))\n",
    "        seed_metrics[seed_val]['recall'].append((label, recall[label]))\n",
    "        seed_metrics[seed_val]['f1'].append((label, f1[label]))\n",
    "\n",
    "# Write the precision, recall, F1 scores, and seed values to a file\n",
    "with open('combine_to6_20times_results_with_seeds_Ev_CADEC.txt', 'w') as f:\n",
    "    f.write('Seed\\tLabel\\tPrecision\\tRecall\\tF1\\tAccuracy\\n')\n",
    "    for seed_val in seed_values:\n",
    "        for label, precision_val in seed_metrics[seed_val]['precision']:\n",
    "            recall_val = next(val for lbl, val in seed_metrics[seed_val]['recall'] if lbl == label)\n",
    "            f1_val = next(val for lbl, val in seed_metrics[seed_val]['f1'] if lbl == label)\n",
    "            accuracy = seed_metrics[seed_val]['accuracy']\n",
    "            f.write(f'{seed_val}\\t{label}\\t{precision_val:.4f}\\t{recall_val:.4f}\\t{f1_val:.4f}\\t{accuracy:.4f}\\n')\n",
    "\n",
    "        # Save the confusion matrix\n",
    "        f.write(f'\\nConfusion Matrix for Seed {seed_val}:\\n')\n",
    "        f.write(np.array2string(seed_metrics[seed_val]['confusion_matrix'], separator=', '))\n",
    "        f.write('\\n')\n",
    "    \n",
    "# Initialize lists to hold precision, recall, and f1 values for each label\n",
    "precision_dict, recall_dict, f1_dict = {}, {}, {}\n",
    "\n",
    "# Collect metrics across seeds\n",
    "for seed in seed_metrics:\n",
    "    for label, value in seed_metrics[seed]['precision']:\n",
    "        precision_dict.setdefault(label, []).append(value)\n",
    "    for label, value in seed_metrics[seed]['recall']:\n",
    "        recall_dict.setdefault(label, []).append(value)\n",
    "    for label, value in seed_metrics[seed]['f1']:\n",
    "        f1_dict.setdefault(label, []).append(value)\n",
    "\n",
    "# Compute mean and std for precision, recall, and f1\n",
    "labels = sorted(precision_dict.keys())\n",
    "precision_mean = [np.mean(precision_dict[label]) for label in labels]\n",
    "precision_std = [np.std(precision_dict[label]) for label in labels]\n",
    "recall_mean = [np.mean(recall_dict[label]) for label in labels]\n",
    "recall_std = [np.std(recall_dict[label]) for label in labels]\n",
    "f1_mean = [np.mean(f1_dict[label]) for label in labels]\n",
    "f1_std = [np.std(f1_dict[label]) for label in labels]\n",
    "\n",
    "# Plotting\n",
    "x = np.arange(len(labels))  # label indices\n",
    "width = 0.25  # width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Bar plots with mean values\n",
    "bars_precision = ax.bar(x - width, precision_mean, width, label='Precision', color='b')\n",
    "bars_recall = ax.bar(x, recall_mean, width, label='Recall', color='g')\n",
    "bars_f1 = ax.bar(x + width, f1_mean, width, label='F1 Score', color='r')\n",
    "\n",
    "# Annotate bars with mean and std values\n",
    "# Annotate bars with mean and std values, with smaller font size\n",
    "for bars, means, stds in zip([bars_precision, bars_recall, bars_f1],\n",
    "                             [precision_mean, recall_mean, f1_mean],\n",
    "                             [precision_std, recall_std, f1_std]):\n",
    "    for bar, mean, std in zip(bars, means, stds):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2.0, height,\n",
    "                f'{mean:.2f}\\n±{std:.2f}', ha='center', va='bottom', fontsize=8)  # Smaller font size\n",
    "\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Label')\n",
    "ax.set_ylabel('Performance')\n",
    "ax.set_title('Mean and Standard Deviation of Precision, Recall, and F1 Score by Label')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "# Set y-axis limit to [0, 1]\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Move legend outside the plot\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust the plot to fit the legend\n",
    "plt.savefig('combine_top6_20times_results_plot_Ev_CADEC.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd69b5e-c47f-46d5-aa85-dc75901e5e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
