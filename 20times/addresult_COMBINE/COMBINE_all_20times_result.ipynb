{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3056cfc-5af3-4370-a0ee-badee5783431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "smm4h data: (1712, 2)\n",
      "smm4h data after filtering: (1710, 2)\n",
      "SOC count in SMM4H:  soc_code\n",
      "10037175    287\n",
      "10018065    235\n",
      "10029205    212\n",
      "10017947     63\n",
      "10028395     58\n",
      "10022891     54\n",
      "10027433     48\n",
      "10040785     28\n",
      "10038738     22\n",
      "10022117     16\n",
      "10015919     16\n",
      "10038604     10\n",
      "10047065     10\n",
      "10021428      8\n",
      "10041244      7\n",
      "10007541      7\n",
      "10038359      6\n",
      "10021881      5\n",
      "10013993      4\n",
      "10019805      2\n",
      "10042613      2\n",
      "10029104      2\n",
      "10077536      1\n",
      "10010331      1\n",
      "10014698      1\n",
      "Name: count, dtype: Int64\n",
      "SOC count in CADEC:  soc_code\n",
      "10028395    962\n",
      "10018065    654\n",
      "10037175    401\n",
      "10017947    300\n",
      "10029205    286\n",
      "10040785    184\n",
      "10007541     92\n",
      "10038738     91\n",
      "10022891     82\n",
      "10015919     67\n",
      "10038604     59\n",
      "10038359     50\n",
      "10022117     35\n",
      "10047065     25\n",
      "10013993     16\n",
      "10019805     15\n",
      "10041244      7\n",
      "10027433      6\n",
      "10021881      5\n",
      "10021428      4\n",
      "10014698      3\n",
      "10005329      3\n",
      "10029104      1\n",
      "Name: count, dtype: int64\n",
      "SMM4H :                             ade  soc_code  label\n",
      "1                     allergies  10021428     13\n",
      "2               HURT YOUR Liver  10019805     19\n",
      "3                            AD  10037175      0\n",
      "4                         focus  10029205      2\n",
      "5                          died  10018065      1\n",
      "...                         ...       ...    ...\n",
      "1703                 chest hurt  10018065      1\n",
      "1704   got ten minutes of sleep  10037175      0\n",
      "1706                  Nosebleed  10038738      8\n",
      "1708  never have another orgasm  10037175      0\n",
      "1710        gain so much weight  10022891      5\n",
      "\n",
      "[1105 rows x 3 columns]\n",
      "CADEC :                                    ade  soc_code  label\n",
      "3                      ankles swelling  10007541     15\n",
      "4             sever swelling of ankles  10007541     15\n",
      "5                      Edema of ankles  10007541     15\n",
      "6                    severe arrythmias  10007541     15\n",
      "7                            arrythmia  10007541     15\n",
      "...                                ...       ...    ...\n",
      "5955                      hypertension  10047065     12\n",
      "5956           Elevated blood pressure  10047065     12\n",
      "5959  LITTLE CIRCULATION IN MY FINGERS  10047065     12\n",
      "5960                  going into shock  10047065     12\n",
      "5961     vein in my one leg is bulging  10047065     12\n",
      "\n",
      "[3345 rows x 3 columns]\n",
      "df:                                     ade  soc_code  label data_type\n",
      "1                            allergies  10021428     13     train\n",
      "2                      HURT YOUR Liver  10019805     19     train\n",
      "3                                   AD  10037175      0     train\n",
      "4                                focus  10029205      2     train\n",
      "5                                 died  10018065      1     train\n",
      "...                                ...       ...    ...       ...\n",
      "5955                      hypertension  10047065     12     train\n",
      "5956           Elevated blood pressure  10047065     12     train\n",
      "5959  LITTLE CIRCULATION IN MY FINGERS  10047065     12       val\n",
      "5960                  going into shock  10047065     12     train\n",
      "5961     vein in my one leg is bulging  10047065     12     train\n",
      "\n",
      "[4450 rows x 4 columns]\n",
      "                          ade\n",
      "soc_code label data_type     \n",
      "10007541 15    train       79\n",
      "               val         20\n",
      "10010331 23    val          1\n",
      "10013993 18    train       16\n",
      "               val          4\n",
      "10014698 24    train        2\n",
      "               val          2\n",
      "10015919 10    train       67\n",
      "               val         16\n",
      "10017947 3     train      290\n",
      "               val         73\n",
      "10018065 1     train      711\n",
      "               val        178\n",
      "10019805 19    train       13\n",
      "               val          4\n",
      "10021428 13    train        9\n",
      "               val          3\n",
      "10021881 17    train        8\n",
      "               val          2\n",
      "10022117 9     train       41\n",
      "               val         10\n",
      "10022891 5     train      108\n",
      "               val         28\n",
      "10027433 6     train       43\n",
      "               val         11\n",
      "10028395 4     train      815\n",
      "               val        205\n",
      "10029104 21    train        1\n",
      "               val          2\n",
      "10029205 2     train      399\n",
      "               val         99\n",
      "10037175 0     train      550\n",
      "               val        138\n",
      "10038359 16    train       45\n",
      "               val         11\n",
      "10038604 11    train       55\n",
      "               val         14\n",
      "10038738 8     train       91\n",
      "               val         22\n",
      "10040785 7     train      169\n",
      "               val         43\n",
      "10041244 14    train       12\n",
      "               val          2\n",
      "10042613 20    train        1\n",
      "               val          1\n",
      "10047065 12    train       28\n",
      "               val          7\n",
      "10077536 22    val          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2888: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch Progress:   0%|                                                                                                 | 0/40 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|                                                                                                       | 0/223 [00:00<?, ?it/s]\u001b[AC:\\Users\\fd\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "\n",
      "Epoch 1:   0%|                                                                                  | 0/223 [00:01<?, ?it/s, training_loss=1.048]\u001b[A\n",
      "Epoch 1:   0%|▎                                                                         | 1/223 [00:01<04:01,  1.09s/it, training_loss=1.048]\u001b[A\n",
      "Epoch 1:   0%|▎                                                                         | 1/223 [00:01<04:01,  1.09s/it, training_loss=1.070]\u001b[A\n",
      "Epoch 1:   1%|▋                                                                         | 2/223 [00:01<02:47,  1.32it/s, training_loss=1.070]\u001b[A\n",
      "Epoch 1:   1%|▋                                                                         | 2/223 [00:02<02:47,  1.32it/s, training_loss=1.049]\u001b[A\n",
      "Epoch 1:   1%|▉                                                                         | 3/223 [00:02<02:23,  1.53it/s, training_loss=1.049]\u001b[A\n",
      "Epoch 1:   1%|▉                                                                         | 3/223 [00:02<02:23,  1.53it/s, training_loss=1.015]\u001b[A\n",
      "Epoch 1:   2%|█▎                                                                        | 4/223 [00:02<02:10,  1.67it/s, training_loss=1.015]\u001b[A\n",
      "Epoch 1:   2%|█▎                                                                        | 4/223 [00:03<02:10,  1.67it/s, training_loss=1.017]\u001b[A\n",
      "Epoch 1:   2%|█▋                                                                        | 5/223 [00:03<02:03,  1.76it/s, training_loss=1.017]\u001b[A\n",
      "Epoch 1:   2%|█▋                                                                        | 5/223 [00:03<02:03,  1.76it/s, training_loss=0.971]\u001b[A\n",
      "Epoch 1:   3%|█▉                                                                        | 6/223 [00:03<01:58,  1.83it/s, training_loss=0.971]\u001b[A\n",
      "Epoch 1:   3%|█▉                                                                        | 6/223 [00:04<01:58,  1.83it/s, training_loss=0.968]\u001b[A\n",
      "Epoch 1:   3%|██▎                                                                       | 7/223 [00:04<01:55,  1.87it/s, training_loss=0.968]\u001b[A\n",
      "Epoch 1:   3%|██▎                                                                       | 7/223 [00:04<01:55,  1.87it/s, training_loss=0.961]\u001b[A\n",
      "Epoch 1:   4%|██▋                                                                       | 8/223 [00:04<01:54,  1.88it/s, training_loss=0.961]\u001b[A\n",
      "Epoch 1:   4%|██▋                                                                       | 8/223 [00:05<01:54,  1.88it/s, training_loss=0.982]\u001b[A\n",
      "Epoch 1:   4%|██▉                                                                       | 9/223 [00:05<01:50,  1.94it/s, training_loss=0.982]\u001b[A\n",
      "Epoch 1:   4%|██▉                                                                       | 9/223 [00:05<01:50,  1.94it/s, training_loss=0.877]\u001b[A\n",
      "Epoch 1:   4%|███▎                                                                     | 10/223 [00:05<01:50,  1.94it/s, training_loss=0.877]\u001b[A\n",
      "Epoch 1:   4%|███▎                                                                     | 10/223 [00:06<01:50,  1.94it/s, training_loss=0.903]\u001b[A\n",
      "Epoch 1:   5%|███▌                                                                     | 11/223 [00:06<01:48,  1.96it/s, training_loss=0.903]\u001b[A\n",
      "Epoch 1:   5%|███▌                                                                     | 11/223 [00:06<01:48,  1.96it/s, training_loss=0.938]\u001b[A\n",
      "Epoch 1:   5%|███▉                                                                     | 12/223 [00:06<01:47,  1.95it/s, training_loss=0.938]\u001b[A\n",
      "Epoch 1:   5%|███▉                                                                     | 12/223 [00:07<01:47,  1.95it/s, training_loss=0.858]\u001b[A\n",
      "Epoch 1:   6%|████▎                                                                    | 13/223 [00:07<01:45,  2.00it/s, training_loss=0.858]\u001b[A\n",
      "Epoch 1:   6%|████▎                                                                    | 13/223 [00:07<01:45,  2.00it/s, training_loss=0.798]\u001b[A\n",
      "Epoch 1:   6%|████▌                                                                    | 14/223 [00:07<01:44,  2.00it/s, training_loss=0.798]\u001b[A\n",
      "Epoch 1:   6%|████▌                                                                    | 14/223 [00:08<01:44,  2.00it/s, training_loss=0.730]\u001b[A\n",
      "Epoch 1:   7%|████▉                                                                    | 15/223 [00:08<01:44,  1.99it/s, training_loss=0.730]\u001b[A\n",
      "Epoch 1:   7%|████▉                                                                    | 15/223 [00:08<01:44,  1.99it/s, training_loss=0.620]\u001b[A\n",
      "Epoch 1:   7%|█████▏                                                                   | 16/223 [00:08<01:43,  2.00it/s, training_loss=0.620]\u001b[A\n",
      "Epoch 1:   7%|█████▏                                                                   | 16/223 [00:09<01:43,  2.00it/s, training_loss=0.902]\u001b[A\n",
      "Epoch 1:   8%|█████▌                                                                   | 17/223 [00:09<01:43,  1.99it/s, training_loss=0.902]\u001b[A\n",
      "Epoch 1:   8%|█████▌                                                                   | 17/223 [00:09<01:43,  1.99it/s, training_loss=0.865]\u001b[A\n",
      "Epoch 1:   8%|█████▉                                                                   | 18/223 [00:09<01:43,  1.98it/s, training_loss=0.865]\u001b[A\n",
      "Epoch 1:   8%|█████▉                                                                   | 18/223 [00:10<01:43,  1.98it/s, training_loss=0.918]\u001b[A\n",
      "Epoch 1:   9%|██████▏                                                                  | 19/223 [00:10<01:42,  1.99it/s, training_loss=0.918]\u001b[A\n",
      "Epoch 1:   9%|██████▏                                                                  | 19/223 [00:10<01:42,  1.99it/s, training_loss=0.955]\u001b[A\n",
      "Epoch 1:   9%|██████▌                                                                  | 20/223 [00:10<01:42,  1.97it/s, training_loss=0.955]\u001b[A\n",
      "Epoch 1:   9%|██████▌                                                                  | 20/223 [00:11<01:42,  1.97it/s, training_loss=0.811]\u001b[A\n",
      "Epoch 1:   9%|██████▊                                                                  | 21/223 [00:11<01:41,  1.98it/s, training_loss=0.811]\u001b[A\n",
      "Epoch 1:   9%|██████▊                                                                  | 21/223 [00:11<01:41,  1.98it/s, training_loss=0.806]\u001b[A\n",
      "Epoch 1:  10%|███████▏                                                                 | 22/223 [00:11<01:41,  1.99it/s, training_loss=0.806]\u001b[A\n",
      "Epoch 1:  10%|███████▏                                                                 | 22/223 [00:12<01:41,  1.99it/s, training_loss=0.840]\u001b[A\n",
      "Epoch 1:  10%|███████▌                                                                 | 23/223 [00:12<01:39,  2.01it/s, training_loss=0.840]\u001b[A\n",
      "Epoch 1:  10%|███████▌                                                                 | 23/223 [00:12<01:39,  2.01it/s, training_loss=0.802]\u001b[A\n",
      "Epoch 1:  11%|███████▊                                                                 | 24/223 [00:12<01:39,  2.01it/s, training_loss=0.802]\u001b[A\n",
      "Epoch 1:  11%|███████▊                                                                 | 24/223 [00:13<01:39,  2.01it/s, training_loss=0.744]\u001b[A\n",
      "Epoch 1:  11%|████████▏                                                                | 25/223 [00:13<01:39,  1.99it/s, training_loss=0.744]\u001b[A\n",
      "Epoch 1:  11%|████████▏                                                                | 25/223 [00:13<01:39,  1.99it/s, training_loss=0.643]\u001b[A\n",
      "Epoch 1:  12%|████████▌                                                                | 26/223 [00:13<01:38,  2.01it/s, training_loss=0.643]\u001b[A\n",
      "Epoch 1:  12%|████████▌                                                                | 26/223 [00:14<01:38,  2.01it/s, training_loss=0.885]\u001b[A\n",
      "Epoch 1:  12%|████████▊                                                                | 27/223 [00:14<01:36,  2.03it/s, training_loss=0.885]\u001b[A\n",
      "Epoch 1:  12%|████████▊                                                                | 27/223 [00:14<01:36,  2.03it/s, training_loss=0.775]\u001b[A\n",
      "Epoch 1:  13%|█████████▏                                                               | 28/223 [00:14<01:37,  2.00it/s, training_loss=0.775]\u001b[A\n",
      "Epoch 1:  13%|█████████▏                                                               | 28/223 [00:15<01:37,  2.00it/s, training_loss=0.674]\u001b[A\n",
      "Epoch 1:  13%|█████████▍                                                               | 29/223 [00:15<01:37,  2.00it/s, training_loss=0.674]\u001b[A\n",
      "Epoch 1:  13%|█████████▍                                                               | 29/223 [00:15<01:37,  2.00it/s, training_loss=0.648]\u001b[A\n",
      "Epoch 1:  13%|█████████▊                                                               | 30/223 [00:15<01:36,  2.00it/s, training_loss=0.648]\u001b[A\n",
      "Epoch 1:  13%|█████████▊                                                               | 30/223 [00:16<01:36,  2.00it/s, training_loss=0.583]\u001b[A\n",
      "Epoch 1:  14%|██████████▏                                                              | 31/223 [00:16<01:35,  2.00it/s, training_loss=0.583]\u001b[A\n",
      "Epoch 1:  14%|██████████▏                                                              | 31/223 [00:16<01:35,  2.00it/s, training_loss=0.759]\u001b[A\n",
      "Epoch 1:  14%|██████████▍                                                              | 32/223 [00:16<01:34,  2.02it/s, training_loss=0.759]\u001b[A\n",
      "Epoch 1:  14%|██████████▍                                                              | 32/223 [00:17<01:34,  2.02it/s, training_loss=0.882]\u001b[A\n",
      "Epoch 1:  15%|██████████▊                                                              | 33/223 [00:17<01:32,  2.05it/s, training_loss=0.882]\u001b[A\n",
      "Epoch 1:  15%|██████████▊                                                              | 33/223 [00:17<01:32,  2.05it/s, training_loss=0.745]\u001b[A\n",
      "Epoch 1:  15%|███████████▏                                                             | 34/223 [00:17<01:32,  2.04it/s, training_loss=0.745]\u001b[A\n",
      "Epoch 1:  15%|███████████▏                                                             | 34/223 [00:18<01:32,  2.04it/s, training_loss=0.723]\u001b[A\n",
      "Epoch 1:  16%|███████████▍                                                             | 35/223 [00:18<01:32,  2.03it/s, training_loss=0.723]\u001b[A\n",
      "Epoch 1:  16%|███████████▍                                                             | 35/223 [00:18<01:32,  2.03it/s, training_loss=0.741]\u001b[A\n",
      "Epoch 1:  16%|███████████▊                                                             | 36/223 [00:18<01:31,  2.04it/s, training_loss=0.741]\u001b[A\n",
      "Epoch 1:  16%|███████████▊                                                             | 36/223 [00:19<01:31,  2.04it/s, training_loss=0.733]\u001b[A\n",
      "Epoch 1:  17%|████████████                                                             | 37/223 [00:19<01:31,  2.03it/s, training_loss=0.733]\u001b[A\n",
      "Epoch 1:  17%|████████████                                                             | 37/223 [00:19<01:31,  2.03it/s, training_loss=0.809]\u001b[A\n",
      "Epoch 1:  17%|████████████▍                                                            | 38/223 [00:19<01:30,  2.04it/s, training_loss=0.809]\u001b[A\n",
      "Epoch 1:  17%|████████████▍                                                            | 38/223 [00:20<01:30,  2.04it/s, training_loss=0.704]\u001b[A\n",
      "Epoch 1:  17%|████████████▊                                                            | 39/223 [00:20<01:31,  2.01it/s, training_loss=0.704]\u001b[A\n",
      "Epoch 1:  17%|████████████▊                                                            | 39/223 [00:20<01:31,  2.01it/s, training_loss=0.708]\u001b[A\n",
      "Epoch 1:  18%|█████████████                                                            | 40/223 [00:20<01:30,  2.02it/s, training_loss=0.708]\u001b[A\n",
      "Epoch 1:  18%|█████████████                                                            | 40/223 [00:21<01:30,  2.02it/s, training_loss=0.509]\u001b[A\n",
      "Epoch 1:  18%|█████████████▍                                                           | 41/223 [00:21<01:29,  2.04it/s, training_loss=0.509]\u001b[A\n",
      "Epoch 1:  18%|█████████████▍                                                           | 41/223 [00:21<01:29,  2.04it/s, training_loss=0.728]\u001b[A\n",
      "Epoch 1:  19%|█████████████▋                                                           | 42/223 [00:21<01:30,  2.01it/s, training_loss=0.728]\u001b[A\n",
      "Epoch 1:  19%|█████████████▋                                                           | 42/223 [00:22<01:30,  2.01it/s, training_loss=0.650]\u001b[A\n",
      "Epoch 1:  19%|██████████████                                                           | 43/223 [00:22<01:28,  2.02it/s, training_loss=0.650]\u001b[A\n",
      "Epoch 1:  19%|██████████████                                                           | 43/223 [00:22<01:28,  2.02it/s, training_loss=0.837]\u001b[A\n",
      "Epoch 1:  20%|██████████████▍                                                          | 44/223 [00:22<01:27,  2.04it/s, training_loss=0.837]\u001b[A\n",
      "Epoch 1:  20%|██████████████▍                                                          | 44/223 [00:23<01:27,  2.04it/s, training_loss=0.713]\u001b[A\n",
      "Epoch 1:  20%|██████████████▋                                                          | 45/223 [00:23<01:27,  2.03it/s, training_loss=0.713]\u001b[A\n",
      "Epoch 1:  20%|██████████████▋                                                          | 45/223 [00:23<01:27,  2.03it/s, training_loss=0.667]\u001b[A\n",
      "Epoch 1:  21%|███████████████                                                          | 46/223 [00:23<01:26,  2.04it/s, training_loss=0.667]\u001b[A\n",
      "Epoch 1:  21%|███████████████                                                          | 46/223 [00:24<01:26,  2.04it/s, training_loss=0.610]\u001b[A\n",
      "Epoch 1:  21%|███████████████▍                                                         | 47/223 [00:24<01:26,  2.03it/s, training_loss=0.610]\u001b[A\n",
      "Epoch 1:  21%|███████████████▍                                                         | 47/223 [00:24<01:26,  2.03it/s, training_loss=0.770]\u001b[A\n",
      "Epoch 1:  22%|███████████████▋                                                         | 48/223 [00:24<01:25,  2.04it/s, training_loss=0.770]\u001b[A\n",
      "Epoch 1:  22%|███████████████▋                                                         | 48/223 [00:25<01:25,  2.04it/s, training_loss=0.542]\u001b[A\n",
      "Epoch 1:  22%|████████████████                                                         | 49/223 [00:25<01:25,  2.03it/s, training_loss=0.542]\u001b[A\n",
      "Epoch 1:  22%|████████████████                                                         | 49/223 [00:25<01:25,  2.03it/s, training_loss=0.716]\u001b[A\n",
      "Epoch 1:  22%|████████████████▎                                                        | 50/223 [00:25<01:23,  2.08it/s, training_loss=0.716]\u001b[A\n",
      "Epoch 1:  22%|████████████████▎                                                        | 50/223 [00:26<01:23,  2.08it/s, training_loss=0.828]\u001b[A\n",
      "Epoch 1:  23%|████████████████▋                                                        | 51/223 [00:26<01:23,  2.05it/s, training_loss=0.828]\u001b[A\n",
      "Epoch 1:  23%|████████████████▋                                                        | 51/223 [00:26<01:23,  2.05it/s, training_loss=0.567]\u001b[A\n",
      "Epoch 1:  23%|█████████████████                                                        | 52/223 [00:26<01:23,  2.04it/s, training_loss=0.567]\u001b[A\n",
      "Epoch 1:  23%|█████████████████                                                        | 52/223 [00:27<01:23,  2.04it/s, training_loss=0.632]\u001b[A\n",
      "Epoch 1:  24%|█████████████████▎                                                       | 53/223 [00:27<01:23,  2.03it/s, training_loss=0.632]\u001b[A\n",
      "Epoch 1:  24%|█████████████████▎                                                       | 53/223 [00:27<01:23,  2.03it/s, training_loss=0.702]\u001b[A\n",
      "Epoch 1:  24%|█████████████████▋                                                       | 54/223 [00:27<01:22,  2.04it/s, training_loss=0.702]\u001b[A\n",
      "Epoch 1:  24%|█████████████████▋                                                       | 54/223 [00:28<01:22,  2.04it/s, training_loss=0.746]\u001b[A\n",
      "Epoch 1:  25%|██████████████████                                                       | 55/223 [00:28<01:22,  2.03it/s, training_loss=0.746]\u001b[A\n",
      "Epoch 1:  25%|██████████████████                                                       | 55/223 [00:28<01:22,  2.03it/s, training_loss=0.773]\u001b[A\n",
      "Epoch 1:  25%|██████████████████▎                                                      | 56/223 [00:28<01:21,  2.04it/s, training_loss=0.773]\u001b[A\n",
      "Epoch 1:  25%|██████████████████▎                                                      | 56/223 [00:28<01:21,  2.04it/s, training_loss=0.719]\u001b[A\n",
      "Epoch 1:  26%|██████████████████▋                                                      | 57/223 [00:28<01:21,  2.03it/s, training_loss=0.719]\u001b[A\n",
      "Epoch 1:  26%|██████████████████▋                                                      | 57/223 [00:29<01:21,  2.03it/s, training_loss=0.613]\u001b[A\n",
      "Epoch 1:  26%|██████████████████▉                                                      | 58/223 [00:29<01:21,  2.02it/s, training_loss=0.613]\u001b[A\n",
      "Epoch 1:  26%|██████████████████▉                                                      | 58/223 [00:29<01:21,  2.02it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  26%|███████████████████▎                                                     | 59/223 [00:29<01:19,  2.07it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  26%|███████████████████▎                                                     | 59/223 [00:30<01:19,  2.07it/s, training_loss=0.663]\u001b[A\n",
      "Epoch 1:  27%|███████████████████▋                                                     | 60/223 [00:30<01:19,  2.05it/s, training_loss=0.663]\u001b[A\n",
      "Epoch 1:  27%|███████████████████▋                                                     | 60/223 [00:30<01:19,  2.05it/s, training_loss=0.659]\u001b[A\n",
      "Epoch 1:  27%|███████████████████▉                                                     | 61/223 [00:30<01:18,  2.07it/s, training_loss=0.659]\u001b[A\n",
      "Epoch 1:  27%|███████████████████▉                                                     | 61/223 [00:31<01:18,  2.07it/s, training_loss=0.692]\u001b[A\n",
      "Epoch 1:  28%|████████████████████▎                                                    | 62/223 [00:31<01:18,  2.05it/s, training_loss=0.692]\u001b[A\n",
      "Epoch 1:  28%|████████████████████▎                                                    | 62/223 [00:31<01:18,  2.05it/s, training_loss=0.669]\u001b[A\n",
      "Epoch 1:  28%|████████████████████▌                                                    | 63/223 [00:31<01:17,  2.06it/s, training_loss=0.669]\u001b[A\n",
      "Epoch 1:  28%|████████████████████▌                                                    | 63/223 [00:32<01:17,  2.06it/s, training_loss=0.661]\u001b[A\n",
      "Epoch 1:  29%|████████████████████▉                                                    | 64/223 [00:32<01:17,  2.04it/s, training_loss=0.661]\u001b[A\n",
      "Epoch 1:  29%|████████████████████▉                                                    | 64/223 [00:32<01:17,  2.04it/s, training_loss=0.724]\u001b[A\n",
      "Epoch 1:  29%|█████████████████████▎                                                   | 65/223 [00:32<01:17,  2.05it/s, training_loss=0.724]\u001b[A\n",
      "Epoch 1:  29%|█████████████████████▎                                                   | 65/223 [00:33<01:17,  2.05it/s, training_loss=0.438]\u001b[A\n",
      "Epoch 1:  30%|█████████████████████▌                                                   | 66/223 [00:33<01:17,  2.03it/s, training_loss=0.438]\u001b[A\n",
      "Epoch 1:  30%|█████████████████████▌                                                   | 66/223 [00:33<01:17,  2.03it/s, training_loss=0.613]\u001b[A\n",
      "Epoch 1:  30%|█████████████████████▉                                                   | 67/223 [00:33<01:15,  2.06it/s, training_loss=0.613]\u001b[A\n",
      "Epoch 1:  30%|█████████████████████▉                                                   | 67/223 [00:34<01:15,  2.06it/s, training_loss=0.638]\u001b[A\n",
      "Epoch 1:  30%|██████████████████████▎                                                  | 68/223 [00:34<01:15,  2.04it/s, training_loss=0.638]\u001b[A\n",
      "Epoch 1:  30%|██████████████████████▎                                                  | 68/223 [00:34<01:15,  2.04it/s, training_loss=0.671]\u001b[A\n",
      "Epoch 1:  31%|██████████████████████▌                                                  | 69/223 [00:34<01:15,  2.05it/s, training_loss=0.671]\u001b[A\n",
      "Epoch 1:  31%|██████████████████████▌                                                  | 69/223 [00:35<01:15,  2.05it/s, training_loss=0.529]\u001b[A\n",
      "Epoch 1:  31%|██████████████████████▉                                                  | 70/223 [00:35<01:15,  2.03it/s, training_loss=0.529]\u001b[A\n",
      "Epoch 1:  31%|██████████████████████▉                                                  | 70/223 [00:35<01:15,  2.03it/s, training_loss=0.504]\u001b[A\n",
      "Epoch 1:  32%|███████████████████████▏                                                 | 71/223 [00:35<01:15,  2.02it/s, training_loss=0.504]\u001b[A\n",
      "Epoch 1:  32%|███████████████████████▏                                                 | 71/223 [00:36<01:15,  2.02it/s, training_loss=0.649]\u001b[A\n",
      "Epoch 1:  32%|███████████████████████▌                                                 | 72/223 [00:36<01:14,  2.04it/s, training_loss=0.649]\u001b[A\n",
      "Epoch 1:  32%|███████████████████████▌                                                 | 72/223 [00:36<01:14,  2.04it/s, training_loss=0.600]\u001b[A\n",
      "Epoch 1:  33%|███████████████████████▉                                                 | 73/223 [00:36<01:14,  2.03it/s, training_loss=0.600]\u001b[A\n",
      "Epoch 1:  33%|███████████████████████▉                                                 | 73/223 [00:37<01:14,  2.03it/s, training_loss=0.516]\u001b[A\n",
      "Epoch 1:  33%|████████████████████████▏                                                | 74/223 [00:37<01:13,  2.02it/s, training_loss=0.516]\u001b[A\n",
      "Epoch 1:  33%|████████████████████████▏                                                | 74/223 [00:37<01:13,  2.02it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  34%|████████████████████████▌                                                | 75/223 [00:37<01:12,  2.03it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  34%|████████████████████████▌                                                | 75/223 [00:38<01:12,  2.03it/s, training_loss=0.611]\u001b[A\n",
      "Epoch 1:  34%|████████████████████████▉                                                | 76/223 [00:38<01:12,  2.02it/s, training_loss=0.611]\u001b[A\n",
      "Epoch 1:  34%|████████████████████████▉                                                | 76/223 [00:38<01:12,  2.02it/s, training_loss=0.587]\u001b[A\n",
      "Epoch 1:  35%|█████████████████████████▏                                               | 77/223 [00:38<01:11,  2.03it/s, training_loss=0.587]\u001b[A\n",
      "Epoch 1:  35%|█████████████████████████▏                                               | 77/223 [00:39<01:11,  2.03it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  35%|█████████████████████████▌                                               | 78/223 [00:39<01:11,  2.02it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  35%|█████████████████████████▌                                               | 78/223 [00:39<01:11,  2.02it/s, training_loss=0.570]\u001b[A\n",
      "Epoch 1:  35%|█████████████████████████▊                                               | 79/223 [00:39<01:10,  2.04it/s, training_loss=0.570]\u001b[A\n",
      "Epoch 1:  35%|█████████████████████████▊                                               | 79/223 [00:40<01:10,  2.04it/s, training_loss=0.514]\u001b[A\n",
      "Epoch 1:  36%|██████████████████████████▏                                              | 80/223 [00:40<01:10,  2.03it/s, training_loss=0.514]\u001b[A\n",
      "Epoch 1:  36%|██████████████████████████▏                                              | 80/223 [00:40<01:10,  2.03it/s, training_loss=0.585]\u001b[A\n",
      "Epoch 1:  36%|██████████████████████████▌                                              | 81/223 [00:40<01:09,  2.06it/s, training_loss=0.585]\u001b[A\n",
      "Epoch 1:  36%|██████████████████████████▌                                              | 81/223 [00:41<01:09,  2.06it/s, training_loss=0.635]\u001b[A\n",
      "Epoch 1:  37%|██████████████████████████▊                                              | 82/223 [00:41<01:09,  2.04it/s, training_loss=0.635]\u001b[A\n",
      "Epoch 1:  37%|██████████████████████████▊                                              | 82/223 [00:41<01:09,  2.04it/s, training_loss=0.559]\u001b[A\n",
      "Epoch 1:  37%|███████████████████████████▏                                             | 83/223 [00:41<01:08,  2.05it/s, training_loss=0.559]\u001b[A\n",
      "Epoch 1:  37%|███████████████████████████▏                                             | 83/223 [00:42<01:08,  2.05it/s, training_loss=0.469]\u001b[A\n",
      "Epoch 1:  38%|███████████████████████████▍                                             | 84/223 [00:42<01:08,  2.03it/s, training_loss=0.469]\u001b[A\n",
      "Epoch 1:  38%|███████████████████████████▍                                             | 84/223 [00:42<01:08,  2.03it/s, training_loss=0.409]\u001b[A\n",
      "Epoch 1:  38%|███████████████████████████▊                                             | 85/223 [00:42<01:07,  2.04it/s, training_loss=0.409]\u001b[A\n",
      "Epoch 1:  38%|███████████████████████████▊                                             | 85/223 [00:43<01:07,  2.04it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  39%|████████████████████████████▏                                            | 86/223 [00:43<01:07,  2.03it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  39%|████████████████████████████▏                                            | 86/223 [00:43<01:07,  2.03it/s, training_loss=0.472]\u001b[A\n",
      "Epoch 1:  39%|████████████████████████████▍                                            | 87/223 [00:43<01:06,  2.06it/s, training_loss=0.472]\u001b[A\n",
      "Epoch 1:  39%|████████████████████████████▍                                            | 87/223 [00:44<01:06,  2.06it/s, training_loss=0.449]\u001b[A\n",
      "Epoch 1:  39%|████████████████████████████▊                                            | 88/223 [00:44<01:06,  2.04it/s, training_loss=0.449]\u001b[A\n",
      "Epoch 1:  39%|████████████████████████████▊                                            | 88/223 [00:44<01:06,  2.04it/s, training_loss=0.630]\u001b[A\n",
      "Epoch 1:  40%|█████████████████████████████▏                                           | 89/223 [00:44<01:06,  2.03it/s, training_loss=0.630]\u001b[A\n",
      "Epoch 1:  40%|█████████████████████████████▏                                           | 89/223 [00:45<01:06,  2.03it/s, training_loss=0.529]\u001b[A\n",
      "Epoch 1:  40%|█████████████████████████████▍                                           | 90/223 [00:45<01:05,  2.04it/s, training_loss=0.529]\u001b[A\n",
      "Epoch 1:  40%|█████████████████████████████▍                                           | 90/223 [00:45<01:05,  2.04it/s, training_loss=0.668]\u001b[A\n",
      "Epoch 1:  41%|█████████████████████████████▊                                           | 91/223 [00:45<01:05,  2.03it/s, training_loss=0.668]\u001b[A\n",
      "Epoch 1:  41%|█████████████████████████████▊                                           | 91/223 [00:46<01:05,  2.03it/s, training_loss=0.692]\u001b[A\n",
      "Epoch 1:  41%|██████████████████████████████                                           | 92/223 [00:46<01:04,  2.04it/s, training_loss=0.692]\u001b[A\n",
      "Epoch 1:  41%|██████████████████████████████                                           | 92/223 [00:46<01:04,  2.04it/s, training_loss=0.640]\u001b[A\n",
      "Epoch 1:  42%|██████████████████████████████▍                                          | 93/223 [00:46<01:04,  2.03it/s, training_loss=0.640]\u001b[A\n",
      "Epoch 1:  42%|██████████████████████████████▍                                          | 93/223 [00:47<01:04,  2.03it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  42%|██████████████████████████████▊                                          | 94/223 [00:47<01:03,  2.02it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  42%|██████████████████████████████▊                                          | 94/223 [00:47<01:03,  2.02it/s, training_loss=0.561]\u001b[A\n",
      "Epoch 1:  43%|███████████████████████████████                                          | 95/223 [00:47<01:02,  2.03it/s, training_loss=0.561]\u001b[A\n",
      "Epoch 1:  43%|███████████████████████████████                                          | 95/223 [00:48<01:02,  2.03it/s, training_loss=0.629]\u001b[A\n",
      "Epoch 1:  43%|███████████████████████████████▍                                         | 96/223 [00:48<01:02,  2.04it/s, training_loss=0.629]\u001b[A\n",
      "Epoch 1:  43%|███████████████████████████████▍                                         | 96/223 [00:48<01:02,  2.04it/s, training_loss=0.529]\u001b[A\n",
      "Epoch 1:  43%|███████████████████████████████▊                                         | 97/223 [00:48<01:01,  2.05it/s, training_loss=0.529]\u001b[A\n",
      "Epoch 1:  43%|███████████████████████████████▊                                         | 97/223 [00:49<01:01,  2.05it/s, training_loss=0.433]\u001b[A\n",
      "Epoch 1:  44%|████████████████████████████████                                         | 98/223 [00:49<01:01,  2.03it/s, training_loss=0.433]\u001b[A\n",
      "Epoch 1:  44%|████████████████████████████████                                         | 98/223 [00:49<01:01,  2.03it/s, training_loss=0.596]\u001b[A\n",
      "Epoch 1:  44%|████████████████████████████████▍                                        | 99/223 [00:49<01:01,  2.02it/s, training_loss=0.596]\u001b[A\n",
      "Epoch 1:  44%|████████████████████████████████▍                                        | 99/223 [00:50<01:01,  2.02it/s, training_loss=0.524]\u001b[A\n",
      "Epoch 1:  45%|████████████████████████████████▎                                       | 100/223 [00:50<01:00,  2.02it/s, training_loss=0.524]\u001b[A\n",
      "Epoch 1:  45%|████████████████████████████████▎                                       | 100/223 [00:50<01:00,  2.02it/s, training_loss=0.509]\u001b[A\n",
      "Epoch 1:  45%|████████████████████████████████▌                                       | 101/223 [00:50<01:00,  2.03it/s, training_loss=0.509]\u001b[A\n",
      "Epoch 1:  45%|████████████████████████████████▌                                       | 101/223 [00:51<01:00,  2.03it/s, training_loss=0.488]\u001b[A\n",
      "Epoch 1:  46%|████████████████████████████████▉                                       | 102/223 [00:51<00:59,  2.04it/s, training_loss=0.488]\u001b[A\n",
      "Epoch 1:  46%|████████████████████████████████▉                                       | 102/223 [00:51<00:59,  2.04it/s, training_loss=0.611]\u001b[A\n",
      "Epoch 1:  46%|█████████████████████████████████▎                                      | 103/223 [00:51<00:58,  2.04it/s, training_loss=0.611]\u001b[A\n",
      "Epoch 1:  46%|█████████████████████████████████▎                                      | 103/223 [00:52<00:58,  2.04it/s, training_loss=0.567]\u001b[A\n",
      "Epoch 1:  47%|█████████████████████████████████▌                                      | 104/223 [00:52<00:58,  2.03it/s, training_loss=0.567]\u001b[A\n",
      "Epoch 1:  47%|█████████████████████████████████▌                                      | 104/223 [00:52<00:58,  2.03it/s, training_loss=0.633]\u001b[A\n",
      "Epoch 1:  47%|█████████████████████████████████▉                                      | 105/223 [00:52<00:58,  2.02it/s, training_loss=0.633]\u001b[A\n",
      "Epoch 1:  47%|█████████████████████████████████▉                                      | 105/223 [00:53<00:58,  2.02it/s, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  48%|██████████████████████████████████▏                                     | 106/223 [00:53<00:57,  2.03it/s, training_loss=0.487]\u001b[A\n",
      "Epoch 1:  48%|██████████████████████████████████▏                                     | 106/223 [00:53<00:57,  2.03it/s, training_loss=0.556]\u001b[A\n",
      "Epoch 1:  48%|██████████████████████████████████▌                                     | 107/223 [00:53<00:57,  2.02it/s, training_loss=0.556]\u001b[A\n",
      "Epoch 1:  48%|██████████████████████████████████▌                                     | 107/223 [00:54<00:57,  2.02it/s, training_loss=0.438]\u001b[A\n",
      "Epoch 1:  48%|██████████████████████████████████▊                                     | 108/223 [00:54<00:57,  2.02it/s, training_loss=0.438]\u001b[A\n",
      "Epoch 1:  48%|██████████████████████████████████▊                                     | 108/223 [00:54<00:57,  2.02it/s, training_loss=0.482]\u001b[A\n",
      "Epoch 1:  49%|███████████████████████████████████▏                                    | 109/223 [00:54<00:57,  1.99it/s, training_loss=0.482]\u001b[A\n",
      "Epoch 1:  49%|███████████████████████████████████▏                                    | 109/223 [00:55<00:57,  1.99it/s, training_loss=0.543]\u001b[A\n",
      "Epoch 1:  49%|███████████████████████████████████▌                                    | 110/223 [00:55<00:55,  2.03it/s, training_loss=0.543]\u001b[A\n",
      "Epoch 1:  49%|███████████████████████████████████▌                                    | 110/223 [00:55<00:55,  2.03it/s, training_loss=0.535]\u001b[A\n",
      "Epoch 1:  50%|███████████████████████████████████▊                                    | 111/223 [00:55<00:55,  2.02it/s, training_loss=0.535]\u001b[A\n",
      "Epoch 1:  50%|███████████████████████████████████▊                                    | 111/223 [00:55<00:55,  2.02it/s, training_loss=0.607]\u001b[A\n",
      "Epoch 1:  50%|████████████████████████████████████▏                                   | 112/223 [00:55<00:54,  2.04it/s, training_loss=0.607]\u001b[A\n",
      "Epoch 1:  50%|████████████████████████████████████▏                                   | 112/223 [00:56<00:54,  2.04it/s, training_loss=0.402]\u001b[A\n",
      "Epoch 1:  51%|████████████████████████████████████▍                                   | 113/223 [00:56<00:53,  2.04it/s, training_loss=0.402]\u001b[A\n",
      "Epoch 1:  51%|████████████████████████████████████▍                                   | 113/223 [00:56<00:53,  2.04it/s, training_loss=0.483]\u001b[A\n",
      "Epoch 1:  51%|████████████████████████████████████▊                                   | 114/223 [00:56<00:53,  2.03it/s, training_loss=0.483]\u001b[A\n",
      "Epoch 1:  51%|████████████████████████████████████▊                                   | 114/223 [00:57<00:53,  2.03it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  52%|█████████████████████████████████████▏                                  | 115/223 [00:57<00:52,  2.04it/s, training_loss=0.382]\u001b[A\n",
      "Epoch 1:  52%|█████████████████████████████████████▏                                  | 115/223 [00:57<00:52,  2.04it/s, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  52%|█████████████████████████████████████▍                                  | 116/223 [00:57<00:52,  2.03it/s, training_loss=0.308]\u001b[A\n",
      "Epoch 1:  52%|█████████████████████████████████████▍                                  | 116/223 [00:58<00:52,  2.03it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  52%|█████████████████████████████████████▊                                  | 117/223 [00:58<00:51,  2.04it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  52%|█████████████████████████████████████▊                                  | 117/223 [00:58<00:51,  2.04it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  53%|██████████████████████████████████████                                  | 118/223 [00:58<00:51,  2.05it/s, training_loss=0.339]\u001b[A\n",
      "Epoch 1:  53%|██████████████████████████████████████                                  | 118/223 [00:59<00:51,  2.05it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  53%|██████████████████████████████████████▍                                 | 119/223 [00:59<00:51,  2.03it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  53%|██████████████████████████████████████▍                                 | 119/223 [00:59<00:51,  2.03it/s, training_loss=0.527]\u001b[A\n",
      "Epoch 1:  54%|██████████████████████████████████████▋                                 | 120/223 [00:59<00:50,  2.04it/s, training_loss=0.527]\u001b[A\n",
      "Epoch 1:  54%|██████████████████████████████████████▋                                 | 120/223 [01:00<00:50,  2.04it/s, training_loss=0.562]\u001b[A\n",
      "Epoch 1:  54%|███████████████████████████████████████                                 | 121/223 [01:00<00:49,  2.05it/s, training_loss=0.562]\u001b[A\n",
      "Epoch 1:  54%|███████████████████████████████████████                                 | 121/223 [01:00<00:49,  2.05it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  55%|███████████████████████████████████████▍                                | 122/223 [01:00<00:49,  2.03it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  55%|███████████████████████████████████████▍                                | 122/223 [01:01<00:49,  2.03it/s, training_loss=0.503]\u001b[A\n",
      "Epoch 1:  55%|███████████████████████████████████████▋                                | 123/223 [01:01<00:48,  2.04it/s, training_loss=0.503]\u001b[A\n",
      "Epoch 1:  55%|███████████████████████████████████████▋                                | 123/223 [01:01<00:48,  2.04it/s, training_loss=0.443]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████████████████                                | 124/223 [01:01<00:48,  2.03it/s, training_loss=0.443]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████████████████                                | 124/223 [01:02<00:48,  2.03it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████████████████▎                               | 125/223 [01:02<00:48,  2.04it/s, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  56%|████████████████████████████████████████▎                               | 125/223 [01:02<00:48,  2.04it/s, training_loss=0.681]\u001b[A\n",
      "Epoch 1:  57%|████████████████████████████████████████▋                               | 126/223 [01:02<00:48,  2.01it/s, training_loss=0.681]\u001b[A\n",
      "Epoch 1:  57%|████████████████████████████████████████▋                               | 126/223 [01:03<00:48,  2.01it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  57%|█████████████████████████████████████████                               | 127/223 [01:03<00:47,  2.03it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 1:  57%|█████████████████████████████████████████                               | 127/223 [01:03<00:47,  2.03it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  57%|█████████████████████████████████████████▎                              | 128/223 [01:03<00:46,  2.04it/s, training_loss=0.554]\u001b[A\n",
      "Epoch 1:  57%|█████████████████████████████████████████▎                              | 128/223 [01:04<00:46,  2.04it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  58%|█████████████████████████████████████████▋                              | 129/223 [01:04<00:46,  2.03it/s, training_loss=0.347]\u001b[A\n",
      "Epoch 1:  58%|█████████████████████████████████████████▋                              | 129/223 [01:04<00:46,  2.03it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  58%|█████████████████████████████████████████▉                              | 130/223 [01:04<00:45,  2.04it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  58%|█████████████████████████████████████████▉                              | 130/223 [01:05<00:45,  2.04it/s, training_loss=0.599]\u001b[A\n",
      "Epoch 1:  59%|██████████████████████████████████████████▎                             | 131/223 [01:05<00:44,  2.05it/s, training_loss=0.599]\u001b[A\n",
      "Epoch 1:  59%|██████████████████████████████████████████▎                             | 131/223 [01:05<00:44,  2.05it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  59%|██████████████████████████████████████████▌                             | 132/223 [01:05<00:44,  2.05it/s, training_loss=0.363]\u001b[A\n",
      "Epoch 1:  59%|██████████████████████████████████████████▌                             | 132/223 [01:06<00:44,  2.05it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  60%|██████████████████████████████████████████▉                             | 133/223 [01:06<00:44,  2.02it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  60%|██████████████████████████████████████████▉                             | 133/223 [01:06<00:44,  2.02it/s, training_loss=0.580]\u001b[A\n",
      "Epoch 1:  60%|███████████████████████████████████████████▎                            | 134/223 [01:06<00:43,  2.03it/s, training_loss=0.580]\u001b[A\n",
      "Epoch 1:  60%|███████████████████████████████████████████▎                            | 134/223 [01:07<00:43,  2.03it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  61%|███████████████████████████████████████████▌                            | 135/223 [01:07<00:43,  2.04it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  61%|███████████████████████████████████████████▌                            | 135/223 [01:07<00:43,  2.04it/s, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  61%|███████████████████████████████████████████▉                            | 136/223 [01:07<00:42,  2.03it/s, training_loss=0.294]\u001b[A\n",
      "Epoch 1:  61%|███████████████████████████████████████████▉                            | 136/223 [01:08<00:42,  2.03it/s, training_loss=0.377]\u001b[A\n",
      "Epoch 1:  61%|████████████████████████████████████████████▏                           | 137/223 [01:08<00:42,  2.04it/s, training_loss=0.377]\u001b[A\n",
      "Epoch 1:  61%|████████████████████████████████████████████▏                           | 137/223 [01:08<00:42,  2.04it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  62%|████████████████████████████████████████████▌                           | 138/223 [01:08<00:42,  2.01it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  62%|████████████████████████████████████████████▌                           | 138/223 [01:09<00:42,  2.01it/s, training_loss=0.472]\u001b[A\n",
      "Epoch 1:  62%|████████████████████████████████████████████▉                           | 139/223 [01:09<00:41,  2.04it/s, training_loss=0.472]\u001b[A\n",
      "Epoch 1:  62%|████████████████████████████████████████████▉                           | 139/223 [01:09<00:41,  2.04it/s, training_loss=0.432]\u001b[A\n",
      "Epoch 1:  63%|█████████████████████████████████████████████▏                          | 140/223 [01:09<00:40,  2.05it/s, training_loss=0.432]\u001b[A\n",
      "Epoch 1:  63%|█████████████████████████████████████████████▏                          | 140/223 [01:10<00:40,  2.05it/s, training_loss=0.410]\u001b[A\n",
      "Epoch 1:  63%|█████████████████████████████████████████████▌                          | 141/223 [01:10<00:40,  2.02it/s, training_loss=0.410]\u001b[A\n",
      "Epoch 1:  63%|█████████████████████████████████████████████▌                          | 141/223 [01:10<00:40,  2.02it/s, training_loss=0.399]\u001b[A\n",
      "Epoch 1:  64%|█████████████████████████████████████████████▊                          | 142/223 [01:10<00:39,  2.03it/s, training_loss=0.399]\u001b[A\n",
      "Epoch 1:  64%|█████████████████████████████████████████████▊                          | 142/223 [01:11<00:39,  2.03it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  64%|██████████████████████████████████████████████▏                         | 143/223 [01:11<00:39,  2.02it/s, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  64%|██████████████████████████████████████████████▏                         | 143/223 [01:11<00:39,  2.02it/s, training_loss=0.472]\u001b[A\n",
      "Epoch 1:  65%|██████████████████████████████████████████████▍                         | 144/223 [01:11<00:38,  2.03it/s, training_loss=0.472]\u001b[A\n",
      "Epoch 1:  65%|██████████████████████████████████████████████▍                         | 144/223 [01:12<00:38,  2.03it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  65%|██████████████████████████████████████████████▊                         | 145/223 [01:12<00:38,  2.02it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 1:  65%|██████████████████████████████████████████████▊                         | 145/223 [01:12<00:38,  2.02it/s, training_loss=0.631]\u001b[A\n",
      "Epoch 1:  65%|███████████████████████████████████████████████▏                        | 146/223 [01:12<00:37,  2.06it/s, training_loss=0.631]\u001b[A\n",
      "Epoch 1:  65%|███████████████████████████████████████████████▏                        | 146/223 [01:13<00:37,  2.06it/s, training_loss=0.492]\u001b[A\n",
      "Epoch 1:  66%|███████████████████████████████████████████████▍                        | 147/223 [01:13<00:37,  2.04it/s, training_loss=0.492]\u001b[A\n",
      "Epoch 1:  66%|███████████████████████████████████████████████▍                        | 147/223 [01:13<00:37,  2.04it/s, training_loss=0.480]\u001b[A\n",
      "Epoch 1:  66%|███████████████████████████████████████████████▊                        | 148/223 [01:13<00:36,  2.05it/s, training_loss=0.480]\u001b[A\n",
      "Epoch 1:  66%|███████████████████████████████████████████████▊                        | 148/223 [01:14<00:36,  2.05it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  67%|████████████████████████████████████████████████                        | 149/223 [01:14<00:36,  2.03it/s, training_loss=0.340]\u001b[A\n",
      "Epoch 1:  67%|████████████████████████████████████████████████                        | 149/223 [01:14<00:36,  2.03it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  67%|████████████████████████████████████████████████▍                       | 150/223 [01:14<00:35,  2.04it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  67%|████████████████████████████████████████████████▍                       | 150/223 [01:15<00:35,  2.04it/s, training_loss=0.466]\u001b[A\n",
      "Epoch 1:  68%|████████████████████████████████████████████████▊                       | 151/223 [01:15<00:35,  2.03it/s, training_loss=0.466]\u001b[A\n",
      "Epoch 1:  68%|████████████████████████████████████████████████▊                       | 151/223 [01:15<00:35,  2.03it/s, training_loss=0.602]\u001b[A\n",
      "Epoch 1:  68%|█████████████████████████████████████████████████                       | 152/223 [01:15<00:34,  2.04it/s, training_loss=0.602]\u001b[A\n",
      "Epoch 1:  68%|█████████████████████████████████████████████████                       | 152/223 [01:16<00:34,  2.04it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  69%|█████████████████████████████████████████████████▍                      | 153/223 [01:16<00:34,  2.05it/s, training_loss=0.395]\u001b[A\n",
      "Epoch 1:  69%|█████████████████████████████████████████████████▍                      | 153/223 [01:16<00:34,  2.05it/s, training_loss=0.422]\u001b[A\n",
      "Epoch 1:  69%|█████████████████████████████████████████████████▋                      | 154/223 [01:16<00:33,  2.07it/s, training_loss=0.422]\u001b[A\n",
      "Epoch 1:  69%|█████████████████████████████████████████████████▋                      | 154/223 [01:17<00:33,  2.07it/s, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  70%|██████████████████████████████████████████████████                      | 155/223 [01:17<00:33,  2.05it/s, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  70%|██████████████████████████████████████████████████                      | 155/223 [01:17<00:33,  2.05it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  70%|██████████████████████████████████████████████████▎                     | 156/223 [01:17<00:33,  2.02it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 1:  70%|██████████████████████████████████████████████████▎                     | 156/223 [01:18<00:33,  2.02it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  70%|██████████████████████████████████████████████████▋                     | 157/223 [01:18<00:32,  2.03it/s, training_loss=0.388]\u001b[A\n",
      "Epoch 1:  70%|██████████████████████████████████████████████████▋                     | 157/223 [01:18<00:32,  2.03it/s, training_loss=0.414]\u001b[A\n",
      "Epoch 1:  71%|███████████████████████████████████████████████████                     | 158/223 [01:18<00:32,  2.02it/s, training_loss=0.414]\u001b[A\n",
      "Epoch 1:  71%|███████████████████████████████████████████████████                     | 158/223 [01:19<00:32,  2.02it/s, training_loss=0.409]\u001b[A\n",
      "Epoch 1:  71%|███████████████████████████████████████████████████▎                    | 159/223 [01:19<00:32,  2.00it/s, training_loss=0.409]\u001b[A\n",
      "Epoch 1:  71%|███████████████████████████████████████████████████▎                    | 159/223 [01:19<00:32,  2.00it/s, training_loss=0.519]\u001b[A\n",
      "Epoch 1:  72%|███████████████████████████████████████████████████▋                    | 160/223 [01:19<00:31,  1.98it/s, training_loss=0.519]\u001b[A\n",
      "Epoch 1:  72%|███████████████████████████████████████████████████▋                    | 160/223 [01:20<00:31,  1.98it/s, training_loss=0.447]\u001b[A\n",
      "Epoch 1:  72%|███████████████████████████████████████████████████▉                    | 161/223 [01:20<00:31,  1.97it/s, training_loss=0.447]\u001b[A\n",
      "Epoch 1:  72%|███████████████████████████████████████████████████▉                    | 161/223 [01:20<00:31,  1.97it/s, training_loss=0.417]\u001b[A\n",
      "Epoch 1:  73%|████████████████████████████████████████████████████▎                   | 162/223 [01:20<00:28,  2.16it/s, training_loss=0.417]\u001b[A\n",
      "Epoch 1:  73%|████████████████████████████████████████████████████▎                   | 162/223 [01:20<00:28,  2.16it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  73%|████████████████████████████████████████████████████▋                   | 163/223 [01:20<00:25,  2.36it/s, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  73%|████████████████████████████████████████████████████▋                   | 163/223 [01:21<00:25,  2.36it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  74%|████████████████████████████████████████████████████▉                   | 164/223 [01:21<00:23,  2.53it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  74%|████████████████████████████████████████████████████▉                   | 164/223 [01:21<00:23,  2.53it/s, training_loss=0.530]\u001b[A\n",
      "Epoch 1:  74%|█████████████████████████████████████████████████████▎                  | 165/223 [01:21<00:21,  2.67it/s, training_loss=0.530]\u001b[A\n",
      "Epoch 1:  74%|█████████████████████████████████████████████████████▎                  | 165/223 [01:21<00:21,  2.67it/s, training_loss=0.464]\u001b[A\n",
      "Epoch 1:  74%|█████████████████████████████████████████████████████▌                  | 166/223 [01:21<00:21,  2.70it/s, training_loss=0.464]\u001b[A\n",
      "Epoch 1:  74%|█████████████████████████████████████████████████████▌                  | 166/223 [01:22<00:21,  2.70it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  75%|█████████████████████████████████████████████████████▉                  | 167/223 [01:22<00:20,  2.76it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  75%|█████████████████████████████████████████████████████▉                  | 167/223 [01:22<00:20,  2.76it/s, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  75%|██████████████████████████████████████████████████████▏                 | 168/223 [01:22<00:19,  2.77it/s, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  75%|██████████████████████████████████████████████████████▏                 | 168/223 [01:22<00:19,  2.77it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  76%|██████████████████████████████████████████████████████▌                 | 169/223 [01:22<00:19,  2.81it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  76%|██████████████████████████████████████████████████████▌                 | 169/223 [01:23<00:19,  2.81it/s, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  76%|██████████████████████████████████████████████████████▉                 | 170/223 [01:23<00:19,  2.73it/s, training_loss=0.224]\u001b[A\n",
      "Epoch 1:  76%|██████████████████████████████████████████████████████▉                 | 170/223 [01:23<00:19,  2.73it/s, training_loss=0.396]\u001b[A\n",
      "Epoch 1:  77%|███████████████████████████████████████████████████████▏                | 171/223 [01:23<00:21,  2.46it/s, training_loss=0.396]\u001b[A\n",
      "Epoch 1:  77%|███████████████████████████████████████████████████████▏                | 171/223 [01:24<00:21,  2.46it/s, training_loss=0.630]\u001b[A\n",
      "Epoch 1:  77%|███████████████████████████████████████████████████████▌                | 172/223 [01:24<00:21,  2.33it/s, training_loss=0.630]\u001b[A\n",
      "Epoch 1:  77%|███████████████████████████████████████████████████████▌                | 172/223 [01:24<00:21,  2.33it/s, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  78%|███████████████████████████████████████████████████████▊                | 173/223 [01:24<00:22,  2.24it/s, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  78%|███████████████████████████████████████████████████████▊                | 173/223 [01:25<00:22,  2.24it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  78%|████████████████████████████████████████████████████████▏               | 174/223 [01:25<00:22,  2.16it/s, training_loss=0.455]\u001b[A\n",
      "Epoch 1:  78%|████████████████████████████████████████████████████████▏               | 174/223 [01:25<00:22,  2.16it/s, training_loss=0.445]\u001b[A\n",
      "Epoch 1:  78%|████████████████████████████████████████████████████████▌               | 175/223 [01:25<00:22,  2.13it/s, training_loss=0.445]\u001b[A\n",
      "Epoch 1:  78%|████████████████████████████████████████████████████████▌               | 175/223 [01:26<00:22,  2.13it/s, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  79%|████████████████████████████████████████████████████████▊               | 176/223 [01:26<00:22,  2.09it/s, training_loss=0.349]\u001b[A\n",
      "Epoch 1:  79%|████████████████████████████████████████████████████████▊               | 176/223 [01:26<00:22,  2.09it/s, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  79%|█████████████████████████████████████████████████████████▏              | 177/223 [01:26<00:22,  2.06it/s, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  79%|█████████████████████████████████████████████████████████▏              | 177/223 [01:27<00:22,  2.06it/s, training_loss=0.403]\u001b[A\n",
      "Epoch 1:  80%|█████████████████████████████████████████████████████████▍              | 178/223 [01:27<00:21,  2.06it/s, training_loss=0.403]\u001b[A\n",
      "Epoch 1:  80%|█████████████████████████████████████████████████████████▍              | 178/223 [01:27<00:21,  2.06it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  80%|█████████████████████████████████████████████████████████▊              | 179/223 [01:27<00:21,  2.04it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  80%|█████████████████████████████████████████████████████████▊              | 179/223 [01:28<00:21,  2.04it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  81%|██████████████████████████████████████████████████████████              | 180/223 [01:28<00:20,  2.05it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 1:  81%|██████████████████████████████████████████████████████████              | 180/223 [01:28<00:20,  2.05it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  81%|██████████████████████████████████████████████████████████▍             | 181/223 [01:28<00:20,  2.05it/s, training_loss=0.387]\u001b[A\n",
      "Epoch 1:  81%|██████████████████████████████████████████████████████████▍             | 181/223 [01:29<00:20,  2.05it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  82%|██████████████████████████████████████████████████████████▊             | 182/223 [01:29<00:19,  2.06it/s, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  82%|██████████████████████████████████████████████████████████▊             | 182/223 [01:29<00:19,  2.06it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  82%|███████████████████████████████████████████████████████████             | 183/223 [01:29<00:19,  2.04it/s, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  82%|███████████████████████████████████████████████████████████             | 183/223 [01:30<00:19,  2.04it/s, training_loss=0.469]\u001b[A\n",
      "Epoch 1:  83%|███████████████████████████████████████████████████████████▍            | 184/223 [01:30<00:19,  2.05it/s, training_loss=0.469]\u001b[A\n",
      "Epoch 1:  83%|███████████████████████████████████████████████████████████▍            | 184/223 [01:30<00:19,  2.05it/s, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  83%|███████████████████████████████████████████████████████████▋            | 185/223 [01:30<00:18,  2.05it/s, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  83%|███████████████████████████████████████████████████████████▋            | 185/223 [01:31<00:18,  2.05it/s, training_loss=0.416]\u001b[A\n",
      "Epoch 1:  83%|████████████████████████████████████████████████████████████            | 186/223 [01:31<00:18,  2.04it/s, training_loss=0.416]\u001b[A\n",
      "Epoch 1:  83%|████████████████████████████████████████████████████████████            | 186/223 [01:31<00:18,  2.04it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  84%|████████████████████████████████████████████████████████████▍           | 187/223 [01:31<00:17,  2.05it/s, training_loss=0.228]\u001b[A\n",
      "Epoch 1:  84%|████████████████████████████████████████████████████████████▍           | 187/223 [01:32<00:17,  2.05it/s, training_loss=0.451]\u001b[A\n",
      "Epoch 1:  84%|████████████████████████████████████████████████████████████▋           | 188/223 [01:32<00:17,  2.03it/s, training_loss=0.451]\u001b[A\n",
      "Epoch 1:  84%|████████████████████████████████████████████████████████████▋           | 188/223 [01:32<00:17,  2.03it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  85%|█████████████████████████████████████████████████████████████           | 189/223 [01:32<00:16,  2.02it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  85%|█████████████████████████████████████████████████████████████           | 189/223 [01:33<00:16,  2.02it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  85%|█████████████████████████████████████████████████████████████▎          | 190/223 [01:33<00:16,  2.03it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  85%|█████████████████████████████████████████████████████████████▎          | 190/223 [01:33<00:16,  2.03it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  86%|█████████████████████████████████████████████████████████████▋          | 191/223 [01:33<00:15,  2.02it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  86%|█████████████████████████████████████████████████████████████▋          | 191/223 [01:34<00:15,  2.02it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  86%|█████████████████████████████████████████████████████████████▉          | 192/223 [01:34<00:15,  2.04it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  86%|█████████████████████████████████████████████████████████████▉          | 192/223 [01:34<00:15,  2.04it/s, training_loss=0.415]\u001b[A\n",
      "Epoch 1:  87%|██████████████████████████████████████████████████████████████▎         | 193/223 [01:34<00:14,  2.03it/s, training_loss=0.415]\u001b[A\n",
      "Epoch 1:  87%|██████████████████████████████████████████████████████████████▎         | 193/223 [01:35<00:14,  2.03it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  87%|██████████████████████████████████████████████████████████████▋         | 194/223 [01:35<00:14,  2.04it/s, training_loss=0.290]\u001b[A\n",
      "Epoch 1:  87%|██████████████████████████████████████████████████████████████▋         | 194/223 [01:35<00:14,  2.04it/s, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  87%|██████████████████████████████████████████████████████████████▉         | 195/223 [01:35<00:13,  2.03it/s, training_loss=0.343]\u001b[A\n",
      "Epoch 1:  87%|██████████████████████████████████████████████████████████████▉         | 195/223 [01:36<00:13,  2.03it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  88%|███████████████████████████████████████████████████████████████▎        | 196/223 [01:36<00:13,  2.02it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  88%|███████████████████████████████████████████████████████████████▎        | 196/223 [01:36<00:13,  2.02it/s, training_loss=0.418]\u001b[A\n",
      "Epoch 1:  88%|███████████████████████████████████████████████████████████████▌        | 197/223 [01:36<00:12,  2.03it/s, training_loss=0.418]\u001b[A\n",
      "Epoch 1:  88%|███████████████████████████████████████████████████████████████▌        | 197/223 [01:37<00:12,  2.03it/s, training_loss=0.426]\u001b[A\n",
      "Epoch 1:  89%|███████████████████████████████████████████████████████████████▉        | 198/223 [01:37<00:12,  2.02it/s, training_loss=0.426]\u001b[A\n",
      "Epoch 1:  89%|███████████████████████████████████████████████████████████████▉        | 198/223 [01:37<00:12,  2.02it/s, training_loss=0.391]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████████████████████████████████████████▎       | 199/223 [01:37<00:11,  2.02it/s, training_loss=0.391]\u001b[A\n",
      "Epoch 1:  89%|████████████████████████████████████████████████████████████████▎       | 199/223 [01:38<00:11,  2.02it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  90%|████████████████████████████████████████████████████████████████▌       | 200/223 [01:38<00:11,  2.03it/s, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  90%|████████████████████████████████████████████████████████████████▌       | 200/223 [01:38<00:11,  2.03it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 1:  90%|████████████████████████████████████████████████████████████████▉       | 201/223 [01:38<00:10,  2.02it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 1:  90%|████████████████████████████████████████████████████████████████▉       | 201/223 [01:39<00:10,  2.02it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████████████████████████▏      | 202/223 [01:39<00:10,  2.03it/s, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████████████████████████▏      | 202/223 [01:39<00:10,  2.03it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████████████████████████▌      | 203/223 [01:39<00:09,  2.02it/s, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████████████████████████▌      | 203/223 [01:40<00:09,  2.02it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████████████████████████▊      | 204/223 [01:40<00:09,  2.04it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 1:  91%|█████████████████████████████████████████████████████████████████▊      | 204/223 [01:40<00:09,  2.04it/s, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  92%|██████████████████████████████████████████████████████████████████▏     | 205/223 [01:40<00:08,  2.03it/s, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  92%|██████████████████████████████████████████████████████████████████▏     | 205/223 [01:41<00:08,  2.03it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  92%|██████████████████████████████████████████████████████████████████▌     | 206/223 [01:41<00:08,  2.04it/s, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  92%|██████████████████████████████████████████████████████████████████▌     | 206/223 [01:41<00:08,  2.04it/s, training_loss=0.484]\u001b[A\n",
      "Epoch 1:  93%|██████████████████████████████████████████████████████████████████▊     | 207/223 [01:41<00:07,  2.03it/s, training_loss=0.484]\u001b[A\n",
      "Epoch 1:  93%|██████████████████████████████████████████████████████████████████▊     | 207/223 [01:41<00:07,  2.03it/s, training_loss=0.381]\u001b[A\n",
      "Epoch 1:  93%|███████████████████████████████████████████████████████████████████▏    | 208/223 [01:41<00:07,  2.04it/s, training_loss=0.381]\u001b[A\n",
      "Epoch 1:  93%|███████████████████████████████████████████████████████████████████▏    | 208/223 [01:42<00:07,  2.04it/s, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  94%|███████████████████████████████████████████████████████████████████▍    | 209/223 [01:42<00:06,  2.05it/s, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  94%|███████████████████████████████████████████████████████████████████▍    | 209/223 [01:42<00:06,  2.05it/s, training_loss=0.566]\u001b[A\n",
      "Epoch 1:  94%|███████████████████████████████████████████████████████████████████▊    | 210/223 [01:42<00:06,  2.03it/s, training_loss=0.566]\u001b[A\n",
      "Epoch 1:  94%|███████████████████████████████████████████████████████████████████▊    | 210/223 [01:43<00:06,  2.03it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  95%|████████████████████████████████████████████████████████████████████▏   | 211/223 [01:43<00:05,  2.04it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  95%|████████████████████████████████████████████████████████████████████▏   | 211/223 [01:43<00:05,  2.04it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  95%|████████████████████████████████████████████████████████████████████▍   | 212/223 [01:43<00:05,  2.03it/s, training_loss=0.370]\u001b[A\n",
      "Epoch 1:  95%|████████████████████████████████████████████████████████████████████▍   | 212/223 [01:44<00:05,  2.03it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████████████████████████▊   | 213/223 [01:44<00:04,  2.04it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  96%|████████████████████████████████████████████████████████████████████▊   | 213/223 [01:44<00:04,  2.04it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████████████████████████████████████████████████████   | 214/223 [01:44<00:04,  2.03it/s, training_loss=0.389]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████████████████████████████████████████████████████   | 214/223 [01:45<00:04,  2.03it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████████████████████████████████████████████████████▍  | 215/223 [01:45<00:03,  2.02it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  96%|█████████████████████████████████████████████████████████████████████▍  | 215/223 [01:45<00:03,  2.02it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  97%|█████████████████████████████████████████████████████████████████████▋  | 216/223 [01:45<00:03,  2.01it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 1:  97%|█████████████████████████████████████████████████████████████████████▋  | 216/223 [01:46<00:03,  2.01it/s, training_loss=0.415]\u001b[A\n",
      "Epoch 1:  97%|██████████████████████████████████████████████████████████████████████  | 217/223 [01:46<00:02,  2.01it/s, training_loss=0.415]\u001b[A\n",
      "Epoch 1:  97%|██████████████████████████████████████████████████████████████████████  | 217/223 [01:46<00:02,  2.01it/s, training_loss=0.443]\u001b[A\n",
      "Epoch 1:  98%|██████████████████████████████████████████████████████████████████████▍ | 218/223 [01:46<00:02,  2.03it/s, training_loss=0.443]\u001b[A\n",
      "Epoch 1:  98%|██████████████████████████████████████████████████████████████████████▍ | 218/223 [01:47<00:02,  2.03it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  98%|██████████████████████████████████████████████████████████████████████▋ | 219/223 [01:47<00:01,  2.02it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  98%|██████████████████████████████████████████████████████████████████████▋ | 219/223 [01:47<00:01,  2.02it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  99%|███████████████████████████████████████████████████████████████████████ | 220/223 [01:47<00:01,  2.01it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  99%|███████████████████████████████████████████████████████████████████████ | 220/223 [01:48<00:01,  2.01it/s, training_loss=0.608]\u001b[A\n",
      "Epoch 1:  99%|███████████████████████████████████████████████████████████████████████▎| 221/223 [01:48<00:00,  2.03it/s, training_loss=0.608]\u001b[A\n",
      "Epoch 1:  99%|███████████████████████████████████████████████████████████████████████▎| 221/223 [01:48<00:00,  2.03it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████▋| 222/223 [01:48<00:00,  2.02it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████▋| 222/223 [01:49<00:00,  2.02it/s, training_loss=0.023]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████████| 223/223 [01:49<00:00,  2.51it/s, training_loss=0.023]\u001b[A\n",
      "Epoch Progress:   2%|██▏                                                                                   | 1/40 [01:49<1:10:54, 109.10s/it]\u001b[A\n",
      "Epoch 2:   0%|                                                                                                       | 0/223 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|                                                                                  | 0/223 [00:00<?, ?it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 2:   0%|▎                                                                         | 1/223 [00:00<01:47,  2.07it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 2:   0%|▎                                                                         | 1/223 [00:00<01:47,  2.07it/s, training_loss=0.471]\u001b[A\n",
      "Epoch 2:   1%|▋                                                                         | 2/223 [00:00<01:47,  2.07it/s, training_loss=0.471]\u001b[A\n",
      "Epoch 2:   1%|▋                                                                         | 2/223 [00:01<01:47,  2.07it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 2:   1%|▉                                                                         | 3/223 [00:01<01:48,  2.04it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 2:   1%|▉                                                                         | 3/223 [00:01<01:48,  2.04it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 2:   2%|█▎                                                                        | 4/223 [00:01<01:48,  2.02it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 2:   2%|█▎                                                                        | 4/223 [00:02<01:48,  2.02it/s, training_loss=0.433]\u001b[A\n",
      "Epoch 2:   2%|█▋                                                                        | 5/223 [00:02<01:47,  2.04it/s, training_loss=0.433]\u001b[A\n",
      "Epoch 2:   2%|█▋                                                                        | 5/223 [00:02<01:47,  2.04it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 2:   3%|█▉                                                                        | 6/223 [00:02<01:47,  2.02it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 2:   3%|█▉                                                                        | 6/223 [00:03<01:47,  2.02it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 2:   3%|██▎                                                                       | 7/223 [00:03<01:46,  2.04it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 2:   3%|██▎                                                                       | 7/223 [00:03<01:46,  2.04it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 2:   4%|██▋                                                                       | 8/223 [00:03<01:46,  2.03it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 2:   4%|██▋                                                                       | 8/223 [00:04<01:46,  2.03it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 2:   4%|██▉                                                                       | 9/223 [00:04<01:45,  2.04it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 2:   4%|██▉                                                                       | 9/223 [00:04<01:45,  2.04it/s, training_loss=0.300]\u001b[A\n",
      "Epoch 2:   4%|███▎                                                                     | 10/223 [00:04<01:45,  2.03it/s, training_loss=0.300]\u001b[A\n",
      "Epoch 2:   4%|███▎                                                                     | 10/223 [00:05<01:45,  2.03it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 2:   5%|███▌                                                                     | 11/223 [00:05<01:45,  2.02it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 2:   5%|███▌                                                                     | 11/223 [00:05<01:45,  2.02it/s, training_loss=0.230]\u001b[A\n",
      "Epoch 2:   5%|███▉                                                                     | 12/223 [00:05<01:44,  2.01it/s, training_loss=0.230]\u001b[A\n",
      "Epoch 2:   5%|███▉                                                                     | 12/223 [00:06<01:44,  2.01it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 2:   6%|████▎                                                                    | 13/223 [00:06<01:43,  2.03it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 2:   6%|████▎                                                                    | 13/223 [00:06<01:43,  2.03it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 2:   6%|████▌                                                                    | 14/223 [00:06<01:42,  2.04it/s, training_loss=0.383]\u001b[A\n",
      "Epoch 2:   6%|████▌                                                                    | 14/223 [00:07<01:42,  2.04it/s, training_loss=0.422]\u001b[A\n",
      "Epoch 2:   7%|████▉                                                                    | 15/223 [00:07<01:43,  2.02it/s, training_loss=0.422]\u001b[A\n",
      "Epoch 2:   7%|████▉                                                                    | 15/223 [00:07<01:43,  2.02it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 2:   7%|█████▏                                                                   | 16/223 [00:07<01:42,  2.01it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 2:   7%|█████▏                                                                   | 16/223 [00:08<01:42,  2.01it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:   8%|█████▌                                                                   | 17/223 [00:08<01:41,  2.03it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:   8%|█████▌                                                                   | 17/223 [00:08<01:41,  2.03it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 2:   8%|█████▉                                                                   | 18/223 [00:08<01:41,  2.02it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 2:   8%|█████▉                                                                   | 18/223 [00:09<01:41,  2.02it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 2:   9%|██████▏                                                                  | 19/223 [00:09<01:41,  2.01it/s, training_loss=0.427]\u001b[A\n",
      "Epoch 2:   9%|██████▏                                                                  | 19/223 [00:09<01:41,  2.01it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 2:   9%|██████▌                                                                  | 20/223 [00:09<01:40,  2.01it/s, training_loss=0.329]\u001b[A\n",
      "Epoch 2:   9%|██████▌                                                                  | 20/223 [00:10<01:40,  2.01it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:   9%|██████▊                                                                  | 21/223 [00:10<01:38,  2.05it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:   9%|██████▊                                                                  | 21/223 [00:10<01:38,  2.05it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 2:  10%|███████▏                                                                 | 22/223 [00:10<01:38,  2.03it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 2:  10%|███████▏                                                                 | 22/223 [00:11<01:38,  2.03it/s, training_loss=0.366]\u001b[A\n",
      "Epoch 2:  10%|███████▌                                                                 | 23/223 [00:11<01:37,  2.06it/s, training_loss=0.366]\u001b[A\n",
      "Epoch 2:  10%|███████▌                                                                 | 23/223 [00:11<01:37,  2.06it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 2:  11%|███████▊                                                                 | 24/223 [00:11<01:37,  2.04it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 2:  11%|███████▊                                                                 | 24/223 [00:12<01:37,  2.04it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 2:  11%|████████▏                                                                | 25/223 [00:12<01:36,  2.05it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 2:  11%|████████▏                                                                | 25/223 [00:12<01:36,  2.05it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 2:  12%|████████▌                                                                | 26/223 [00:12<01:36,  2.03it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 2:  12%|████████▌                                                                | 26/223 [00:13<01:36,  2.03it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 2:  12%|████████▊                                                                | 27/223 [00:13<01:35,  2.04it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 2:  12%|████████▊                                                                | 27/223 [00:13<01:35,  2.04it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 2:  13%|█████████▏                                                               | 28/223 [00:13<01:36,  2.03it/s, training_loss=0.335]\u001b[A\n",
      "Epoch 2:  13%|█████████▏                                                               | 28/223 [00:14<01:36,  2.03it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 2:  13%|█████████▍                                                               | 29/223 [00:14<01:35,  2.04it/s, training_loss=0.134]\u001b[A\n",
      "Epoch 2:  13%|█████████▍                                                               | 29/223 [00:14<01:35,  2.04it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:  13%|█████████▊                                                               | 30/223 [00:14<01:33,  2.07it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:  13%|█████████▊                                                               | 30/223 [00:15<01:33,  2.07it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 2:  14%|██████████▏                                                              | 31/223 [00:15<01:33,  2.05it/s, training_loss=0.181]\u001b[A\n",
      "Epoch 2:  14%|██████████▏                                                              | 31/223 [00:15<01:33,  2.05it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  14%|██████████▍                                                              | 32/223 [00:15<01:33,  2.05it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  14%|██████████▍                                                              | 32/223 [00:16<01:33,  2.05it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 2:  15%|██████████▊                                                              | 33/223 [00:16<01:34,  2.02it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 2:  15%|██████████▊                                                              | 33/223 [00:16<01:34,  2.02it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 2:  15%|███████████▏                                                             | 34/223 [00:16<01:33,  2.03it/s, training_loss=0.190]\u001b[A\n",
      "Epoch 2:  15%|███████████▏                                                             | 34/223 [00:17<01:33,  2.03it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  16%|███████████▍                                                             | 35/223 [00:17<01:32,  2.02it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  16%|███████████▍                                                             | 35/223 [00:17<01:32,  2.02it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 2:  16%|███████████▊                                                             | 36/223 [00:17<01:31,  2.03it/s, training_loss=0.255]\u001b[A\n",
      "Epoch 2:  16%|███████████▊                                                             | 36/223 [00:18<01:31,  2.03it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 2:  17%|████████████                                                             | 37/223 [00:18<01:31,  2.04it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 2:  17%|████████████                                                             | 37/223 [00:18<01:31,  2.04it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 2:  17%|████████████▍                                                            | 38/223 [00:18<01:31,  2.03it/s, training_loss=0.341]\u001b[A\n",
      "Epoch 2:  17%|████████████▍                                                            | 38/223 [00:19<01:31,  2.03it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 2:  17%|████████████▊                                                            | 39/223 [00:19<01:30,  2.04it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 2:  17%|████████████▊                                                            | 39/223 [00:19<01:30,  2.04it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 2:  18%|█████████████                                                            | 40/223 [00:19<01:30,  2.03it/s, training_loss=0.244]\u001b[A\n",
      "Epoch 2:  18%|█████████████                                                            | 40/223 [00:20<01:30,  2.03it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 2:  18%|█████████████▍                                                           | 41/223 [00:20<01:29,  2.04it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 2:  18%|█████████████▍                                                           | 41/223 [00:20<01:29,  2.04it/s, training_loss=0.385]\u001b[A\n",
      "Epoch 2:  19%|█████████████▋                                                           | 42/223 [00:20<01:29,  2.03it/s, training_loss=0.385]\u001b[A\n",
      "Epoch 2:  19%|█████████████▋                                                           | 42/223 [00:21<01:29,  2.03it/s, training_loss=0.179]\u001b[A\n",
      "Epoch 2:  19%|██████████████                                                           | 43/223 [00:21<01:28,  2.04it/s, training_loss=0.179]\u001b[A\n",
      "Epoch 2:  19%|██████████████                                                           | 43/223 [00:21<01:28,  2.04it/s, training_loss=0.221]\u001b[A\n",
      "Epoch 2:  20%|██████████████▍                                                          | 44/223 [00:21<01:28,  2.03it/s, training_loss=0.221]\u001b[A\n",
      "Epoch 2:  20%|██████████████▍                                                          | 44/223 [00:22<01:28,  2.03it/s, training_loss=0.321]\u001b[A\n",
      "Epoch 2:  20%|██████████████▋                                                          | 45/223 [00:22<01:27,  2.04it/s, training_loss=0.321]\u001b[A\n",
      "Epoch 2:  20%|██████████████▋                                                          | 45/223 [00:22<01:27,  2.04it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 2:  21%|███████████████                                                          | 46/223 [00:22<01:27,  2.03it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 2:  21%|███████████████                                                          | 46/223 [00:23<01:27,  2.03it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 2:  21%|███████████████▍                                                         | 47/223 [00:23<01:26,  2.04it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 2:  21%|███████████████▍                                                         | 47/223 [00:23<01:26,  2.04it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 2:  22%|███████████████▋                                                         | 48/223 [00:23<01:26,  2.03it/s, training_loss=0.199]\u001b[A\n",
      "Epoch 2:  22%|███████████████▋                                                         | 48/223 [00:24<01:26,  2.03it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  22%|████████████████                                                         | 49/223 [00:24<01:25,  2.04it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  22%|████████████████                                                         | 49/223 [00:24<01:25,  2.04it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 2:  22%|████████████████▎                                                        | 50/223 [00:24<01:25,  2.03it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 2:  22%|████████████████▎                                                        | 50/223 [00:25<01:25,  2.03it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 2:  23%|████████████████▋                                                        | 51/223 [00:25<01:23,  2.06it/s, training_loss=0.200]\u001b[A\n",
      "Epoch 2:  23%|████████████████▋                                                        | 51/223 [00:25<01:23,  2.06it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  23%|█████████████████                                                        | 52/223 [00:25<01:22,  2.08it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  23%|█████████████████                                                        | 52/223 [00:26<01:22,  2.08it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 2:  24%|█████████████████▎                                                       | 53/223 [00:26<01:21,  2.08it/s, training_loss=0.350]\u001b[A\n",
      "Epoch 2:  24%|█████████████████▎                                                       | 53/223 [00:26<01:21,  2.08it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  24%|█████████████████▋                                                       | 54/223 [00:26<01:23,  2.03it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  24%|█████████████████▋                                                       | 54/223 [00:27<01:23,  2.03it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  25%|██████████████████                                                       | 55/223 [00:27<01:22,  2.04it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  25%|██████████████████                                                       | 55/223 [00:27<01:22,  2.04it/s, training_loss=0.414]\u001b[A\n",
      "Epoch 2:  25%|██████████████████▎                                                      | 56/223 [00:27<01:22,  2.03it/s, training_loss=0.414]\u001b[A\n",
      "Epoch 2:  25%|██████████████████▎                                                      | 56/223 [00:28<01:22,  2.03it/s, training_loss=0.487]\u001b[A\n",
      "Epoch 2:  26%|██████████████████▋                                                      | 57/223 [00:28<01:21,  2.04it/s, training_loss=0.487]\u001b[A\n",
      "Epoch 2:  26%|██████████████████▋                                                      | 57/223 [00:28<01:21,  2.04it/s, training_loss=0.331]\u001b[A\n",
      "Epoch 2:  26%|██████████████████▉                                                      | 58/223 [00:28<01:22,  2.01it/s, training_loss=0.331]\u001b[A\n",
      "Epoch 2:  26%|██████████████████▉                                                      | 58/223 [00:28<01:22,  2.01it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 2:  26%|███████████████████▎                                                     | 59/223 [00:28<01:20,  2.04it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 2:  26%|███████████████████▎                                                     | 59/223 [00:29<01:20,  2.04it/s, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  27%|███████████████████▋                                                     | 60/223 [00:29<01:21,  2.01it/s, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  27%|███████████████████▋                                                     | 60/223 [00:29<01:21,  2.01it/s, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  27%|███████████████████▉                                                     | 61/223 [00:29<01:19,  2.05it/s, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  27%|███████████████████▉                                                     | 61/223 [00:30<01:19,  2.05it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 2:  28%|████████████████████▎                                                    | 62/223 [00:30<01:18,  2.05it/s, training_loss=0.345]\u001b[A\n",
      "Epoch 2:  28%|████████████████████▎                                                    | 62/223 [00:30<01:18,  2.05it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  28%|████████████████████▌                                                    | 63/223 [00:30<01:17,  2.06it/s, training_loss=0.258]\u001b[A\n",
      "Epoch 2:  28%|████████████████████▌                                                    | 63/223 [00:31<01:17,  2.06it/s, training_loss=0.256]\u001b[A\n",
      "Epoch 2:  29%|████████████████████▉                                                    | 64/223 [00:31<01:17,  2.04it/s, training_loss=0.256]\u001b[A\n",
      "Epoch 2:  29%|████████████████████▉                                                    | 64/223 [00:31<01:17,  2.04it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 2:  29%|█████████████████████▎                                                   | 65/223 [00:31<01:17,  2.05it/s, training_loss=0.360]\u001b[A\n",
      "Epoch 2:  29%|█████████████████████▎                                                   | 65/223 [00:32<01:17,  2.05it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 2:  30%|█████████████████████▌                                                   | 66/223 [00:32<01:17,  2.03it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 2:  30%|█████████████████████▌                                                   | 66/223 [00:32<01:17,  2.03it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 2:  30%|█████████████████████▉                                                   | 67/223 [00:32<01:17,  2.02it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 2:  30%|█████████████████████▉                                                   | 67/223 [00:33<01:17,  2.02it/s, training_loss=0.253]\u001b[A\n",
      "Epoch 2:  30%|██████████████████████▎                                                  | 68/223 [00:33<01:16,  2.04it/s, training_loss=0.253]\u001b[A\n",
      "Epoch 2:  30%|██████████████████████▎                                                  | 68/223 [00:33<01:16,  2.04it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 2:  31%|██████████████████████▌                                                  | 69/223 [00:33<01:16,  2.02it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 2:  31%|██████████████████████▌                                                  | 69/223 [00:34<01:16,  2.02it/s, training_loss=0.259]\u001b[A\n",
      "Epoch 2:  31%|██████████████████████▉                                                  | 70/223 [00:34<01:15,  2.04it/s, training_loss=0.259]\u001b[A\n",
      "Epoch 2:  31%|██████████████████████▉                                                  | 70/223 [00:34<01:15,  2.04it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 2:  32%|███████████████████████▏                                                 | 71/223 [00:34<01:15,  2.03it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 2:  32%|███████████████████████▏                                                 | 71/223 [00:35<01:15,  2.03it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 2:  32%|███████████████████████▌                                                 | 72/223 [00:35<01:14,  2.04it/s, training_loss=0.320]\u001b[A\n",
      "Epoch 2:  32%|███████████████████████▌                                                 | 72/223 [00:35<01:14,  2.04it/s, training_loss=0.409]\u001b[A\n",
      "Epoch 2:  33%|███████████████████████▉                                                 | 73/223 [00:35<01:14,  2.03it/s, training_loss=0.409]\u001b[A\n",
      "Epoch 2:  33%|███████████████████████▉                                                 | 73/223 [00:36<01:14,  2.03it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 2:  33%|████████████████████████▏                                                | 74/223 [00:36<01:14,  2.00it/s, training_loss=0.434]\u001b[A\n",
      "Epoch 2:  33%|████████████████████████▏                                                | 74/223 [00:36<01:14,  2.00it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 2:  34%|████████████████████████▌                                                | 75/223 [00:36<01:13,  2.02it/s, training_loss=0.239]\u001b[A\n",
      "Epoch 2:  34%|████████████████████████▌                                                | 75/223 [00:37<01:13,  2.02it/s, training_loss=0.514]\u001b[A\n",
      "Epoch 2:  34%|████████████████████████▉                                                | 76/223 [00:37<01:12,  2.03it/s, training_loss=0.514]\u001b[A\n",
      "Epoch 2:  34%|████████████████████████▉                                                | 76/223 [00:37<01:12,  2.03it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  35%|█████████████████████████▏                                               | 77/223 [00:37<01:11,  2.04it/s, training_loss=0.119]\u001b[A\n",
      "Epoch 2:  35%|█████████████████████████▏                                               | 77/223 [00:38<01:11,  2.04it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  35%|█████████████████████████▌                                               | 78/223 [00:38<01:11,  2.03it/s, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  35%|█████████████████████████▌                                               | 78/223 [00:38<01:11,  2.03it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  35%|█████████████████████████▊                                               | 79/223 [00:38<01:10,  2.04it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  35%|█████████████████████████▊                                               | 79/223 [00:39<01:10,  2.04it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 2:  36%|██████████████████████████▏                                              | 80/223 [00:39<01:11,  2.01it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 2:  36%|██████████████████████████▏                                              | 80/223 [00:39<01:11,  2.01it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 2:  36%|██████████████████████████▌                                              | 81/223 [00:39<01:10,  2.03it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 2:  36%|██████████████████████████▌                                              | 81/223 [00:40<01:10,  2.03it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  37%|██████████████████████████▊                                              | 82/223 [00:40<01:09,  2.02it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  37%|██████████████████████████▊                                              | 82/223 [00:40<01:09,  2.02it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  37%|███████████████████████████▏                                             | 83/223 [00:40<01:08,  2.03it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  37%|███████████████████████████▏                                             | 83/223 [00:41<01:08,  2.03it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 2:  38%|███████████████████████████▍                                             | 84/223 [00:41<01:08,  2.04it/s, training_loss=0.278]\u001b[A\n",
      "Epoch 2:  38%|███████████████████████████▍                                             | 84/223 [00:41<01:08,  2.04it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 2:  38%|███████████████████████████▊                                             | 85/223 [00:41<01:08,  2.03it/s, training_loss=0.208]\u001b[A\n",
      "Epoch 2:  38%|███████████████████████████▊                                             | 85/223 [00:42<01:08,  2.03it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 2:  39%|████████████████████████████▏                                            | 86/223 [00:42<01:07,  2.02it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 2:  39%|████████████████████████████▏                                            | 86/223 [00:42<01:07,  2.02it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 2:  39%|████████████████████████████▍                                            | 87/223 [00:42<01:06,  2.03it/s, training_loss=0.247]\u001b[A\n",
      "Epoch 2:  39%|████████████████████████████▍                                            | 87/223 [00:43<01:06,  2.03it/s, training_loss=0.253]\u001b[A\n",
      "Epoch 2:  39%|████████████████████████████▊                                            | 88/223 [00:43<01:06,  2.02it/s, training_loss=0.253]\u001b[A\n",
      "Epoch 2:  39%|████████████████████████████▊                                            | 88/223 [00:43<01:06,  2.02it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 2:  40%|█████████████████████████████▏                                           | 89/223 [00:43<01:05,  2.04it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 2:  40%|█████████████████████████████▏                                           | 89/223 [00:44<01:05,  2.04it/s, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  40%|█████████████████████████████▍                                           | 90/223 [00:44<01:05,  2.03it/s, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  40%|█████████████████████████████▍                                           | 90/223 [00:44<01:05,  2.03it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 2:  41%|█████████████████████████████▊                                           | 91/223 [00:44<01:04,  2.04it/s, training_loss=0.277]\u001b[A\n",
      "Epoch 2:  41%|█████████████████████████████▊                                           | 91/223 [00:45<01:04,  2.04it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  41%|██████████████████████████████                                           | 92/223 [00:45<01:04,  2.03it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  41%|██████████████████████████████                                           | 92/223 [00:45<01:04,  2.03it/s, training_loss=0.301]\u001b[A\n",
      "Epoch 2:  42%|██████████████████████████████▍                                          | 93/223 [00:45<01:03,  2.06it/s, training_loss=0.301]\u001b[A\n",
      "Epoch 2:  42%|██████████████████████████████▍                                          | 93/223 [00:46<01:03,  2.06it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 2:  42%|██████████████████████████████▊                                          | 94/223 [00:46<01:03,  2.04it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 2:  42%|██████████████████████████████▊                                          | 94/223 [00:46<01:03,  2.04it/s, training_loss=0.369]\u001b[A\n",
      "Epoch 2:  43%|███████████████████████████████                                          | 95/223 [00:46<01:02,  2.05it/s, training_loss=0.369]\u001b[A\n",
      "Epoch 2:  43%|███████████████████████████████                                          | 95/223 [00:47<01:02,  2.05it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  43%|███████████████████████████████▍                                         | 96/223 [00:47<01:02,  2.03it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  43%|███████████████████████████████▍                                         | 96/223 [00:47<01:02,  2.03it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  43%|███████████████████████████████▊                                         | 97/223 [00:47<01:02,  2.02it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  43%|███████████████████████████████▊                                         | 97/223 [00:48<01:02,  2.02it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 2:  44%|████████████████████████████████                                         | 98/223 [00:48<01:01,  2.02it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 2:  44%|████████████████████████████████                                         | 98/223 [00:48<01:01,  2.02it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 2:  44%|████████████████████████████████▍                                        | 99/223 [00:48<01:01,  2.03it/s, training_loss=0.299]\u001b[A\n",
      "Epoch 2:  44%|████████████████████████████████▍                                        | 99/223 [00:49<01:01,  2.03it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  45%|████████████████████████████████▎                                       | 100/223 [00:49<01:00,  2.02it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  45%|████████████████████████████████▎                                       | 100/223 [00:49<01:00,  2.02it/s, training_loss=0.393]\u001b[A\n",
      "Epoch 2:  45%|████████████████████████████████▌                                       | 101/223 [00:49<00:59,  2.03it/s, training_loss=0.393]\u001b[A\n",
      "Epoch 2:  45%|████████████████████████████████▌                                       | 101/223 [00:50<00:59,  2.03it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 2:  46%|████████████████████████████████▉                                       | 102/223 [00:50<00:59,  2.04it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 2:  46%|████████████████████████████████▉                                       | 102/223 [00:50<00:59,  2.04it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 2:  46%|█████████████████████████████████▎                                      | 103/223 [00:50<00:59,  2.03it/s, training_loss=0.242]\u001b[A\n",
      "Epoch 2:  46%|█████████████████████████████████▎                                      | 103/223 [00:51<00:59,  2.03it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 2:  47%|█████████████████████████████████▌                                      | 104/223 [00:51<00:58,  2.04it/s, training_loss=0.280]\u001b[A\n",
      "Epoch 2:  47%|█████████████████████████████████▌                                      | 104/223 [00:51<00:58,  2.04it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  47%|█████████████████████████████████▉                                      | 105/223 [00:51<00:57,  2.05it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 2:  47%|█████████████████████████████████▉                                      | 105/223 [00:52<00:57,  2.05it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  48%|██████████████████████████████████▏                                     | 106/223 [00:52<00:57,  2.03it/s, training_loss=0.282]\u001b[A\n",
      "Epoch 2:  48%|██████████████████████████████████▏                                     | 106/223 [00:52<00:57,  2.03it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  48%|██████████████████████████████████▌                                     | 107/223 [00:52<00:57,  2.02it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  48%|██████████████████████████████████▌                                     | 107/223 [00:53<00:57,  2.02it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 2:  48%|██████████████████████████████████▊                                     | 108/223 [00:53<00:56,  2.04it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 2:  48%|██████████████████████████████████▊                                     | 108/223 [00:53<00:56,  2.04it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 2:  49%|███████████████████████████████████▏                                    | 109/223 [00:53<00:56,  2.03it/s, training_loss=0.215]\u001b[A\n",
      "Epoch 2:  49%|███████████████████████████████████▏                                    | 109/223 [00:54<00:56,  2.03it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 2:  49%|███████████████████████████████████▌                                    | 110/223 [00:54<00:55,  2.04it/s, training_loss=0.285]\u001b[A\n",
      "Epoch 2:  49%|███████████████████████████████████▌                                    | 110/223 [00:54<00:55,  2.04it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  50%|███████████████████████████████████▊                                    | 111/223 [00:54<00:55,  2.03it/s, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  50%|███████████████████████████████████▊                                    | 111/223 [00:55<00:55,  2.03it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 2:  50%|████████████████████████████████████▏                                   | 112/223 [00:55<00:54,  2.04it/s, training_loss=0.170]\u001b[A\n",
      "Epoch 2:  50%|████████████████████████████████████▏                                   | 112/223 [00:55<00:54,  2.04it/s, training_loss=0.312]\u001b[A\n",
      "Epoch 2:  51%|████████████████████████████████████▍                                   | 113/223 [00:55<00:53,  2.05it/s, training_loss=0.312]\u001b[A\n",
      "Epoch 2:  51%|████████████████████████████████████▍                                   | 113/223 [00:56<00:53,  2.05it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 2:  51%|████████████████████████████████████▊                                   | 114/223 [00:56<00:53,  2.03it/s, training_loss=0.276]\u001b[A\n",
      "Epoch 2:  51%|████████████████████████████████████▊                                   | 114/223 [00:56<00:53,  2.03it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 2:  52%|█████████████████████████████████████▏                                  | 115/223 [00:56<00:52,  2.04it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 2:  52%|█████████████████████████████████████▏                                  | 115/223 [00:57<00:52,  2.04it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  52%|█████████████████████████████████████▍                                  | 116/223 [00:57<00:52,  2.05it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 2:  52%|█████████████████████████████████████▍                                  | 116/223 [00:57<00:52,  2.05it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  52%|█████████████████████████████████████▊                                  | 117/223 [00:57<00:51,  2.07it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  52%|█████████████████████████████████████▊                                  | 117/223 [00:57<00:51,  2.07it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 2:  53%|██████████████████████████████████████                                  | 118/223 [00:57<00:50,  2.07it/s, training_loss=0.191]\u001b[A\n",
      "Epoch 2:  53%|██████████████████████████████████████                                  | 118/223 [00:58<00:50,  2.07it/s, training_loss=0.381]\u001b[A\n",
      "Epoch 2:  53%|██████████████████████████████████████▍                                 | 119/223 [00:58<00:50,  2.05it/s, training_loss=0.381]\u001b[A\n",
      "Epoch 2:  53%|██████████████████████████████████████▍                                 | 119/223 [00:58<00:50,  2.05it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 2:  54%|██████████████████████████████████████▋                                 | 120/223 [00:58<00:50,  2.03it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 2:  54%|██████████████████████████████████████▋                                 | 120/223 [00:59<00:50,  2.03it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 2:  54%|███████████████████████████████████████                                 | 121/223 [00:59<00:49,  2.04it/s, training_loss=0.183]\u001b[A\n",
      "Epoch 2:  54%|███████████████████████████████████████                                 | 121/223 [00:59<00:49,  2.04it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 2:  55%|███████████████████████████████████████▍                                | 122/223 [00:59<00:49,  2.03it/s, training_loss=0.374]\u001b[A\n",
      "Epoch 2:  55%|███████████████████████████████████████▍                                | 122/223 [01:00<00:49,  2.03it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 2:  55%|███████████████████████████████████████▋                                | 123/223 [01:00<00:49,  2.04it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 2:  55%|███████████████████████████████████████▋                                | 123/223 [01:00<00:49,  2.04it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████████████████                                | 124/223 [01:00<00:48,  2.05it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████████████████                                | 124/223 [01:01<00:48,  2.05it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████████████████▎                               | 125/223 [01:01<00:48,  2.01it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  56%|████████████████████████████████████████▎                               | 125/223 [01:01<00:48,  2.01it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 2:  57%|████████████████████████████████████████▋                               | 126/223 [01:01<00:47,  2.05it/s, training_loss=0.291]\u001b[A\n",
      "Epoch 2:  57%|████████████████████████████████████████▋                               | 126/223 [01:02<00:47,  2.05it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  57%|█████████████████████████████████████████                               | 127/223 [01:02<00:47,  2.03it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 2:  57%|█████████████████████████████████████████                               | 127/223 [01:02<00:47,  2.03it/s, training_loss=0.393]\u001b[A\n",
      "Epoch 2:  57%|█████████████████████████████████████████▎                              | 128/223 [01:02<00:46,  2.04it/s, training_loss=0.393]\u001b[A\n",
      "Epoch 2:  57%|█████████████████████████████████████████▎                              | 128/223 [01:03<00:46,  2.04it/s, training_loss=0.422]\u001b[A\n",
      "Epoch 2:  58%|█████████████████████████████████████████▋                              | 129/223 [01:03<00:46,  2.03it/s, training_loss=0.422]\u001b[A\n",
      "Epoch 2:  58%|█████████████████████████████████████████▋                              | 129/223 [01:03<00:46,  2.03it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 2:  58%|█████████████████████████████████████████▉                              | 130/223 [01:03<00:45,  2.04it/s, training_loss=0.314]\u001b[A\n",
      "Epoch 2:  58%|█████████████████████████████████████████▉                              | 130/223 [01:04<00:45,  2.04it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 2:  59%|██████████████████████████████████████████▎                             | 131/223 [01:04<00:45,  2.03it/s, training_loss=0.132]\u001b[A\n",
      "Epoch 2:  59%|██████████████████████████████████████████▎                             | 131/223 [01:04<00:45,  2.03it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  59%|██████████████████████████████████████████▌                             | 132/223 [01:04<00:44,  2.04it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  59%|██████████████████████████████████████████▌                             | 132/223 [01:05<00:44,  2.04it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 2:  60%|██████████████████████████████████████████▉                             | 133/223 [01:05<00:44,  2.03it/s, training_loss=0.287]\u001b[A\n",
      "Epoch 2:  60%|██████████████████████████████████████████▉                             | 133/223 [01:05<00:44,  2.03it/s, training_loss=0.421]\u001b[A\n",
      "Epoch 2:  60%|███████████████████████████████████████████▎                            | 134/223 [01:05<00:43,  2.04it/s, training_loss=0.421]\u001b[A\n",
      "Epoch 2:  60%|███████████████████████████████████████████▎                            | 134/223 [01:06<00:43,  2.04it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 2:  61%|███████████████████████████████████████████▌                            | 135/223 [01:06<00:43,  2.03it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 2:  61%|███████████████████████████████████████████▌                            | 135/223 [01:06<00:43,  2.03it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:  61%|███████████████████████████████████████████▉                            | 136/223 [01:06<00:42,  2.04it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:  61%|███████████████████████████████████████████▉                            | 136/223 [01:07<00:42,  2.04it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  61%|████████████████████████████████████████████▏                           | 137/223 [01:07<00:42,  2.03it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  61%|████████████████████████████████████████████▏                           | 137/223 [01:07<00:42,  2.03it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 2:  62%|████████████████████████████████████████████▌                           | 138/223 [01:07<00:42,  2.02it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 2:  62%|████████████████████████████████████████████▌                           | 138/223 [01:08<00:42,  2.02it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  62%|████████████████████████████████████████████▉                           | 139/223 [01:08<00:41,  2.03it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  62%|████████████████████████████████████████████▉                           | 139/223 [01:08<00:41,  2.03it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 2:  63%|█████████████████████████████████████████████▏                          | 140/223 [01:08<00:40,  2.04it/s, training_loss=0.182]\u001b[A\n",
      "Epoch 2:  63%|█████████████████████████████████████████████▏                          | 140/223 [01:09<00:40,  2.04it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  63%|█████████████████████████████████████████████▌                          | 141/223 [01:09<00:40,  2.05it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 2:  63%|█████████████████████████████████████████████▌                          | 141/223 [01:09<00:40,  2.05it/s, training_loss=0.270]\u001b[A\n",
      "Epoch 2:  64%|█████████████████████████████████████████████▊                          | 142/223 [01:09<00:39,  2.03it/s, training_loss=0.270]\u001b[A\n",
      "Epoch 2:  64%|█████████████████████████████████████████████▊                          | 142/223 [01:10<00:39,  2.03it/s, training_loss=0.166]\u001b[A\n",
      "Epoch 2:  64%|██████████████████████████████████████████████▏                         | 143/223 [01:10<00:39,  2.02it/s, training_loss=0.166]\u001b[A\n",
      "Epoch 2:  64%|██████████████████████████████████████████████▏                         | 143/223 [01:10<00:39,  2.02it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 2:  65%|██████████████████████████████████████████████▍                         | 144/223 [01:10<00:38,  2.04it/s, training_loss=0.336]\u001b[A\n",
      "Epoch 2:  65%|██████████████████████████████████████████████▍                         | 144/223 [01:11<00:38,  2.04it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 2:  65%|██████████████████████████████████████████████▊                         | 145/223 [01:11<00:38,  2.03it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 2:  65%|██████████████████████████████████████████████▊                         | 145/223 [01:11<00:38,  2.03it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  65%|███████████████████████████████████████████████▏                        | 146/223 [01:11<00:38,  2.02it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  65%|███████████████████████████████████████████████▏                        | 146/223 [01:12<00:38,  2.02it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 2:  66%|███████████████████████████████████████████████▍                        | 147/223 [01:12<00:37,  2.03it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 2:  66%|███████████████████████████████████████████████▍                        | 147/223 [01:12<00:37,  2.03it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 2:  66%|███████████████████████████████████████████████▊                        | 148/223 [01:12<00:37,  2.02it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 2:  66%|███████████████████████████████████████████████▊                        | 148/223 [01:13<00:37,  2.02it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 2:  67%|████████████████████████████████████████████████                        | 149/223 [01:13<00:36,  2.02it/s, training_loss=0.196]\u001b[A\n",
      "Epoch 2:  67%|████████████████████████████████████████████████                        | 149/223 [01:13<00:36,  2.02it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 2:  67%|████████████████████████████████████████████████▍                       | 150/223 [01:13<00:35,  2.03it/s, training_loss=0.082]\u001b[A\n",
      "Epoch 2:  67%|████████████████████████████████████████████████▍                       | 150/223 [01:14<00:35,  2.03it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  68%|████████████████████████████████████████████████▊                       | 151/223 [01:14<00:35,  2.00it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  68%|████████████████████████████████████████████████▊                       | 151/223 [01:14<00:35,  2.00it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 2:  68%|█████████████████████████████████████████████████                       | 152/223 [01:14<00:35,  2.00it/s, training_loss=0.365]\u001b[A\n",
      "Epoch 2:  68%|█████████████████████████████████████████████████                       | 152/223 [01:15<00:35,  2.00it/s, training_loss=0.376]\u001b[A\n",
      "Epoch 2:  69%|█████████████████████████████████████████████████▍                      | 153/223 [01:15<00:34,  2.04it/s, training_loss=0.376]\u001b[A\n",
      "Epoch 2:  69%|█████████████████████████████████████████████████▍                      | 153/223 [01:15<00:34,  2.04it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 2:  69%|█████████████████████████████████████████████████▋                      | 154/223 [01:15<00:34,  2.03it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 2:  69%|█████████████████████████████████████████████████▋                      | 154/223 [01:16<00:34,  2.03it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 2:  70%|██████████████████████████████████████████████████                      | 155/223 [01:16<00:33,  2.04it/s, training_loss=0.168]\u001b[A\n",
      "Epoch 2:  70%|██████████████████████████████████████████████████                      | 155/223 [01:16<00:33,  2.04it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  70%|██████████████████████████████████████████████████▎                     | 156/223 [01:16<00:32,  2.05it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  70%|██████████████████████████████████████████████████▎                     | 156/223 [01:17<00:32,  2.05it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 2:  70%|██████████████████████████████████████████████████▋                     | 157/223 [01:17<00:31,  2.07it/s, training_loss=0.302]\u001b[A\n",
      "Epoch 2:  70%|██████████████████████████████████████████████████▋                     | 157/223 [01:17<00:31,  2.07it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:  71%|███████████████████████████████████████████████████                     | 158/223 [01:17<00:31,  2.07it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 2:  71%|███████████████████████████████████████████████████                     | 158/223 [01:18<00:31,  2.07it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 2:  71%|███████████████████████████████████████████████████▎                    | 159/223 [01:18<00:30,  2.09it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 2:  71%|███████████████████████████████████████████████████▎                    | 159/223 [01:18<00:30,  2.09it/s, training_loss=0.331]\u001b[A\n",
      "Epoch 2:  72%|███████████████████████████████████████████████████▋                    | 160/223 [01:18<00:30,  2.06it/s, training_loss=0.331]\u001b[A\n",
      "Epoch 2:  72%|███████████████████████████████████████████████████▋                    | 160/223 [01:19<00:30,  2.06it/s, training_loss=0.351]\u001b[A\n",
      "Epoch 2:  72%|███████████████████████████████████████████████████▉                    | 161/223 [01:19<00:30,  2.06it/s, training_loss=0.351]\u001b[A\n",
      "Epoch 2:  72%|███████████████████████████████████████████████████▉                    | 161/223 [01:19<00:30,  2.06it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  73%|████████████████████████████████████████████████████▎                   | 162/223 [01:19<00:29,  2.04it/s, training_loss=0.250]\u001b[A\n",
      "Epoch 2:  73%|████████████████████████████████████████████████████▎                   | 162/223 [01:20<00:29,  2.04it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  73%|████████████████████████████████████████████████████▋                   | 163/223 [01:20<00:29,  2.03it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 2:  73%|████████████████████████████████████████████████████▋                   | 163/223 [01:20<00:29,  2.03it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 2:  74%|████████████████████████████████████████████████████▉                   | 164/223 [01:20<00:28,  2.04it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 2:  74%|████████████████████████████████████████████████████▉                   | 164/223 [01:21<00:28,  2.04it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 2:  74%|█████████████████████████████████████████████████████▎                  | 165/223 [01:21<00:28,  2.03it/s, training_loss=0.234]\u001b[A\n",
      "Epoch 2:  74%|█████████████████████████████████████████████████████▎                  | 165/223 [01:21<00:28,  2.03it/s, training_loss=0.254]\u001b[A\n",
      "Epoch 2:  74%|█████████████████████████████████████████████████████▌                  | 166/223 [01:21<00:27,  2.06it/s, training_loss=0.254]\u001b[A\n",
      "Epoch 2:  74%|█████████████████████████████████████████████████████▌                  | 166/223 [01:22<00:27,  2.06it/s, training_loss=0.254]\u001b[A\n",
      "Epoch 2:  75%|█████████████████████████████████████████████████████▉                  | 167/223 [01:22<00:27,  2.06it/s, training_loss=0.254]\u001b[A\n",
      "Epoch 2:  75%|█████████████████████████████████████████████████████▉                  | 167/223 [01:22<00:27,  2.06it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 2:  75%|██████████████████████████████████████████████████████▏                 | 168/223 [01:22<00:26,  2.04it/s, training_loss=0.174]\u001b[A\n",
      "Epoch 2:  75%|██████████████████████████████████████████████████████▏                 | 168/223 [01:23<00:26,  2.04it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 2:  76%|██████████████████████████████████████████████████████▌                 | 169/223 [01:23<00:26,  2.05it/s, training_loss=0.128]\u001b[A\n",
      "Epoch 2:  76%|██████████████████████████████████████████████████████▌                 | 169/223 [01:23<00:26,  2.05it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 2:  76%|██████████████████████████████████████████████████████▉                 | 170/223 [01:23<00:26,  2.03it/s, training_loss=0.546]\u001b[A\n",
      "Epoch 2:  76%|██████████████████████████████████████████████████████▉                 | 170/223 [01:24<00:26,  2.03it/s, training_loss=0.474]\u001b[A\n",
      "Epoch 2:  77%|███████████████████████████████████████████████████████▏                | 171/223 [01:24<00:25,  2.04it/s, training_loss=0.474]\u001b[A\n",
      "Epoch 2:  77%|███████████████████████████████████████████████████████▏                | 171/223 [01:24<00:25,  2.04it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  77%|███████████████████████████████████████████████████████▌                | 172/223 [01:24<00:24,  2.05it/s, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  77%|███████████████████████████████████████████████████████▌                | 172/223 [01:24<00:24,  2.05it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  78%|███████████████████████████████████████████████████████▊                | 173/223 [01:24<00:24,  2.03it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  78%|███████████████████████████████████████████████████████▊                | 173/223 [01:25<00:24,  2.03it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  78%|████████████████████████████████████████████████████████▏               | 174/223 [01:25<00:24,  2.02it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  78%|████████████████████████████████████████████████████████▏               | 174/223 [01:25<00:24,  2.02it/s, training_loss=0.235]\u001b[A\n",
      "Epoch 2:  78%|████████████████████████████████████████████████████████▌               | 175/223 [01:25<00:23,  2.04it/s, training_loss=0.235]\u001b[A\n",
      "Epoch 2:  78%|████████████████████████████████████████████████████████▌               | 175/223 [01:26<00:23,  2.04it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 2:  79%|████████████████████████████████████████████████████████▊               | 176/223 [01:26<00:22,  2.04it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 2:  79%|████████████████████████████████████████████████████████▊               | 176/223 [01:26<00:22,  2.04it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 2:  79%|█████████████████████████████████████████████████████████▏              | 177/223 [01:26<00:22,  2.05it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 2:  79%|█████████████████████████████████████████████████████████▏              | 177/223 [01:27<00:22,  2.05it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 2:  80%|█████████████████████████████████████████████████████████▍              | 178/223 [01:27<00:22,  2.04it/s, training_loss=0.419]\u001b[A\n",
      "Epoch 2:  80%|█████████████████████████████████████████████████████████▍              | 178/223 [01:27<00:22,  2.04it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 2:  80%|█████████████████████████████████████████████████████████▊              | 179/223 [01:27<00:21,  2.02it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 2:  80%|█████████████████████████████████████████████████████████▊              | 179/223 [01:28<00:21,  2.02it/s, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  81%|██████████████████████████████████████████████████████████              | 180/223 [01:28<00:21,  2.02it/s, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  81%|██████████████████████████████████████████████████████████              | 180/223 [01:28<00:21,  2.02it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 2:  81%|██████████████████████████████████████████████████████████▍             | 181/223 [01:28<00:20,  2.03it/s, training_loss=0.423]\u001b[A\n",
      "Epoch 2:  81%|██████████████████████████████████████████████████████████▍             | 181/223 [01:29<00:20,  2.03it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 2:  82%|██████████████████████████████████████████████████████████▊             | 182/223 [01:29<00:20,  2.04it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 2:  82%|██████████████████████████████████████████████████████████▊             | 182/223 [01:29<00:20,  2.04it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  82%|███████████████████████████████████████████████████████████             | 183/223 [01:29<00:19,  2.03it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 2:  82%|███████████████████████████████████████████████████████████             | 183/223 [01:30<00:19,  2.03it/s, training_loss=0.433]\u001b[A\n",
      "Epoch 2:  83%|███████████████████████████████████████████████████████████▍            | 184/223 [01:30<00:19,  2.04it/s, training_loss=0.433]\u001b[A\n",
      "Epoch 2:  83%|███████████████████████████████████████████████████████████▍            | 184/223 [01:30<00:19,  2.04it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  83%|███████████████████████████████████████████████████████████▋            | 185/223 [01:30<00:18,  2.03it/s, training_loss=0.216]\u001b[A\n",
      "Epoch 2:  83%|███████████████████████████████████████████████████████████▋            | 185/223 [01:31<00:18,  2.03it/s, training_loss=0.150]\u001b[A\n",
      "Epoch 2:  83%|████████████████████████████████████████████████████████████            | 186/223 [01:31<00:18,  2.04it/s, training_loss=0.150]\u001b[A\n",
      "Epoch 2:  83%|████████████████████████████████████████████████████████████            | 186/223 [01:31<00:18,  2.04it/s, training_loss=0.366]\u001b[A\n",
      "Epoch 2:  84%|████████████████████████████████████████████████████████████▍           | 187/223 [01:31<00:17,  2.03it/s, training_loss=0.366]\u001b[A\n",
      "Epoch 2:  84%|████████████████████████████████████████████████████████████▍           | 187/223 [01:32<00:17,  2.03it/s, training_loss=0.560]\u001b[A\n",
      "Epoch 2:  84%|████████████████████████████████████████████████████████████▋           | 188/223 [01:32<00:17,  2.04it/s, training_loss=0.560]\u001b[A\n",
      "Epoch 2:  84%|████████████████████████████████████████████████████████████▋           | 188/223 [01:32<00:17,  2.04it/s, training_loss=0.218]\u001b[A\n",
      "Epoch 2:  85%|█████████████████████████████████████████████████████████████           | 189/223 [01:32<00:16,  2.05it/s, training_loss=0.218]\u001b[A\n",
      "Epoch 2:  85%|█████████████████████████████████████████████████████████████           | 189/223 [01:33<00:16,  2.05it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 2:  85%|█████████████████████████████████████████████████████████████▎          | 190/223 [01:33<00:16,  2.03it/s, training_loss=0.265]\u001b[A\n",
      "Epoch 2:  85%|█████████████████████████████████████████████████████████████▎          | 190/223 [01:33<00:16,  2.03it/s, training_loss=0.268]\u001b[A\n",
      "Epoch 2:  86%|█████████████████████████████████████████████████████████████▋          | 191/223 [01:33<00:15,  2.04it/s, training_loss=0.268]\u001b[A\n",
      "Epoch 2:  86%|█████████████████████████████████████████████████████████████▋          | 191/223 [01:34<00:15,  2.04it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  86%|█████████████████████████████████████████████████████████████▉          | 192/223 [01:34<00:15,  2.03it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  86%|█████████████████████████████████████████████████████████████▉          | 192/223 [01:34<00:15,  2.03it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 2:  87%|██████████████████████████████████████████████████████████████▎         | 193/223 [01:34<00:14,  2.04it/s, training_loss=0.195]\u001b[A\n",
      "Epoch 2:  87%|██████████████████████████████████████████████████████████████▎         | 193/223 [01:35<00:14,  2.04it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  87%|██████████████████████████████████████████████████████████████▋         | 194/223 [01:35<00:14,  2.03it/s, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  87%|██████████████████████████████████████████████████████████████▋         | 194/223 [01:35<00:14,  2.03it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  87%|██████████████████████████████████████████████████████████████▉         | 195/223 [01:35<00:13,  2.04it/s, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  87%|██████████████████████████████████████████████████████████████▉         | 195/223 [01:36<00:13,  2.04it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  88%|███████████████████████████████████████████████████████████████▎        | 196/223 [01:36<00:13,  2.01it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  88%|███████████████████████████████████████████████████████████████▎        | 196/223 [01:36<00:13,  2.01it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 2:  88%|███████████████████████████████████████████████████████████████▌        | 197/223 [01:36<00:12,  2.02it/s, training_loss=0.217]\u001b[A\n",
      "Epoch 2:  88%|███████████████████████████████████████████████████████████████▌        | 197/223 [01:37<00:12,  2.02it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  89%|███████████████████████████████████████████████████████████████▉        | 198/223 [01:37<00:12,  2.02it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 2:  89%|███████████████████████████████████████████████████████████████▉        | 198/223 [01:37<00:12,  2.02it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████████████████████████████████████████▎       | 199/223 [01:37<00:11,  2.03it/s, training_loss=0.237]\u001b[A\n",
      "Epoch 2:  89%|████████████████████████████████████████████████████████████████▎       | 199/223 [01:38<00:11,  2.03it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 2:  90%|████████████████████████████████████████████████████████████████▌       | 200/223 [01:38<00:11,  2.02it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 2:  90%|████████████████████████████████████████████████████████████████▌       | 200/223 [01:38<00:11,  2.02it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 2:  90%|████████████████████████████████████████████████████████████████▉       | 201/223 [01:38<00:10,  2.02it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 2:  90%|████████████████████████████████████████████████████████████████▉       | 201/223 [01:39<00:10,  2.02it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████████████████████████▏      | 202/223 [01:39<00:10,  2.01it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████████████████████████▏      | 202/223 [01:39<00:10,  2.01it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████████████████████████▌      | 203/223 [01:39<00:09,  2.03it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████████████████████████▌      | 203/223 [01:40<00:09,  2.03it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████████████████████████▊      | 204/223 [01:40<00:09,  2.04it/s, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  91%|█████████████████████████████████████████████████████████████████▊      | 204/223 [01:40<00:09,  2.04it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 2:  92%|██████████████████████████████████████████████████████████████████▏     | 205/223 [01:40<00:08,  2.03it/s, training_loss=0.245]\u001b[A\n",
      "Epoch 2:  92%|██████████████████████████████████████████████████████████████████▏     | 205/223 [01:41<00:08,  2.03it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 2:  92%|██████████████████████████████████████████████████████████████████▌     | 206/223 [01:41<00:08,  2.04it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 2:  92%|██████████████████████████████████████████████████████████████████▌     | 206/223 [01:41<00:08,  2.04it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 2:  93%|██████████████████████████████████████████████████████████████████▊     | 207/223 [01:41<00:07,  2.03it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 2:  93%|██████████████████████████████████████████████████████████████████▊     | 207/223 [01:42<00:07,  2.03it/s, training_loss=0.466]\u001b[A\n",
      "Epoch 2:  93%|███████████████████████████████████████████████████████████████████▏    | 208/223 [01:42<00:07,  2.02it/s, training_loss=0.466]\u001b[A\n",
      "Epoch 2:  93%|███████████████████████████████████████████████████████████████████▏    | 208/223 [01:42<00:07,  2.02it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 2:  94%|███████████████████████████████████████████████████████████████████▍    | 209/223 [01:42<00:06,  2.03it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 2:  94%|███████████████████████████████████████████████████████████████████▍    | 209/223 [01:43<00:06,  2.03it/s, training_loss=0.443]\u001b[A\n",
      "Epoch 2:  94%|███████████████████████████████████████████████████████████████████▊    | 210/223 [01:43<00:06,  2.02it/s, training_loss=0.443]\u001b[A\n",
      "Epoch 2:  94%|███████████████████████████████████████████████████████████████████▊    | 210/223 [01:43<00:06,  2.02it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  95%|████████████████████████████████████████████████████████████████████▏   | 211/223 [01:43<00:05,  2.04it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  95%|████████████████████████████████████████████████████████████████████▏   | 211/223 [01:44<00:05,  2.04it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 2:  95%|████████████████████████████████████████████████████████████████████▍   | 212/223 [01:44<00:05,  2.02it/s, training_loss=0.214]\u001b[A\n",
      "Epoch 2:  95%|████████████████████████████████████████████████████████████████████▍   | 212/223 [01:44<00:05,  2.02it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████████████████████████▊   | 213/223 [01:44<00:04,  2.02it/s, training_loss=0.297]\u001b[A\n",
      "Epoch 2:  96%|████████████████████████████████████████████████████████████████████▊   | 213/223 [01:45<00:04,  2.02it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  96%|█████████████████████████████████████████████████████████████████████   | 214/223 [01:45<00:04,  2.03it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 2:  96%|█████████████████████████████████████████████████████████████████████   | 214/223 [01:45<00:04,  2.03it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  96%|█████████████████████████████████████████████████████████████████████▍  | 215/223 [01:45<00:03,  2.02it/s, training_loss=0.092]\u001b[A\n",
      "Epoch 2:  96%|█████████████████████████████████████████████████████████████████████▍  | 215/223 [01:46<00:03,  2.02it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  97%|█████████████████████████████████████████████████████████████████████▋  | 216/223 [01:46<00:03,  2.03it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 2:  97%|█████████████████████████████████████████████████████████████████████▋  | 216/223 [01:46<00:03,  2.03it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 2:  97%|██████████████████████████████████████████████████████████████████████  | 217/223 [01:46<00:02,  2.02it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 2:  97%|██████████████████████████████████████████████████████████████████████  | 217/223 [01:47<00:02,  2.02it/s, training_loss=0.166]\u001b[A\n",
      "Epoch 2:  98%|██████████████████████████████████████████████████████████████████████▍ | 218/223 [01:47<00:02,  2.04it/s, training_loss=0.166]\u001b[A\n",
      "Epoch 2:  98%|██████████████████████████████████████████████████████████████████████▍ | 218/223 [01:47<00:02,  2.04it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  98%|██████████████████████████████████████████████████████████████████████▋ | 219/223 [01:47<00:01,  2.03it/s, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  98%|██████████████████████████████████████████████████████████████████████▋ | 219/223 [01:48<00:01,  2.03it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 2:  99%|███████████████████████████████████████████████████████████████████████ | 220/223 [01:48<00:01,  2.02it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 2:  99%|███████████████████████████████████████████████████████████████████████ | 220/223 [01:48<00:01,  2.02it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 2:  99%|███████████████████████████████████████████████████████████████████████▎| 221/223 [01:48<00:00,  2.01it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 2:  99%|███████████████████████████████████████████████████████████████████████▎| 221/223 [01:49<00:00,  2.01it/s, training_loss=0.284]\u001b[A\n",
      "Epoch 2: 100%|███████████████████████████████████████████████████████████████████████▋| 222/223 [01:49<00:00,  2.03it/s, training_loss=0.284]\u001b[A\n",
      "Epoch 2: 100%|███████████████████████████████████████████████████████████████████████▋| 222/223 [01:49<00:00,  2.03it/s, training_loss=0.030]\u001b[A\n",
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████████████| 223/223 [01:49<00:00,  2.55it/s, training_loss=0.030]\u001b[A\n",
      "Epoch Progress:   5%|████▎                                                                                 | 2/40 [03:38<1:09:10, 109.21s/it]\u001b[A\n",
      "Epoch 3:   0%|                                                                                                       | 0/223 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|                                                                                  | 0/223 [00:00<?, ?it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:   0%|▎                                                                         | 1/223 [00:00<01:50,  2.00it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:   0%|▎                                                                         | 1/223 [00:00<01:50,  2.00it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 3:   1%|▋                                                                         | 2/223 [00:00<01:48,  2.04it/s, training_loss=0.273]\u001b[A\n",
      "Epoch 3:   1%|▋                                                                         | 2/223 [00:01<01:48,  2.04it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 3:   1%|▉                                                                         | 3/223 [00:01<01:50,  1.99it/s, training_loss=0.227]\u001b[A\n",
      "Epoch 3:   1%|▉                                                                         | 3/223 [00:01<01:50,  1.99it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 3:   2%|█▎                                                                        | 4/223 [00:01<01:49,  2.00it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 3:   2%|█▎                                                                        | 4/223 [00:02<01:49,  2.00it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:   2%|█▋                                                                        | 5/223 [00:02<01:47,  2.02it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:   2%|█▋                                                                        | 5/223 [00:02<01:47,  2.02it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:   3%|█▉                                                                        | 6/223 [00:02<01:46,  2.04it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:   3%|█▉                                                                        | 6/223 [00:03<01:46,  2.04it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 3:   3%|██▎                                                                       | 7/223 [00:03<01:46,  2.02it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 3:   3%|██▎                                                                       | 7/223 [00:03<01:46,  2.02it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 3:   4%|██▋                                                                       | 8/223 [00:03<01:46,  2.02it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 3:   4%|██▋                                                                       | 8/223 [00:04<01:46,  2.02it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 3:   4%|██▉                                                                       | 9/223 [00:04<01:45,  2.03it/s, training_loss=0.071]\u001b[A\n",
      "Epoch 3:   4%|██▉                                                                       | 9/223 [00:04<01:45,  2.03it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 3:   4%|███▎                                                                     | 10/223 [00:04<01:45,  2.02it/s, training_loss=0.141]\u001b[A\n",
      "Epoch 3:   4%|███▎                                                                     | 10/223 [00:05<01:45,  2.02it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 3:   5%|███▌                                                                     | 11/223 [00:05<01:44,  2.03it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 3:   5%|███▌                                                                     | 11/223 [00:05<01:44,  2.03it/s, training_loss=0.143]\u001b[A\n",
      "Epoch 3:   5%|███▉                                                                     | 12/223 [00:05<01:44,  2.02it/s, training_loss=0.143]\u001b[A\n",
      "Epoch 3:   5%|███▉                                                                     | 12/223 [00:06<01:44,  2.02it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:   6%|████▎                                                                    | 13/223 [00:06<01:43,  2.04it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:   6%|████▎                                                                    | 13/223 [00:06<01:43,  2.04it/s, training_loss=0.236]\u001b[A\n",
      "Epoch 3:   6%|████▌                                                                    | 14/223 [00:06<01:42,  2.04it/s, training_loss=0.236]\u001b[A\n",
      "Epoch 3:   6%|████▌                                                                    | 14/223 [00:07<01:42,  2.04it/s, training_loss=0.089]\u001b[A\n",
      "Epoch 3:   7%|████▉                                                                    | 15/223 [00:07<01:41,  2.05it/s, training_loss=0.089]\u001b[A\n",
      "Epoch 3:   7%|████▉                                                                    | 15/223 [00:07<01:41,  2.05it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 3:   7%|█████▏                                                                   | 16/223 [00:07<01:40,  2.06it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 3:   7%|█████▏                                                                   | 16/223 [00:08<01:40,  2.06it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:   8%|█████▌                                                                   | 17/223 [00:08<01:41,  2.04it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:   8%|█████▌                                                                   | 17/223 [00:08<01:41,  2.04it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:   8%|█████▉                                                                   | 18/223 [00:08<01:40,  2.05it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:   8%|█████▉                                                                   | 18/223 [00:09<01:40,  2.05it/s, training_loss=0.085]\u001b[A\n",
      "Epoch 3:   9%|██████▏                                                                  | 19/223 [00:09<01:40,  2.03it/s, training_loss=0.085]\u001b[A\n",
      "Epoch 3:   9%|██████▏                                                                  | 19/223 [00:09<01:40,  2.03it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 3:   9%|██████▌                                                                  | 20/223 [00:09<01:39,  2.04it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 3:   9%|██████▌                                                                  | 20/223 [00:10<01:39,  2.04it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 3:   9%|██████▊                                                                  | 21/223 [00:10<01:38,  2.05it/s, training_loss=0.153]\u001b[A\n",
      "Epoch 3:   9%|██████▊                                                                  | 21/223 [00:10<01:38,  2.05it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 3:  10%|███████▏                                                                 | 22/223 [00:10<01:38,  2.03it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 3:  10%|███████▏                                                                 | 22/223 [00:11<01:38,  2.03it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 3:  10%|███████▌                                                                 | 23/223 [00:11<01:37,  2.04it/s, training_loss=0.210]\u001b[A\n",
      "Epoch 3:  10%|███████▌                                                                 | 23/223 [00:11<01:37,  2.04it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 3:  11%|███████▊                                                                 | 24/223 [00:11<01:38,  2.03it/s, training_loss=0.180]\u001b[A\n",
      "Epoch 3:  11%|███████▊                                                                 | 24/223 [00:12<01:38,  2.03it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 3:  11%|████████▏                                                                | 25/223 [00:12<01:37,  2.04it/s, training_loss=0.103]\u001b[A\n",
      "Epoch 3:  11%|████████▏                                                                | 25/223 [00:12<01:37,  2.04it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 3:  12%|████████▌                                                                | 26/223 [00:12<01:37,  2.03it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 3:  12%|████████▌                                                                | 26/223 [00:13<01:37,  2.03it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 3:  12%|████████▊                                                                | 27/223 [00:13<01:36,  2.04it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 3:  12%|████████▊                                                                | 27/223 [00:13<01:36,  2.04it/s, training_loss=0.251]\u001b[A\n",
      "Epoch 3:  13%|█████████▏                                                               | 28/223 [00:13<01:36,  2.03it/s, training_loss=0.251]\u001b[A\n",
      "Epoch 3:  13%|█████████▏                                                               | 28/223 [00:14<01:36,  2.03it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 3:  13%|█████████▍                                                               | 29/223 [00:14<01:36,  2.02it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 3:  13%|█████████▍                                                               | 29/223 [00:14<01:36,  2.02it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 3:  13%|█████████▊                                                               | 30/223 [00:14<01:34,  2.03it/s, training_loss=0.130]\u001b[A\n",
      "Epoch 3:  13%|█████████▊                                                               | 30/223 [00:15<01:34,  2.03it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 3:  14%|██████████▏                                                              | 31/223 [00:15<01:34,  2.02it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 3:  14%|██████████▏                                                              | 31/223 [00:15<01:34,  2.02it/s, training_loss=0.089]\u001b[A\n",
      "Epoch 3:  14%|██████████▍                                                              | 32/223 [00:15<01:33,  2.04it/s, training_loss=0.089]\u001b[A\n",
      "Epoch 3:  14%|██████████▍                                                              | 32/223 [00:16<01:33,  2.04it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 3:  15%|██████████▊                                                              | 33/223 [00:16<01:34,  2.01it/s, training_loss=0.172]\u001b[A\n",
      "Epoch 3:  15%|██████████▊                                                              | 33/223 [00:16<01:34,  2.01it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  15%|███████████▏                                                             | 34/223 [00:16<01:33,  2.02it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  15%|███████████▏                                                             | 34/223 [00:17<01:33,  2.02it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  16%|███████████▍                                                             | 35/223 [00:17<01:32,  2.04it/s, training_loss=0.076]\u001b[A\n",
      "Epoch 3:  16%|███████████▍                                                             | 35/223 [00:17<01:32,  2.04it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 3:  16%|███████████▊                                                             | 36/223 [00:17<01:31,  2.04it/s, training_loss=0.125]\u001b[A\n",
      "Epoch 3:  16%|███████████▊                                                             | 36/223 [00:18<01:31,  2.04it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  17%|████████████                                                             | 37/223 [00:18<01:28,  2.09it/s, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  17%|████████████                                                             | 37/223 [00:18<01:28,  2.09it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 3:  17%|████████████▍                                                            | 38/223 [00:18<01:29,  2.06it/s, training_loss=0.184]\u001b[A\n",
      "Epoch 3:  17%|████████████▍                                                            | 38/223 [00:19<01:29,  2.06it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  17%|████████████▊                                                            | 39/223 [00:19<01:29,  2.06it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  17%|████████████▊                                                            | 39/223 [00:19<01:29,  2.06it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 3:  18%|█████████████                                                            | 40/223 [00:19<01:28,  2.06it/s, training_loss=0.069]\u001b[A\n",
      "Epoch 3:  18%|█████████████                                                            | 40/223 [00:20<01:28,  2.06it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 3:  18%|█████████████▍                                                           | 41/223 [00:20<01:27,  2.08it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 3:  18%|█████████████▍                                                           | 41/223 [00:20<01:27,  2.08it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 3:  19%|█████████████▋                                                           | 42/223 [00:20<01:29,  2.02it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 3:  19%|█████████████▋                                                           | 42/223 [00:21<01:29,  2.02it/s, training_loss=0.404]\u001b[A\n",
      "Epoch 3:  19%|██████████████                                                           | 43/223 [00:21<01:28,  2.03it/s, training_loss=0.404]\u001b[A\n",
      "Epoch 3:  19%|██████████████                                                           | 43/223 [00:21<01:28,  2.03it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 3:  20%|██████████████▍                                                          | 44/223 [00:21<01:28,  2.02it/s, training_loss=0.073]\u001b[A\n",
      "Epoch 3:  20%|██████████████▍                                                          | 44/223 [00:22<01:28,  2.02it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 3:  20%|██████████████▋                                                          | 45/223 [00:22<01:27,  2.04it/s, training_loss=0.133]\u001b[A\n",
      "Epoch 3:  20%|██████████████▋                                                          | 45/223 [00:22<01:27,  2.04it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 3:  21%|███████████████                                                          | 46/223 [00:22<01:27,  2.02it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 3:  21%|███████████████                                                          | 46/223 [00:23<01:27,  2.02it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 3:  21%|███████████████▍                                                         | 47/223 [00:23<01:26,  2.04it/s, training_loss=0.114]\u001b[A\n",
      "Epoch 3:  21%|███████████████▍                                                         | 47/223 [00:23<01:26,  2.04it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 3:  22%|███████████████▋                                                         | 48/223 [00:23<01:25,  2.05it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 3:  22%|███████████████▋                                                         | 48/223 [00:24<01:25,  2.05it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:  22%|████████████████                                                         | 49/223 [00:24<01:25,  2.03it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:  22%|████████████████                                                         | 49/223 [00:24<01:25,  2.03it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  22%|████████████████▎                                                        | 50/223 [00:24<01:24,  2.04it/s, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  22%|████████████████▎                                                        | 50/223 [00:25<01:24,  2.04it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  23%|████████████████▋                                                        | 51/223 [00:25<01:25,  2.01it/s, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  23%|████████████████▋                                                        | 51/223 [00:25<01:25,  2.01it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 3:  23%|█████████████████                                                        | 52/223 [00:25<01:24,  2.03it/s, training_loss=0.163]\u001b[A\n",
      "Epoch 3:  23%|█████████████████                                                        | 52/223 [00:26<01:24,  2.03it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 3:  24%|█████████████████▎                                                       | 53/223 [00:26<01:24,  2.02it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 3:  24%|█████████████████▎                                                       | 53/223 [00:26<01:24,  2.02it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 3:  24%|█████████████████▋                                                       | 54/223 [00:26<01:23,  2.03it/s, training_loss=0.053]\u001b[A\n",
      "Epoch 3:  24%|█████████████████▋                                                       | 54/223 [00:27<01:23,  2.03it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 3:  25%|██████████████████                                                       | 55/223 [00:27<01:23,  2.00it/s, training_loss=0.246]\u001b[A\n",
      "Epoch 3:  25%|██████████████████                                                       | 55/223 [00:27<01:23,  2.00it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  25%|██████████████████▎                                                      | 56/223 [00:27<01:23,  2.00it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  25%|██████████████████▎                                                      | 56/223 [00:28<01:23,  2.00it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 3:  26%|██████████████████▋                                                      | 57/223 [00:28<01:21,  2.04it/s, training_loss=0.197]\u001b[A\n",
      "Epoch 3:  26%|██████████████████▋                                                      | 57/223 [00:28<01:21,  2.04it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 3:  26%|██████████████████▉                                                      | 58/223 [00:28<01:21,  2.03it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 3:  26%|██████████████████▉                                                      | 58/223 [00:29<01:21,  2.03it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  26%|███████████████████▎                                                     | 59/223 [00:29<01:20,  2.04it/s, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  26%|███████████████████▎                                                     | 59/223 [00:29<01:20,  2.04it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 3:  27%|███████████████████▋                                                     | 60/223 [00:29<01:20,  2.03it/s, training_loss=0.117]\u001b[A\n",
      "Epoch 3:  27%|███████████████████▋                                                     | 60/223 [00:29<01:20,  2.03it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 3:  27%|███████████████████▉                                                     | 61/223 [00:29<01:19,  2.04it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 3:  27%|███████████████████▉                                                     | 61/223 [00:30<01:19,  2.04it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 3:  28%|████████████████████▎                                                    | 62/223 [00:30<01:19,  2.03it/s, training_loss=0.219]\u001b[A\n",
      "Epoch 3:  28%|████████████████████▎                                                    | 62/223 [00:30<01:19,  2.03it/s, training_loss=0.368]\u001b[A\n",
      "Epoch 3:  28%|████████████████████▌                                                    | 63/223 [00:30<01:18,  2.04it/s, training_loss=0.368]\u001b[A\n",
      "Epoch 3:  28%|████████████████████▌                                                    | 63/223 [00:31<01:18,  2.04it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 3:  29%|████████████████████▉                                                    | 64/223 [00:31<01:18,  2.03it/s, training_loss=0.138]\u001b[A\n",
      "Epoch 3:  29%|████████████████████▉                                                    | 64/223 [00:31<01:18,  2.03it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  29%|█████████████████████▎                                                   | 65/223 [00:31<01:18,  2.02it/s, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  29%|█████████████████████▎                                                   | 65/223 [00:32<01:18,  2.02it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 3:  30%|█████████████████████▌                                                   | 66/223 [00:32<01:16,  2.05it/s, training_loss=0.193]\u001b[A\n",
      "Epoch 3:  30%|█████████████████████▌                                                   | 66/223 [00:32<01:16,  2.05it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 3:  30%|█████████████████████▉                                                   | 67/223 [00:32<01:15,  2.06it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 3:  30%|█████████████████████▉                                                   | 67/223 [00:33<01:15,  2.06it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 3:  30%|██████████████████████▎                                                  | 68/223 [00:33<01:16,  2.04it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 3:  30%|██████████████████████▎                                                  | 68/223 [00:33<01:16,  2.04it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 3:  31%|██████████████████████▌                                                  | 69/223 [00:33<01:15,  2.05it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 3:  31%|██████████████████████▌                                                  | 69/223 [00:34<01:15,  2.05it/s, training_loss=0.346]\u001b[A\n",
      "Epoch 3:  31%|██████████████████████▉                                                  | 70/223 [00:34<01:14,  2.05it/s, training_loss=0.346]\u001b[A\n",
      "Epoch 3:  31%|██████████████████████▉                                                  | 70/223 [00:34<01:14,  2.05it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:  32%|███████████████████████▏                                                 | 71/223 [00:34<01:14,  2.04it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:  32%|███████████████████████▏                                                 | 71/223 [00:35<01:14,  2.04it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  32%|███████████████████████▌                                                 | 72/223 [00:35<01:13,  2.06it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  32%|███████████████████████▌                                                 | 72/223 [00:35<01:13,  2.06it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 3:  33%|███████████████████████▉                                                 | 73/223 [00:35<01:14,  2.03it/s, training_loss=0.203]\u001b[A\n",
      "Epoch 3:  33%|███████████████████████▉                                                 | 73/223 [00:36<01:14,  2.03it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  33%|████████████████████████▏                                                | 74/223 [00:36<01:12,  2.06it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  33%|████████████████████████▏                                                | 74/223 [00:36<01:12,  2.06it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 3:  34%|████████████████████████▌                                                | 75/223 [00:36<01:13,  2.02it/s, training_loss=0.198]\u001b[A\n",
      "Epoch 3:  34%|████████████████████████▌                                                | 75/223 [00:37<01:13,  2.02it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  34%|████████████████████████▉                                                | 76/223 [00:37<01:12,  2.03it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  34%|████████████████████████▉                                                | 76/223 [00:37<01:12,  2.03it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 3:  35%|█████████████████████████▏                                               | 77/223 [00:37<01:11,  2.04it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 3:  35%|█████████████████████████▏                                               | 77/223 [00:38<01:11,  2.04it/s, training_loss=0.262]\u001b[A\n",
      "Epoch 3:  35%|█████████████████████████▌                                               | 78/223 [00:38<01:10,  2.05it/s, training_loss=0.262]\u001b[A\n",
      "Epoch 3:  35%|█████████████████████████▌                                               | 78/223 [00:38<01:10,  2.05it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 3:  35%|█████████████████████████▊                                               | 79/223 [00:38<01:10,  2.05it/s, training_loss=0.042]\u001b[A\n",
      "Epoch 3:  35%|█████████████████████████▊                                               | 79/223 [00:39<01:10,  2.05it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 3:  36%|██████████████████████████▏                                              | 80/223 [00:39<01:10,  2.04it/s, training_loss=0.296]\u001b[A\n",
      "Epoch 3:  36%|██████████████████████████▏                                              | 80/223 [00:39<01:10,  2.04it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  36%|██████████████████████████▌                                              | 81/223 [00:39<01:10,  2.03it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  36%|██████████████████████████▌                                              | 81/223 [00:40<01:10,  2.03it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 3:  37%|██████████████████████████▊                                              | 82/223 [00:40<01:09,  2.02it/s, training_loss=0.225]\u001b[A\n",
      "Epoch 3:  37%|██████████████████████████▊                                              | 82/223 [00:40<01:09,  2.02it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 3:  37%|███████████████████████████▏                                             | 83/223 [00:40<01:08,  2.03it/s, training_loss=0.155]\u001b[A\n",
      "Epoch 3:  37%|███████████████████████████▏                                             | 83/223 [00:41<01:08,  2.03it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  38%|███████████████████████████▍                                             | 84/223 [00:41<01:08,  2.04it/s, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  38%|███████████████████████████▍                                             | 84/223 [00:41<01:08,  2.04it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  38%|███████████████████████████▊                                             | 85/223 [00:41<01:08,  2.03it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  38%|███████████████████████████▊                                             | 85/223 [00:42<01:08,  2.03it/s, training_loss=0.235]\u001b[A\n",
      "Epoch 3:  39%|████████████████████████████▏                                            | 86/223 [00:42<01:07,  2.04it/s, training_loss=0.235]\u001b[A\n",
      "Epoch 3:  39%|████████████████████████████▏                                            | 86/223 [00:42<01:07,  2.04it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 3:  39%|████████████████████████████▍                                            | 87/223 [00:42<01:07,  2.03it/s, training_loss=0.173]\u001b[A\n",
      "Epoch 3:  39%|████████████████████████████▍                                            | 87/223 [00:43<01:07,  2.03it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  39%|████████████████████████████▊                                            | 88/223 [00:43<01:06,  2.02it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  39%|████████████████████████████▊                                            | 88/223 [00:43<01:06,  2.02it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  40%|█████████████████████████████▏                                           | 89/223 [00:43<01:05,  2.03it/s, training_loss=0.077]\u001b[A\n",
      "Epoch 3:  40%|█████████████████████████████▏                                           | 89/223 [00:44<01:05,  2.03it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  40%|█████████████████████████████▍                                           | 90/223 [00:44<01:05,  2.04it/s, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  40%|█████████████████████████████▍                                           | 90/223 [00:44<01:05,  2.04it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 3:  41%|█████████████████████████████▊                                           | 91/223 [00:44<01:05,  2.03it/s, training_loss=0.319]\u001b[A\n",
      "Epoch 3:  41%|█████████████████████████████▊                                           | 91/223 [00:45<01:05,  2.03it/s, training_loss=0.257]\u001b[A\n",
      "Epoch 3:  41%|██████████████████████████████                                           | 92/223 [00:45<01:04,  2.02it/s, training_loss=0.257]\u001b[A\n",
      "Epoch 3:  41%|██████████████████████████████                                           | 92/223 [00:45<01:04,  2.02it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 3:  42%|██████████████████████████████▍                                          | 93/223 [00:45<01:03,  2.03it/s, training_loss=0.187]\u001b[A\n",
      "Epoch 3:  42%|██████████████████████████████▍                                          | 93/223 [00:46<01:03,  2.03it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 3:  42%|██████████████████████████████▊                                          | 94/223 [00:46<01:03,  2.02it/s, training_loss=0.122]\u001b[A\n",
      "Epoch 3:  42%|██████████████████████████████▊                                          | 94/223 [00:46<01:03,  2.02it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 3:  43%|███████████████████████████████                                          | 95/223 [00:46<01:02,  2.04it/s, training_loss=0.066]\u001b[A\n",
      "Epoch 3:  43%|███████████████████████████████                                          | 95/223 [00:47<01:02,  2.04it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 3:  43%|███████████████████████████████▍                                         | 96/223 [00:47<01:02,  2.03it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 3:  43%|███████████████████████████████▍                                         | 96/223 [00:47<01:02,  2.03it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 3:  43%|███████████████████████████████▊                                         | 97/223 [00:47<01:01,  2.04it/s, training_loss=0.084]\u001b[A\n",
      "Epoch 3:  43%|███████████████████████████████▊                                         | 97/223 [00:48<01:01,  2.04it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 3:  44%|████████████████████████████████                                         | 98/223 [00:48<01:01,  2.03it/s, training_loss=0.322]\u001b[A\n",
      "Epoch 3:  44%|████████████████████████████████                                         | 98/223 [00:48<01:01,  2.03it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  44%|████████████████████████████████▍                                        | 99/223 [00:48<01:00,  2.04it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  44%|████████████████████████████████▍                                        | 99/223 [00:49<01:00,  2.04it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 3:  45%|████████████████████████████████▎                                       | 100/223 [00:49<01:00,  2.03it/s, training_loss=0.116]\u001b[A\n",
      "Epoch 3:  45%|████████████████████████████████▎                                       | 100/223 [00:49<01:00,  2.03it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  45%|████████████████████████████████▌                                       | 101/223 [00:49<01:00,  2.02it/s, training_loss=0.126]\u001b[A\n",
      "Epoch 3:  45%|████████████████████████████████▌                                       | 101/223 [00:50<01:00,  2.02it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  46%|████████████████████████████████▉                                       | 102/223 [00:50<00:59,  2.03it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  46%|████████████████████████████████▉                                       | 102/223 [00:50<00:59,  2.03it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  46%|█████████████████████████████████▎                                      | 103/223 [00:50<00:58,  2.04it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  46%|█████████████████████████████████▎                                      | 103/223 [00:51<00:58,  2.04it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  47%|█████████████████████████████████▌                                      | 104/223 [00:51<00:59,  2.01it/s, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  47%|█████████████████████████████████▌                                      | 104/223 [00:51<00:59,  2.01it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  47%|█████████████████████████████████▉                                      | 105/223 [00:51<00:57,  2.05it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  47%|█████████████████████████████████▉                                      | 105/223 [00:52<00:57,  2.05it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  48%|██████████████████████████████████▏                                     | 106/223 [00:52<00:57,  2.03it/s, training_loss=0.059]\u001b[A\n",
      "Epoch 3:  48%|██████████████████████████████████▏                                     | 106/223 [00:52<00:57,  2.03it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  48%|██████████████████████████████████▌                                     | 107/223 [00:52<00:57,  2.02it/s, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  48%|██████████████████████████████████▌                                     | 107/223 [00:53<00:57,  2.02it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 3:  48%|██████████████████████████████████▊                                     | 108/223 [00:53<00:57,  2.02it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 3:  48%|██████████████████████████████████▊                                     | 108/223 [00:53<00:57,  2.02it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 3:  49%|███████████████████████████████████▏                                    | 109/223 [00:53<00:56,  2.03it/s, training_loss=0.189]\u001b[A\n",
      "Epoch 3:  49%|███████████████████████████████████▏                                    | 109/223 [00:54<00:56,  2.03it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 3:  49%|███████████████████████████████████▌                                    | 110/223 [00:54<00:55,  2.04it/s, training_loss=0.063]\u001b[A\n",
      "Epoch 3:  49%|███████████████████████████████████▌                                    | 110/223 [00:54<00:55,  2.04it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  50%|███████████████████████████████████▊                                    | 111/223 [00:54<00:55,  2.03it/s, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  50%|███████████████████████████████████▊                                    | 111/223 [00:55<00:55,  2.03it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  50%|████████████████████████████████████▏                                   | 112/223 [00:55<00:54,  2.04it/s, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  50%|████████████████████████████████████▏                                   | 112/223 [00:55<00:54,  2.04it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 3:  51%|████████████████████████████████████▍                                   | 113/223 [00:55<00:53,  2.05it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 3:  51%|████████████████████████████████████▍                                   | 113/223 [00:56<00:53,  2.05it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 3:  51%|████████████████████████████████████▊                                   | 114/223 [00:56<00:53,  2.03it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 3:  51%|████████████████████████████████████▊                                   | 114/223 [00:56<00:53,  2.03it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 3:  52%|█████████████████████████████████████▏                                  | 115/223 [00:56<00:53,  2.02it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 3:  52%|█████████████████████████████████████▏                                  | 115/223 [00:57<00:53,  2.02it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 3:  52%|█████████████████████████████████████▍                                  | 116/223 [00:57<00:52,  2.04it/s, training_loss=0.110]\u001b[A\n",
      "Epoch 3:  52%|█████████████████████████████████████▍                                  | 116/223 [00:57<00:52,  2.04it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 3:  52%|█████████████████████████████████████▊                                  | 117/223 [00:57<00:51,  2.04it/s, training_loss=0.160]\u001b[A\n",
      "Epoch 3:  52%|█████████████████████████████████████▊                                  | 117/223 [00:58<00:51,  2.04it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 3:  53%|██████████████████████████████████████                                  | 118/223 [00:58<00:51,  2.03it/s, training_loss=0.070]\u001b[A\n",
      "Epoch 3:  53%|██████████████████████████████████████                                  | 118/223 [00:58<00:51,  2.03it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 3:  53%|██████████████████████████████████████▍                                 | 119/223 [00:58<00:50,  2.04it/s, training_loss=0.309]\u001b[A\n",
      "Epoch 3:  53%|██████████████████████████████████████▍                                 | 119/223 [00:58<00:50,  2.04it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 3:  54%|██████████████████████████████████████▋                                 | 120/223 [00:58<00:50,  2.05it/s, training_loss=0.107]\u001b[A\n",
      "Epoch 3:  54%|██████████████████████████████████████▋                                 | 120/223 [00:59<00:50,  2.05it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  54%|███████████████████████████████████████                                 | 121/223 [00:59<00:50,  2.03it/s, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  54%|███████████████████████████████████████                                 | 121/223 [00:59<00:50,  2.03it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 3:  55%|███████████████████████████████████████▍                                | 122/223 [00:59<00:49,  2.02it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 3:  55%|███████████████████████████████████████▍                                | 122/223 [01:00<00:49,  2.02it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:  55%|███████████████████████████████████████▋                                | 123/223 [01:00<00:49,  2.04it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:  55%|███████████████████████████████████████▋                                | 123/223 [01:00<00:49,  2.04it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████████████████                                | 124/223 [01:00<00:48,  2.03it/s, training_loss=0.229]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████████████████                                | 124/223 [01:01<00:48,  2.03it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████████████████▎                               | 125/223 [01:01<00:48,  2.04it/s, training_loss=0.118]\u001b[A\n",
      "Epoch 3:  56%|████████████████████████████████████████▎                               | 125/223 [01:01<00:48,  2.04it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 3:  57%|████████████████████████████████████████▋                               | 126/223 [01:01<00:47,  2.03it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 3:  57%|████████████████████████████████████████▋                               | 126/223 [01:02<00:47,  2.03it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 3:  57%|█████████████████████████████████████████                               | 127/223 [01:02<00:47,  2.02it/s, training_loss=0.292]\u001b[A\n",
      "Epoch 3:  57%|█████████████████████████████████████████                               | 127/223 [01:02<00:47,  2.02it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 3:  57%|█████████████████████████████████████████▎                              | 128/223 [01:02<00:46,  2.03it/s, training_loss=0.099]\u001b[A\n",
      "Epoch 3:  57%|█████████████████████████████████████████▎                              | 128/223 [01:03<00:46,  2.03it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 3:  58%|█████████████████████████████████████████▋                              | 129/223 [01:03<00:46,  2.02it/s, training_loss=0.194]\u001b[A\n",
      "Epoch 3:  58%|█████████████████████████████████████████▋                              | 129/223 [01:03<00:46,  2.02it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 3:  58%|█████████████████████████████████████████▉                              | 130/223 [01:03<00:45,  2.05it/s, training_loss=0.240]\u001b[A\n",
      "Epoch 3:  58%|█████████████████████████████████████████▉                              | 130/223 [01:04<00:45,  2.05it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 3:  59%|██████████████████████████████████████████▎                             | 131/223 [01:04<00:44,  2.06it/s, training_loss=0.209]\u001b[A\n",
      "Epoch 3:  59%|██████████████████████████████████████████▎                             | 131/223 [01:04<00:44,  2.06it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 3:  59%|██████████████████████████████████████████▌                             | 132/223 [01:04<00:44,  2.04it/s, training_loss=0.211]\u001b[A\n",
      "Epoch 3:  59%|██████████████████████████████████████████▌                             | 132/223 [01:05<00:44,  2.04it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  60%|██████████████████████████████████████████▉                             | 133/223 [01:05<00:43,  2.05it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  60%|██████████████████████████████████████████▉                             | 133/223 [01:05<00:43,  2.05it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  60%|███████████████████████████████████████████▎                            | 134/223 [01:05<00:43,  2.05it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  60%|███████████████████████████████████████████▎                            | 134/223 [01:06<00:43,  2.05it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  61%|███████████████████████████████████████████▌                            | 135/223 [01:06<00:43,  2.04it/s, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  61%|███████████████████████████████████████████▌                            | 135/223 [01:06<00:43,  2.04it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  61%|███████████████████████████████████████████▉                            | 136/223 [01:06<00:42,  2.05it/s, training_loss=0.101]\u001b[A\n",
      "Epoch 3:  61%|███████████████████████████████████████████▉                            | 136/223 [01:07<00:42,  2.05it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  61%|████████████████████████████████████████████▏                           | 137/223 [01:07<00:42,  2.03it/s, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  61%|████████████████████████████████████████████▏                           | 137/223 [01:07<00:42,  2.03it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 3:  62%|████████████████████████████████████████████▌                           | 138/223 [01:07<00:42,  2.02it/s, training_loss=0.152]\u001b[A\n",
      "Epoch 3:  62%|████████████████████████████████████████████▌                           | 138/223 [01:08<00:42,  2.02it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  62%|████████████████████████████████████████████▉                           | 139/223 [01:08<00:41,  2.03it/s, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  62%|████████████████████████████████████████████▉                           | 139/223 [01:08<00:41,  2.03it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 3:  63%|█████████████████████████████████████████████▏                          | 140/223 [01:08<00:41,  2.02it/s, training_loss=0.238]\u001b[A\n",
      "Epoch 3:  63%|█████████████████████████████████████████████▏                          | 140/223 [01:09<00:41,  2.02it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 3:  63%|█████████████████████████████████████████████▌                          | 141/223 [01:09<00:40,  2.04it/s, training_loss=0.167]\u001b[A\n",
      "Epoch 3:  63%|█████████████████████████████████████████████▌                          | 141/223 [01:09<00:40,  2.04it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 3:  64%|█████████████████████████████████████████████▊                          | 142/223 [01:09<00:39,  2.04it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 3:  64%|█████████████████████████████████████████████▊                          | 142/223 [01:10<00:39,  2.04it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  64%|██████████████████████████████████████████████▏                         | 143/223 [01:10<00:38,  2.07it/s, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  64%|██████████████████████████████████████████████▏                         | 143/223 [01:10<00:38,  2.07it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 3:  65%|██████████████████████████████████████████████▍                         | 144/223 [01:10<00:38,  2.05it/s, training_loss=0.109]\u001b[A\n",
      "Epoch 3:  65%|██████████████████████████████████████████████▍                         | 144/223 [01:11<00:38,  2.05it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 3:  65%|██████████████████████████████████████████████▊                         | 145/223 [01:11<00:37,  2.05it/s, training_loss=0.135]\u001b[A\n",
      "Epoch 3:  65%|██████████████████████████████████████████████▊                         | 145/223 [01:11<00:37,  2.05it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 3:  65%|███████████████████████████████████████████████▏                        | 146/223 [01:11<00:37,  2.04it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 3:  65%|███████████████████████████████████████████████▏                        | 146/223 [01:12<00:37,  2.04it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  66%|███████████████████████████████████████████████▍                        | 147/223 [01:12<00:37,  2.05it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  66%|███████████████████████████████████████████████▍                        | 147/223 [01:12<00:37,  2.05it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 3:  66%|███████████████████████████████████████████████▊                        | 148/223 [01:12<00:36,  2.05it/s, training_loss=0.036]\u001b[A\n",
      "Epoch 3:  66%|███████████████████████████████████████████████▊                        | 148/223 [01:13<00:36,  2.05it/s, training_loss=0.186]\u001b[A\n",
      "Epoch 3:  67%|████████████████████████████████████████████████                        | 149/223 [01:13<00:36,  2.06it/s, training_loss=0.186]\u001b[A\n",
      "Epoch 3:  67%|████████████████████████████████████████████████                        | 149/223 [01:13<00:36,  2.06it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  67%|████████████████████████████████████████████████▍                       | 150/223 [01:13<00:35,  2.04it/s, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  67%|████████████████████████████████████████████████▍                       | 150/223 [01:14<00:35,  2.04it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  68%|████████████████████████████████████████████████▊                       | 151/223 [01:14<00:35,  2.05it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  68%|████████████████████████████████████████████████▊                       | 151/223 [01:14<00:35,  2.05it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 3:  68%|█████████████████████████████████████████████████                       | 152/223 [01:14<00:34,  2.03it/s, training_loss=0.087]\u001b[A\n",
      "Epoch 3:  68%|█████████████████████████████████████████████████                       | 152/223 [01:15<00:34,  2.03it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 3:  69%|█████████████████████████████████████████████████▍                      | 153/223 [01:15<00:33,  2.06it/s, training_loss=0.162]\u001b[A\n",
      "Epoch 3:  69%|█████████████████████████████████████████████████▍                      | 153/223 [01:15<00:33,  2.06it/s, training_loss=0.424]\u001b[A\n",
      "Epoch 3:  69%|█████████████████████████████████████████████████▋                      | 154/223 [01:15<00:33,  2.04it/s, training_loss=0.424]\u001b[A\n",
      "Epoch 3:  69%|█████████████████████████████████████████████████▋                      | 154/223 [01:16<00:33,  2.04it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  70%|██████████████████████████████████████████████████                      | 155/223 [01:16<00:33,  2.03it/s, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  70%|██████████████████████████████████████████████████                      | 155/223 [01:16<00:33,  2.03it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 3:  70%|██████████████████████████████████████████████████▎                     | 156/223 [01:16<00:32,  2.04it/s, training_loss=0.146]\u001b[A\n",
      "Epoch 3:  70%|██████████████████████████████████████████████████▎                     | 156/223 [01:17<00:32,  2.04it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 3:  70%|██████████████████████████████████████████████████▋                     | 157/223 [01:17<00:32,  2.03it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 3:  70%|██████████████████████████████████████████████████▋                     | 157/223 [01:17<00:32,  2.03it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 3:  71%|███████████████████████████████████████████████████                     | 158/223 [01:17<00:32,  2.02it/s, training_loss=0.094]\u001b[A\n",
      "Epoch 3:  71%|███████████████████████████████████████████████████                     | 158/223 [01:18<00:32,  2.02it/s, training_loss=0.226]\u001b[A\n",
      "Epoch 3:  71%|███████████████████████████████████████████████████▎                    | 159/223 [01:18<00:31,  2.01it/s, training_loss=0.226]\u001b[A\n",
      "Epoch 3:  71%|███████████████████████████████████████████████████▎                    | 159/223 [01:18<00:31,  2.01it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 3:  72%|███████████████████████████████████████████████████▋                    | 160/223 [01:18<00:31,  2.03it/s, training_loss=0.175]\u001b[A\n",
      "Epoch 3:  72%|███████████████████████████████████████████████████▋                    | 160/223 [01:19<00:31,  2.03it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  72%|███████████████████████████████████████████████████▉                    | 161/223 [01:19<00:30,  2.04it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  72%|███████████████████████████████████████████████████▉                    | 161/223 [01:19<00:30,  2.04it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  73%|████████████████████████████████████████████████████▎                   | 162/223 [01:19<00:30,  2.03it/s, training_loss=0.064]\u001b[A\n",
      "Epoch 3:  73%|████████████████████████████████████████████████████▎                   | 162/223 [01:20<00:30,  2.03it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 3:  73%|████████████████████████████████████████████████████▋                   | 163/223 [01:20<00:29,  2.02it/s, training_loss=0.149]\u001b[A\n",
      "Epoch 3:  73%|████████████████████████████████████████████████████▋                   | 163/223 [01:20<00:29,  2.02it/s, training_loss=0.230]\u001b[A\n",
      "Epoch 3:  74%|████████████████████████████████████████████████████▉                   | 164/223 [01:20<00:29,  2.03it/s, training_loss=0.230]\u001b[A\n",
      "Epoch 3:  74%|████████████████████████████████████████████████████▉                   | 164/223 [01:21<00:29,  2.03it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  74%|█████████████████████████████████████████████████████▎                  | 165/223 [01:21<00:28,  2.02it/s, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  74%|█████████████████████████████████████████████████████▎                  | 165/223 [01:21<00:28,  2.02it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 3:  74%|█████████████████████████████████████████████████████▌                  | 166/223 [01:21<00:28,  2.04it/s, training_loss=0.288]\u001b[A\n",
      "Epoch 3:  74%|█████████████████████████████████████████████████████▌                  | 166/223 [01:22<00:28,  2.04it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  75%|█████████████████████████████████████████████████████▉                  | 167/223 [01:22<00:27,  2.02it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  75%|█████████████████████████████████████████████████████▉                  | 167/223 [01:22<00:27,  2.02it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 3:  75%|██████████████████████████████████████████████████████▏                 | 168/223 [01:22<00:27,  2.04it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 3:  75%|██████████████████████████████████████████████████████▏                 | 168/223 [01:23<00:27,  2.04it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:  76%|██████████████████████████████████████████████████████▌                 | 169/223 [01:23<00:26,  2.05it/s, training_loss=0.097]\u001b[A\n",
      "Epoch 3:  76%|██████████████████████████████████████████████████████▌                 | 169/223 [01:23<00:26,  2.05it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 3:  76%|██████████████████████████████████████████████████████▉                 | 170/223 [01:23<00:26,  2.03it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 3:  76%|██████████████████████████████████████████████████████▉                 | 170/223 [01:24<00:26,  2.03it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 3:  77%|███████████████████████████████████████████████████████▏                | 171/223 [01:24<00:25,  2.04it/s, training_loss=0.157]\u001b[A\n",
      "Epoch 3:  77%|███████████████████████████████████████████████████████▏                | 171/223 [01:24<00:25,  2.04it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 3:  77%|███████████████████████████████████████████████████████▌                | 172/223 [01:24<00:24,  2.05it/s, training_loss=0.325]\u001b[A\n",
      "Epoch 3:  77%|███████████████████████████████████████████████████████▌                | 172/223 [01:25<00:24,  2.05it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 3:  78%|███████████████████████████████████████████████████████▊                | 173/223 [01:25<00:24,  2.03it/s, training_loss=0.106]\u001b[A\n",
      "Epoch 3:  78%|███████████████████████████████████████████████████████▊                | 173/223 [01:25<00:24,  2.03it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 3:  78%|████████████████████████████████████████████████████████▏               | 174/223 [01:25<00:23,  2.04it/s, training_loss=0.032]\u001b[A\n",
      "Epoch 3:  78%|████████████████████████████████████████████████████████▏               | 174/223 [01:25<00:23,  2.04it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  78%|████████████████████████████████████████████████████████▌               | 175/223 [01:25<00:23,  2.05it/s, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  78%|████████████████████████████████████████████████████████▌               | 175/223 [01:26<00:23,  2.05it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  79%|████████████████████████████████████████████████████████▊               | 176/223 [01:26<00:22,  2.05it/s, training_loss=0.206]\u001b[A\n",
      "Epoch 3:  79%|████████████████████████████████████████████████████████▊               | 176/223 [01:26<00:22,  2.05it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:  79%|█████████████████████████████████████████████████████████▏              | 177/223 [01:26<00:22,  2.02it/s, training_loss=0.129]\u001b[A\n",
      "Epoch 3:  79%|█████████████████████████████████████████████████████████▏              | 177/223 [01:27<00:22,  2.02it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  80%|█████████████████████████████████████████████████████████▍              | 178/223 [01:27<00:22,  2.01it/s, training_loss=0.020]\u001b[A\n",
      "Epoch 3:  80%|█████████████████████████████████████████████████████████▍              | 178/223 [01:27<00:22,  2.01it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  80%|█████████████████████████████████████████████████████████▊              | 179/223 [01:27<00:21,  2.03it/s, training_loss=0.038]\u001b[A\n",
      "Epoch 3:  80%|█████████████████████████████████████████████████████████▊              | 179/223 [01:28<00:21,  2.03it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  81%|██████████████████████████████████████████████████████████              | 180/223 [01:28<00:21,  2.02it/s, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  81%|██████████████████████████████████████████████████████████              | 180/223 [01:28<00:21,  2.02it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 3:  81%|██████████████████████████████████████████████████████████▍             | 181/223 [01:28<00:20,  2.05it/s, training_loss=0.108]\u001b[A\n",
      "Epoch 3:  81%|██████████████████████████████████████████████████████████▍             | 181/223 [01:29<00:20,  2.05it/s, training_loss=0.306]\u001b[A\n",
      "Epoch 3:  82%|██████████████████████████████████████████████████████████▊             | 182/223 [01:29<00:19,  2.06it/s, training_loss=0.306]\u001b[A\n",
      "Epoch 3:  82%|██████████████████████████████████████████████████████████▊             | 182/223 [01:29<00:19,  2.06it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 3:  82%|███████████████████████████████████████████████████████████             | 183/223 [01:29<00:19,  2.02it/s, training_loss=0.201]\u001b[A\n",
      "Epoch 3:  82%|███████████████████████████████████████████████████████████             | 183/223 [01:30<00:19,  2.02it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 3:  83%|███████████████████████████████████████████████████████████▍            | 184/223 [01:30<00:19,  2.01it/s, training_loss=0.222]\u001b[A\n",
      "Epoch 3:  83%|███████████████████████████████████████████████████████████▍            | 184/223 [01:30<00:19,  2.01it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  83%|███████████████████████████████████████████████████████████▋            | 185/223 [01:30<00:18,  2.03it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  83%|███████████████████████████████████████████████████████████▋            | 185/223 [01:31<00:18,  2.03it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  83%|████████████████████████████████████████████████████████████            | 186/223 [01:31<00:18,  2.02it/s, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  83%|████████████████████████████████████████████████████████████            | 186/223 [01:31<00:18,  2.02it/s, training_loss=0.226]\u001b[A\n",
      "Epoch 3:  84%|████████████████████████████████████████████████████████████▍           | 187/223 [01:31<00:17,  2.03it/s, training_loss=0.226]\u001b[A\n",
      "Epoch 3:  84%|████████████████████████████████████████████████████████████▍           | 187/223 [01:32<00:17,  2.03it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 3:  84%|████████████████████████████████████████████████████████████▋           | 188/223 [01:32<00:17,  2.02it/s, training_loss=0.220]\u001b[A\n",
      "Epoch 3:  84%|████████████████████████████████████████████████████████████▋           | 188/223 [01:32<00:17,  2.02it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 3:  85%|█████████████████████████████████████████████████████████████           | 189/223 [01:32<00:16,  2.04it/s, training_loss=0.123]\u001b[A\n",
      "Epoch 3:  85%|█████████████████████████████████████████████████████████████           | 189/223 [01:33<00:16,  2.04it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 3:  85%|█████████████████████████████████████████████████████████████▎          | 190/223 [01:33<00:16,  2.04it/s, training_loss=0.148]\u001b[A\n",
      "Epoch 3:  85%|█████████████████████████████████████████████████████████████▎          | 190/223 [01:33<00:16,  2.04it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  86%|█████████████████████████████████████████████████████████████▋          | 191/223 [01:33<00:15,  2.03it/s, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  86%|█████████████████████████████████████████████████████████████▋          | 191/223 [01:34<00:15,  2.03it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 3:  86%|█████████████████████████████████████████████████████████████▉          | 192/223 [01:34<00:15,  2.04it/s, training_loss=0.161]\u001b[A\n",
      "Epoch 3:  86%|█████████████████████████████████████████████████████████████▉          | 192/223 [01:34<00:15,  2.04it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  87%|██████████████████████████████████████████████████████████████▎         | 193/223 [01:34<00:14,  2.03it/s, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  87%|██████████████████████████████████████████████████████████████▎         | 193/223 [01:35<00:14,  2.03it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 3:  87%|██████████████████████████████████████████████████████████████▋         | 194/223 [01:35<00:14,  2.02it/s, training_loss=0.016]\u001b[A\n",
      "Epoch 3:  87%|██████████████████████████████████████████████████████████████▋         | 194/223 [01:35<00:14,  2.02it/s, training_loss=0.321]\u001b[A\n",
      "Epoch 3:  87%|██████████████████████████████████████████████████████████████▉         | 195/223 [01:35<00:13,  2.03it/s, training_loss=0.321]\u001b[A\n",
      "Epoch 3:  87%|██████████████████████████████████████████████████████████████▉         | 195/223 [01:36<00:13,  2.03it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  88%|███████████████████████████████████████████████████████████████▎        | 196/223 [01:36<00:13,  2.02it/s, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  88%|███████████████████████████████████████████████████████████████▎        | 196/223 [01:36<00:13,  2.02it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 3:  88%|███████████████████████████████████████████████████████████████▌        | 197/223 [01:36<00:12,  2.04it/s, training_loss=0.035]\u001b[A\n",
      "Epoch 3:  88%|███████████████████████████████████████████████████████████████▌        | 197/223 [01:37<00:12,  2.04it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 3:  89%|███████████████████████████████████████████████████████████████▉        | 198/223 [01:37<00:12,  2.03it/s, training_loss=0.074]\u001b[A\n",
      "Epoch 3:  89%|███████████████████████████████████████████████████████████████▉        | 198/223 [01:37<00:12,  2.03it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 3:  89%|████████████████████████████████████████████████████████████████▎       | 199/223 [01:37<00:11,  2.04it/s, training_loss=0.131]\u001b[A\n",
      "Epoch 3:  89%|████████████████████████████████████████████████████████████████▎       | 199/223 [01:38<00:11,  2.04it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 3:  90%|████████████████████████████████████████████████████████████████▌       | 200/223 [01:38<00:11,  2.03it/s, training_loss=0.158]\u001b[A\n",
      "Epoch 3:  90%|████████████████████████████████████████████████████████████████▌       | 200/223 [01:38<00:11,  2.03it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 3:  90%|████████████████████████████████████████████████████████████████▉       | 201/223 [01:38<00:10,  2.04it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 3:  90%|████████████████████████████████████████████████████████████████▉       | 201/223 [01:39<00:10,  2.04it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 3:  91%|█████████████████████████████████████████████████████████████████▏      | 202/223 [01:39<00:10,  2.03it/s, training_loss=0.078]\u001b[A\n",
      "Epoch 3:  91%|█████████████████████████████████████████████████████████████████▏      | 202/223 [01:39<00:10,  2.03it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 3:  91%|█████████████████████████████████████████████████████████████████▌      | 203/223 [01:39<00:09,  2.04it/s, training_loss=0.348]\u001b[A\n",
      "Epoch 3:  91%|█████████████████████████████████████████████████████████████████▌      | 203/223 [01:40<00:09,  2.04it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  91%|█████████████████████████████████████████████████████████████████▊      | 204/223 [01:40<00:09,  2.05it/s, training_loss=0.029]\u001b[A\n",
      "Epoch 3:  91%|█████████████████████████████████████████████████████████████████▊      | 204/223 [01:40<00:09,  2.05it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  92%|██████████████████████████████████████████████████████████████████▏     | 205/223 [01:40<00:08,  2.03it/s, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  92%|██████████████████████████████████████████████████████████████████▏     | 205/223 [01:41<00:08,  2.03it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 3:  92%|██████████████████████████████████████████████████████████████████▌     | 206/223 [01:41<00:08,  2.02it/s, training_loss=0.055]\u001b[A\n",
      "Epoch 3:  92%|██████████████████████████████████████████████████████████████████▌     | 206/223 [01:41<00:08,  2.02it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 3:  93%|██████████████████████████████████████████████████████████████████▊     | 207/223 [01:41<00:07,  2.04it/s, training_loss=0.154]\u001b[A\n",
      "Epoch 3:  93%|██████████████████████████████████████████████████████████████████▊     | 207/223 [01:42<00:07,  2.04it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 3:  93%|███████████████████████████████████████████████████████████████████▏    | 208/223 [01:42<00:07,  2.04it/s, training_loss=0.176]\u001b[A\n",
      "Epoch 3:  93%|███████████████████████████████████████████████████████████████████▏    | 208/223 [01:42<00:07,  2.04it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 3:  94%|███████████████████████████████████████████████████████████████████▍    | 209/223 [01:42<00:06,  2.03it/s, training_loss=0.104]\u001b[A\n",
      "Epoch 3:  94%|███████████████████████████████████████████████████████████████████▍    | 209/223 [01:43<00:06,  2.03it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 3:  94%|███████████████████████████████████████████████████████████████████▊    | 210/223 [01:43<00:06,  2.04it/s, training_loss=0.061]\u001b[A\n",
      "Epoch 3:  94%|███████████████████████████████████████████████████████████████████▊    | 210/223 [01:43<00:06,  2.04it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  95%|████████████████████████████████████████████████████████████████████▏   | 211/223 [01:43<00:05,  2.05it/s, training_loss=0.095]\u001b[A\n",
      "Epoch 3:  95%|████████████████████████████████████████████████████████████████████▏   | 211/223 [01:44<00:05,  2.05it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  95%|████████████████████████████████████████████████████████████████████▍   | 212/223 [01:44<00:05,  2.05it/s, training_loss=0.120]\u001b[A\n",
      "Epoch 3:  95%|████████████████████████████████████████████████████████████████████▍   | 212/223 [01:44<00:05,  2.05it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 3:  96%|████████████████████████████████████████████████████████████████████▊   | 213/223 [01:44<00:04,  2.04it/s, training_loss=0.091]\u001b[A\n",
      "Epoch 3:  96%|████████████████████████████████████████████████████████████████████▊   | 213/223 [01:45<00:04,  2.04it/s, training_loss=0.137]\u001b[A\n",
      "Epoch 3:  96%|█████████████████████████████████████████████████████████████████████   | 214/223 [01:45<00:04,  2.05it/s, training_loss=0.137]\u001b[A\n",
      "Epoch 3:  96%|█████████████████████████████████████████████████████████████████████   | 214/223 [01:45<00:04,  2.05it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 3:  96%|█████████████████████████████████████████████████████████████████████▍  | 215/223 [01:45<00:03,  2.03it/s, training_loss=0.178]\u001b[A\n",
      "Epoch 3:  96%|█████████████████████████████████████████████████████████████████████▍  | 215/223 [01:46<00:03,  2.03it/s, training_loss=0.027]\u001b[A\n",
      "Epoch 3:  97%|█████████████████████████████████████████████████████████████████████▋  | 216/223 [01:46<00:03,  2.02it/s, training_loss=0.027]\u001b[A"
     ]
    }
   ],
   "source": [
    " #install packages\n",
    "!pip install transformers\n",
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import logging\n",
    "import random\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "def custom_train_test_split(df, test_size=0.2, random_state=None):\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X = df[['ade', 'soc_code']]\n",
    "    y = df['label']\n",
    "    \n",
    "    # Identify classes and their counts\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    \n",
    "    # Identify small classes\n",
    "    small_classes = classes[counts < 5]\n",
    "    \n",
    "    # Initialize lists for train and test sets\n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    X_test_list = []\n",
    "    y_test_list = []\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # Handle small classes separately\n",
    "    for cls in small_classes:\n",
    "        cls_mask = (y == cls)\n",
    "        cls_X = X[cls_mask]\n",
    "        cls_y = y[cls_mask]\n",
    "        cls_idx = df.index[cls_mask].tolist()\n",
    "        \n",
    "        if len(cls_X) == 1:\n",
    "            # If only one instance, put it in test set\n",
    "            test_indices.append(cls_idx[0])\n",
    "        else:\n",
    "            # Randomly choose one instance for testing\n",
    "            test_idx = np.random.choice(len(cls_X))\n",
    "            test_indices.append(cls_idx[test_idx])\n",
    "            \n",
    "            # Remaining instances go to training\n",
    "            train_indices.extend(np.delete(cls_idx, test_idx))\n",
    "    \n",
    "    # Combine the small class data into test and train sets\n",
    "    test_indices = np.array(test_indices)\n",
    "    train_indices = np.array(train_indices)\n",
    "    \n",
    "    X_test = df.loc[test_indices]\n",
    "    y_test = X_test['label']\n",
    "    \n",
    "    X_train = df.loc[train_indices]\n",
    "    y_train = X_train['label']\n",
    "    \n",
    "    # Handle large classes with stratified split\n",
    "    large_class_mask = ~np.isin(y, small_classes)\n",
    "    X_large = X[large_class_mask]\n",
    "    y_large = y[large_class_mask]\n",
    "    \n",
    "    X_train_large, X_test_large, y_train_large, y_test_large = train_test_split(\n",
    "        X_large, y_large, test_size=test_size, random_state=random_state, stratify=y_large\n",
    "    )\n",
    "    \n",
    "    # Combine large class data with the small class data\n",
    "    X_train = pd.concat([X_train, X_train_large], axis=0)\n",
    "    y_train = pd.concat([y_train, y_train_large], axis=0)\n",
    "    \n",
    "    X_test = pd.concat([X_test, X_test_large], axis=0)\n",
    "    y_test = pd.concat([y_test, y_test_large], axis=0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#evaluation\n",
    "def accuracy_per_class(predictions, true_vals):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "\n",
    "    accuracy_dict = {}\n",
    "    count_dict = {}\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = pred_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        accuracy_dict[label] = np.sum(y_preds == y_true) / len(y_true) if len(y_true) > 0 else 0\n",
    "        count_dict[label] = len(y_true)\n",
    "\n",
    "    return accuracy_dict, count_dict\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "\n",
    "# Function to calculate precision, recall, and F1 for each label\n",
    "def calculate_metrics(predictions, true_vals):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score per label\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels_flat, pred_flat, average=None, labels=np.unique(labels_flat))\n",
    "    \n",
    "    return precision, recall, f1\n",
    "    \n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='combine_all_training_40ep_16bs_5e-5lr_log_fix.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class TQDMLoggingWrapper(tqdm):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.logger = logger\n",
    "\n",
    "    def display(self, msg=None, pos=None):\n",
    "        if msg is not None:\n",
    "            self.logger.info(msg)\n",
    "        super().display(msg, pos)\n",
    "\n",
    "    def update(self, n=1):\n",
    "        super().update(n)\n",
    "        desc = self.format_dict.get('desc', 'No description')\n",
    "        postfix = self.format_dict.get('postfix', '')\n",
    "        self.logger.info(f'{desc} - {postfix}')\n",
    "\n",
    "    def set_description(self, desc=None, refresh=True):\n",
    "        super().set_description(desc, refresh)\n",
    "        if desc:\n",
    "            self.logger.info(f'Set description: {desc}')\n",
    "\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "\n",
    "#Read data from git:\n",
    "#https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\n",
    "# URL of the CSV file\n",
    "cadec_csv_url = \"https://raw.githubusercontent.com/FANMISUA/TweetAENormalization/main/ADENormalization/Data/CADEC/3.csv\"\n",
    "# read data from smm4h\n",
    "smm4h_csv_url = \"https://raw.githubusercontent.com/FANMISUA/ADE_Norm/main/Data/smm4h_soc.tsv\"\n",
    "\n",
    "allSMM4H = [10037175, 10018065,10029205, 10017947, 10028395, 10022891, 10027433, 10040785, 10038738, 10022117, 10015919, 10038604, 10047065, \n",
    "            10021428,10041244, 10007541, 10038359, 10021881, 10013993, 10019805, 10042613, 10029104, 10077536, 10010331, 10014698]\n",
    "\n",
    "label_dict = {\n",
    "    10037175: 0,\n",
    "    10018065: 1,\n",
    "    10029205: 2,\n",
    "    10017947: 3,\n",
    "    10028395: 4,\n",
    "    10022891: 5,\n",
    "    10027433: 6,\n",
    "    10040785: 7,\n",
    "    10038738: 8,\n",
    "    10022117: 9,\n",
    "    10015919: 10,\n",
    "    10038604: 11,\n",
    "    10047065: 12,\n",
    "    10021428: 13,\n",
    "    10041244: 14,\n",
    "    10007541: 15,\n",
    "    10038359: 16,\n",
    "    10021881: 17,\n",
    "    10013993: 18,\n",
    "    10019805: 19,\n",
    "    10042613: 20,\n",
    "    10029104: 21,\n",
    "    10077536: 22,\n",
    "    10010331: 23,\n",
    "    10014698: 24\n",
    "}\n",
    "\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"ade\", \"soc_code\"]\n",
    "smm4h_all = pd.read_csv(smm4h_csv_url,names=column_names, sep = '\\t', header=None)\n",
    "print(\"smm4h data:\",smm4h_all.shape)\n",
    "\n",
    "smm4h_all['soc_code'] = pd.to_numeric(smm4h_all['soc_code'], errors='coerce').astype('Int64')\n",
    "smm4h_all = smm4h_all[smm4h_all['soc_code'] != 0]\n",
    "\n",
    "smm4h_unique = smm4h_all.drop_duplicates(subset='ade')\n",
    "\n",
    "print(\"smm4h data after filtering:\",smm4h_all.shape)\n",
    "smm4h_soc_code_counts = smm4h_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "print(\"SOC count in SMM4H: \",smm4h_soc_code_counts)\n",
    "# Filter DataFrame\n",
    "smm4h_filtered_data3 = smm4h_unique[smm4h_unique['soc_code'].isin(allSMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "allinSMM4H = smm4h_filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "column_names = [\"TT\", \"llt_code\", \"ade\", \"soc_code\"]\n",
    "cadec_all = pd.read_csv(cadec_csv_url,names=column_names, header=None)\n",
    "\n",
    "# Remove duplicate rows based on the 'ade' column\n",
    "cadec_unique = cadec_all.drop_duplicates(subset='ade')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "# print(\"clean cadec data:\",cadec_unique.shape)\n",
    "# Count occurrences of each 'soc_code'\n",
    "cadec_soc_code_counts = cadec_unique['soc_code'].value_counts()\n",
    "# Sort the counts from high to low and print the result\n",
    "print(\"SOC count in CADEC: \",cadec_soc_code_counts)\n",
    "\n",
    "\n",
    "# Filter DataFrame\n",
    "cadec_filtered_data3 = cadec_unique[cadec_unique['soc_code'].isin(allSMM4H)]\n",
    "# filtered_data6 = cadec_unique[cadec_unique['soc_code'].isin(top6SMM4H)]\n",
    "\n",
    "# Select only the Term and SOC columns\n",
    "CADECallinSMM4H = cadec_filtered_data3[['ade', 'soc_code']]\n",
    "# CADECtop6inSMM4H = filtered_data6[['ade', 'soc_code']]\n",
    "\n",
    "\n",
    "# For SMM4H data\n",
    "df1 = allinSMM4H.copy()\n",
    "df1.loc[:, 'label'] = df1['soc_code'].map(label_dict)\n",
    "\n",
    "# For CADEC data\n",
    "df2 = CADECallinSMM4H.copy()\n",
    "df2.loc[:, 'label'] = df2['soc_code'].map(label_dict)\n",
    "\n",
    "print(\"SMM4H :\",df1)\n",
    "print(\"CADEC :\",df2)\n",
    "\n",
    "\n",
    "# Define the random seeds and other parameters\n",
    "seed_values = list(range(2, 42, 2))\n",
    "batch_size = 16\n",
    "epochs = 40\n",
    "learningrate = 5e-5\n",
    "\n",
    "# Placeholder for accuracies\n",
    "all_accuracies = {label: [] for label in range(len(label_dict))}\n",
    "\n",
    "# Initialize dictionaries to hold metrics for each seed\n",
    "# seed_metrics = {seed_val: {'precision': [], 'recall': [], 'f1': []} for seed_val in seed_values}\n",
    "seed_metrics = {seed_val: {'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'confusion_matrix': []} for seed_val in seed_values}\n",
    "\n",
    "\n",
    "# Main loop over seed values\n",
    "for seed_val in seed_values:\n",
    "    # Set seeds\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    # Data preparation\n",
    "     # Perform train-test split on df1\n",
    "    X_train_idx1, X_val_idx1, y_train1, y_val1 = custom_train_test_split(df1, test_size=0.2, random_state=seed_val)\n",
    "\n",
    "    # Perform train-test split on df2\n",
    "    X_train_idx2, X_val_idx2, y_train2, y_val2 = custom_train_test_split(df2, test_size=0.2, random_state=seed_val)\n",
    "\n",
    "    #  set the 'data_type' column for df1 and df2\n",
    "    df1['data_type'] = 'not_set'\n",
    "    df2['data_type'] = 'not_set'\n",
    "\n",
    "    df1.loc[df1.index.isin(X_train_idx1.index), 'data_type'] = 'train'\n",
    "    df1.loc[df1.index.isin(X_val_idx1.index), 'data_type'] = 'val'\n",
    "\n",
    "    df2.loc[df2.index.isin(X_train_idx2.index), 'data_type'] = 'train'\n",
    "    df2.loc[df2.index.isin(X_val_idx2.index), 'data_type'] = 'val'\n",
    "\n",
    "\n",
    "    # If you want to combine df1 and df2 into a single dataframe:\n",
    "    df = pd.concat([df1, df2])\n",
    "    print(\"df: \",df)\n",
    "    logger.info(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "    print(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    encoded_data_train = tokenizer.batch_encode_plus(\n",
    "        df[df.data_type == 'train'].ade.values,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    encoded_data_val = tokenizer.batch_encode_plus(\n",
    "        df[df.data_type == 'val'].ade.values,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids_train = encoded_data_train['input_ids']\n",
    "    attention_masks_train = encoded_data_train['attention_mask']\n",
    "    labels_train = torch.tensor(df[df.data_type == 'train'].label.values)\n",
    "\n",
    "    input_ids_val = encoded_data_val['input_ids']\n",
    "    attention_masks_val = encoded_data_val['attention_mask']\n",
    "    labels_val = torch.tensor(df[df.data_type == 'val'].label.values)\n",
    "\n",
    "    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_dict), output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "    dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learningrate, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train) * epochs)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    logger.info(f\"Device used: {device}\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in TQDMLoggingWrapper(range(1, epochs+1), desc='Epoch Progress'):\n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "\n",
    "        progress_bar = TQDMLoggingWrapper(dataloader_train, desc=f'Epoch {epoch}', leave=False, disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            progress_bar.set_postfix({'training_loss': f'{loss.item()/len(batch):.3f}'})\n",
    "\n",
    "        # torch.save(model.state_dict(), f'./ADENorm_top3_epoch_{epoch}.model')\n",
    "\n",
    "        logger.info(f'\\nEpoch {epoch}')\n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        logger.info(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_vals.flatten(), np.argmax(predictions, axis=1).flatten(), average=None, labels=np.unique(true_vals.flatten()))\n",
    "\n",
    "    # Ensure that you use `true_vals` for the true labels\n",
    "    predicted_labels = np.argmax(predictions, axis=1).flatten()\n",
    "    true_labels = true_vals.flatten()\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    seed_metrics[seed_val]['accuracy'] = accuracy\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=np.unique(true_labels))\n",
    "    seed_metrics[seed_val]['confusion_matrix'] = conf_matrix\n",
    "    \n",
    "    for label in label_dict.values():\n",
    "        seed_metrics[seed_val]['precision'].append((label, precision[label]))\n",
    "        seed_metrics[seed_val]['recall'].append((label, recall[label]))\n",
    "        seed_metrics[seed_val]['f1'].append((label, f1[label]))\n",
    "\n",
    "# Write the precision, recall, F1 scores, and seed values to a file\n",
    "with open('combine_all_20times_results_with_seeds.txt', 'w') as f:\n",
    "    f.write('Seed\\tLabel\\tPrecision\\tRecall\\tF1\\tAccuracy\\n')\n",
    "    for seed_val in seed_values:\n",
    "        for label, precision_val in seed_metrics[seed_val]['precision']:\n",
    "            recall_val = next(val for lbl, val in seed_metrics[seed_val]['recall'] if lbl == label)\n",
    "            f1_val = next(val for lbl, val in seed_metrics[seed_val]['f1'] if lbl == label)\n",
    "            accuracy = seed_metrics[seed_val]['accuracy']\n",
    "            f.write(f'{seed_val}\\t{label}\\t{precision_val:.4f}\\t{recall_val:.4f}\\t{f1_val:.4f}\\t{accuracy:.4f}\\n')\n",
    "\n",
    "        # Save the confusion matrix\n",
    "        f.write(f'\\nConfusion Matrix for Seed {seed_val}:\\n')\n",
    "        f.write(np.array2string(seed_metrics[seed_val]['confusion_matrix'], separator=', '))\n",
    "        f.write('\\n')\n",
    "\n",
    "    \n",
    "# Initialize lists to hold precision, recall, and f1 values for each label\n",
    "precision_dict, recall_dict, f1_dict = {}, {}, {}\n",
    "\n",
    "# Collect metrics across seeds\n",
    "for seed in seed_metrics:\n",
    "    for label, value in seed_metrics[seed]['precision']:\n",
    "        precision_dict.setdefault(label, []).append(value)\n",
    "    for label, value in seed_metrics[seed]['recall']:\n",
    "        recall_dict.setdefault(label, []).append(value)\n",
    "    for label, value in seed_metrics[seed]['f1']:\n",
    "        f1_dict.setdefault(label, []).append(value)\n",
    "\n",
    "# Compute mean and std for precision, recall, and f1\n",
    "labels = sorted(precision_dict.keys())\n",
    "precision_mean = [np.mean(precision_dict[label]) for label in labels]\n",
    "precision_std = [np.std(precision_dict[label]) for label in labels]\n",
    "recall_mean = [np.mean(recall_dict[label]) for label in labels]\n",
    "recall_std = [np.std(recall_dict[label]) for label in labels]\n",
    "f1_mean = [np.mean(f1_dict[label]) for label in labels]\n",
    "f1_std = [np.std(f1_dict[label]) for label in labels]\n",
    "\n",
    "# Plotting\n",
    "x = np.arange(len(labels))  # label indices\n",
    "width = 0.25  # width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Bar plots with mean values\n",
    "bars_precision = ax.bar(x - width, precision_mean, width, label='Precision', color='b')\n",
    "bars_recall = ax.bar(x, recall_mean, width, label='Recall', color='g')\n",
    "bars_f1 = ax.bar(x + width, f1_mean, width, label='F1 Score', color='r')\n",
    "\n",
    "# # Annotate bars with mean and std values\n",
    "# Annotate bars with mean and std values, with smaller font size\n",
    "# for bars, means, stds in zip([bars_precision, bars_recall, bars_f1],\n",
    "#                              [precision_mean, recall_mean, f1_mean],\n",
    "#                              [precision_std, recall_std, f1_std]):\n",
    "#     for bar, mean, std in zip(bars, means, stds):\n",
    "#         height = bar.get_height()\n",
    "#         ax.text(bar.get_x() + bar.get_width() / 2.0, height,\n",
    "#                 f'{mean:.2f}\\n±{std:.2f}', ha='center', va='bottom', fontsize=8)  # Smaller font size\n",
    "\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('Label')\n",
    "ax.set_ylabel('Performance')\n",
    "ax.set_title('Mean and Standard Deviation of Precision, Recall, and F1 Score by Label')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "# Set y-axis limit to [0, 1]\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Move legend outside the plot\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust the plot to fit the legend\n",
    "plt.savefig('COMBINE_all_20times_results_plot_fix.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71935ae8-8a25-4e2f-83d6-0f57e1001a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
