{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a883a3f-b03d-4e22-996d-227f10df3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score as f1_score_func\n",
    "from tqdm import tqdm\n",
    "\n",
    "def custom_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    if test_size == 0:\n",
    "        return X, [], y, []\n",
    "    # Find classes with only one or two instances\n",
    "    small_classes = classes[counts < 5]\n",
    "\n",
    "    # Separate out the instances of small classes\n",
    "    large_class_mask = ~np.isin(y, small_classes)\n",
    "    X_large = X[large_class_mask]\n",
    "    y_large = y[large_class_mask]\n",
    "    X_small = X[~large_class_mask]\n",
    "    y_small = y[~large_class_mask]\n",
    "\n",
    "    # Perform stratified split on the larger classes dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_large, y_large, test_size=test_size, random_state=random_state, stratify=y_large\n",
    "    )\n",
    "\n",
    "    # Randomly assign instances of small classes to training or testing sets\n",
    "    for i in range(len(X_small)):\n",
    "        if np.random.rand() < test_size:\n",
    "            X_test = np.vstack([X_test, X_small[i]])\n",
    "            y_test = np.hstack([y_test, y_small[i]])\n",
    "        else:\n",
    "            X_train = np.vstack([X_train, X_small[i]])\n",
    "            y_train = np.hstack([y_train, y_small[i]])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#evaluation\n",
    "def accuracy_per_class(predictions, true_vals):\n",
    "    pred_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    labels_flat = true_vals.flatten()\n",
    "\n",
    "    accuracy_dict = {}\n",
    "    count_dict = {}\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = pred_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        accuracy_dict[label] = np.sum(y_preds == y_true) / len(y_true) if len(y_true) > 0 else 0\n",
    "        count_dict[label] = len(y_true)\n",
    "\n",
    "    return accuracy_dict, count_dict\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='Combined_top3_20times_training_log.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "class TQDMLoggingWrapper(tqdm):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.logger = logger\n",
    "\n",
    "    def display(self, msg=None, pos=None):\n",
    "        if msg is not None:\n",
    "            self.logger.info(msg)\n",
    "        super().display(msg, pos)\n",
    "\n",
    "    def update(self, n=1):\n",
    "        super().update(n)\n",
    "        desc = self.format_dict.get('desc', 'No description')\n",
    "        postfix = self.format_dict.get('postfix', '')\n",
    "        self.logger.info(f'{desc} - {postfix}')\n",
    "\n",
    "    def set_description(self, desc=None, refresh=True):\n",
    "        super().set_description(desc, refresh)\n",
    "        if desc:\n",
    "            self.logger.info(f'Set description: {desc}')\n",
    "\n",
    "\n",
    "# Define the random seeds and other parameters\n",
    "seed_values = list(range(2, 6, 2))\n",
    "batch_size = 8\n",
    "epochs = 5\n",
    "learningrate = 1e-5\n",
    "\n",
    "# Placeholder for accuracies\n",
    "all_accuracies = {label: [] for label in range(len(top3label_dict))}\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "# Main loop over seed values\n",
    "for seed_val in seed_values:\n",
    "    # Set seeds\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    # # Data preparation\n",
    "    # X_train, X_val, y_train, y_val = custom_train_test_split(df.index.values, df.label.values, test_size=0.2, random_state=seed_val)\n",
    "    # df['data_type'] = ['not_set'] * df.shape[0]\n",
    "    # df.loc[X_train, 'data_type'] = 'train'\n",
    "    # df.loc[X_val, 'data_type'] = 'val'\n",
    "    # # logger.info(df.groupby(['soc_code', 'label', 'data_type']).count())\n",
    "    \n",
    "    # Perform train-test split on df1\n",
    "    X_train_idx1, X_val_idx1, y_train1, y_val1 = custom_train_test_split(df1.index.values, df1.label.values, test_size=0.2, random_state=seed_val)\n",
    "    \n",
    "    # Perform train-test split on df2\n",
    "    X_train_idx2, X_val_idx2, y_train2, y_val2 = custom_train_test_split(df2.index.values, df2.label.values, test_size=0.2, random_state=seed_val)\n",
    "    \n",
    "    # Combine the training indices and labels from df1 and df2\n",
    "    X_train_combined = np.concatenate((X_train_idx1, X_train_idx2))\n",
    "    y_train_combined = np.concatenate((y_train1, y_train2))\n",
    "    \n",
    "    # Combine the validation indices and labels from df1 and df2\n",
    "    X_val_combined = np.concatenate((X_val_idx1, X_val_idx2))\n",
    "    y_val_combined = np.concatenate((y_val1, y_val2))\n",
    "    \n",
    "    # Optionally, you can set the 'data_type' column for df1 and df2\n",
    "    df1['data_type'] = 'not_set'\n",
    "    df2['data_type'] = 'not_set'\n",
    "    \n",
    "    df1.loc[X_train_idx1, 'data_type'] = 'train'\n",
    "    df1.loc[X_val_idx1, 'data_type'] = 'val'\n",
    "    \n",
    "    df2.loc[X_train_idx2, 'data_type'] = 'train'\n",
    "    df2.loc[X_val_idx2, 'data_type'] = 'val'\n",
    "    \n",
    "    # If you want to combine df1 and df2 into a single dataframe:\n",
    "    df = pd.concat([df1, df2])\n",
    "\n",
    "    # Print the DataFrame with the 'data_type' column\n",
    "    print(\"Combined DataFrame with 'data_type' column:\\n\", df)\n",
    "        \n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    encoded_data_train = tokenizer.batch_encode_plus(\n",
    "        df[df.data_type == 'train'].ade.values,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    encoded_data_val = tokenizer.batch_encode_plus(\n",
    "        df[df.data_type == 'val'].ade.values,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids_train = encoded_data_train['input_ids']\n",
    "    attention_masks_train = encoded_data_train['attention_mask']\n",
    "    labels_train = torch.tensor(df[df.data_type == 'train'].label.values)\n",
    "\n",
    "    input_ids_val = encoded_data_val['input_ids']\n",
    "    attention_masks_val = encoded_data_val['attention_mask']\n",
    "    labels_val = torch.tensor(df[df.data_type == 'val'].label.values)\n",
    "\n",
    "    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(top3label_dict), output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "    dataloader_validation = DataLoader(dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learningrate, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train) * epochs)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    logger.info(f\"Device used: {device}\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in TQDMLoggingWrapper(range(1, epochs+1), desc='Epoch Progress'):\n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "\n",
    "        progress_bar = TQDMLoggingWrapper(dataloader_train, desc=f'Epoch {epoch}', leave=False, disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            progress_bar.set_postfix({'training_loss': f'{loss.item()/len(batch):.3f}'})\n",
    "\n",
    "        # torch.save(model.state_dict(), f'./ADENorm_top3_epoch_{epoch}.model')\n",
    "\n",
    "        logger.info(f'\\nEpoch {epoch}')\n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        logger.info(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "        val_f1 = f1_score_func(true_vals, np.argmax(predictions, axis=1), average='weighted')\n",
    "        logger.info(f'Validation loss: {val_loss}')\n",
    "        logger.info(f'F1 Score (Weighted): {val_f1}')\n",
    "\n",
    "    _, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    accuracy_dict, count_dict = accuracy_per_class(predictions, true_vals)\n",
    "\n",
    "    for label, accuracy in accuracy_dict.items():\n",
    "        all_accuracies[label].append(accuracy)\n",
    "    logger.info(f'Seed {seed_val} - Accuracy: {accuracy_dict} - Count: {count_dict}')\n",
    "\n",
    "# Compute average and standard deviation of accuracy\n",
    "avg_accuracy = {label: np.mean(accs) for label, accs in all_accuracies.items()}\n",
    "std_accuracy = {label: np.std(accs) for label, accs in all_accuracies.items()}\n",
    "\n",
    "# Save accuracies to file\n",
    "with open('Combined_top3_20times_accuracies.txt', 'w') as f:\n",
    "    # Write header for the accuracies\n",
    "    f.write('Label\\tSeed\\tAccuracy\\n')\n",
    "    # Write individual accuracies\n",
    "    for label in all_accuracies:\n",
    "        accuracies = all_accuracies[label]\n",
    "        for i, acc in enumerate(accuracies):\n",
    "            f.write(f'{label}\\tSeed_{i+1}\\t{acc:.4f}\\n')\n",
    "    \n",
    "    # Write the average and standard deviation\n",
    "    f.write('\\nLabel\\tAverage Accuracy\\tStandard Deviation\\n')\n",
    "    for label in all_accuracies:\n",
    "        avg_acc = avg_accuracy.get(label, 'N/A')\n",
    "        std_acc = std_accuracy.get(label, 'N/A')\n",
    "        f.write(f'{label}\\t{avg_acc:.4f}\\t{std_acc:.4f}\\n')\n",
    "\n",
    "# Log the final results\n",
    "logger.info('All accuracies: {}'.format(all_accuracies))\n",
    "logger.info('Average Accuracy: {}'.format(avg_accuracy))\n",
    "logger.info('Standard Deviation of Accuracy: {}'.format(std_accuracy))\n",
    "\n",
    "print(\"Average Accuracy:\", avg_accuracy)\n",
    "print(\"Standard Deviation of Accuracy:\", std_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
